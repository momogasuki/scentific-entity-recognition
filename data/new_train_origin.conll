In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
approaches -X- _ O
to -X- _ O
finetuning -X- _ O
and -X- _ O
interpolation -X- _ O
that -X- _ O
are -X- _ O
novel -X- _ O
in -X- _ O
that -X- _ O
they -X- _ O
leverage -X- _ O
data -X- _ O
from -X- _ O
similar -X- _ O
users -X- _ O
to -X- _ O
boost -X- _ O
personalized -X- _ O
LM -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
users -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
available -X- _ O
tokens -X- _ O
and -X- _ O
propose -X- _ O
ways -X- _ O
to -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
find -X- _ O
similar -X- _ O
users -X- _ O
in -X- _ O
our -X- _ O
corpus -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
leverage -X- _ O
data -X- _ O
from -X- _ O
similar -X- _ O
users -X- _ O
to -X- _ O
build -X- _ O
a -X- _ O
personalized -X- _ O
LM -X- _ O
for -X- _ O
a -X- _ O
new -X- _ O
user -X- _ O
. -X- _ O
We -X- _ O
explore -X- _ O
the -X- _ O
trade -X- _ O
- -X- _ O
offs -X- _ O
between -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
available -X- _ O
data -X- _ O
from -X- _ O
existing -X- _ O
users -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
existing -X- _ O
users -X- _ O
and -X- _ O
new -X- _ O
users -X- _ O
, -X- _ O
and -X- _ O
how -X- _ O
our -X- _ O
similarity -X- _ O
metrics -X- _ O
and -X- _ O
methods -X- _ O
scale -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
show -X- _ O
an -X- _ O
analysis -X- _ O
to -X- _ O
explore -X- _ O
what -X- _ O
types -X- _ O
of -X- _ O
words -X- _ O
our -X- _ O
method -X- _ O
predicts -X- _ O
more -X- _ O
accurately -X- _ O
and -X- _ O
are -X- _ O
thus -X- _ O
more -X- _ O
important -X- _ O
to -X- _ O
consider -X- _ O
in -X- _ O
personalization -X- _ O
methods -X- _ O
. -X- _ O
Personalized -X- _ B-TaskName
Language -X- _ I-TaskName
Modeling -X- _ I-TaskName
. -X- _ O
King -X- _ O
and -X- _ O
Cook -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
examined -X- _ O
methods -X- _ O
for -X- _ O
creating -X- _ O
personalized -X- _ O
LMs -X- _ O
and -X- _ O
their -X- _ O
work -X- _ O
is -X- _ O
most -X- _ O
similar -X- _ O
to -X- _ O
ours -X- _ O
. -X- _ O
They -X- _ O
consider -X- _ O
interpolating -X- _ O
, -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
and -X- _ O
priming -X- _ O
LMs -X- _ O
as -X- _ O
methods -X- _ O
of -X- _ O
personalization -X- _ O
, -X- _ O
though -X- _ O
they -X- _ O
use -X- _ O
these -X- _ O
methods -X- _ O
with -X- _ O
a -X- _ O
large -X- _ O
generic -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
work -X- _ O
shows -X- _ O
that -X- _ O
performance -X- _ O
can -X- _ O
be -X- _ O
improved -X- _ O
by -X- _ O
leveraging -X- _ O
data -X- _ O
from -X- _ O
similar -X- _ O
users -X- _ O
. -X- _ O
They -X- _ O
also -X- _ O
analyzed -X- _ O
model -X- _ O
adaptation -X- _ O
for -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
users -X- _ O
with -X- _ O
similar -X- _ O
demographics -X- _ O
, -X- _ O
inspired -X- _ O
by -X- _ O
Lynn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
who -X- _ O
showed -X- _ O
that -X- _ O
these -X- _ O
demographic -X- _ O
factors -X- _ O
could -X- _ O
help -X- _ O
model -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
found -X- _ O
that -X- _ O
personalized -X- _ O
models -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
those -X- _ O
adapted -X- _ O
from -X- _ O
similar -X- _ O
demographics -X- _ O
. -X- _ O
Shao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
have -X- _ O
also -X- _ O
explored -X- _ O
models -X- _ O
for -X- _ O
personalization -X- _ O
but -X- _ O
focused -X- _ O
on -X- _ O
handling -X- _ O
OOV -X- _ O
tokens -X- _ O
. -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
framework -X- _ O
to -X- _ O
learn -X- _ O
user -X- _ O
embeddings -X- _ O
from -X- _ O
Reddit -X- _ O
posts -X- _ O
. -X- _ O
Their -X- _ O
user -X- _ O
embeddings -X- _ O
were -X- _ O
built -X- _ O
on -X- _ O
the -X- _ O
sentence -X- _ O
embeddings -X- _ O
generated -X- _ O
by -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
. -X- _ O
By -X- _ O
using -X- _ O
the -X- _ O
learned -X- _ O
user -X- _ O
embeddings -X- _ O
to -X- _ O
predict -X- _ O
gender -X- _ O
, -X- _ O
detect -X- _ O
depression -X- _ O
and -X- _ O
classify -X- _ O
MBTI -X- _ O
personality -X- _ O
, -X- _ O
they -X- _ O
concluded -X- _ O
that -X- _ O
their -X- _ O
embeddings -X- _ O
incorporate -X- _ O
intrinsic -X- _ O
attributes -X- _ O
of -X- _ O
users -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
user -X- _ O
embeddings -X- _ O
are -X- _ O
learned -X- _ O
in -X- _ O
a -X- _ O
different -X- _ O
approach -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
how -X- _ O
to -X- _ O
use -X- _ O
similarity -X- _ O
calculated -X- _ O
from -X- _ O
user -X- _ O
embeddings -X- _ O
to -X- _ O
build -X- _ O
better -X- _ O
LMs -X- _ O
. -X- _ O

We -X- _ O
study -X- _ O
personalization -X- _ O
in -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
, -X- _ O
a -X- _ O
core -X- _ O
task -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O
Direct -X- _ O
applications -X- _ O
of -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
LM -X- _ O
) -X- _ O
include -X- _ O
predictive -X- _ O
text -X- _ O
, -X- _ O
authorship -X- _ O
attribution -X- _ O
, -X- _ O
and -X- _ O
dialog -X- _ O
systems -X- _ O
used -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
style -X- _ O
of -X- _ O
an -X- _ O
individual -X- _ O
or -X- _ O
profession -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
therapist -X- _ O
, -X- _ O
counselor -X- _ O
) -X- _ O
. -X- _ O
LMs -X- _ O
are -X- _ O
increasingly -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
backbone -X- _ O
of -X- _ O
models -X- _ O
for -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
tasks -X- _ O
in -X- _ O
NLP -X- _ O
, -X- _ O
increasing -X- _ O
the -X- _ O
potential -X- _ O
impact -X- _ O
of -X- _ O
personalization -X- _ O
even -X- _ O
further -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Recent -X- _ O
work -X- _ O
has -X- _ O
suggested -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
several -X- _ O
benefits -X- _ O
to -X- _ O
personalized -X- _ O
models -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
over -X- _ O
one -X- _ O
- -X- _ O
size -X- _ O
- -X- _ O
fits -X- _ O
- -X- _ O
all -X- _ O
solutions -X- _ O
: -X- _ O
they -X- _ O
are -X- _ O
more -X- _ O
accurate -X- _ O
for -X- _ O
individual -X- _ O
users -X- _ O
; -X- _ O
they -X- _ O
help -X- _ O
us -X- _ O
understand -X- _ O
communities -X- _ O
better -X- _ O
; -X- _ O
and -X- _ O
they -X- _ O
focus -X- _ O
the -X- _ O
attention -X- _ O
of -X- _ O
our -X- _ O
evaluations -X- _ O
on -X- _ O
the -X- _ O
enduser -X- _ O
( -X- _ O
Flek -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Generation -X- _ B-TaskName
tasks -X- _ O
in -X- _ O
particular -X- _ O
benefit -X- _ O
from -X- _ O
a -X- _ O
personalized -X- _ O
approach -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
Dudy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
argue -X- _ O
that -X- _ O
user -X- _ O
intention -X- _ O
is -X- _ O
more -X- _ O
often -X- _ O
difficult -X- _ O
to -X- _ O
recover -X- _ O
from -X- _ O
the -X- _ O
context -X- _ O
alone -X- _ O
. -X- _ O

In -X- _ O
FSS -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
, -X- _ O
the -X- _ O
visual -X- _ O
features -X- _ O
output -X- _ O
from -X- _ O
convolutional -X- _ O
layers -X- _ O
are -X- _ O
passed -X- _ O
through -X- _ O
a -X- _ O
1layer -X- _ B-HyperparameterValue
Bi -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
LSTM -X- _ I-HyperparameterValue
with -X- _ O
256 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
per -X- _ O
direction -X- _ O
to -X- _ O
capture -X- _ O
temporal -X- _ O
information -X- _ O
. -X- _ O
To -X- _ O
generate -X- _ O
proposals -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
transform -X- _ O
the -X- _ O
feature -X- _ O
sequence -X- _ O
via -X- _ O
a -X- _ O
1D -X- _ O
- -X- _ O
CNN -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
architecture -X- _ O
: -X- _ O
conv -X- _ O
layer -X- _ O
( -X- _ O
512 -X- _ B-HyperparameterValue
output -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
, -X- _ O
kernel -X- _ B-HyperparameterName
width -X- _ I-HyperparameterName
8) -X- _ B-HyperparameterValue
, -X- _ O
max -X- _ O
pooling -X- _ O
( -X- _ O
kernel -X- _ B-HyperparameterName
width -X- _ I-HyperparameterName
8 -X- _ B-HyperparameterValue
, -X- _ O
stride -X- _ B-HyperparameterName
4 -X- _ B-HyperparameterValue
) -X- _ O
, -X- _ O
conv -X- _ O
layer -X- _ O
( -X- _ O
256 -X- _ B-HyperparameterValue
output -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
, -X- _ O
kernel -X- _ B-HyperparameterName
width -X- _ I-HyperparameterName
3 -X- _ B-HyperparameterValue
) -X- _ O
and -X- _ O
conv -X- _ O
layer -X- _ O
( -X- _ O
256 -X- _ B-HyperparameterValue
output -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
, -X- _ O
kernel -X- _ B-HyperparameterName
width -X- _ I-HyperparameterName
3 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
The -X- _ O
scale -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
anchors -X- _ I-HyperparameterName
is -X- _ O
chosen -X- _ O
from -X- _ O
the -X- _ O
range -X- _ O
: -X- _ O
{ -X- _ O
1 -X- _ B-HyperparameterValue
, -X- _ O
2 -X- _ B-HyperparameterValue
, -X- _ O
3 -X- _ B-HyperparameterValue
, -X- _ O
4 -X- _ B-HyperparameterValue
, -X- _ O
5 -X- _ B-HyperparameterValue
, -X- _ O
6 -X- _ B-HyperparameterValue
, -X- _ O
7 -X- _ B-HyperparameterValue
, -X- _ O
8 -X- _ B-HyperparameterValue
, -X- _ O
9 -X- _ B-HyperparameterValue
, -X- _ O
10 -X- _ B-HyperparameterValue
, -X- _ O
12 -X- _ B-HyperparameterValue
, -X- _ O
14 -X- _ B-HyperparameterValue
, -X- _ O
18 -X- _ B-HyperparameterValue
, -X- _ O
20 -X- _ B-HyperparameterValue
, -X- _ O
24 -X- _ B-HyperparameterValue
, -X- _ B-HyperparameterValue
32 -X- _ I-HyperparameterValue
, -X- _ O
40 -X- _ B-HyperparameterValue
, -X- _ O
60 -X- _ B-HyperparameterValue
, -X- _ O
75 -X- _ B-HyperparameterValue
} -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
typical -X- _ O
fingerspelling -X- _ O
lengths -X- _ O
in -X- _ O
the -X- _ O
two -X- _ O
datasets -X- _ O
. -X- _ O
The -X- _ O
positve -X- _ B-HyperparameterName
/ -X- _ I-HyperparameterName
negative -X- _ I-HyperparameterName
threshold -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
anchors -X- _ O
are -X- _ O
0.6/0.3 -X- _ B-HyperparameterValue
respectively -X- _ O
. -X- _ O
δ -X- _ B-HyperparameterName
IoU -X- _ I-HyperparameterName
/δ -X- _ B-HyperparameterName
IS -X- _ I-HyperparameterName
are -X- _ O
1.0/0.8 -X- _ B-HyperparameterValue
( -X- _ O
chosen -X- _ O
from -X- _ O
{ -X- _ O
0.4 -X- _ B-HyperparameterValue
, -X- _ O
0.6 -X- _ B-HyperparameterValue
, -X- _ O
0.8 -X- _ B-HyperparameterValue
, -X- _ O
1.0 -X- _ B-HyperparameterValue
} -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
FS -X- _ O
- -X- _ O
encoder -X- _ O
and -X- _ O
text -X- _ O
encoder -X- _ O
are -X- _ O
3 -X- _ B-HyperparameterValue
- -X- _ O
layer/1 -X- _ B-HyperparameterName
- -X- _ O
layer -X- _ B-HyperparameterName
BiLSTM -X- _ B-HyperparameterValue
with -X- _ O
256 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
respectively -X- _ O
. -X- _ O
The -X- _ O
margin -X- _ B-HyperparameterName
m -X- _ B-HyperparameterName
, -X- _ B-HyperparameterName
number -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
negative -X- _ I-HyperparameterName
samples -X- _ I-HyperparameterName
in -X- _ O
N -X- _ O
v -X- _ O
and -X- _ O
N -X- _ O
w -X- _ O
are -X- _ O
tuned -X- _ O
to -X- _ O
be -X- _ O
0.45 -X- _ B-HyperparameterValue
, -X- _ O
5 -X- _ B-HyperparameterValue
and -X- _ O
5 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
for -X- _ O
25 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ B-HyperparameterValue
Adam -X- _ I-HyperparameterValue
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
at -X- _ O
initial -X- _ B-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.001 -X- _ B-HyperparameterValue
and -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
halved -X- _ O
if -X- _ O
the -X- _ O
mean -X- _ B-MetricName
average -X- _ I-MetricName
precision -X- _ I-MetricName
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
does -X- _ O
not -X- _ O
improve -X- _ O
for -X- _ O
3 -X- _ B-HyperparameterValue
epochs -X- _ O
. -X- _ O
λ -X- _ B-HyperparameterName
det -X- _ I-HyperparameterName
in -X- _ O
equation -X- _ O
4 -X- _ O
is -X- _ O
0.1 -X- _ B-HyperparameterValue
( -X- _ O
chosen -X- _ O
from -X- _ O
{ -X- _ O
0.1 -X- _ B-HyperparameterValue
, -X- _ O
0.5 -X- _ B-HyperparameterValue
, -X- _ O
1.0 -X- _ B-HyperparameterValue
} -X- _ O
) -X- _ O
. -X- _ O
At -X- _ O
test -X- _ O
time -X- _ O
, -X- _ O
we -X- _ O
generate -X- _ O
M -X- _ B-HyperparameterName
= -X- _ O
50 -X- _ B-HyperparameterValue
proposals -X- _ O
after -X- _ O
NMS -X- _ O
with -X- _ O
IoU -X- _ B-HyperparameterName
threshold -X- _ I-HyperparameterName
of -X- _ O
0.7 -X- _ B-HyperparameterValue
. -X- _ O
β -X- _ B-HyperparameterName
is -X- _ O
tuned -X- _ O
to -X- _ O
1 -X- _ B-HyperparameterValue
( -X- _ O
chosen -X- _ O
from -X- _ O
{ -X- _ O
0.5 -X- _ B-HyperparameterValue
, -X- _ O
1 -X- _ B-HyperparameterValue
, -X- _ O
2 -X- _ B-HyperparameterValue
, -X- _ O
3 -X- _ B-HyperparameterValue
} -X- _ O
) -X- _ O
. -X- _ O

Model -X- _ O
implementation -X- _ O
The -X- _ O
backbone -X- _ O
convolutional -X- _ O
layers -X- _ O
are -X- _ O
taken -X- _ O
from -X- _ O
VGG-19 -X- _ O
( -X- _ O
Simonyan -X- _ O
and -X- _ O
Zisserman -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
the -X- _ O
convolutional -X- _ O
layers -X- _ O
with -X- _ O
a -X- _ O
fingerspelling -X- _ O
recognition -X- _ O
task -X- _ O
using -X- _ O
the -X- _ O
video -X- _ O
- -X- _ O
text -X- _ O
pairs -X- _ O
from -X- _ O
the -X- _ O
corresponding -X- _ O
dataset -X- _ O
. -X- _ O
In -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
VGG-19 -X- _ O
layers -X- _ O
are -X- _ O
first -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
ImageNet -X- _ B-DatasetName
( -X- _ O
Deng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
image -X- _ O
features -X- _ O
further -X- _ O
go -X- _ O
through -X- _ O
a -X- _ O
1- -X- _ B-HyperparameterValue
layer -X- _ B-HyperparameterName
Bi -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
LSTM -X- _ I-HyperparameterValue
with -X- _ O
512 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
per -X- _ O
direction -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
CTC -X- _ B-HyperparameterValue
loss -X- _ I-HyperparameterValue
( -X- _ O
Graves -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
output -X- _ O
labels -X- _ O
include -X- _ O
the -X- _ O
English -X- _ O
alphabet -X- _ O
plus -X- _ O
the -X- _ O
few -X- _ O
special -X- _ O
symbols -X- _ O
, -X- _ O
<space> -X- _ O
, -X- _ O
' -X- _ O
, -X- _ O
& -X- _ O
, -X- _ O
. -X- _ O
, -X- _ O
@ -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
blank -X- _ O
symbol -X- _ O
for -X- _ O
CTC -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
SGD -X- _ B-HyperparameterValue
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
1 -X- _ B-HyperparameterValue
at -X- _ O
the -X- _ O
initial -X- _ B-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.01 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
for -X- _ O
30 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
and -X- _ O
the -X- _ B-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
decayed -X- _ O
to -X- _ O
0.001 -X- _ B-HyperparameterValue
after -X- _ O
20 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O
The -X- _ O
recognizer -X- _ B-HyperparameterName
achieves -X- _ O
52.5%/64.4 -X- _ B-MetricValue
% -X- _ B-MetricValue
lettter -X- _ B-MetricName
accuracy -X- _ I-MetricName
on -X- _ O
ChicagoFSWild -X- _ B-DatasetName
/ -X- _ O
ChicagoFSWild+ -X- _ B-DatasetName
test -X- _ O
sets -X- _ O
. -X- _ O
The -X- _ O
VGG-19 -X- _ O
convolutional -X- _ O
layers -X- _ O
are -X- _ O
frozen -X- _ O
in -X- _ O
FSS -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
training -X- _ O
. -X- _ O

The -X- _ O
ASL -X- _ O
fingerspelling -X- _ O
alphabet -X- _ O
, -X- _ O
from -X- _ O
( -X- _ O
Keane -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
Table -X- _ O
6 -X- _ O
shows -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
video -X- _ O
clips -X- _ O
in -X- _ O
the -X- _ O
two -X- _ O
datasets -X- _ O
. -X- _ O
Figure -X- _ O
6 -X- _ O
shows -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
fingerspelling -X- _ O
sequence -X- _ O
length -X- _ O
in -X- _ O
the -X- _ O
two -X- _ O
datasets -X- _ O
. -X- _ O
Figure -X- _ O
7 -X- _ O
shows -X- _ O
image -X- _ O
examples -X- _ O
from -X- _ O
the -X- _ O
following -X- _ O
three -X- _ O
data -X- _ O
sources -X- _ O
: -X- _ O
YouTube -X- _ O
, -X- _ O
DeafVIDEO -X- _ O
, -X- _ O
misc -X- _ O
. -X- _ O
Pre -X- _ O
- -X- _ O
processing -X- _ O
The -X- _ O
raw -X- _ O
images -X- _ O
in -X- _ O
ChicagoF -X- _ B-DatasetName
- -X- _ I-DatasetName
SWild -X- _ I-DatasetName
and -X- _ O
ChicagoFSWild+ -X- _ B-DatasetName
datasets -X- _ O
contain -X- _ O
diverse -X- _ O
visual -X- _ O
scenes -X- _ O
which -X- _ O
can -X- _ O
involve -X- _ O
multiple -X- _ O
persons -X- _ O
. -X- _ O
We -X- _ O
adapt -X- _ O
the -X- _ O
heuristic -X- _ O
approach -X- _ O
used -X- _ O
in -X- _ O
( -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
target -X- _ O
signer -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
an -X- _ O
off -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
shelf -X- _ O
face -X- _ O
detector -X- _ O
to -X- _ O
detect -X- _ O
all -X- _ O
the -X- _ O
faces -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
We -X- _ O
extend -X- _ O
each -X- _ O
face -X- _ O
bounding -X- _ O
box -X- _ O
by -X- _ O
1.5 -X- _ O
times -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
bounding -X- _ O
box -X- _ O
in -X- _ O
4 -X- _ O
directions -X- _ O
and -X- _ O
select -X- _ O
the -X- _ O
largest -X- _ O
one -X- _ O
with -X- _ O
highest -X- _ O
average -X- _ O
magnitude -X- _ O
of -X- _ O
optical -X- _ O
flow -X- _ O
( -X- _ O
Farnebäck -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
use -X- _ O
the -X- _ O
bounding -X- _ O
box -X- _ O
averaged -X- _ O
over -X- _ O
the -X- _ O
whole -X- _ O
sequence -X- _ O
to -X- _ O
crop -X- _ O
the -X- _ O
ROI -X- _ O
area -X- _ O
, -X- _ O
which -X- _ O
roughly -X- _ O
denotes -X- _ O
the -X- _ O
signing -X- _ O
region -X- _ O
of -X- _ O
a -X- _ O
signer -X- _ O
. -X- _ O
Each -X- _ O
image -X- _ O
is -X- _ O
resized -X- _ O
to -X- _ O
160 -X- _ O
× -X- _ O
160 -X- _ O
before -X- _ O
feeding -X- _ O
into -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

The -X- _ O
datasets -X- _ O
we -X- _ O
use -X- _ O
are -X- _ O
collected -X- _ O
from -X- _ O
multiple -X- _ O
sources -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
video -X- _ O
quality -X- _ O
varies -X- _ O
between -X- _ O
them -X- _ O
. -X- _ O
To -X- _ O
quantify -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
visual -X- _ O
quality -X- _ O
on -X- _ O
search -X- _ O
/ -X- _ O
retrieval -X- _ O
performance -X- _ O
, -X- _ O
we -X- _ O
categorize -X- _ O
the -X- _ O
ASL -X- _ O
videos -X- _ O
into -X- _ O
three -X- _ O
categories -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
source -X- _ O
: -X- _ O
YouTube -X- _ O
, -X- _ O
DeafVIDEO -X- _ O
, -X- _ O
and -X- _ O
other -X- _ O
miscellaneous -X- _ O
sources -X- _ O
( -X- _ O
misc -X- _ O
) -X- _ O
. -X- _ O
YouTube -X- _ O
videos -X- _ O
are -X- _ O
mostly -X- _ O
ASL -X- _ O
lectures -X- _ O
with -X- _ O
high -X- _ O
resolution -X- _ O
. -X- _ O
DeafVIDEO -X- _ O
videos -X- _ O
are -X- _ O
vlogs -X- _ O
from -X- _ O
deaf -X- _ O
users -X- _ O
of -X- _ O
the -X- _ O
social -X- _ O
media -X- _ O
site -X- _ O
deafvideo.tv -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
style -X- _ O
, -X- _ O
camera -X- _ O
angle -X- _ O
, -X- _ O
and -X- _ O
image -X- _ O
quality -X- _ O
vary -X- _ O
greatly -X- _ O
. -X- _ O
The -X- _ O
visual -X- _ O
quality -X- _ O
of -X- _ O
videos -X- _ O
in -X- _ O
the -X- _ O
miscellaneous -X- _ O
category -X- _ O
tends -X- _ O
to -X- _ O
fall -X- _ O
between -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
categories -X- _ O
. -X- _ O
Typical -X- _ O
image -X- _ O
examples -X- _ O
from -X- _ O
the -X- _ O
three -X- _ O
categories -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
( -X- _ O
figure -X- _ O
7 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
FWS -X- _ B-TaskName
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
videos -X- _ O
in -X- _ O
YouTube -X- _ O
, -X- _ O
Deaf -X- _ O
- -X- _ O
VIDEO -X- _ O
, -X- _ O
and -X- _ O
misc -X- _ O
are -X- _ O
0.684 -X- _ B-MetricValue
, -X- _ O
0.584 -X- _ B-MetricValue
, -X- _ O
0.629 -X- _ B-MetricValue
( -X- _ O
mAP -X- _ B-MetricName
) -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
overall -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
perceived -X- _ O
relative -X- _ O
visual -X- _ O
qualities -X- _ O
of -X- _ O
these -X- _ O
categories -X- _ O
. -X- _ O

6 -X- _ O
Results -X- _ O
and -X- _ O
analysisTable -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
above -X- _ O
approaches -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
datasets -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
notice -X- _ O
that -X- _ O
embedding -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
consistently -X- _ O
outperform -X- _ O
the -X- _ O
recognizer -X- _ O
baseline -X- _ O
in -X- _ O
the -X- _ O
larger -X- _ O
data -X- _ O
setting -X- _ O
( -X- _ O
ChicagoFSWild+ -X- _ B-DatasetName
) -X- _ O
but -X- _ O
not -X- _ O
the -X- _ O
smaller -X- _ O
data -X- _ O
setting -X- _ O
( -X- _ O
ChicagoFSWild -X- _ B-DatasetName
) -X- _ O
, -X- _ O
which -X- _ O
suggests -X- _ O
that -X- _ O
embedding -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
generally -X- _ O
require -X- _ O
more -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
inferior -X- _ O
performance -X- _ O
of -X- _ O
recognizer -X- _ O
also -X- _ O
shows -X- _ O
that -X- _ O
explicit -X- _ O
fingerspelling -X- _ O
recognition -X- _ O
is -X- _ O
not -X- _ O
necessary -X- _ O
for -X- _ O
the -X- _ O
search -X- _ O
tasks -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
explicit -X- _ O
fingerspelling -X- _ O
detection -X- _ O
( -X- _ O
Ext -X- _ B-MethodName
- -X- _ I-MethodName
Det -X- _ I-MethodName
, -X- _ O
FSS -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
) -X- _ O
improves -X- _ O
performance -X- _ O
over -X- _ O
implicit -X- _ O
fin- -X- _ O
Of -X- _ O
the -X- _ O
models -X- _ O
that -X- _ O
do -X- _ O
n't -X- _ O
use -X- _ O
such -X- _ O
supervision -X- _ O
, -X- _ O
Attn -X- _ B-MethodName
- -X- _ I-MethodName
KWS -X- _ I-MethodName
is -X- _ O
the -X- _ O
best -X- _ O
performer -X- _ O
given -X- _ O
enough -X- _ O
data -X- _ O
, -X- _ O
but -X- _ O
is -X- _ O
still -X- _ O
far -X- _ O
behind -X- _ O
FSS -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
. -X- _ O
Our -X- _ O
model -X- _ O
outperforms -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
alternatives -X- _ O
. -X- _ O
The -X- _ O
relative -X- _ O
performance -X- _ O
of -X- _ O
different -X- _ O
models -X- _ O
remains -X- _ O
consistent -X- _ O
across -X- _ O
the -X- _ O
various -X- _ O
metrics -X- _ O
and -X- _ O
the -X- _ O
two -X- _ O
search -X- _ O
tasks -X- _ O
. -X- _ O
For -X- _ O
completeness -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
measure -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
different -X- _ O
models -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
rankingbased -X- _ O
metrics -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Precision@N -X- _ B-MetricName
, -X- _ O
Recall@N -X- _ B-MetricName
) -X- _ O
, -X- _ O
as -X- _ O
in -X- _ O
prior -X- _ O
work -X- _ O
on -X- _ O
video -X- _ B-TaskName
- -X- _ I-TaskName
text -X- _ I-TaskName
retrieval -X- _ I-TaskName
( -X- _ O
Ging -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Ranjay -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
( -X- _ O
see -X- _ O
full -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
relative -X- _ O
performance -X- _ O
of -X- _ O
different -X- _ O
models -X- _ O
remains -X- _ O
consistent -X- _ O
on -X- _ O
these -X- _ O
metrics -X- _ O
. -X- _ O
The -X- _ O
analysis -X- _ O
below -X- _ O
is -X- _ O
done -X- _ O
on -X- _ O
ChicagoFSWild -X- _ B-DatasetName
for -X- _ O
simplicity -X- _ O
. -X- _ O
The -X- _ O
conclusions -X- _ O
also -X- _ O
hold -X- _ O
for -X- _ O
ChicagoF -X- _ B-DatasetName
- -X- _ I-DatasetName
SWild+.In -X- _ I-DatasetName
the -X- _ O
previous -X- _ O
section -X- _ O
we -X- _ O
have -X- _ O
seen -X- _ O
that -X- _ O
models -X- _ O
that -X- _ O
explicitly -X- _ O
detect -X- _ O
and -X- _ O
localize -X- _ O
fingerspelling -X- _ O
outperform -X- _ O
ones -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
. -X- _ O
Next -X- _ O
we -X- _ O
look -X- _ O
more -X- _ O
closely -X- _ O
at -X- _ O
how -X- _ O
well -X- _ O
several -X- _ O
models -X- _ O
- -X- _ O
Ext -X- _ B-MethodName
- -X- _ I-MethodName
Det -X- _ I-MethodName
, -X- _ O
Attn -X- _ B-MethodName
- -X- _ I-MethodName
KWS -X- _ I-MethodName
and -X- _ O
FSS -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
- -X- _ O
perform -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
localizing -X- _ O
fingerspelling -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
byproduct -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
' -X- _ O
output -X- _ O
. -X- _ O
We -X- _ O
measure -X- _ O
performance -X- _ O
via -X- _ O
AP@IoU -X- _ B-MetricName
, -X- _ O
a -X- _ O
commonly -X- _ O
used -X- _ O
evaluation -X- _ O
metric -X- _ O
for -X- _ O
action -X- _ B-TaskName
detection -X- _ I-TaskName
( -X- _ O
Idrees -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Heilbron -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
that -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
used -X- _ O
for -X- _ O
fingerspelling -X- _ B-TaskName
detection -X- _ I-TaskName
( -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
AP@IoU -X- _ B-MetricName
measures -X- _ O
the -X- _ O
average -X- _ B-MetricName
precision -X- _ I-MetricName
of -X- _ O
a -X- _ O
detector -X- _ O
under -X- _ O
the -X- _ O
constraint -X- _ O
that -X- _ O
the -X- _ O
overlap -X- _ O
of -X- _ O
its -X- _ O
predicted -X- _ O
segments -X- _ O
with -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
is -X- _ O
above -X- _ O
some -X- _ O
threshold -X- _ O
Intersectionover -X- _ B-MetricName
- -X- _ I-MetricName
Union -X- _ I-MetricName
( -X- _ O
IoU -X- _ B-MetricName
) -X- _ O
value -X- _ O
. -X- _ O
For -X- _ O
Attn -X- _ B-MethodName
- -X- _ I-MethodName
KWS -X- _ I-MethodName
, -X- _ O
the -X- _ O
model -X- _ O
outputs -X- _ O
an -X- _ O
attention -X- _ O
vector -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
convert -X- _ O
to -X- _ O
segments -X- _ O
as -X- _ O
in -X- _ O
( -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
general -X- _ O
, -X- _ O
the -X- _ O
models -X- _ O
with -X- _ O
more -X- _ O
accurate -X- _ O
localization -X- _ O
also -X- _ O
have -X- _ O
higher -X- _ O
search -X- _ O
and -X- _ O
retrieval -X- _ O
performance -X- _ O
, -X- _ O
as -X- _ O
seen -X- _ O
by -X- _ O
comparing -X- _ O
Table -X- _ O
2 -X- _ O
with -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
differences -X- _ O
in -X- _ O
AP@IoU -X- _ B-MetricName
do -X- _ O
not -X- _ O
directly -X- _ O
translate -X- _ O
to -X- _ O
differences -X- _ O
in -X- _ O
search -X- _ O
performance -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
AP@IoU -X- _ B-MetricName
of -X- _ O
Ext -X- _ B-MethodName
- -X- _ I-MethodName
Det -X- _ I-MethodName
( -X- _ O
0.344 -X- _ B-MetricValue
) -X- _ O
is -X- _ O
an -X- _ O
order -X- _ O
of -X- _ O
magnitude -X- _ O
higher -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
Attn -X- _ B-MethodName
- -X- _ I-MethodName
KWS -X- _ I-MethodName
( -X- _ O
0.035 -X- _ B-MetricValue
) -X- _ O
while -X- _ O
their -X- _ O
FVS -X- _ B-TaskName
mAP -X- _ B-MetricName
results -X- _ O
are -X- _ O
much -X- _ O
closer -X- _ O
( -X- _ O
0.593 -X- _ B-MetricValue
vs. -X- _ O
0.573 -X- _ B-MetricValue
) -X- _ O
. -X- _ O

Attention -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
keyword -X- _ I-MethodName
search -X- _ I-MethodName
( -X- _ O
Attn -X- _ B-MethodName
- -X- _ I-MethodName
KWS -X- _ I-MethodName
) -X- _ O
This -X- _ O
model -X- _ O
is -X- _ O
adapted -X- _ O
from -X- _ O
( -X- _ O
Tamer -X- _ O
and -X- _ O
Saraçlar -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
's -X- _ O
approach -X- _ O
for -X- _ O
keyword -X- _ O
search -X- _ O
in -X- _ O
sign -X- _ O
language -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
employs -X- _ O
an -X- _ O
attention -X- _ O
mechanism -X- _ O
to -X- _ O
match -X- _ O
a -X- _ O
text -X- _ O
query -X- _ O
with -X- _ O
a -X- _ O
video -X- _ O
clip -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
frame -X- _ O
is -X- _ O
weighted -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
query -X- _ O
embedding -X- _ O
. -X- _ O
The -X- _ O
attention -X- _ O
mechanism -X- _ O
enables -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
implicitly -X- _ O
localize -X- _ O
frames -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
text -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
of -X- _ O
( -X- _ O
Tamer -X- _ O
and -X- _ O
Saraçlar -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
is -X- _ O
designed -X- _ O
for -X- _ O
lexical -X- _ O
signs -X- _ O
rather -X- _ O
than -X- _ O
fingerspelling -X- _ O
. -X- _ O
To -X- _ O
adapt -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
our -X- _ O
open -X- _ O
- -X- _ O
vocabulary -X- _ O
fingerspelling -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
text -X- _ O
encoder -X- _ O
as -X- _ O
in -X- _ O
FSS -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
to -X- _ O
map -X- _ O
words -X- _ O
into -X- _ O
embeddings -X- _ O
instead -X- _ O
of -X- _ O
using -X- _ O
a -X- _ O
word -X- _ O
embedding -X- _ O
matrix -X- _ O
as -X- _ O
in -X- _ O
( -X- _ O
Tamer -X- _ O
and -X- _ O
Saraçlar -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
Fingerspelling -X- _ O
boundary -X- _ O
information -X- _ O
is -X- _ O
again -X- _ O
not -X- _ O
used -X- _ O
in -X- _ O
training -X- _ O
this -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
arguably -X- _ O
puts -X- _ O
it -X- _ O
at -X- _ O
a -X- _ O
disadvantage -X- _ O
compared -X- _ O
to -X- _ O
FSS -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
. -X- _ O
More -X- _ O
details -X- _ O
on -X- _ O
the -X- _ O
formulation -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O
For -X- _ O
FWS -X- _ B-TaskName
, -X- _ O
we -X- _ O
use -X- _ O
all -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
as -X- _ O
the -X- _ O
test -X- _ O
vocabulary -X- _ O
w -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
. -X- _ O
For -X- _ O
FVS -X- _ B-TaskName
, -X- _ O
all -X- _ O
video -X- _ O
clips -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
candidates -X- _ O
and -X- _ O
the -X- _ O
text -X- _ O
queries -X- _ O
are -X- _ O
again -X- _ O
the -X- _ O
entire -X- _ O
test -X- _ O
vocabulary -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
standard -X- _ O
metrics -X- _ O
from -X- _ O
the -X- _ O
video -X- _ O
- -X- _ O
text -X- _ O
retrieval -X- _ O
literature -X- _ O
Tamer -X- _ O
and -X- _ O
Saraçlar -X- _ O
, -X- _ O
2020a -X- _ O
): -X- _ O
mean -X- _ B-MetricName
Average -X- _ I-MetricName
Precision -X- _ I-MetricName
( -X- _ B-MetricName
mAP -X- _ I-MetricName
) -X- _ O
and -X- _ O
mean -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
( -X- _ O
mF1 -X- _ B-MetricName
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
averages -X- _ O
are -X- _ O
over -X- _ O
words -X- _ O
for -X- _ O
FVS -X- _ B-TaskName
and -X- _ O
over -X- _ O
videos -X- _ O
for -X- _ O
FWS -X- _ B-TaskName
. -X- _ O
Hyperparameters -X- _ O
are -X- _ O
chosen -X- _ O
to -X- _ O
maximize -X- _ O
the -X- _ O
mAP -X- _ B-MetricName
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
, -X- _ O
independently -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
tasks -X- _ O
( -X- _ O
though -X- _ O
ultimately -X- _ O
, -X- _ O
the -X- _ O
best -X- _ O
hyperparameter -X- _ O
values -X- _ O
in -X- _ O
our -X- _ O
search -X- _ O
are -X- _ O
identical -X- _ O
for -X- _ O
both -X- _ O
tasks -X- _ O
) -X- _ O
. -X- _ O
Additional -X- _ O
details -X- _ O
on -X- _ O
data -X- _ O
, -X- _ O
preprocessing -X- _ O
, -X- _ O
model -X- _ O
implementation -X- _ O
, -X- _ O
and -X- _ O
hyperparameters -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O

External -X- _ B-MethodName
detector -X- _ I-MethodName
( -X- _ O
Ext -X- _ B-MethodName
- -X- _ I-MethodName
Det -X- _ I-MethodName
) -X- _ O
This -X- _ O
baseline -X- _ O
uses -X- _ O
the -X- _ O
off -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
shelf -X- _ O
fingerspelling -X- _ O
detectors -X- _ O
of -X- _ O
( -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
generate -X- _ O
fingerspelling -X- _ O
proposals -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
our -X- _ O
proposal -X- _ O
generator -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
otherwise -X- _ O
identical -X- _ O
to -X- _ O
FSS -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
. -X- _ O
For -X- _ O
each -X- _ O
dataset -X- _ O
( -X- _ O
ChicagoF -X- _ B-DatasetName
- -X- _ I-DatasetName
SWild -X- _ I-DatasetName
, -X- _ O
ChicagoFSWild+ -X- _ B-DatasetName
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
detector -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
subset -X- _ O
of -X- _ O
that -X- _ O
dataset -X- _ O
. -X- _ O
This -X- _ O
baseline -X- _ O
uses -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
fingerspelling -X- _ O
boundaries -X- _ O
for -X- _ O
the -X- _ O
detector -X- _ O
training -X- _ O
. -X- _ O

where -X- _ O
d -X- _ O
is -X- _ O
the -X- _ O
cosine -X- _ O
distance -X- _ O
as -X- _ O
in -X- _ O
FSS -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
. -X- _ O
Fingerspelling -X- _ O
boundary -X- _ O
information -X- _ O
is -X- _ O
again -X- _ O
not -X- _ O
used -X- _ O
in -X- _ O
this -X- _ O
baseline -X- _ O
. -X- _ O

Whole -X- _ B-MethodName
- -X- _ I-MethodName
clip -X- _ I-MethodName
The -X- _ O
whole -X- _ B-MethodName
- -X- _ I-MethodName
clip -X- _ I-MethodName
baseline -X- _ O
encodes -X- _ O
the -X- _ O
whole -X- _ O
video -X- _ O
clip -X- _ O
I -X- _ O
1 -X- _ O
: -X- _ O
T -X- _ O
into -X- _ O
a -X- _ O
visual -X- _ O
embedding -X- _ O
e -X- _ O
I -X- _ O
v -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
matched -X- _ O
to -X- _ O
the -X- _ O
textual -X- _ O
embedding -X- _ O
e -X- _ O
w -X- _ O
x -X- _ O
of -X- _ O
the -X- _ O
query -X- _ O
w. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
contrastive -X- _ O
loss -X- _ O
as -X- _ O
in -X- _ O
equation -X- _ O
2 -X- _ O
. -X- _ O
At -X- _ O
test -X- _ O
time -X- _ O
, -X- _ O
the -X- _ O
score -X- _ O
for -X- _ O
video -X- _ O
clip -X- _ O
I -X- _ O
1 -X- _ O
: -X- _ O
T -X- _ O
and -X- _ O
word -X- _ O
w -X- _ O
is -X- _ O
: -X- _ O

Recognizer -X- _ B-MethodName
In -X- _ O
this -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
recognizer -X- _ O
that -X- _ O
transcribes -X- _ O
the -X- _ O
video -X- _ O
clip -X- _ O
into -X- _ O
text -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
recognizer -X- _ B-MethodName
to -X- _ O
output -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
symbols -X- _ O
consisting -X- _ O
of -X- _ O
either -X- _ O
fingerspelled -X- _ O
letters -X- _ O
or -X- _ O
a -X- _ O
special -X- _ O
non -X- _ O
- -X- _ O
fingerspelling -X- _ O
symbol -X- _ O
< -X- _ O
x -X- _ O
> -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
the -X- _ O
recognizer -X- _ B-MethodName
with -X- _ O
a -X- _ O
connectionist -X- _ O
temporal -X- _ O
classification -X- _ O
( -X- _ O
CTC -X- _ O
) -X- _ O
loss -X- _ O
( -X- _ O
Graves -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
commonly -X- _ O
used -X- _ O
for -X- _ O
speech -X- _ B-TaskName
recognition -X- _ I-TaskName
. -X- _ O
At -X- _ O
test -X- _ O
time -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
beam -X- _ O
search -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
hypothesesŵ -X- _ O
1 -X- _ O
: -X- _ O
M -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
video -X- _ O
clip -X- _ O
I -X- _ O
1 -X- _ O
: -X- _ O
T -X- _ O
. -X- _ O
Each -X- _ O
hypothesisŵ -X- _ O
m -X- _ O
is -X- _ O
split -X- _ O
into -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
words -X- _ O
{ -X- _ O
ŵ -X- _ O
n -X- _ O
m -X- _ O
} -X- _ O
1≤n≤N -X- _ O
separated -X- _ O
by -X- _ O
< -X- _ O
x -X- _ O
> -X- _ O
. -X- _ O
The -X- _ O
matching -X- _ O
score -X- _ O
between -X- _ O
video -X- _ O
I -X- _ O
1 -X- _ O
: -X- _ O
T -X- _ O
and -X- _ O
w -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
: -X- _ O

where -X- _ O
the -X- _ O
letter -X- _ O
error -X- _ O
rate -X- _ O
LER -X- _ O
is -X- _ O
the -X- _ O
Levenshtein -X- _ O
edit -X- _ O
distance -X- _ O
. -X- _ O
This -X- _ O
approach -X- _ O
is -X- _ O
adapted -X- _ O
from -X- _ O
( -X- _ O
Saraçlar -X- _ O
and -X- _ O
Sproat -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
for -X- _ O
spoken -X- _ B-TaskName
utterance -X- _ I-TaskName
retrieval -X- _ I-TaskName
. -X- _ O
Fingerspelling -X- _ O
boundary -X- _ O
information -X- _ O
is -X- _ O
not -X- _ O
used -X- _ O
in -X- _ O
training -X- _ O
this -X- _ O
baseline -X- _ O
model -X- _ O
. -X- _ O

5 -X- _ O
Experimental -X- _ O
SetupWe -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
ChicagoFSWild -X- _ B-DatasetName
( -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
ChicagoFSWild+ -X- _ B-DatasetName
( -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
two -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
publicly -X- _ O
available -X- _ O
fingerspelling -X- _ O
datasets -X- _ O
containing -X- _ O
7,304 -X- _ O
and -X- _ O
55,272 -X- _ O
fingerspelling -X- _ O
sequences -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
ASL -X- _ O
videos -X- _ O
in -X- _ O
the -X- _ O
two -X- _ O
datasets -X- _ O
are -X- _ O
collected -X- _ O
from -X- _ O
online -X- _ O
resources -X- _ O
and -X- _ O
include -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
viewpoints -X- _ O
and -X- _ O
styles -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
webcam -X- _ O
videos -X- _ O
and -X- _ O
lectures -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
setup -X- _ O
of -X- _ O
( -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
split -X- _ O
the -X- _ O
raw -X- _ O
ASL -X- _ O
videos -X- _ O
into -X- _ O
300 -X- _ O
- -X- _ O
frame -X- _ O
clips -X- _ O
with -X- _ O
a -X- _ O
75frame -X- _ O
overlap -X- _ O
between -X- _ O
neighboring -X- _ O
chunks -X- _ O
and -X- _ O
remove -X- _ O
clips -X- _ O
without -X- _ O
fingerspelling -X- _ O
. -X- _ O
The -X- _ O
numbers -X- _ O
of -X- _ O
clips -X- _ O
in -X- _ O
the -X- _ O
various -X- _ O
splits -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O
On -X- _ O
average -X- _ O
, -X- _ O
each -X- _ O
clip -X- _ O
contains -X- _ O
1.9/1.8 -X- _ O
fingerspelling -X- _ O
segments -X- _ O
in -X- _ O
the -X- _ O
ChicagoFSWild -X- _ B-DatasetName
and -X- _ O
ChicagoFSWild+ -X- _ B-DatasetName
datasets -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
, -X- _ O
FSS -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
, -X- _ O
to -X- _ O
the -X- _ O
following -X- _ O
baselines -X- _ O
adapted -X- _ O
from -X- _ O
common -X- _ O
approaches -X- _ O
for -X- _ O
search -X- _ O
and -X- _ O
retrieval -X- _ O
in -X- _ O
related -X- _ O
fields -X- _ O
. -X- _ O
To -X- _ O
facilitate -X- _ O
comparison -X- _ O
, -X- _ O
the -X- _ O
network -X- _ O
architecture -X- _ O
for -X- _ O
the -X- _ O
visual -X- _ O
and -X- _ O
text -X- _ O
encoding -X- _ O
in -X- _ O
all -X- _ O
baselines -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
in -X- _ O
FSS -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
. -X- _ O

In -X- _ O
addition -X- _ O
to -X- _ O
introducing -X- _ O
the -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
address -X- _ O
the -X- _ O
research -X- _ O
question -X- _ O
of -X- _ O
whether -X- _ O
the -X- _ O
explicit -X- _ O
temporal -X- _ O
localization -X- _ O
of -X- _ O
fingerspelling -X- _ O
can -X- _ O
help -X- _ O
its -X- _ O
search -X- _ O
and -X- _ O
retrieval -X- _ O
, -X- _ O
and -X- _ O
how -X- _ O
best -X- _ O
to -X- _ O
localize -X- _ O
it -X- _ O
. -X- _ O
As -X- _ O
fingerspelling -X- _ O
occurs -X- _ O
sparsely -X- _ O
in -X- _ O
the -X- _ O
signing -X- _ O
stream -X- _ O
, -X- _ O
explicit -X- _ O
detection -X- _ O
of -X- _ O
fingerspelling -X- _ O
could -X- _ O
potentially -X- _ O
improve -X- _ O
search -X- _ O
performance -X- _ O
by -X- _ O
removing -X- _ O
unrelated -X- _ O
signs -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
model -X- _ O
, -X- _ O
FSS -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
, -X- _ O
which -X- _ O
jointly -X- _ O
detects -X- _ O
fingerspelling -X- _ O
from -X- _ O
unconstrained -X- _ O
signing -X- _ O
video -X- _ O
and -X- _ O
matches -X- _ O
it -X- _ O
to -X- _ O
text -X- _ O
queries -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
consistently -X- _ O
outperforms -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
baselines -X- _ O
without -X- _ O
explicit -X- _ O
detection -X- _ O
and -X- _ O
a -X- _ O
baseline -X- _ O
with -X- _ O
an -X- _ O
off -X- _ O
- -X- _ O
theshelf -X- _ O
fingerspelling -X- _ O
detector -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
. -X- _ O
In -X- _ O
existing -X- _ O
work -X- _ O
on -X- _ O
sign -X- _ B-TaskName
language -X- _ I-TaskName
video -X- _ I-TaskName
processing -X- _ I-TaskName
, -X- _ O
search -X- _ O
and -X- _ O
retrieval -X- _ O
tasks -X- _ O
have -X- _ O
been -X- _ O
studied -X- _ O
much -X- _ O
less -X- _ O
than -X- _ O
sign -X- _ B-TaskName
language -X- _ I-TaskName
recognition -X- _ I-TaskName
( -X- _ O
mapping -X- _ O
from -X- _ O
sign -X- _ O
language -X- _ O
video -X- _ O
to -X- _ O
gloss -X- _ O
labels -X- _ O
) -X- _ O
( -X- _ O
Koller -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Forster -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
translation -X- _ B-TaskName
( -X- _ O
mapping -X- _ O
from -X- _ O
sign -X- _ O
language -X- _ O
video -X- _ O
to -X- _ O
text -X- _ O
in -X- _ O
another -X- _ O
language -X- _ O
) -X- _ O
( -X- _ O
Yin -X- _ O
and -X- _ O
Read -X- _ O
, -X- _ O
2020;Camgöz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Work -X- _ O
thus -X- _ O
far -X- _ O
on -X- _ O
sign -X- _ O
language -X- _ O
search -X- _ O
has -X- _ O
been -X- _ O
framed -X- _ O
mainly -X- _ O
as -X- _ O
the -X- _ O
retrieval -X- _ O
of -X- _ O
lexical -X- _ O
signs -X- _ O
rather -X- _ O
than -X- _ O
fingerspelling -X- _ O
. -X- _ O
Pfister -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
; -X- _ O
employ -X- _ O
mouthing -X- _ O
to -X- _ O
detect -X- _ O
keywords -X- _ O
in -X- _ O
sign -X- _ O
- -X- _ O
interpreted -X- _ O
TV -X- _ O
programs -X- _ O
with -X- _ O
coarsely -X- _ O
aligned -X- _ O
subtitles -X- _ O
. -X- _ O
Tamer -X- _ O
and -X- _ O
Saraçlar -X- _ O
( -X- _ O
2020a -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
utilize -X- _ O
whole -X- _ O
- -X- _ O
body -X- _ O
pose -X- _ O
estimation -X- _ O
to -X- _ O
search -X- _ O
for -X- _ O
sign -X- _ O
language -X- _ O
keywords -X- _ O
( -X- _ O
gloss -X- _ O
or -X- _ O
translated -X- _ O
word -X- _ O
) -X- _ O
in -X- _ O
a -X- _ O
German -X- _ B-TaskName
Sign -X- _ I-TaskName
Language -X- _ I-TaskName
translation -X- _ I-TaskName
dataset -X- _ O
PHOENIX-2014 -X- _ B-DatasetName
T -X- _ I-DatasetName
( -X- _ O
Camgöz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
prior -X- _ O
work -X- _ O
on -X- _ O
keyword -X- _ O
search -X- _ O
for -X- _ O
sign -X- _ O
language -X- _ O
has -X- _ O
been -X- _ O
done -X- _ O
in -X- _ O
a -X- _ O
closed -X- _ O
- -X- _ O
vocabulary -X- _ O
setting -X- _ O
, -X- _ O
which -X- _ O
assumes -X- _ O
that -X- _ O
only -X- _ O
words -X- _ O
from -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
determined -X- _ O
set -X- _ O
will -X- _ O
be -X- _ O
queried -X- _ O
. -X- _ O
Searching -X- _ O
in -X- _ O
an -X- _ O
open -X- _ O
- -X- _ O
vocabulary -X- _ O
setting -X- _ O
, -X- _ O
including -X- _ O
proper -X- _ O
nouns -X- _ O
, -X- _ O
typically -X- _ O
requires -X- _ O
searching -X- _ O
for -X- _ O
fingerspelling -X- _ O
. -X- _ O
Some -X- _ O
related -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
speech -X- _ O
processing -X- _ O
literature -X- _ O
are -X- _ O
spoken -X- _ B-TaskName
term -X- _ I-TaskName
detection -X- _ I-TaskName
( -X- _ O
STD -X- _ O
) -X- _ O
and -X- _ O
queryby -X- _ B-TaskName
- -X- _ I-TaskName
example -X- _ I-TaskName
search -X- _ I-TaskName
, -X- _ O
which -X- _ O
are -X- _ O
the -X- _ O
tasks -X- _ O
of -X- _ O
automatically -X- _ O
retrieving -X- _ O
speech -X- _ O
segments -X- _ O
from -X- _ O
a -X- _ O
database -X- _ O
that -X- _ O
match -X- _ O
a -X- _ O
given -X- _ O
text -X- _ O
or -X- _ O
audio -X- _ O
query -X- _ O
( -X- _ O
Knill -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013;Mamou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007;Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
methodology -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
also -X- _ O
shares -X- _ O
some -X- _ O
aspects -X- _ O
with -X- _ O
prior -X- _ O
work -X- _ O
on -X- _ O
moment -X- _ O
retrieval -X- _ O
( -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
also -X- _ O
combines -X- _ O
candidate -X- _ O
generation -X- _ O
and -X- _ O
matching -X- _ O
components -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
incorporate -X- _ O
additional -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
elements -X- _ O
that -X- _ O
consistently -X- _ O
improve -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
two -X- _ O
tasks -X- _ O
: -X- _ O
Fingerspelled -X- _ B-TaskName
Word -X- _ I-TaskName
Search -X- _ I-TaskName
( -X- _ O
FWS -X- _ B-TaskName
) -X- _ O
and -X- _ O
Fingerspelling -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
Video -X- _ I-TaskName
Search -X- _ I-TaskName
( -X- _ O
FVS -X- _ B-TaskName
) -X- _ O
. -X- _ O
FWS -X- _ B-TaskName
and -X- _ O
FVS -X- _ B-TaskName
respectively -X- _ O
consist -X- _ O
of -X- _ O
detecting -X- _ O
fingerspelled -X- _ O
words -X- _ O
within -X- _ O
a -X- _ O
given -X- _ O
raw -X- _ O
ASL -X- _ O
video -X- _ O
stream -X- _ O
and -X- _ O
detecting -X- _ O
video -X- _ O
clips -X- _ O
of -X- _ O
interest -X- _ O
containing -X- _ O
a -X- _ O
given -X- _ O
fingerspelled -X- _ O
word -X- _ O
. -X- _ O
2 -X- _ O
Given -X- _ O
a -X- _ O
query -X- _ O
video -X- _ O
clip -X- _ O
v -X- _ O
and -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
n -X- _ O
words -X- _ O
w -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
, -X- _ O
FWS -X- _ B-TaskName
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
finding -X- _ O
which -X- _ O
( -X- _ O
if -X- _ O
any -X- _ O
) -X- _ O
of -X- _ O
w -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
are -X- _ O
present -X- _ O
in -X- _ O
v. -X- _ O
Conversely -X- _ O
, -X- _ O
in -X- _ O
FVS -X- _ B-TaskName
the -X- _ O
input -X- _ O
is -X- _ O
a -X- _ O
query -X- _ O
word -X- _ O
w -X- _ O
and -X- _ O
n -X- _ O
video -X- _ O
clips -X- _ O
v -X- _ O
1 -X- _ O
: -X- _ O
n -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
task -X- _ O
consists -X- _ O
of -X- _ O
finding -X- _ O
all -X- _ O
videos -X- _ O
containing -X- _ O
the -X- _ O
fingerspelled -X- _ O
word -X- _ O
w. -X- _ O
We -X- _ O
consider -X- _ O
an -X- _ O
openvocabulary -X- _ O
setting -X- _ O
where -X- _ O
the -X- _ O
word -X- _ O
w -X- _ O
is -X- _ O
not -X- _ O
constrained -X- _ O
to -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
determined -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
two -X- _ O
tasks -X- _ O
correspond -X- _ O
to -X- _ O
two -X- _ O
directions -X- _ O
of -X- _ O
search -X- _ O
( -X- _ O
video−→text -X- _ O
and -X- _ O
text−→video -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
is -X- _ O
standard -X- _ O
practice -X- _ O
in -X- _ O
other -X- _ O
retrieval -X- _ O
work -X- _ O
such -X- _ O
as -X- _ O
video -X- _ O
- -X- _ O
text -X- _ O
search -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Ranjay -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Ging -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020).We -X- _ O
propose -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
, -X- _ O
FSS -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
( -X- _ O
for -X- _ O
" -X- _ O
Finger -X- _ B-MethodName
- -X- _ I-MethodName
Spelling -X- _ I-MethodName
Search -X- _ I-MethodName
Network -X- _ I-MethodName
" -X- _ O
) -X- _ O
, -X- _ O
summarized -X- _ O
in -X- _ O
Fig- -X- _ O
Image -X- _ O
encoding -X- _ O
The -X- _ O
input -X- _ O
image -X- _ O
frames -X- _ O
are -X- _ O
encoded -X- _ O
into -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
feature -X- _ O
vectors -X- _ O
via -X- _ O
an -X- _ O
image -X- _ O
encoder -X- _ O
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
the -X- _ O
VGG-19 -X- _ O
( -X- _ O
Simonyan -X- _ O
and -X- _ O
Zisserman -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
convolutional -X- _ O
layers -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
Bi -X- _ O
- -X- _ O
LSTM -X- _ O
. -X- _ O
3 -X- _ O
We -X- _ O
use -X- _ O
raw -X- _ O
RGB -X- _ O
images -X- _ O
as -X- _ O
input -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
signer -X- _ O
pose -X- _ O
as -X- _ O
used -X- _ O
in -X- _ O
some -X- _ O
prior -X- _ O
work -X- _ O
( -X- _ O
Tamer -X- _ O
and -X- _ O
Saraçlar -X- _ O
, -X- _ O
2020b -X- _ O
, -X- _ O
a -X- _ O
) -X- _ O
on -X- _ O
sign -X- _ O
language -X- _ O
search -X- _ O
, -X- _ O
as -X- _ O
estimating -X- _ O
pose -X- _ O
for -X- _ O
hands -X- _ O
is -X- _ O
particularly -X- _ O
hard -X- _ O
for -X- _ O
signing -X- _ O
videos -X- _ O
in -X- _ O
the -X- _ O
wild -X- _ O
( -X- _ O
see -X- _ O
Section -X- _ O
6 -X- _ O
for -X- _ O
details -X- _ O
) -X- _ O
. -X- _ O

Automatic -X- _ B-TaskName
sign -X- _ I-TaskName
language -X- _ I-TaskName
processing -X- _ I-TaskName
has -X- _ O
recently -X- _ O
received -X- _ O
growing -X- _ O
interest -X- _ O
in -X- _ O
the -X- _ O
computer -X- _ O
vision -X- _ O
( -X- _ O
CV -X- _ O
) -X- _ O
and -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
communities -X- _ O
. -X- _ O
Yin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
make -X- _ O
several -X- _ O
recommendations -X- _ O
for -X- _ O
the -X- _ O
study -X- _ O
of -X- _ O
sign -X- _ O
languages -X- _ O
in -X- _ O
NLP -X- _ O
research -X- _ O
, -X- _ O
including -X- _ O
greater -X- _ O
emphasis -X- _ O
on -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
data -X- _ O
. -X- _ O
Most -X- _ O
studies -X- _ O
on -X- _ O
sign -X- _ O
language -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
data -X- _ O
collected -X- _ O
in -X- _ O
a -X- _ O
controlled -X- _ O
environment -X- _ O
, -X- _ O
either -X- _ O
1 -X- _ O
From -X- _ O
https://wfdeaf.org/our-work/ -X- _ O
in -X- _ O
a -X- _ O
studio -X- _ O
setting -X- _ O
( -X- _ O
Martínez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002;Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
or -X- _ O
in -X- _ O
a -X- _ O
specific -X- _ O
domain -X- _ O
( -X- _ O
Forster -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
challenges -X- _ O
involved -X- _ O
in -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
signing -X- _ O
videos -X- _ O
, -X- _ O
including -X- _ O
various -X- _ O
visual -X- _ O
conditions -X- _ O
and -X- _ O
different -X- _ O
levels -X- _ O
of -X- _ O
fluency -X- _ O
in -X- _ O
signing -X- _ O
, -X- _ O
are -X- _ O
not -X- _ O
fully -X- _ O
reflected -X- _ O
in -X- _ O
such -X- _ O
datasets -X- _ O
. -X- _ O
Automatic -X- _ O
processing -X- _ O
of -X- _ O
sign -X- _ O
language -X- _ O
videos -X- _ O
" -X- _ O
in -X- _ O
the -X- _ O
wild -X- _ O
" -X- _ O
has -X- _ O
not -X- _ O
been -X- _ O
addressed -X- _ O
until -X- _ O
recently -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
still -X- _ O
restricted -X- _ O
to -X- _ O
tasks -X- _ O
like -X- _ O
isolated -X- _ B-TaskName
sign -X- _ I-TaskName
recognition -X- _ I-TaskName
Joze -X- _ O
and -X- _ O
Koller -X- _ O
, -X- _ O
2019;Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
fingerspelling -X- _ B-TaskName
recognition -X- _ I-TaskName
( -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018(Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2019 -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
take -X- _ O
a -X- _ O
step -X- _ O
further -X- _ O
and -X- _ O
study -X- _ O
search -X- _ O
and -X- _ O
retrieval -X- _ O
of -X- _ O
arbitrary -X- _ O
fingerspelled -X- _ O
content -X- _ O
in -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
American -X- _ O
Sign -X- _ O
Language -X- _ O
( -X- _ O
ASL -X- _ O
) -X- _ O
video -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
fingerspelling -X- _ O
video -X- _ O
search -X- _ O
( -X- _ O
FVS -X- _ O
) -X- _ O
for -X- _ O
searching -X- _ O
for -X- _ O
sign -X- _ O
language -X- _ O
videos -X- _ O
that -X- _ O
include -X- _ O
a -X- _ O
fingerspelled -X- _ O
query -X- _ O
word -X- _ O
/ -X- _ O
phrase -X- _ O
. -X- _ O
The -X- _ O
sign -X- _ O
language -X- _ O
videos -X- _ O
are -X- _ O
untrimmed -X- _ O
, -X- _ O
i.e. -X- _ O
they -X- _ O
include -X- _ O
regular -X- _ O
signs -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
fingerspelling -X- _ O
, -X- _ O
and -X- _ O
are -X- _ O
downsampled -X- _ O
here -X- _ O
for -X- _ O
visualization -X- _ O
. -X- _ O

In -X- _ O
activation -X- _ O
boundary -X- _ O
distillation -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
a -X- _ O
grid -X- _ O
search -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
( -X- _ O
e -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
) -X- _ O
and -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
( -X- _ O
lr -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
) -X- _ O
for -X- _ O
initial -X- _ O
student -X- _ O
finetuning -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
another -X- _ O
grid -X- _ O
search -X- _ O
of -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
( -X- _ O
lr -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
) -X- _ O
, -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
( -X- _ B-HyperparameterName
e -X- _ I-HyperparameterName
2 -X- _ I-HyperparameterName
) -X- _ O
, -X- _ O
weight -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
confidence -X- _ I-HyperparameterName
penalty -X- _ I-HyperparameterName
( -X- _ O
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
) -X- _ O
, -X- _ O
and -X- _ O
loss -X- _ B-HyperparameterName
switch -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
( -X- _ O
γ -X- _ B-HyperparameterName
) -X- _ O
for -X- _ O
the -X- _ O
distillation -X- _ O
and -X- _ O
refinement -X- _ O
steps -X- _ O
. -X- _ O
Both -X- _ O
searches -X- _ O
are -X- _ O
performed -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
actual -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
hyperparameters -X- _ O
for -X- _ O
the -X- _ O
ALBERT -X- _ B-MethodName
student -X- _ O
are -X- _ O
summarized -X- _ O
in -X- _ O
Table -X- _ O
A2 -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
as -X- _ O
a -X- _ O
student -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
teacher -X- _ O
with -X- _ O
ALBERT -X- _ B-MethodName
. -X- _ O
The -X- _ O
hyperparameters -X- _ O
of -X- _ O
the -X- _ O
activation -X- _ O
boundary -X- _ O
distillation -X- _ O
for -X- _ O
the -X- _ O
RoBERTa -X- _ B-MethodName
student -X- _ O
are -X- _ O
searched -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
manner -X- _ O
with -X- _ O
the -X- _ O
ALBERT -X- _ B-MethodName
and -X- _ O
summarized -X- _ O
in -X- _ O
Table -X- _ O
A3.In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
on -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
two -X- _ O
financial -X- _ O
downstream -X- _ O
task -X- _ O
datasets -X- _ O
, -X- _ O
the -X- _ O
experimental -X- _ O
details -X- _ O
, -X- _ O
and -X- _ O
hyperparameters -X- _ O
of -X- _ O
the -X- _ O
financial -X- _ O
task -X- _ O
experiments -X- _ O
. -X- _ O

The -X- _ O
actual -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
hyperparameters -X- _ O
for -X- _ O
the -X- _ O
calibrated -X- _ O
teacher -X- _ O
training -X- _ O
are -X- _ O
summarized -X- _ O
in -X- _ O
Table -X- _ O
A1 -X- _ O
. -X- _ O

In -X- _ O
calibrated -X- _ O
teacher -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
select -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
and -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
as -X- _ O
the -X- _ O
default -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
BioBERT -X- _ B-MethodName
code -X- _ O
and -X- _ O
slightly -X- _ O
change -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
( -X- _ O
e -X- _ B-HyperparameterName
) -X- _ O
for -X- _ O
the -X- _ O
unreported -X- _ O
tasks -X- _ O
from -X- _ O
BioBERT -X- _ B-MethodName
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
the -X- _ O
strength -X- _ O
of -X- _ O
the -X- _ O
confidence -X- _ B-HyperparameterName
regularization -X- _ I-HyperparameterName
( -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
) -X- _ O
by -X- _ O
a -X- _ O
grid -X- _ O
search -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
and -X- _ O
expected -X- _ B-MetricName
calibration -X- _ I-MetricName
error -X- _ I-MetricName
( -X- _ O
ECE -X- _ B-MetricName
) -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
formula -X- _ O
for -X- _ O
calculating -X- _ O
ECE -X- _ B-MetricName
is -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
, -X- _ O
ALBERT -X- _ B-MethodName
- -X- _ I-MethodName
DoKTRa -X- _ I-MethodName
and -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
DoKTRa -X- _ I-MethodName
outperformed -X- _ O
the -X- _ O
FinBERT -X- _ B-MethodName
- -X- _ I-MethodName
ft -X- _ I-MethodName
teacher -X- _ O
on -X- _ O
financial -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
model -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
stability -X- _ O
. -X- _ O
This -X- _ O
result -X- _ O
suggests -X- _ O
that -X- _ O
DoKTra -X- _ B-MethodName
can -X- _ O
be -X- _ O
applied -X- _ O
regardless -X- _ O
of -X- _ O
the -X- _ O
domain -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
an -X- _ O
efficient -X- _ O
alternative -X- _ O
to -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
proposed -X- _ O
the -X- _ O
DoKTra -X- _ B-MethodName
framework -X- _ O
as -X- _ O
a -X- _ O
domain -X- _ O
knowledge -X- _ O
transfer -X- _ O
method -X- _ O
for -X- _ O
PLMs -X- _ O
. -X- _ O
The -X- _ O
experimental -X- _ O
results -X- _ O
from -X- _ O
the -X- _ O
biomedical -X- _ O
, -X- _ O
clinical -X- _ O
, -X- _ O
and -X- _ O
financial -X- _ O
domain -X- _ O
downstream -X- _ O
tasks -X- _ O
demonstrated -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
framework -X- _ O
could -X- _ O
transfer -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
knowledge -X- _ O
into -X- _ O
a -X- _ O
PLM -X- _ O
, -X- _ O
while -X- _ O
preserving -X- _ O
its -X- _ O
own -X- _ O
expressive -X- _ O
advantages -X- _ O
without -X- _ O
any -X- _ O
further -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
with -X- _ O
additional -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
employed -X- _ O
advanced -X- _ O
models -X- _ O
as -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
and -X- _ O
verified -X- _ O
the -X- _ O
future -X- _ O
applicability -X- _ O
of -X- _ O
our -X- _ O
framework -X- _ O
to -X- _ O
emerging -X- _ O
language -X- _ O
models -X- _ O
by -X- _ O
achieving -X- _ O
even -X- _ O
higher -X- _ O
performances -X- _ O
than -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
are -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
and -X- _ O
was -X- _ O
evaluated -X- _ O
only -X- _ O
in -X- _ O
classification -X- _ O
tasks -X- _ O
. -X- _ O
Our -X- _ O
future -X- _ O
studies -X- _ O
would -X- _ O
focus -X- _ O
on -X- _ O
developing -X- _ O
the -X- _ O
proposed -X- _ O
framework -X- _ O
as -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
method -X- _ O
and -X- _ O
evaluating -X- _ O
it -X- _ O
on -X- _ O
various -X- _ O
tasks -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
searching -X- _ O
scheme -X- _ O
and -X- _ O
actual -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
hyperparameters -X- _ O
used -X- _ O
by -X- _ O
us -X- _ O
. -X- _ O
In -X- _ O
all -X- _ O
cases -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
to -X- _ O
the -X- _ O
maximum -X- _ O
that -X- _ O
a -X- _ O
single -X- _ O
GPU -X- _ O
can -X- _ O
process -X- _ O
, -X- _ O
with -X- _ O
128 -X- _ B-HyperparameterValue
being -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
. -X- _ O

In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
selected -X- _ O
the -X- _ O
FinBERT -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
model -X- _ O
as -X- _ O
a -X- _ O
teacher -X- _ O
in -X- _ O
the -X- _ O
DoKTra -X- _ B-MethodName
framework -X- _ O
and -X- _ O
evaluated -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
two -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
Financial -X- _ B-DatasetName
PhraseBank -X- _ I-DatasetName
( -X- _ O
FPB -X- _ B-DatasetName
) -X- _ O
and -X- _ O
Fin -X- _ B-DatasetName
- -X- _ I-DatasetName
TextSen -X- _ I-DatasetName
( -X- _ O
FTS -X- _ B-DatasetName
) -X- _ O
. -X- _ O
The -X- _ O
Financial -X- _ B-DatasetName
PhraseBank -X- _ I-DatasetName
( -X- _ O
FPB -X- _ B-DatasetName
) -X- _ O
( -X- _ O
Malo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
contains -X- _ O
sentences -X- _ O
from -X- _ O
financial -X- _ O
news -X- _ O
annotated -X- _ O
for -X- _ O
positive -X- _ O
, -X- _ O
neutral -X- _ O
, -X- _ O
and -X- _ O
negative -X- _ O
sentiments -X- _ O
. -X- _ O
The -X- _ O
FinTextSen -X- _ B-DatasetName
( -X- _ O
FTS -X- _ B-DatasetName
) -X- _ O
( -X- _ O
Cortis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
consists -X- _ O
of -X- _ O
financial -X- _ O
tweets -X- _ O
from -X- _ O
Twitter -X- _ O
and -X- _ O
StockTwits -X- _ O
with -X- _ O
real -X- _ O
- -X- _ O
valued -X- _ O
sentiment -X- _ O
scores -X- _ O
. -X- _ O
To -X- _ O
transform -X- _ O
it -X- _ O
into -X- _ O
a -X- _ O
classification -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
clustered -X- _ O
the -X- _ O
sentiment -X- _ O
score -X- _ O
into -X- _ O
a -X- _ O
3 -X- _ O
- -X- _ O
class -X- _ O
label -X- _ O
, -X- _ O
following -X- _ O
Daudert -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
Financial -X- _ B-DatasetName
PhraseBank -X- _ I-DatasetName
dataset -X- _ O
contains -X- _ O
4,846 -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
set -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
examples -X- _ O
as -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
while -X- _ O
preserving -X- _ O
the -X- _ O
label -X- _ O
distribution -X- _ O
. -X- _ O
The -X- _ O
FinTextSen -X- _ B-DatasetName
originally -X- _ O
includes -X- _ O
2,488 -X- _ O
tweets -X- _ O
, -X- _ O
but -X- _ O
only -X- _ O
1,700 -X- _ O
tweets -X- _ O
are -X- _ O
available -X- _ O
now -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
entire -X- _ O
data -X- _ O
as -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
FPB -X- _ B-DatasetName
. -X- _ O

Table -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
four -X- _ O
relation -X- _ O
extraction -X- _ O
tasks -X- _ O
with -X- _ O
ALBERT -X- _ B-MethodName
students -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
the -X- _ O
application -X- _ O
of -X- _ O
the -X- _ O
calibrated -X- _ O
teacher -X- _ O
training -X- _ O
reduces -X- _ O
the -X- _ O
L -X- _ O
AT -X- _ O
and -X- _ O
improves -X- _ O
the -X- _ O
classification -X- _ O
performance -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
calibration -X- _ O
on -X- _ O
the -X- _ O
teacher -X- _ O
training -X- _ O
clearly -X- _ O
aids -X- _ O
the -X- _ O
supervision -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
in -X- _ O
activation -X- _ O
boundary -X- _ O
distillation -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
the -X- _ O
output -X- _ O
probability -X- _ O
information -X- _ O
is -X- _ O
not -X- _ O
directly -X- _ O
used -X- _ O
in -X- _ O
distillation -X- _ O
. -X- _ O
To -X- _ O
observe -X- _ O
how -X- _ O
each -X- _ O
component -X- _ O
contributed -X- _ O
to -X- _ O
the -X- _ O
proposed -X- _ O
framework -X- _ O
, -X- _ O
we -X- _ O
conducted -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
. -X- _ O
We -X- _ O
ablated -X- _ O
two -X- _ O
major -X- _ O
components -X- _ O
: -X- _ O
calibrated -X- _ O
teacher -X- _ O
training -X- _ O
( -X- _ O
CTT -X- _ O
) -X- _ O
and -X- _ O
activation -X- _ O
boundary -X- _ O
distillation -X- _ O
( -X- _ O
ABD -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
experiments -X- _ O
were -X- _ O
performed -X- _ O
on -X- _ O
the -X- _ O
ChemProt -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
ALBERT -X- _ B-MethodName
- -X- _ I-MethodName
xlarge -X- _ I-MethodName
model -X- _ O
as -X- _ O
the -X- _ O
student -X- _ O
architecture -X- _ O
. -X- _ O
To -X- _ O
ablate -X- _ O
the -X- _ O
calibrated -X- _ O
teacher -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
trained -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
using -X- _ O
only -X- _ O
L -X- _ O
CE -X- _ O
. -X- _ O
We -X- _ O
compared -X- _ O
the -X- _ O
activation -X- _ O
boundary -X- _ O
distillation -X- _ O
with -X- _ O
KL -X- _ O
- -X- _ O
divergence -X- _ O
based -X- _ O
distillation -X- _ O
( -X- _ O
KLD -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
penalizes -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
output -X- _ O
probability -X- _ O
distributions -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
models -X- _ O
. -X- _ O
Table -X- _ O
6 -X- _ O
presents -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
ablation -X- _ O
study -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
proposed -X- _ O
, -X- _ O
applying -X- _ O
both -X- _ O
calibrated -X- _ O
teacher -X- _ O
training -X- _ O
and -X- _ O
activation -X- _ O
boundary -X- _ O
distillation -X- _ O
resulted -X- _ O
in -X- _ O
a -X- _ O
superior -X- _ O
performance -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
the -X- _ O
calibrated -X- _ O
teacher -X- _ O
model -X- _ O
was -X- _ O
able -X- _ O
to -X- _ O
distil -X- _ O
its -X- _ O
activation -X- _ O
boundary -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
much -X- _ O
more -X- _ O
effectively -X- _ O
, -X- _ O
thus -X- _ O
improving -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
hypothesized -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
section -X- _ O
. -X- _ O
Applying -X- _ O
KL -X- _ O
- -X- _ O
divergence -X- _ O
- -X- _ O
based -X- _ O
distillation -X- _ O
yielded -X- _ O
positive -X- _ O
results -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
classification -X- _ O
performance -X- _ O
. -X- _ O
Notably -X- _ O
, -X- _ O
calibrated -X- _ O
teacher -X- _ O
training -X- _ O
also -X- _ O
improved -X- _ O
the -X- _ O
KL -X- _ O
- -X- _ O
divergence -X- _ O
- -X- _ O
based -X- _ O
distillation -X- _ O
because -X- _ O
it -X- _ O
enabled -X- _ O
the -X- _ O
distillation -X- _ O
of -X- _ O
a -X- _ O
considerably -X- _ O
more -X- _ O
reliable -X- _ O
output -X- _ O
probability -X- _ O
, -X- _ O
as -X- _ O
reported -X- _ O
in -X- _ O
Menon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
applying -X- _ O
the -X- _ O
confidence -X- _ O
regularizer -X- _ O
to -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
only -X- _ O
slightly -X- _ O
improved -X- _ O
the -X- _ O
performance -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
the -X- _ O
observed -X- _ O
gains -X- _ O
in -X- _ O
our -X- _ O
model -X- _ O
are -X- _ O
only -X- _ O
partially -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
calibration -X- _ O
regularizer -X- _ O
. -X- _ O
To -X- _ O
verify -X- _ O
the -X- _ O
general -X- _ O
applicability -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
conducted -X- _ O
experiments -X- _ O
on -X- _ O
financial -X- _ B-TaskName
sentiment -X- _ I-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
. -X- _ O
( -X- _ O
Araci -X- _ O
, -X- _ O
2019;Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
fill -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
general -X- _ O
and -X- _ O
financial -X- _ O
domains -X- _ O
. -X- _ O

Irrespective -X- _ O
of -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
an -X- _ O
alternative -X- _ O
version -X- _ O
( -X- _ O
Equation -X- _ O
5 -X- _ O
) -X- _ O
during -X- _ O
the -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
the -X- _ O
activation -X- _ O
pattern -X- _ O
is -X- _ O
distilled -X- _ O
can -X- _ O
be -X- _ O
intuitively -X- _ O
observed -X- _ O
by -X- _ O
calculating -X- _ O
the -X- _ O
original -X- _ O
" -X- _ O
activation -X- _ O
transfer -X- _ O
loss -X- _ O
" -X- _ O
( -X- _ O
Equation -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
value -X- _ O
of -X- _ O
Equation -X- _ O
4 -X- _ O
directly -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
neurons -X- _ O
activated -X- _ O
differently -X- _ O
than -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
if -X- _ O
L -X- _ O
AT -X- _ O
= -X- _ O
500 -X- _ O
for -X- _ O
an -X- _ O
ALBERT -X- _ B-MethodName
model -X- _ O
( -X- _ O
H=2,048 -X- _ B-HyperparameterName
) -X- _ O
, -X- _ O
it -X- _ O
indicates -X- _ O
that -X- _ O
500 -X- _ O
of -X- _ O
the -X- _ O
2,048 -X- _ O
elements -X- _ O
in -X- _ O
the -X- _ O
hidden -X- _ O
representation -X- _ O
vector -X- _ O
exhibited -X- _ O
signs -X- _ O
different -X- _ O
to -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
. -X- _ O

The -X- _ O
comparison -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
GAD -X- _ B-DatasetName
in -X- _ O
Table -X- _ O
4 -X- _ O
was -X- _ O
evaluated -X- _ O
with -X- _ O
the -X- _ O
first -X- _ O
split -X- _ O
of -X- _ O
a -X- _ O
10 -X- _ B-HyperparameterValue
- -X- _ O
fold -X- _ O
crossvalidation -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
main -X- _ O
result -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
was -X- _ O
evaluated -X- _ O
with -X- _ O
all -X- _ O
splits -X- _ O
. -X- _ O
As -X- _ O
revealed -X- _ O
in -X- _ O
the -X- _ O
results -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
TAPT -X- _ B-MethodName
showed -X- _ O
improved -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
study -X- _ O
with -X- _ O
Google -X- _ O
Cloud -X- _ O
TPU -X- _ O
, -X- _ O
it -X- _ O
was -X- _ O
unstable -X- _ O
with -X- _ O
the -X- _ O
small -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
and -X- _ O
sequence -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
; -X- _ O
the -X- _ O
performances -X- _ O
were -X- _ O
even -X- _ O
degraded -X- _ O
in -X- _ O
the -X- _ O
general -X- _ O
GPU -X- _ O
environment -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
TAPT -X- _ B-MethodName
performance -X- _ O
improved -X- _ O
when -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
increased -X- _ O
through -X- _ O
distributed -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
improvement -X- _ O
was -X- _ O
inadequate -X- _ O
. -X- _ O
This -X- _ O
may -X- _ O
be -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
being -X- _ O
smaller -X- _ O
than -X- _ O
that -X- _ O
in -X- _ O
the -X- _ O
TPU -X- _ O
environment -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
DoKTra -X- _ B-MethodName
required -X- _ O
less -X- _ O
training -X- _ O
time -X- _ O
than -X- _ O
TAPT -X- _ B-MethodName
while -X- _ O
both -X- _ O
methods -X- _ O
were -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
TAPT -X- _ B-MethodName
required -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
seven -X- _ O
hours -X- _ O
of -X- _ O
training -X- _ O
, -X- _ O
while -X- _ O
DoKTRa -X- _ B-MethodName
was -X- _ O
completed -X- _ O
in -X- _ O
only -X- _ O
1.1 -X- _ O
hours -X- _ O
for -X- _ O
the -X- _ O
ChemProt -X- _ B-DatasetName
task -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
DoKTra -X- _ B-MethodName
leverages -X- _ O
the -X- _ O
knowledge -X- _ O
of -X- _ O
an -X- _ O
existing -X- _ O
indomain -X- _ O
PLM -X- _ O
, -X- _ O
thus -X- _ O
requiring -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
and -X- _ O
distillation -X- _ O
steps -X- _ O
. -X- _ O
The -X- _ O
comparison -X- _ O
of -X- _ O
TAPT -X- _ B-MethodName
and -X- _ O
DoKTra -X- _ B-MethodName
using -X- _ O
more -X- _ O
advanced -X- _ O
computing -X- _ O
resources -X- _ O
is -X- _ O
left -X- _ O
as -X- _ O
a -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
We -X- _ O
conducted -X- _ O
an -X- _ O
experiment -X- _ O
to -X- _ O
verify -X- _ O
the -X- _ O
positive -X- _ O
effect -X- _ O
of -X- _ O
combining -X- _ O
calibrated -X- _ O
teacher -X- _ O
training -X- _ O
and -X- _ O
activation -X- _ O
boundary -X- _ O
distillation -X- _ O
. -X- _ O
Because -X- _ O
the -X- _ O
entropy -X- _ O
regularizer -X- _ O
in -X- _ O
calibrated -X- _ O
teacher -X- _ O
training -X- _ O
issues -X- _ O
penalties -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
output -X- _ O
probability -X- _ O
distribution -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
intuitively -X- _ O
understand -X- _ O
how -X- _ O
it -X- _ O
positively -X- _ O
affects -X- _ O
activation -X- _ O
boundary -X- _ O
distillation -X- _ O
, -X- _ O
which -X- _ O
uses -X- _ O
hidden -X- _ O
representation -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
ablate -X- _ O
the -X- _ O
calibrated -X- _ O
teacher -X- _ O
training -X- _ O
steps -X- _ O
in -X- _ O
our -X- _ O
framework -X- _ O
and -X- _ O
compare -X- _ O
the -X- _ O
final -X- _ O
performances -X- _ O
and -X- _ O
loss -X- _ O
values -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
model -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
were -X- _ O
unstable -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
performed -X- _ O
a -X- _ O
distributed -X- _ O
training -X- _ O
with -X- _ O
three -X- _ O
GPUs -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
108 -X- _ B-HyperparameterValue
. -X- _ O

We -X- _ O
also -X- _ O
compared -X- _ O
our -X- _ O
framework -X- _ O
with -X- _ O
taskadaptive -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
( -X- _ O
TAPT -X- _ B-MethodName
) -X- _ O
( -X- _ O
Gururangan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
an -X- _ O
additional -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
method -X- _ O
for -X- _ O
PLMs -X- _ O
. -X- _ O
The -X- _ O
TAPT -X- _ B-MethodName
approach -X- _ O
additionally -X- _ O
pre -X- _ O
- -X- _ O
trains -X- _ O
an -X- _ O
existing -X- _ O
PLM -X- _ O
before -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
it -X- _ O
with -X- _ O
the -X- _ O
training -X- _ O
samples -X- _ O
of -X- _ O
each -X- _ O
task -X- _ O
. -X- _ O
As -X- _ O
both -X- _ O
TAPT -X- _ B-MethodName
and -X- _ O
DoK -X- _ B-MethodName
- -X- _ I-MethodName
Tra -X- _ I-MethodName
only -X- _ O
utilize -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
they -X- _ O
can -X- _ O
be -X- _ O
fairly -X- _ O
compared -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
performance -X- _ O
and -X- _ O
training -X- _ O
resources -X- _ O
. -X- _ O
For -X- _ O
TAPT -X- _ B-MethodName
, -X- _ O
we -X- _ O
additionally -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
the -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
model -X- _ O
with -X- _ O
each -X- _ O
pre -X- _ O
- -X- _ O
processed -X- _ O
downstream -X- _ O
task -X- _ O
's -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
followed -X- _ O
the -X- _ O
hyperparameters -X- _ O
used -X- _ O
in -X- _ O
TAPT -X- _ B-MethodName
except -X- _ O
for -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
and -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
because -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
same -X- _ O
computing -X- _ O
resource -X- _ O
as -X- _ O
DoKTra -X- _ B-MethodName
for -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
. -X- _ O
The -X- _ O
possible -X- _ O
maximum -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
with -X- _ O
the -X- _ O
given -X- _ O
computing -X- _ O
resource -X- _ O
for -X- _ O
the -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
model -X- _ O
was -X- _ O
36 -X- _ B-HyperparameterValue
. -X- _ O

Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
classification -X- _ O
performance -X- _ O
of -X- _ O
BioBERT -X- _ B-MethodName
, -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
PM -X- _ I-MethodName
, -X- _ O
and -X- _ O
our -X- _ O
approach -X- _ O
in -X- _ O
five -X- _ O
biomedical -X- _ O
and -X- _ O
clinical -X- _ O
tasks -X- _ O
. -X- _ O
As -X- _ O
mentioned -X- _ O
before -X- _ O
, -X- _ O
our -X- _ O
best -X- _ O
model -X- _ O
outperformed -X- _ O
the -X- _ O
BioBERT -X- _ B-MethodName
( -X- _ O
teacher -X- _ O
) -X- _ O
model -X- _ O
on -X- _ O
four -X- _ O
of -X- _ O
the -X- _ O
five -X- _ O
tasks -X- _ O
. -X- _ O
Notably -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
even -X- _ O
outperformed -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
PM -X- _ I-MethodName
on -X- _ O
two -X- _ O
tasks -X- _ O
and -X- _ O
demonstrated -X- _ O
comparable -X- _ O
performances -X- _ O
on -X- _ O
the -X- _ O
others -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
are -X- _ O
remarkable -X- _ O
since -X- _ O
our -X- _ O
approach -X- _ O
spent -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
hours -X- _ O
on -X- _ O
each -X- _ O
task -X- _ O
, -X- _ O
whereas -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
PM -X- _ I-MethodName
may -X- _ O
require -X- _ O
several -X- _ O
days -X- _ O
and -X- _ O
billions -X- _ O
of -X- _ O
words -X- _ O
to -X- _ O
be -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
PM -X- _ I-MethodName
has -X- _ O
an -X- _ O
advantage -X- _ O
in -X- _ O
the -X- _ O
i2b2 -X- _ B-DatasetName
task -X- _ O
since -X- _ O
its -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
contains -X- _ O
MIMIC -X- _ B-DatasetName
- -X- _ I-DatasetName
III -X- _ I-DatasetName
clinical -X- _ O
text -X- _ O
data -X- _ O
, -X- _ O
while -X- _ O
our -X- _ O
teacher -X- _ O
model -X- _ O
was -X- _ O
pretrained -X- _ O
with -X- _ O
only -X- _ O
biomedical -X- _ O
texts -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
this -X- _ O
implies -X- _ O
our -X- _ O
approach -X- _ O
has -X- _ O
a -X- _ O
room -X- _ O
for -X- _ O
further -X- _ O
improvement -X- _ O
when -X- _ O
a -X- _ O
better -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
model -X- _ O
is -X- _ O
set -X- _ O
as -X- _ O
a -X- _ O
teacher -X- _ O
. -X- _ O

The -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
that -X- _ O
was -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
proposed -X- _ O
framework -X- _ O
outperformed -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
on -X- _ O
an -X- _ O
average -X- _ O
, -X- _ O
specifically -X- _ O
in -X- _ O
four -X- _ O
of -X- _ O
five -X- _ O
downstream -X- _ O
tasks -X- _ O
( -X- _ O
ChemProt -X- _ B-DatasetName
, -X- _ O
DDI -X- _ B-DatasetName
, -X- _ O
i2b2 -X- _ B-DatasetName
, -X- _ O
and -X- _ O
HoC -X- _ B-DatasetName
) -X- _ O
. -X- _ O
RoBERTa -X- _ B-MethodName
's -X- _ O
performance -X- _ O
was -X- _ O
already -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
in -X- _ O
the -X- _ O
initial -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
stage -X- _ O
because -X- _ O
it -X- _ O
was -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
more -X- _ O
data -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
exhibited -X- _ O
a -X- _ O
greater -X- _ O
robustness -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
on -X- _ O
RoBERTa -X- _ B-MethodName
imply -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
framework -X- _ O
can -X- _ O
be -X- _ O
effectively -X- _ O
applied -X- _ O
to -X- _ O
emerging -X- _ O
and -X- _ O
advanced -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
knowledge -X- _ O
can -X- _ O
be -X- _ O
transferred -X- _ O
into -X- _ O
advanced -X- _ O
models -X- _ O
without -X- _ O
a -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
pre- -X- _ O
training -X- _ O
and -X- _ O
perturbing -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
efficacy -X- _ O
in -X- _ O
the -X- _ O
general -X- _ O
domain -X- _ O
. -X- _ O
To -X- _ O
compare -X- _ O
our -X- _ O
approach -X- _ O
with -X- _ O
the -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
method -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
PM -X- _ I-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
model -X- _ O
additionally -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
large -X- _ O
biomedical -X- _ O
and -X- _ O
clinical -X- _ O
corpus -X- _ O
consisting -X- _ O
of -X- _ O
14 -X- _ O
billion -X- _ O
words -X- _ O
. -X- _ O
We -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
the -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
PM -X- _ I-MethodName
for -X- _ O
each -X- _ O
task -X- _ O
. -X- _ O

By -X- _ O
applying -X- _ O
the -X- _ O
DoKTra -X- _ B-MethodName
framework -X- _ O
, -X- _ O
the -X- _ O
ALBERT -X- _ B-MethodName
- -X- _ I-MethodName
xlarge -X- _ I-MethodName
student -X- _ O
model -X- _ O
was -X- _ O
able -X- _ O
to -X- _ O
retain -X- _ O
99.72 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
an -X- _ O
average -X- _ O
. -X- _ O
ALBERT -X- _ B-MethodName
has -X- _ O
two -X- _ O
advantages -X- _ O
: -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
and -X- _ O
high -X- _ O
performance -X- _ O
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Applying -X- _ O
our -X- _ O
framework -X- _ O
to -X- _ O
ALBERT -X- _ B-MethodName
allowed -X- _ O
us -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
student -X- _ O
model -X- _ O
with -X- _ O
performance -X- _ O
comparable -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
with -X- _ O
half -X- _ O
the -X- _ O
parameters -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
we -X- _ O
successfully -X- _ O
transferred -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
knowledge -X- _ O
to -X- _ O
AL -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
while -X- _ O
maintaining -X- _ O
its -X- _ O
existing -X- _ O
advantages -X- _ O
. -X- _ O
Consequently -X- _ O
, -X- _ O
the -X- _ O
distilled -X- _ O
ALBERT -X- _ B-MethodName
achieved -X- _ O
a -X- _ O
higher -X- _ O
performance -X- _ O
than -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
on -X- _ O
ChemProt -X- _ B-DatasetName
and -X- _ O
DDI -X- _ B-DatasetName
. -X- _ O

The -X- _ O
experiments -X- _ O
were -X- _ O
run -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
RTX -X- _ O
3090 -X- _ O
24 -X- _ O
GB -X- _ O
GPU -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
training -X- _ O
codes -X- _ O
were -X- _ O
implemented -X- _ O
in -X- _ O
PyTorch -X- _ O
. -X- _ O
All -X- _ O
experiments -X- _ O
were -X- _ O
repeated -X- _ O
three -X- _ B-HyperparameterValue
times -X- _ O
with -X- _ O
different -X- _ O
random -X- _ O
seeds -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
average -X- _ O
performances -X- _ O
and -X- _ O
standard -X- _ O
deviations -X- _ O
have -X- _ O
been -X- _ O
reported -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
overall -X- _ O
experimental -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
DoKTra -X- _ B-MethodName
framework -X- _ O
on -X- _ O
five -X- _ O
biomedical -X- _ B-TaskName
and -X- _ O
clinical -X- _ B-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
. -X- _ O
The -X- _ O
initially -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
student -X- _ O
models -X- _ O
are -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
and -X- _ O
fourth -X- _ O
rows -X- _ O
and -X- _ O
the -X- _ O
DoKTra -X- _ B-MethodName
framework -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
both -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
third -X- _ O
and -X- _ O
fifth -X- _ O
rows -X- _ O
. -X- _ O

We -X- _ O
pre -X- _ O
- -X- _ O
process -X- _ O
every -X- _ O
classification -X- _ O
dataset -X- _ O
except -X- _ O
for -X- _ O
GAD -X- _ B-DatasetName
in -X- _ O
the -X- _ O
same -X- _ O
manner -X- _ O
as -X- _ O
the -X- _ O
BLUE -X- _ B-MethodName
( -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
benchmark -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
entity -X- _ O
anonymization -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
all -X- _ O
relation -X- _ O
extraction -X- _ O
datasets -X- _ O
, -X- _ O
which -X- _ O
replace -X- _ O
the -X- _ O
entity -X- _ O
mentions -X- _ O
with -X- _ O
anonymous -X- _ O
tokens -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
@GENE$ -X- _ O
, -X- _ O
@DISEASE$ -X- _ O
) -X- _ O
to -X- _ O
avoid -X- _ O
confusion -X- _ O
in -X- _ O
using -X- _ O
complex -X- _ O
entity -X- _ O
names -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
processed -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
GAD -X- _ B-DatasetName
dataset -X- _ O
provided -X- _ O
by -X- _ O
BioBERT -X- _ B-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
split -X- _ O
for -X- _ O
10 -X- _ O
- -X- _ O
fold -X- _ O
cross -X- _ O
- -X- _ O
validation -X- _ O
. -X- _ O
The -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
processed -X- _ O
downstream -X- _ O
task -X- _ O
datasets -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
For -X- _ O
the -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BioBERT -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
model -X- _ O
( -X- _ O
L=12 -X- _ B-HyperparameterName
, -X- _ O
H=768 -X- _ B-HyperparameterName
, -X- _ O
A=12 -X- _ B-HyperparameterName
) -X- _ O
as -X- _ O
the -X- _ O
initial -X- _ O
teacher -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
two -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
as -X- _ O
the -X- _ O
initial -X- _ O
student -X- _ O
model -X- _ O
: -X- _ O
ALBERT -X- _ B-MethodName
- -X- _ I-MethodName
xlarge -X- _ I-MethodName
( -X- _ O
L=24 -X- _ B-HyperparameterName
, -X- _ O
H=2048 -X- _ B-HyperparameterName
, -X- _ O
A=32 -X- _ B-HyperparameterName
) -X- _ O
and -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
( -X- _ O
L=24 -X- _ B-HyperparameterName
, -X- _ O
H=1024 -X- _ B-HyperparameterName
, -X- _ O
A=16 -X- _ B-HyperparameterName
) -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
previous -X- _ O
description -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
assumed -X- _ O
that -X- _ O
the -X- _ O
embedding -X- _ B-HyperparameterName
dimensions -X- _ I-HyperparameterName
of -X- _ O
teachers -X- _ O
and -X- _ O
students -X- _ O
are -X- _ O
identical -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
because -X- _ O
the -X- _ O
hidden -X- _ B-HyperparameterName
embedding -X- _ I-HyperparameterName
dimensions -X- _ I-HyperparameterName
of -X- _ O
teachers -X- _ O
and -X- _ O
students -X- _ O
are -X- _ O
different -X- _ O
in -X- _ O
our -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
applied -X- _ O
a -X- _ O
linear -X- _ O
transformation -X- _ O
to -X- _ O
the -X- _ O
teacher -X- _ O
's -X- _ O
classification -X- _ O
embedding -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
dimension -X- _ O
with -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
calibrated -X- _ O
teacher -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
trained -X- _ O
for -X- _ O
3 -X- _ B-HyperparameterValue
- -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e-5 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
hyperparameter -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
, -X- _ O
the -X- _ O
strength -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
confidence -X- _ I-HyperparameterName
penalty -X- _ I-HyperparameterName
in -X- _ O
teacher -X- _ O
training -X- _ O
, -X- _ O
was -X- _ O
chosen -X- _ O
from -X- _ O
{ -X- _ O
0 -X- _ B-HyperparameterValue
, -X- _ O
0.3 -X- _ B-HyperparameterValue
, -X- _ O
0.5 -X- _ B-HyperparameterValue
, -X- _ O
0.7 -X- _ B-HyperparameterValue
} -X- _ O
. -X- _ O
For -X- _ O
activation -X- _ O
boundary -X- _ O
distillation -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
the -X- _ O
initial -X- _ O
student -X- _ O
model -X- _ O
for -X- _ O
5 -X- _ B-HyperparameterValue
- -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
of -X- _ O
{ -X- _ O
6e-6 -X- _ B-HyperparameterValue
, -X- _ O
8e-6 -X- _ B-HyperparameterValue
, -X- _ O
1e-5 -X- _ B-HyperparameterValue
} -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
distilled -X- _ O
for -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ B-HyperparameterName
learning -X- _ I-HyperparameterName
rates -X- _ I-HyperparameterName
of -X- _ O
{ -X- _ O
6e-6 -X- _ B-HyperparameterValue
, -X- _ O
8e-6 -X- _ B-HyperparameterValue
, -X- _ O
1e-5 -X- _ B-HyperparameterValue
} -X- _ O
. -X- _ O
The -X- _ O
confidence -X- _ B-HyperparameterName
penalty -X- _ I-HyperparameterName
strength -X- _ I-HyperparameterName
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
in -X- _ O
the -X- _ O
refinement -X- _ O
step -X- _ O
and -X- _ O
loss -X- _ B-HyperparameterName
switch -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
γ -X- _ B-HyperparameterName
were -X- _ O
chosen -X- _ O
from -X- _ O
{ -X- _ O
0 -X- _ B-HyperparameterValue
, -X- _ O
0.3 -X- _ B-HyperparameterValue
, -X- _ B-HyperparameterValue
0.5 -X- _ I-HyperparameterValue
, -X- _ O
0.7 -X- _ B-HyperparameterValue
} -X- _ O
and -X- _ O
{ -X- _ O
0.6 -X- _ B-HyperparameterValue
, -X- _ O
0.7 -X- _ B-HyperparameterValue
, -X- _ O
0.8 -X- _ B-HyperparameterValue
, -X- _ O
0.9 -X- _ B-HyperparameterValue
} -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
margin -X- _ B-HyperparameterName
µ -X- _ B-HyperparameterName
of -X- _ O
the -X- _ O
activation -X- _ O
transfer -X- _ O
loss -X- _ O
was -X- _ O
set -X- _ O
to -X- _ O
1.0 -X- _ B-HyperparameterValue
. -X- _ O
Every -X- _ O
hyperparameter -X- _ O
was -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
selected -X- _ O
hyperparameters -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O

The -X- _ O
relation -X- _ B-TaskName
extraction -X- _ I-TaskName
task -X- _ O
aims -X- _ O
to -X- _ O
classify -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
two -X- _ O
entities -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
gene -X- _ O
, -X- _ O
chemical -X- _ O
, -X- _ O
and -X- _ O
disease -X- _ O
) -X- _ O
that -X- _ O
are -X- _ O
already -X- _ O
annotated -X- _ O
. -X- _ O
The -X- _ O
ChemProt -X- _ B-DatasetName
( -X- _ O
Krallinger -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
dataset -X- _ O
contains -X- _ O
PubMed -X- _ O
abstracts -X- _ O
with -X- _ O
10 -X- _ O
types -X- _ O
of -X- _ O
chemicalprotein -X- _ O
interaction -X- _ O
annotations -X- _ O
and -X- _ O
only -X- _ O
five -X- _ O
of -X- _ O
the -X- _ O
types -X- _ O
are -X- _ O
used -X- _ O
for -X- _ O
evaluation -X- _ O
. -X- _ O
The -X- _ O
GAD -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Bravo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
consists -X- _ O
of -X- _ O
gene -X- _ O
- -X- _ O
disease -X- _ O
binary -X- _ O
relation -X- _ O
annotations -X- _ O
. -X- _ O
The -X- _ O
DDI -X- _ B-DatasetName
( -X- _ O
Herrero -X- _ O
- -X- _ O
Zazo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
dataset -X- _ O
consists -X- _ O
of -X- _ O
text -X- _ O
from -X- _ O
the -X- _ O
DrugBank -X- _ O
database -X- _ O
and -X- _ O
Medline -X- _ O
abstracts -X- _ O
, -X- _ O
with -X- _ O
four -X- _ O
types -X- _ O
of -X- _ O
drug -X- _ O
- -X- _ O
drug -X- _ O
interaction -X- _ O
annotations -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
clinical -X- _ O
domain -X- _ O
, -X- _ O
the -X- _ O
i2b2 -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Uzuner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
contains -X- _ O
texts -X- _ O
from -X- _ O
clinical -X- _ O
documents -X- _ O
, -X- _ O
and -X- _ O
eight -X- _ O
types -X- _ O
of -X- _ O
relations -X- _ O
between -X- _ O
medical -X- _ O
problems -X- _ O
and -X- _ O
treatments -X- _ O
have -X- _ O
been -X- _ O
annotated -X- _ O
. -X- _ O
The -X- _ O
HoC -X- _ B-DatasetName
( -X- _ O
Baker -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
corpus -X- _ O
consists -X- _ O
of -X- _ O
PubMed -X- _ O
abstracts -X- _ O
with -X- _ O
ten -X- _ O
types -X- _ O
of -X- _ O
hallmarks -X- _ O
of -X- _ O
cancer -X- _ O
annotation -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
HoC -X- _ B-DatasetName
dataset -X- _ O
is -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
label -X- _ O
document -X- _ B-MethodName
classification -X- _ I-MethodName
task -X- _ O
predicting -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
labels -X- _ O
from -X- _ O
an -X- _ O
input -X- _ O
text -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
two -X- _ O
PLMs -X- _ O
as -X- _ O
the -X- _ O
initial -X- _ O
student -X- _ O
model -X- _ O
: -X- _ O
ALBERT -X- _ B-MethodName
- -X- _ I-MethodName
xlarge -X- _ I-MethodName
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
a -X- _ O
smaller -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
but -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
and -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
, -X- _ O
which -X- _ O
has -X- _ O
a -X- _ O
larger -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
and -X- _ O
is -X- _ O
known -X- _ O
to -X- _ O
outperform -X- _ O
BERT -X- _ B-MethodName
significantly -X- _ O
for -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
tasks -X- _ O
. -X- _ O
To -X- _ O
distil -X- _ O
the -X- _ O
knowledge -X- _ O
from -X- _ O
a -X- _ O
teacher -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
to -X- _ O
provide -X- _ O
initial -X- _ O
knowledge -X- _ O
about -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
Then -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
L -X- _ O
AT -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
add -X- _ O
a -X- _ O
few -X- _ O
refinement -X- _ O
steps -X- _ O
to -X- _ O
refine -X- _ O
the -X- _ O
classification -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O
Because -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
already -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
before -X- _ O
the -X- _ O
distillation -X- _ O
step -X- _ O
, -X- _ O
this -X- _ O
additional -X- _ O
refinement -X- _ O
may -X- _ O
cause -X- _ O
overconfidence -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
a -X- _ O
confidence -X- _ O
penalty -X- _ O
regularization -X- _ O
in -X- _ O
the -X- _ O
refinement -X- _ O
step -X- _ O
. -X- _ O
Namely -X- _ O
, -X- _ O
the -X- _ O
student -X- _ O
is -X- _ O
refined -X- _ O
with -X- _ O
L -X- _ O
cls -X- _ O
after -X- _ O
the -X- _ O
distillation -X- _ O
steps -X- _ O
. -X- _ O
We -X- _ O
add -X- _ O
a -X- _ O
hyperparameter -X- _ B-HyperparameterName
γ -X- _ I-HyperparameterName
∈ -X- _ O
[ -X- _ O
0 -X- _ B-HyperparameterValue
, -X- _ O
1 -X- _ B-HyperparameterValue
] -X- _ O
, -X- _ O
which -X- _ O
determines -X- _ O
when -X- _ O
the -X- _ O
training -X- _ O
loss -X- _ O
is -X- _ O
switched -X- _ O
from -X- _ O
distillation -X- _ O
to -X- _ O
refinement -X- _ O
. -X- _ O
The -X- _ O
procedure -X- _ O
of -X- _ O
the -X- _ O
DoKTra -X- _ B-MethodName
framework -X- _ O
is -X- _ O
summarized -X- _ O
in -X- _ O
Algorithm -X- _ O
1.Input -X- _ O
: -X- _ O
Downstream -X- _ O
task -X- _ O
data -X- _ O
D -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
k -X- _ O
, -X- _ O
y -X- _ O
k -X- _ O
} -X- _ O
N -X- _ O
k=1 -X- _ O
, -X- _ O
hyperparameter -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
, -X- _ O
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
, -X- _ O
γ -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
: -X- _ O

We -X- _ O
apply -X- _ O
our -X- _ O
framework -X- _ O
to -X- _ O
the -X- _ O
biomedical -X- _ O
domain -X- _ O
and -X- _ O
verify -X- _ O
its -X- _ O
effectiveness -X- _ O
by -X- _ O
conducting -X- _ O
experiments -X- _ O
on -X- _ O
several -X- _ O
biomedical -X- _ O
and -X- _ O
clinical -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
Consequent -X- _ O
to -X- _ O
applying -X- _ O
our -X- _ O
framework -X- _ O
to -X- _ O
ALBERT -X- _ B-MethodName
and -X- _ O
RoBERTa -X- _ B-MethodName
student -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
were -X- _ O
able -X- _ O
to -X- _ O
obtain -X- _ O
models -X- _ O
that -X- _ O
retained -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
's -X- _ O
performance -X- _ O
with -X- _ O
fewer -X- _ O
model -X- _ O
parameters -X- _ O
( -X- _ O
ALBERT -X- _ B-MethodName
) -X- _ O
, -X- _ O
and -X- _ O
models -X- _ O
with -X- _ O
a -X- _ O
higher -X- _ O
performance -X- _ O
than -X- _ O
both -X- _ O
students -X- _ O
and -X- _ O
teachers -X- _ O
( -X- _ O
RoBERTa -X- _ B-MethodName
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
investigate -X- _ O
the -X- _ O
general -X- _ O
applicability -X- _ O
of -X- _ O
our -X- _ O
framework -X- _ O
by -X- _ O
applying -X- _ O
it -X- _ O
to -X- _ O
a -X- _ O
financial -X- _ O
domain -X- _ O
PLM -X- _ O
and -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
The -X- _ O
contributions -X- _ O
of -X- _ O
this -X- _ O
study -X- _ O
can -X- _ O
be -X- _ O
summarized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

However -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
must -X- _ O
be -X- _ O
further -X- _ O
improved -X- _ O
for -X- _ O
tasks -X- _ O
requiring -X- _ O
domain -X- _ O
knowledge -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
those -X- _ O
in -X- _ O
the -X- _ O
biomedical -X- _ O
or -X- _ O
financial -X- _ O
domains -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
usually -X- _ O
consist -X- _ O
of -X- _ O
general -X- _ O
domain -X- _ O
text -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Wikipedia -X- _ O
) -X- _ O
. -X- _ O
Additional -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
with -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
text -X- _ O
has -X- _ O
been -X- _ O
proposed -X- _ O
to -X- _ O
provide -X- _ O
the -X- _ O
PLMs -X- _ O
with -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
knowledge -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
biomedical -X- _ O
domain -X- _ O
, -X- _ O
several -X- _ O
domainspecific -X- _ O
PLMs -X- _ O
trained -X- _ O
with -X- _ O
large -X- _ O
biomedical -X- _ O
texts -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
BioBERT -X- _ B-MethodName
, -X- _ O
PubMedBERT -X- _ B-MethodName
( -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
BlueBERT -X- _ B-MethodName
( -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
have -X- _ O
been -X- _ O
successfully -X- _ O
used -X- _ O
as -X- _ O
strong -X- _ O
baselines -X- _ O
for -X- _ O
several -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
additional -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
has -X- _ O
several -X- _ O
limitations -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
sufficient -X- _ O
training -X- _ O
data -X- _ O
and -X- _ O
resources -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
longer -X- _ O
training -X- _ O
time -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
whenever -X- _ O
a -X- _ O
new -X- _ O
PLM -X- _ O
emerges -X- _ O
, -X- _ O
it -X- _ O
must -X- _ O
be -X- _ O
re -X- _ O
- -X- _ O
trained -X- _ O
to -X- _ O
create -X- _ O
more -X- _ O
advanced -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
models -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
transformer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017)-based -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
successfully -X- _ O
applied -X- _ O
in -X- _ O
the -X- _ O
field -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
the -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
approach -X- _ O
of -X- _ O
" -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
" -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
has -X- _ O
become -X- _ O
the -X- _ O
standard -X- _ O
for -X- _ O
NLP -X- _ O
applications -X- _ O
. -X- _ O
Generally -X- _ O
, -X- _ O
a -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
is -X- _ O
pretrained -X- _ O
with -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
text -X- _ O
data -X- _ O
in -X- _ O
an -X- _ O
unsu- -X- _ O
* -X- _ O
Hyunju -X- _ O
Lee -X- _ O
is -X- _ O
the -X- _ O
corresponding -X- _ O
author -X- _ O
. -X- _ O
pervised -X- _ O
manner -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
dataset -X- _ O
for -X- _ O
several -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
advanced -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
PLMs -X- _ O
) -X- _ O
with -X- _ O
improved -X- _ O
architectures -X- _ O
or -X- _ O
training -X- _ O
methods -X- _ O
continue -X- _ O
to -X- _ O
emerge -X- _ O
, -X- _ O
including -X- _ B-MethodName
ALBERT -X- _ I-MethodName
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
RoBERTa -X- _ B-MethodName
. -X- _ O

For -X- _ O
γ -X- _ B-HyperparameterName
analysis -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
consistency -X- _ O
of -X- _ O
recognition -X- _ O
results -X- _ O
and -X- _ O
similarity -X- _ O
score -X- _ O
by -X- _ O
teachers -X- _ O
. -X- _ O
The -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
score -X- _ O
and -X- _ O
similarity -X- _ O
score -X- _ O
of -X- _ O
teachers -X- _ O
are -X- _ O
all -X- _ O
higher -X- _ O
in -X- _ O
the -X- _ O
higher -X- _ O
γ -X- _ B-HyperparameterName
intervals -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
6c -X- _ O
. -X- _ O
The -X- _ O
student -X- _ O
model -X- _ O
learns -X- _ O
less -X- _ O
from -X- _ O
unreasonable -X- _ O
results -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
can -X- _ O
make -X- _ O
more -X- _ O
accurate -X- _ O
entity -X- _ B-TaskName
recognition -X- _ I-TaskName
for -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
unsupervised -X- _ O
multipletask -X- _ B-MethodName
and -X- _ I-MethodName
multiple -X- _ I-MethodName
- -X- _ I-MethodName
teacher -X- _ I-MethodName
model -X- _ I-MethodName
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O
The -X- _ O
student -X- _ O
model -X- _ O
learns -X- _ O
two -X- _ O
source -X- _ O
language -X- _ O
patterns -X- _ O
of -X- _ O
entity -X- _ B-TaskName
recognition -X- _ I-TaskName
and -X- _ O
entity -X- _ B-TaskName
similarity -X- _ I-TaskName
evaluation -X- _ I-TaskName
. -X- _ O
Moreover -X- _ O
, -X- _ O
to -X- _ O
guarantee -X- _ O
the -X- _ O
student -X- _ O
learning -X- _ O
performance -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
propose -X- _ O
a -X- _ O
weighting -X- _ O
strategy -X- _ O
to -X- _ O
take -X- _ O
into -X- _ O
consideration -X- _ O
the -X- _ O
reliability -X- _ O
of -X- _ O
the -X- _ O
teachers -X- _ O
. -X- _ O
Our -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
yields -X- _ O
significant -X- _ O
improvements -X- _ O
on -X- _ O
six -X- _ O
target -X- _ O
language -X- _ O
datasets -X- _ O
and -X- _ O
outperforms -X- _ O
the -X- _ O
existing -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
approaches -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
is -X- _ O
supported -X- _ O
partly -X- _ O
by -X- _ O
the -X- _ O
Fundamental -X- _ O
Research -X- _ O
Funds -X- _ O
for -X- _ O
the -X- _ O
Central -X- _ O
Universities -X- _ O
and -X- _ O
by -X- _ O
the -X- _ O
State -X- _ O
Key -X- _ O
Laboratory -X- _ O
of -X- _ O
Software -X- _ O
Development -X- _ O
Environment -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
data -X- _ O
- -X- _ O
augmentation -X- _ O
technique -X- _ O
for -X- _ O
neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
based -X- _ O
on -X- _ O
ROT -X- _ O
- -X- _ O
k -X- _ O
ciphertexts -X- _ O
. -X- _ O
ROT -X- _ O
- -X- _ O
k -X- _ O
is -X- _ O
a -X- _ O
simple -X- _ O
letter -X- _ O
substitution -X- _ O
cipher -X- _ O
that -X- _ O
replaces -X- _ O
a -X- _ O
letter -X- _ O
in -X- _ O
the -X- _ O
plaintext -X- _ O
with -X- _ O
the -X- _ O
kth -X- _ O
letter -X- _ O
after -X- _ O
it -X- _ O
in -X- _ O
the -X- _ O
alphabet -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
generate -X- _ O
multiple -X- _ O
ROT -X- _ O
- -X- _ O
k -X- _ O
ciphertexts -X- _ O
using -X- _ O
different -X- _ O
values -X- _ O
of -X- _ O
k -X- _ O
for -X- _ O
the -X- _ O
plaintext -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
source -X- _ O
side -X- _ O
of -X- _ O
the -X- _ O
parallel -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
leverage -X- _ O
this -X- _ O
enciphered -X- _ O
training -X- _ O
data -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
parallel -X- _ O
data -X- _ O
via -X- _ O
multi -X- _ O
- -X- _ O
source -X- _ O
training -X- _ O
to -X- _ O
improve -X- _ O
neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
. -X- _ O
Our -X- _ O
method -X- _ O
, -X- _ O
CipherDAug -X- _ B-MethodName
, -X- _ O
uses -X- _ O
a -X- _ O
co -X- _ O
- -X- _ O
regularization -X- _ O
- -X- _ O
inspired -X- _ O
training -X- _ O
procedure -X- _ O
, -X- _ O
requires -X- _ O
no -X- _ O
external -X- _ O
data -X- _ O
sources -X- _ O
other -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
uses -X- _ O
a -X- _ O
standard -X- _ O
Transformer -X- _ B-HyperparameterName
to -X- _ O
outperform -X- _ O
strong -X- _ O
data -X- _ O
augmentation -X- _ O
techniques -X- _ O
on -X- _ O
several -X- _ O
datasets -X- _ O
by -X- _ O
a -X- _ O
significant -X- _ O
margin -X- _ O
. -X- _ O
This -X- _ O
technique -X- _ O
combines -X- _ O
easily -X- _ O
with -X- _ O
existing -X- _ O
approaches -X- _ O
to -X- _ O
data -X- _ O
augmentation -X- _ O
, -X- _ O
and -X- _ O
yields -X- _ O
particularly -X- _ O
strong -X- _ O
results -X- _ O
in -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
settings -X- _ O
. -X- _ O
1 -X- _ O

For -X- _ O
β -X- _ B-HyperparameterName
analysis -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
score -X- _ O
are -X- _ O
increasing -X- _ O
with -X- _ O
the -X- _ O
entity -X- _ O
similarity -X- _ O
score -X- _ O
from -X- _ O
0.5 -X- _ O
to -X- _ O
both -X- _ O
sides -X- _ O
0 -X- _ O
and -X- _ O
1 -X- _ O
in -X- _ O
Figure -X- _ O
6b -X- _ O
. -X- _ O
The -X- _ O
encoder -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
obtains -X- _ O
the -X- _ O
clustering -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
with -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
β -X- _ B-HyperparameterName
. -X- _ O

For -X- _ O
α -X- _ B-HyperparameterName
analysis -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
score -X- _ O
in -X- _ O
different -X- _ O
probability -X- _ B-HyperparameterName
intervals -X- _ I-HyperparameterName
of -X- _ O
entity -X- _ O
recognizer -X- _ O
teacher -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
recognizer -X- _ O
teacher -X- _ O
tends -X- _ O
to -X- _ O
predict -X- _ O
more -X- _ O
correct -X- _ O
in -X- _ O
higher -X- _ O
probability -X- _ B-HyperparameterName
interval -X- _ I-HyperparameterName
, -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
6a -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
better -X- _ O
suited -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
with -X- _ O
learning -X- _ O
fewer -X- _ O
low -X- _ O
- -X- _ O
confidence -X- _ O
misrecognitions -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O

( -X- _ O
3 -X- _ O
) -X- _ O
MTMT -X- _ B-MethodName
w/o -X- _ O
similarity -X- _ O
, -X- _ O
which -X- _ O
removes -X- _ O
the -X- _ O
similarity -X- _ O
teacher -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
degrades -X- _ O
into -X- _ O
the -X- _ O
single -X- _ O
teacherstudent -X- _ O
learning -X- _ O
model -X- _ O
as -X- _ O
in -X- _ O
TSL -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
Without -X- _ O
the -X- _ O
similarity -X- _ O
knowledge -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
drops -X- _ O
significantly -X- _ O
. -X- _ O
We -X- _ O
give -X- _ O
a -X- _ O
case -X- _ O
study -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
failed -X- _ O
cases -X- _ O
of -X- _ O
baseline -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
corrected -X- _ O
by -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
try -X- _ O
to -X- _ O
bring -X- _ O
up -X- _ O
insights -X- _ O
on -X- _ O
why -X- _ O
the -X- _ O
proposed -X- _ O
multiple -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
and -X- _ I-MethodName
multiple -X- _ I-MethodName
- -X- _ I-MethodName
teacher -X- _ I-MethodName
model -X- _ I-MethodName
works -X- _ O
. -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
MTMT -X- _ B-MethodName
w/o -X- _ O
weighting -X- _ O
, -X- _ O
which -X- _ O
set -X- _ O
the -X- _ O
α -X- _ B-HyperparameterName
( -X- _ I-HyperparameterName
• -X- _ I-HyperparameterName
) -X- _ I-HyperparameterName
, -X- _ O
β -X- _ B-HyperparameterName
and -X- _ O
γ -X- _ B-HyperparameterName
all -X- _ O
to -X- _ O
be -X- _ O
1 -X- _ B-HyperparameterValue
in -X- _ O
the -X- _ O
loss -X- _ O
of -X- _ O
student -X- _ O
learning -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
decrease -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
score -X- _ O
ranges -X- _ O
from -X- _ O
0.45 -X- _ B-MetricValue
for -X- _ O
Dutch(nl -X- _ O
) -X- _ O
to -X- _ O
0.98 -X- _ B-MetricValue
for -X- _ O
Spanish(es -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
validates -X- _ O
that -X- _ O
weighting -X- _ O
loss -X- _ O
can -X- _ O
bring -X- _ O
more -X- _ O
confident -X- _ O
knowledge -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O

( -X- _ O
1 -X- _ O
) -X- _ O
MTST -X- _ B-MethodName
, -X- _ O
which -X- _ O
combines -X- _ O
the -X- _ O
multiple -X- _ O
- -X- _ O
teacher -X- _ O
to -X- _ O
single -X- _ O
- -X- _ O
teacher -X- _ O
. -X- _ O
That -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
has -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
neural -X- _ O
network -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O
This -X- _ O
causes -X- _ O
a -X- _ O
performance -X- _ O
drop -X- _ O
across -X- _ O
all -X- _ O
languages -X- _ O
due -X- _ O
to -X- _ O
two -X- _ O
single -X- _ O
teachers -X- _ O
can -X- _ O
not -X- _ O
make -X- _ O
a -X- _ O
difference -X- _ O
with -X- _ O
the -X- _ O
combination -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
f -X- _ I-MethodName
performs -X- _ O
better -X- _ O
than -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
Chinese -X- _ O
dataset -X- _ O
due -X- _ O
to -X- _ O
their -X- _ O
re -X- _ O
- -X- _ O
tokenization -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
latest -X- _ O
model -X- _ O
TOF -X- _ B-MethodName
, -X- _ O
RIKD -X- _ B-MethodName
, -X- _ O
Unitrans -X- _ B-MethodName
, -X- _ O
our -X- _ O
model -X- _ O
requires -X- _ O
much -X- _ O
lower -X- _ O
computational -X- _ O
costs -X- _ O
for -X- _ O
both -X- _ O
translation -X- _ O
and -X- _ O
iterative -X- _ O
knowledge -X- _ O
distillation -X- _ O
, -X- _ O
meanwhile -X- _ O
reaching -X- _ O
superior -X- _ O
performance -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
against -X- _ O
the -X- _ O
version -X- _ O
of -X- _ O
TOF -X- _ B-MethodName
w/o -X- _ O
continual -X- _ O
learning -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
RIKD -X- _ B-MethodName
w/o -X- _ O
IKD -X- _ O
( -X- _ O
Liang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
Unitrans -X- _ B-MethodName
w/o -X- _ O
translation -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
as -X- _ O
reported -X- _ O
in -X- _ O
their -X- _ O
paper -X- _ O
. -X- _ O
To -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
designed -X- _ O
the -X- _ O
following -X- _ O
ablation -X- _ O
studies -X- _ O
. -X- _ O
Table -X- _ O
5 -X- _ O
presents -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O

It -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
outperforms -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
arts -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
remarkable -X- _ O
RIKD -X- _ B-MethodName
, -X- _ O
AdvPicker -X- _ B-MethodName
, -X- _ O
and -X- _ O
Unitrans -X- _ B-MethodName
, -X- _ O
which -X- _ O
also -X- _ O
use -X- _ O
knowledge -X- _ O
distillation -X- _ O
but -X- _ O
ignore -X- _ O
the -X- _ O
entity -X- _ O
similarity -X- _ O
knowledge -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
obtains -X- _ O
significant -X- _ O
and -X- _ O
consistent -X- _ O
improvements -X- _ O
in -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
score -X- _ O
ranging -X- _ O
from -X- _ O
0.23 -X- _ B-MetricValue
for -X- _ O
German -X- _ O
[ -X- _ O
de -X- _ O
] -X- _ O
to -X- _ O
6.81 -X- _ B-MetricValue
for -X- _ O
Arabic -X- _ O
[ -X- _ O
ar -X- _ O
] -X- _ O
. -X- _ O
That -X- _ O
demonstrates -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
MTMT -X- _ B-MethodName
model -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
direct -X- _ O
model -X- _ O
transfer -X- _ O
( -X- _ O
Wu -X- _ O
and -X- _ O
Dredze -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

TOF -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
transfers -X- _ O
knowledge -X- _ O
from -X- _ O
three -X- _ O
aspects -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O

RIKD -X- _ B-MethodName
( -X- _ O
Liang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
develops -X- _ O
a -X- _ O
reinforced -X- _ O
iterative -X- _ O
knowledge -X- _ O
distillation -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O

AdvPicker -X- _ B-MethodName
proposes -X- _ O
a -X- _ O
adversarial -X- _ O
discriminator -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O

We -X- _ O
set -X- _ O
our -X- _ O
hyperparameters -X- _ O
empirically -X- _ O
following -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020c -X- _ O
) -X- _ O
with -X- _ O
some -X- _ O
modifications -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
freeze -X- _ O
any -X- _ O
layers -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
as -X- _ O
our -X- _ O
hidden -X- _ O
feature -X- _ O
vector -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ B-HyperparameterName
batch -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
to -X- _ O
be -X- _ O
32 -X- _ B-HyperparameterValue
, -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
to -X- _ O
be -X- _ O
128 -X- _ B-HyperparameterValue
, -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
be -X- _ O
0.2 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
Adam -X- _ B-HyperparameterValue
as -X- _ O
optimizer -X- _ B-HyperparameterName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
recognition -X- _ O
teacher -X- _ O
model -X- _ O
and -X- _ O
similarity -X- _ O
teacher -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
be -X- _ O
1e-5 -X- _ B-HyperparameterValue
and -X- _ O
5e-6 -X- _ B-HyperparameterValue
separately -X- _ O
. -X- _ O
For -X- _ O
knowledge -X- _ O
distillation -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e-6 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
student -X- _ O
models -X- _ O
training -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
if -X- _ O
a -X- _ O
word -X- _ O
is -X- _ O
divided -X- _ O
into -X- _ O
several -X- _ O
subwords -X- _ O
after -X- _ O
tokenization -X- _ O
, -X- _ O
then -X- _ O
only -X- _ O
the -X- _ O
first -X- _ O
subword -X- _ O
is -X- _ O
considered -X- _ O
in -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
. -X- _ O
Following -X- _ O
( -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
entity -X- _ B-MetricName
level -X- _ I-MetricName
F1 -X- _ I-MetricName
- -X- _ O
score -X- _ O
as -X- _ O
the -X- _ O
evaluation -X- _ O
metric -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
each -X- _ O
experiment -X- _ O
5 -X- _ B-HyperparameterValue
times -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
mean -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
score -X- _ O
. -X- _ O
( -X- _ O
Tsai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
48.12 -X- _ B-MetricValue
60.55 -X- _ B-MetricValue
61.56 -X- _ B-MetricValue
WS -X- _ B-MethodName
( -X- _ O
Ni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
58.50 -X- _ B-MetricValue
65.10 -X- _ B-MetricValue
65.40 -X- _ B-MetricValue
TMP -X- _ B-MethodName
( -X- _ O
Jain -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
61.50 -X- _ B-MetricValue
73.50 -X- _ B-MetricValue
69.9 -X- _ B-MetricValue
BERT -X- _ B-MethodName
- -X- _ I-MethodName
f -X- _ I-MethodName
( -X- _ O
Wu -X- _ O
and -X- _ O
Dredze -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
69.56 -X- _ B-MetricValue
74.96 -X- _ B-MetricValue
77.57 -X- _ B-MetricValue
AdvCE -X- _ B-MethodName
( -X- _ O
Keung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
71.90 -X- _ B-MetricValue
74.3 -X- _ B-MetricValue
77.6 -X- _ B-MetricValue
TSL -X- _ B-MethodName
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
73.16 -X- _ B-MetricValue
76.75 -X- _ B-MetricValue
80.44 -X- _ B-MetricValue
Unitrans -X- _ B-MethodName
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
74 -X- _ O
TSL -X- _ B-MethodName
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020c -X- _ O
) -X- _ O
proposes -X- _ O
a -X- _ O
teacher -X- _ O
- -X- _ O
student -X- _ O
learning -X- _ O
model -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER.Unitrans -X- _ I-TaskName
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
unifies -X- _ O
a -X- _ O
data -X- _ O
transfer -X- _ O
and -X- _ O
model -X- _ O
transfer -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O

α -X- _ O
( -X- _ O
• -X- _ O
) -X- _ O
= -X- _ O
( -X- _ O
max(ŷ -X- _ O
T -X- _ O
i -X- _ O
) -X- _ O
) -X- _ O
2 -X- _ O
β -X- _ O
= -X- _ O
( -X- _ O
2 -X- _ O
t -X- _ O
T -X- _ O
( -X- _ O
x -X- _ O
T -X- _ O
, -X- _ O
x -X- _ O
T -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
) -X- _ O
− -X- _ O
1 -X- _ O
) -X- _ O
2 -X- _ O
γ -X- _ O
= -X- _ O
1 -X- _ O
− -X- _ O
|σ(cos(ŷ -X- _ O
T -X- _ O
i -X- _ O
, -X- _ O
ŷ -X- _ O
T -X- _ O
j -X- _ O
) -X- _ O
) -X- _ O
−t -X- _ O
T -X- _ O
( -X- _ O
x -X- _ O
T -X- _ O
, -X- _ O
x -X- _ O
T -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j)|In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
multiple -X- _ O
- -X- _ O
task -X- _ O
and -X- _ O
multiple -X- _ O
- -X- _ O
teacher -X- _ O
model -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
and -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
conducted -X- _ O
experiments -X- _ O
on -X- _ O
three -X- _ O
benchmark -X- _ O
datasets -X- _ O
: -X- _ O
CoNLL2002 -X- _ B-DatasetName
( -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
CoNLL2003 -X- _ B-DatasetName
( -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
and -X- _ O
WikiAnn -X- _ B-DatasetName
( -X- _ O
Pan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
CoNLL2002 -X- _ B-DatasetName
includes -X- _ O
Spanish -X- _ O
and -X- _ O
Dutch -X- _ O
, -X- _ O
CoNLL2003 -X- _ B-DatasetName
includes -X- _ O
English -X- _ O
and -X- _ O
German -X- _ O
, -X- _ O
and -X- _ O
WikiAnn -X- _ B-DatasetName
includes -X- _ O
English -X- _ O
and -X- _ O
three -X- _ O
non -X- _ O
- -X- _ O
western -X- _ O
languages -X- _ O
: -X- _ O
Arabic -X- _ O
, -X- _ O
Hindi -X- _ O
, -X- _ O
and -X- _ O
Chinese -X- _ O
. -X- _ O
Each -X- _ O
language -X- _ O
is -X- _ O
divided -X- _ O
into -X- _ O
a -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
a -X- _ O
development -X- _ O
set -X- _ O
and -X- _ O
a -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
All -X- _ O
datasets -X- _ O
were -X- _ O
annotated -X- _ O
with -X- _ O
four -X- _ O
entity -X- _ O
types -X- _ O
: -X- _ O
LOC -X- _ O
, -X- _ O
MISC -X- _ O
, -X- _ O
ORG -X- _ O
, -X- _ O
and -X- _ O
PER -X- _ O
. -X- _ O
Following -X- _ O
( -X- _ O
Wu -X- _ O
and -X- _ O
Dredze -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
all -X- _ O
datasets -X- _ O
are -X- _ O
annotated -X- _ O
using -X- _ O
the -X- _ O
BIO -X- _ O
entity -X- _ O
labelling -X- _ O
scheme -X- _ O
. -X- _ O
To -X- _ O
imitate -X- _ O
the -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
resource -X- _ I-TaskName
cross -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
case -X- _ O
, -X- _ O
following -X- _ O
( -X- _ O
Wu -X- _ O
and -X- _ O
Dredze -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
English -X- _ O
as -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
and -X- _ O
other -X- _ O
languages -X- _ O
as -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O
In -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
, -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
without -X- _ O
entity -X- _ O
label -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
is -X- _ O
also -X- _ O
available -X- _ O
when -X- _ O
training -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
trained -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
labeled -X- _ O
training -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
and -X- _ O
evaluated -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
each -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
and -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
statistics -X- _ O
of -X- _ O
all -X- _ O
datasets -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
PyTorch -X- _ O
1.7.1 -X- _ O
to -X- _ O
implement -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
All -X- _ O
of -X- _ O
the -X- _ O
feature -X- _ O
encoders -X- _ O
mentioned -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
use -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
mBERT -X- _ B-MethodName
model -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
in -X- _ O
HuggingFace -X- _ O
Transformer -X- _ O
1 -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
12 -X- _ B-HyperparameterValue
Transformer -X- _ B-HyperparameterName
blocks -X- _ I-HyperparameterName
, -X- _ O
12 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
768 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
. -X- _ O

where -X- _ O
α -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
, -X- _ O
α -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
, -X- _ O
β -X- _ B-HyperparameterName
, -X- _ O
and -X- _ O
γ -X- _ B-HyperparameterName
are -X- _ O
weights -X- _ O
in -X- _ O
loss -X- _ O
function -X- _ O
which -X- _ O
are -X- _ O
set -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
learns -X- _ O
less -X- _ O
noisy -X- _ O
knowledge -X- _ O
from -X- _ O
teachers -X- _ O
. -X- _ O
The -X- _ O
weights -X- _ O
are -X- _ O
set -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
α -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
( -X- _ O
α -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
) -X- _ O
is -X- _ O
an -X- _ O
increasing -X- _ O
function -X- _ O
concerning -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
recognizer -X- _ O
teacher -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O
And -X- _ O
β -X- _ B-HyperparameterName
is -X- _ O
set -X- _ O
such -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
high -X- _ O
when -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
similarity -X- _ O
teacher -X- _ O
is -X- _ O
close -X- _ O
to -X- _ O
0 -X- _ O
or -X- _ O
1 -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
low -X- _ O
when -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
close -X- _ O
to -X- _ O
0.5 -X- _ O
. -X- _ O
γ -X- _ B-HyperparameterName
indicates -X- _ O
consistency -X- _ B-HyperparameterName
level -X- _ I-HyperparameterName
between -X- _ O
the -X- _ O
outputs -X- _ O
from -X- _ O
two -X- _ O
teacher -X- _ O
models -X- _ O
, -X- _ O
e.g. -X- _ O
for -X- _ O
two -X- _ O
input -X- _ O
tokens -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
output -X- _ O
from -X- _ O
entity -X- _ O
similarity -X- _ O
teacher -X- _ O
is -X- _ O
high -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
similarity -X- _ O
level -X- _ O
computed -X- _ O
from -X- _ O
the -X- _ O
outputs -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
recognizer -X- _ O
teacher -X- _ O
is -X- _ O
low -X- _ O
, -X- _ O
then -X- _ O
their -X- _ O
consistency -X- _ B-HyperparameterName
level -X- _ I-HyperparameterName
is -X- _ O
low -X- _ O
. -X- _ O
We -X- _ O
want -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
from -X- _ O
the -X- _ O
two -X- _ O
teachers -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
the -X- _ O
higher -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
recognizer -X- _ O
teacher -X- _ O
is -X- _ O
( -X- _ O
the -X- _ O
further -X- _ O
away -X- _ O
from -X- _ O
0.5 -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
similarity -X- _ O
teacher -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
higher -X- _ O
the -X- _ O
consistency -X- _ B-HyperparameterName
level -X- _ I-HyperparameterName
is -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
more -X- _ O
accurate -X- _ O
the -X- _ O
prediction -X- _ O
is -X- _ O
, -X- _ O
thus -X- _ O
the -X- _ O
more -X- _ O
attention -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
pays -X- _ O
attention -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
tokens -X- _ O
, -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
heuristically -X- _ O
devises -X- _ O
the -X- _ O
three -X- _ O
weights -X- _ O
scheduling -X- _ O
as -X- _ O
functions -X- _ O
of -X- _ O
the -X- _ O
inputs -X- _ O
, -X- _ O

Siamese -X- _ B-MethodName
Network -X- _ I-MethodName
is -X- _ O
originally -X- _ O
introduced -X- _ O
by -X- _ O
( -X- _ O
Bromley -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1994 -X- _ O
) -X- _ O
to -X- _ O
treat -X- _ O
signature -X- _ B-TaskName
verification -X- _ I-TaskName
as -X- _ O
a -X- _ O
matching -X- _ O
problem -X- _ O
. -X- _ O
It -X- _ O
has -X- _ O
been -X- _ O
successfully -X- _ O
applied -X- _ O
to -X- _ O
transfer -X- _ O
learning -X- _ O
such -X- _ O
as -X- _ O
one -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
image -X- _ I-TaskName
recognition -X- _ I-TaskName
( -X- _ O
Koch -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
text -X- _ B-TaskName
similarity -X- _ I-TaskName
( -X- _ O
Neculoiu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
dilemma -X- _ O
to -X- _ O
adapt -X- _ O
the -X- _ O
siamese -X- _ B-MethodName
network -X- _ I-MethodName
to -X- _ O
tokenlevel -X- _ B-TaskName
recognition -X- _ I-TaskName
tasks -X- _ O
such -X- _ O
as -X- _ O
NER -X- _ B-TaskName
. -X- _ O
Siamese -X- _ B-MethodName
network -X- _ I-MethodName
assumes -X- _ O
the -X- _ O
input -X- _ O
is -X- _ O
a -X- _ O
pair -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
a -X- _ O
similarity -X- _ O
score -X- _ O
. -X- _ O
To -X- _ O
handle -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
reconstruct -X- _ O
the -X- _ O
data -X- _ O
to -X- _ O
pair -X- _ O
format -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
entity -X- _ O
similarity -X- _ O
by -X- _ O
siamese -X- _ B-MethodName
network -X- _ I-MethodName
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
our -X- _ O
framework -X- _ O
and -X- _ O
its -X- _ O
detailed -X- _ O
implementation -X- _ O
. -X- _ O
Our -X- _ O
framework -X- _ O
is -X- _ O
consist -X- _ O
of -X- _ O
two -X- _ O
models -X- _ O
: -X- _ O
teacher -X- _ O
training -X- _ O
model -X- _ O
learned -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
and -X- _ O
teacher -X- _ O
- -X- _ O
student -X- _ O
distillation -X- _ O
learning -X- _ O
model -X- _ O
learned -X- _ O
from -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
teacher -X- _ O
training -X- _ O
model -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
two -X- _ O
sub -X- _ O
- -X- _ O
models -X- _ O
, -X- _ O
i.e. -X- _ O
an -X- _ O
entity -X- _ O
recognizer -X- _ O
teacher -X- _ O
and -X- _ O
a -X- _ O
similarity -X- _ O
evaluator -X- _ O
teacher -X- _ O
. -X- _ O
These -X- _ O
two -X- _ O
models -X- _ O
are -X- _ O
two -X- _ O
parallel -X- _ O
tasks -X- _ O
, -X- _ O
wherein -X- _ O
the -X- _ O
entity -X- _ O
recognition -X- _ O
teacher -X- _ O
focuses -X- _ O
on -X- _ O
identifying -X- _ O
the -X- _ O
named -X- _ O
entities -X- _ O
and -X- _ O
the -X- _ O
similarity -X- _ O
evaluator -X- _ O
teacher -X- _ O
is -X- _ O
to -X- _ O
decide -X- _ O
if -X- _ O
two -X- _ O
tokens -X- _ O
are -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
type -X- _ O
. -X- _ O

Shared -X- _ O
feature -X- _ O
space -X- _ O
based -X- _ O
models -X- _ O
generally -X- _ O
train -X- _ O
a -X- _ O
language -X- _ O
- -X- _ O
independent -X- _ O
encoder -X- _ O
using -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
language -X- _ O
data -X- _ O
( -X- _ O
Tsai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
multilingual -X- _ O
language -X- _ O
model -X- _ O
is -X- _ O
effective -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
challenge -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
some -X- _ O
research -X- _ O
introduces -X- _ O
new -X- _ O
components -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
mBERT -X- _ B-MethodName
by -X- _ O
directly -X- _ O
transferring -X- _ O
the -X- _ O
model -X- _ O
learned -X- _ O
from -X- _ O
the -X- _ O
labeled -X- _ O
source -X- _ O
language -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
target -X- _ O
languages -X- _ O
( -X- _ O
Keung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
is -X- _ O
still -X- _ O
weak -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
annotations -X- _ O
of -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O

Our -X- _ O
main -X- _ O
contributions -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

We -X- _ O
validate -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
three -X- _ O
commonly -X- _ O
- -X- _ O
used -X- _ O
datasets -X- _ O
across -X- _ O
7 -X- _ O
languages -X- _ O
and -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
our -X- _ O
presented -X- _ O
MTMT -X- _ B-MethodName
model -X- _ O
. -X- _ O

To -X- _ O
leverage -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
tokens -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
languages -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
an -X- _ O
multiple -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
and -X- _ I-MethodName
multiple -X- _ I-MethodName
- -X- _ I-MethodName
teacher -X- _ I-MethodName
model -X- _ O
( -X- _ O
short -X- _ O
as -X- _ O
MTMT -X- _ B-MethodName
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
helps -X- _ O
the -X- _ O
NER -X- _ B-TaskName
learning -X- _ O
process -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
introduce -X- _ O
the -X- _ O
knowledge -X- _ O
distillation -X- _ O
to -X- _ O
build -X- _ O
entity -X- _ O
recognizer -X- _ O
and -X- _ O
similarity -X- _ O
evaluator -X- _ O
teachers -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
and -X- _ O
transfer -X- _ O
the -X- _ O
learned -X- _ O
patterns -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
then -X- _ O
borrow -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
multitask -X- _ O
learning -X- _ O
to -X- _ O
incorporate -X- _ O
a -X- _ O
similarity -X- _ B-TaskName
evaluation -X- _ I-TaskName
task -X- _ O
as -X- _ O
an -X- _ O
auxiliary -X- _ O
task -X- _ O
into -X- _ O
the -X- _ O
entity -X- _ B-TaskName
recognition -X- _ I-TaskName
classifier -X- _ O
. -X- _ O
During -X- _ O
the -X- _ O
student -X- _ O
learning -X- _ O
process -X- _ O
, -X- _ O
we -X- _ O
input -X- _ O
unlabelled -X- _ O
samples -X- _ O
from -X- _ O
the -X- _ O
target -X- _ O
languages -X- _ O
into -X- _ O
the -X- _ O
entity -X- _ O
recognizer -X- _ O
and -X- _ O
evaluator -X- _ O
, -X- _ O
and -X- _ O
take -X- _ O
output -X- _ O
pesudo -X- _ O
labels -X- _ O
as -X- _ O
supervisory -X- _ O
signals -X- _ O
for -X- _ O
these -X- _ O
two -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
a -X- _ O
weighting -X- _ O
strategy -X- _ O
is -X- _ O
also -X- _ O
provide -X- _ O
therein -X- _ O
to -X- _ O
take -X- _ O
into -X- _ O
consideration -X- _ O
of -X- _ O
the -X- _ O
reliability -X- _ O
of -X- _ O
the -X- _ O
teachers -X- _ O
. -X- _ O

Although -X- _ O
the -X- _ O
above -X- _ O
- -X- _ O
mentioned -X- _ O
models -X- _ O
solve -X- _ O
the -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
problem -X- _ O
to -X- _ O
some -X- _ O
extent -X- _ O
, -X- _ O
the -X- _ O
auxiliary -X- _ O
tasks -X- _ O
, -X- _ O
as -X- _ O
in -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
, -X- _ O
have -X- _ O
not -X- _ O
been -X- _ O
studied -X- _ O
in -X- _ O
this -X- _ O
problem -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
distributed -X- _ O
representation -X- _ O
of -X- _ O
natural -X- _ O
languages -X- _ O
, -X- _ O
the -X- _ O
relatedness -X- _ O
among -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
target -X- _ O
languages -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
measured -X- _ O
by -X- _ O
the -X- _ O
similarity -X- _ O
, -X- _ O
can -X- _ O
be -X- _ O
utilized -X- _ O
to -X- _ O
further -X- _ O
boost -X- _ O
the -X- _ O
learned -X- _ O
encoder -X- _ O
and -X- _ O
improve -X- _ O
the -X- _ O
final -X- _ O
NER -X- _ B-TaskName
performance -X- _ O
on -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O

Many -X- _ O
studies -X- _ O
have -X- _ O
been -X- _ O
done -X- _ O
to -X- _ O
solve -X- _ O
this -X- _ O
crosslingual -X- _ B-TaskName
NER -X- _ I-TaskName
problem -X- _ O
. -X- _ O
Existing -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
separated -X- _ O
into -X- _ O
three -X- _ O
categories -X- _ O
, -X- _ O
shared -X- _ O
feature -X- _ O
space -X- _ O
based -X- _ O
, -X- _ O
translation -X- _ O
based -X- _ O
and -X- _ O
knowledge -X- _ O
distillation -X- _ O
based -X- _ O
. -X- _ O
Shared -X- _ O
feature -X- _ O
space -X- _ O
based -X- _ O
models -X- _ O
exploit -X- _ O
language -X- _ O
- -X- _ O
independent -X- _ O
features -X- _ O
, -X- _ O
which -X- _ O
lacks -X- _ O
the -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
features -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
( -X- _ O
Tsai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Wu -X- _ O
and -X- _ O
Dredze -X- _ O
, -X- _ O
2019;Keung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Translation -X- _ O
based -X- _ O
models -X- _ O
generate -X- _ O
pseudo -X- _ O
labeled -X- _ O
target -X- _ O
language -X- _ O
data -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
NER -X- _ I-TaskName
model -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
noise -X- _ O
from -X- _ O
translation -X- _ O
process -X- _ O
restrains -X- _ O
its -X- _ O
performance -X- _ O
. -X- _ O
( -X- _ O
Mayhew -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Xie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
Knowledge -X- _ O
distillation -X- _ O
based -X- _ O
models -X- _ O
train -X- _ O
a -X- _ O
student -X- _ O
model -X- _ O
using -X- _ O
soft -X- _ O
labels -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
, -X- _ O
b;Liang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
, -X- _ O
NER -X- _ B-TaskName
in -X- _ O
short -X- _ O
, -X- _ O
refers -X- _ O
to -X- _ O
identifying -X- _ O
entity -X- _ O
types -X- _ O
, -X- _ O
i.e. -X- _ O
location -X- _ O
, -X- _ O
person -X- _ O
, -X- _ O
organization -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
, -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
sentence -X- _ O
. -X- _ O
The -X- _ O
exploiting -X- _ O
of -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
Bi -X- _ B-MethodName
- -X- _ I-MethodName
LSTM -X- _ I-MethodName
- -X- _ I-MethodName
CRF -X- _ I-MethodName
( -X- _ O
Lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
Bi -X- _ B-MethodName
- -X- _ I-MethodName
LSTM- -X- _ I-MethodName
CNN -X- _ I-MethodName
( -X- _ O
Chiu -X- _ O
and -X- _ O
Nichols -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
makes -X- _ O
this -X- _ O
task -X- _ O
achieve -X- _ O
significant -X- _ O
performances -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
since -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
highly -X- _ O
rely -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
labelled -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
the -X- _ O
annotation -X- _ O
acquiring -X- _ O
process -X- _ O
is -X- _ O
expensive -X- _ O
and -X- _ O
time -X- _ O
consuming -X- _ O
. -X- _ O
This -X- _ O
situation -X- _ O
is -X- _ O
more -X- _ O
severe -X- _ O
for -X- _ O
zero -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
transfer -X- _ O
learning -X- _ O
( -X- _ O
Ruder -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
multilingual -X- _ B-MethodName
BERT -X- _ I-MethodName
( -X- _ O
short -X- _ O
as -X- _ O
mBERT -X- _ O
) -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
* -X- _ O
NER -X- _ O
/ -X- _ O
NER -X- _ O
tea -X- _ O
: -X- _ O
learned -X- _ O
NER -X- _ B-TaskName
model -X- _ O
for -X- _ O
source -X- _ O
language -X- _ O
; -X- _ O
NER -X- _ O
stu -X- _ O
: -X- _ O
learned -X- _ O
NER -X- _ B-TaskName
model -X- _ O
for -X- _ O
target -X- _ O
language -X- _ O
; -X- _ O
SIM -X- _ O
tea -X- _ O
learned -X- _ O
similarity -X- _ O
model -X- _ O
for -X- _ O
source -X- _ O
language -X- _ O
; -X- _ O
{ -X- _ O
X -X- _ O
, -X- _ O
Y -X- _ O
} -X- _ O
src -X- _ O
: -X- _ O
labeled -X- _ O
data -X- _ O
in -X- _ O
source -X- _ O
language -X- _ O
; -X- _ O
{ -X- _ O
X -X- _ O
} -X- _ O
tgt -X- _ O
: -X- _ O
unlabeled -X- _ O
data -X- _ O
in -X- _ O
target -X- _ O
language -X- _ O
; -X- _ O
{ -X- _ O
X -X- _ O
, -X- _ O
P -X- _ O
} -X- _ O
tgt -X- _ O
: -X- _ O
labeled -X- _ O
data -X- _ O
in -X- _ O
target -X- _ O
language -X- _ O
with -X- _ O
probability -X- _ O
; -X- _ O
{ -X- _ O
X -X- _ O
, -X- _ O
S -X- _ O
} -X- _ O
tgt -X- _ O
: -X- _ O
labeled -X- _ O
data -X- _ O
in -X- _ O
target -X- _ O
language -X- _ O
with -X- _ O
entity -X- _ O
similarity -X- _ O
score -X- _ O
. -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
transfer -X- _ O
the -X- _ O
annotated -X- _ O
training -X- _ O
samples -X- _ O
or -X- _ O
trained -X- _ O
models -X- _ O
from -X- _ O
a -X- _ O
rich -X- _ O
- -X- _ O
resource -X- _ O
domain -X- _ O
to -X- _ O
a -X- _ O
zero -X- _ O
- -X- _ O
resource -X- _ O
domain -X- _ O
. -X- _ O

As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
from -X- _ O
the -X- _ O
table -X- _ O
, -X- _ O
teachers -X- _ O
with -X- _ O
smaller -X- _ O
length -X- _ B-HyperparameterName
penalty -X- _ I-HyperparameterName
( -X- _ O
i.e. -X- _ O
, -X- _ O
1.0 -X- _ B-HyperparameterValue
or -X- _ O
0.5 -X- _ B-HyperparameterValue
) -X- _ O
can -X- _ O
not -X- _ O
teach -X- _ O
better -X- _ O
students -X- _ O
than -X- _ O
the -X- _ O
Regular -X- _ O
pseudo -X- _ O
- -X- _ O
labeling -X- _ O
or -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
the -X- _ O
detailed -X- _ O
content -X- _ O
of -X- _ O
the -X- _ O
example -X- _ O
in -X- _ O
Section -X- _ O
1 -X- _ O
in -X- _ O
table -X- _ O
12.We -X- _ O
present -X- _ O
more -X- _ O
examples -X- _ O
of -X- _ O
student -X- _ O
models -X- _ O
' -X- _ O
outputs -X- _ O
and -X- _ O
cross -X- _ O
attention -X- _ O
visualization -X- _ O
here -X- _ O
. -X- _ O
The -X- _ O
student -X- _ O
models -X- _ O
are -X- _ O
with -X- _ O
the -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
6 -X- _ I-MethodName
setting -X- _ O
and -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
CNNDM -X- _ B-DatasetName
and -X- _ O
the -X- _ O
following -X- _ O
examples -X- _ O
are -X- _ O
from -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
of -X- _ O
CNNDM -X- _ B-DatasetName
. -X- _ O

It -X- _ O
's -X- _ O
a -X- _ O
more -X- _ O
direct -X- _ O
idea -X- _ O
to -X- _ O
change -X- _ O
the -X- _ O
softmax -X- _ B-HyperparameterName
temperature -X- _ I-HyperparameterName
in -X- _ O
the -X- _ O
final -X- _ O
decoder -X- _ O
layer -X- _ O
rather -X- _ O
than -X- _ O
attention -X- _ B-HyperparameterName
temperatures -X- _ I-HyperparameterName
, -X- _ O
namely -X- _ O
changing -X- _ O
the -X- _ O
T -X- _ B-HyperparameterName
in -X- _ O
equation -X- _ O
5 -X- _ O
to -X- _ O
some -X- _ O
other -X- _ O
values -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
default -X- _ O
value -X- _ O
1.0 -X- _ B-HyperparameterValue
. -X- _ O

We -X- _ O
apply -X- _ O
our -X- _ O
method -X- _ O
on -X- _ O
the -X- _ O
WMT16 -X- _ B-DatasetName
En -X- _ B-TaskName
- -X- _ I-TaskName
De -X- _ I-TaskName
translation -X- _ I-TaskName
task -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Transformer -X- _ B-MethodName
- -X- _ I-MethodName
Big -X- _ I-MethodName
model -X- _ O
as -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
Transformer -X- _ B-MethodName
- -X- _ I-MethodName
Base -X- _ I-MethodName
as -X- _ O
the -X- _ O
student -X- _ O
. -X- _ O
Our -X- _ O
results -X- _ O
on -X- _ O
newstest2014 -X- _ B-DatasetName
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
. -X- _ O
The -X- _ O
student -X- _ O
models -X- _ O
with -X- _ O
our -X- _ O
method -X- _ O
( -X- _ O
λ -X- _ B-HyperparameterName
= -X- _ O
1.5 -X- _ B-HyperparameterValue
and -X- _ O
λ -X- _ B-HyperparameterName
= -X- _ O
2.0 -X- _ B-HyperparameterValue
) -X- _ O
slightly -X- _ O
outperform -X- _ O
the -X- _ O
student -X- _ O
with -X- _ O
regular -X- _ O
pseudo -X- _ O
- -X- _ O
labeling -X- _ O
method -X- _ O
( -X- _ O
λ -X- _ B-HyperparameterName
= -X- _ O
1.0 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
improvement -X- _ O
is -X- _ O
not -X- _ O
as -X- _ O
significant -X- _ O
as -X- _ O
in -X- _ O
summarization -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
We -X- _ O
speculate -X- _ O
the -X- _ O
reason -X- _ O
may -X- _ O
be -X- _ O
that -X- _ O
, -X- _ O
unlike -X- _ O
summarization -X- _ B-TaskName
, -X- _ O
outputs -X- _ O
of -X- _ O
the -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
task -X- _ O
are -X- _ O
relatively -X- _ O
fixed -X- _ O
. -X- _ O
The -X- _ O
strength -X- _ O
of -X- _ O
our -X- _ O
methodconciseness -X- _ O
and -X- _ O
abstractiveness -X- _ O
are -X- _ O
good -X- _ O
properties -X- _ O
for -X- _ O
summarization -X- _ B-TaskName
but -X- _ O
seem -X- _ O
not -X- _ O
very -X- _ O
beneficial -X- _ O
to -X- _ O
the -X- _ O
translation -X- _ B-TaskName
task -X- _ O
. -X- _ O
Besides -X- _ O
the -X- _ O
λ -X- _ B-HyperparameterName
values -X- _ O
of -X- _ O
1.5 -X- _ B-HyperparameterValue
and -X- _ O
2.0 -X- _ B-HyperparameterValue
, -X- _ O
we -X- _ O
also -X- _ O
try -X- _ O
more -X- _ O
values -X- _ O
in -X- _ O
a -X- _ O
broader -X- _ O
range -X- _ O
. -X- _ O
Table -X- _ O
9 -X- _ O
shows -X- _ O
the -X- _ O
distillation -X- _ O
performance -X- _ O
of -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
6 -X- _ I-MethodName
student -X- _ O
models -X- _ O
with -X- _ O
more -X- _ O
values -X- _ O
of -X- _ O
λ -X- _ B-HyperparameterName
we -X- _ O
try -X- _ O
on -X- _ O
CNNDM -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
we -X- _ O
also -X- _ O
include -X- _ O
the -X- _ O
values -X- _ O
of -X- _ O
1.0 -X- _ B-HyperparameterValue
, -X- _ O
1.5 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
2.0 -X- _ B-HyperparameterValue
in -X- _ O
table -X- _ O
for -X- _ O
convenient -X- _ O
comparison -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
, -X- _ O
both -X- _ O
lower -X- _ O
and -X- _ O
larger -X- _ O
λ -X- _ B-HyperparameterName
values -X- _ O
are -X- _ O
not -X- _ O
helpful -X- _ O
to -X- _ O
the -X- _ O
distillation -X- _ O
. -X- _ O
Though -X- _ O
the -X- _ O
suitable -X- _ O
λ -X- _ B-HyperparameterName
values -X- _ O
may -X- _ O
vary -X- _ O
across -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
recommend -X- _ O
considering -X- _ O
the -X- _ B-HyperparameterName
λ -X- _ I-HyperparameterName
value -X- _ O
1.5 -X- _ B-HyperparameterValue
or -X- _ O
2.0 -X- _ B-HyperparameterValue
firstly -X- _ O
in -X- _ O
most -X- _ O
cases -X- _ O
. -X- _ O
Temperature -X- _ B-HyperparameterName
in -X- _ O
the -X- _ O
Final -X- _ O
Decoder -X- _ O
Layer -X- _ O

To -X- _ O
sum -X- _ O
up -X- _ O
, -X- _ O
teachers -X- _ O
with -X- _ O
higher -X- _ O
attention -X- _ B-HyperparameterName
temperatures -X- _ I-HyperparameterName
can -X- _ O
generate -X- _ O
more -X- _ O
concise -X- _ O
and -X- _ O
abstractive -X- _ O
pseudo -X- _ O
summaries -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
the -X- _ O
teacher -X- _ O
provide -X- _ O
more -X- _ O
summary -X- _ O
- -X- _ O
like -X- _ O
pseudo -X- _ O
labels -X- _ O
to -X- _ O
students -X- _ O
. -X- _ O
High -X- _ O
- -X- _ O
temperature -X- _ B-HyperparameterName
teachers -X- _ O
can -X- _ O
alleviate -X- _ O
the -X- _ O
leading -X- _ O
bias -X- _ O
problems -X- _ O
by -X- _ O
providing -X- _ O
pseudo -X- _ O
labels -X- _ O
with -X- _ O
better -X- _ O
coverage -X- _ O
of -X- _ O
source -X- _ O
documents -X- _ O
to -X- _ O
students -X- _ O
. -X- _ O

Attention -X- _ O
We -X- _ O
have -X- _ O
shown -X- _ O
earlier -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
that -X- _ O
with -X- _ O
higher -X- _ O
attention -X- _ B-HyperparameterName
temperature -X- _ I-HyperparameterName
, -X- _ O
cross -X- _ O
- -X- _ O
attention -X- _ O
modules -X- _ O
of -X- _ O
a -X- _ O
teacher -X- _ O
can -X- _ O
attend -X- _ O
to -X- _ O
later -X- _ O
parts -X- _ O
in -X- _ O
documents -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
students -X- _ O
behave -X- _ O
similarly -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
put -X- _ O
more -X- _ O
cross -X- _ O
attention -X- _ O
visualization -X- _ O
of -X- _ O
students -X- _ O
in -X- _ O
Appendix -X- _ O
F. -X- _ O
To -X- _ O
obtain -X- _ O
corpus -X- _ O
- -X- _ O
level -X- _ O
statistics -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
calculate -X- _ O
the -X- _ O
evident -X- _ B-MetricName
crossattention -X- _ I-MetricName
weight -X- _ I-MetricName
distributions -X- _ I-MetricName
of -X- _ O
the -X- _ O
teacher -X- _ O
when -X- _ O
generating -X- _ O
pseudo -X- _ O
labels -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
of -X- _ O
CN -X- _ B-DatasetName
- -X- _ I-DatasetName
NDM -X- _ I-DatasetName
. -X- _ O
Note -X- _ O
that -X- _ O
an -X- _ O
attention -X- _ O
weight -X- _ O
is -X- _ O
evident -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
greater -X- _ O
than -X- _ O
0.15 -X- _ O
, -X- _ O
and -X- _ O
these -X- _ O
evident -X- _ O
attention -X- _ O
weights -X- _ O
account -X- _ O
for -X- _ O
around -X- _ O
15 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
all -X- _ O
attention -X- _ O
weights -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
normalize -X- _ O
the -X- _ O
token -X- _ O
positions -X- _ O
of -X- _ O
each -X- _ O
document -X- _ O
to -X- _ O
( -X- _ O
0.0 -X- _ O
, -X- _ O
1.0 -X- _ O
] -X- _ O
and -X- _ O
divide -X- _ O
the -X- _ O
normalized -X- _ O
positions -X- _ O
into -X- _ O
five -X- _ O
bins -X- _ O
. -X- _ O
The -X- _ O
mean -X- _ O
proportions -X- _ O
of -X- _ O
evident -X- _ O
attentions -X- _ O
for -X- _ O
all -X- _ O
bins -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
the -X- _ O
teacher -X- _ O
with -X- _ O
normal -X- _ O
attention -X- _ B-HyperparameterName
temperature -X- _ I-HyperparameterName
( -X- _ O
pink -X- _ O
bar -X- _ O
) -X- _ O
, -X- _ O
teachers -X- _ O
with -X- _ O
higher -X- _ O
attention -X- _ B-HyperparameterName
temperatures -X- _ I-HyperparameterName
( -X- _ O
blue -X- _ O
and -X- _ O
green -X- _ O
bars -X- _ O
) -X- _ O
attend -X- _ O
less -X- _ O
on -X- _ O
the -X- _ O
heading -X- _ O
parts -X- _ O
of -X- _ O
documents -X- _ O
while -X- _ O
more -X- _ O
on -X- _ O
the -X- _ O
tail -X- _ O
parts -X- _ O
of -X- _ O
documents -X- _ O
. -X- _ O

Length -X- _ B-MetricName
and -X- _ O
novel -X- _ B-MetricName
n -X- _ I-MetricName
- -X- _ I-MetricName
grams -X- _ I-MetricName
We -X- _ O
first -X- _ O
analyze -X- _ O
the -X- _ O
pseudo -X- _ O
summaries -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
teacher -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
calculate -X- _ O
novel -X- _ B-MetricName
n -X- _ I-MetricName
- -X- _ I-MetricName
grams -X- _ I-MetricName
and -X- _ B-MetricName
lengths -X- _ I-MetricName
of -X- _ O
generated -X- _ O
summaries -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
if -X- _ O
an -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
appears -X- _ O
in -X- _ O
the -X- _ O
summary -X- _ O
, -X- _ O
but -X- _ O
not -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
document -X- _ O
, -X- _ O
we -X- _ O
call -X- _ O
it -X- _ O
a -X- _ O
novel -X- _ B-MetricName
n -X- _ I-MetricName
- -X- _ I-MetricName
gram -X- _ I-MetricName
. -X- _ O
Proportions -X- _ O
of -X- _ O
novel -X- _ B-MetricName
n -X- _ I-MetricName
- -X- _ I-MetricName
grams -X- _ I-MetricName
are -X- _ O
used -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
abstractiveness -X- _ O
of -X- _ O
summaries -X- _ O
( -X- _ O
See -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Liu -X- _ O
and -X- _ O
Lapata -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
, -X- _ O
when -X- _ O
using -X- _ O
a -X- _ O
larger -X- _ O
λ -X- _ B-HyperparameterName
, -X- _ O
pseudo -X- _ O
summaries -X- _ O
are -X- _ O
shorter -X- _ O
6 -X- _ O
and -X- _ O
contain -X- _ O
a -X- _ O
larger -X- _ O
portion -X- _ O
of -X- _ O
novel -X- _ B-MetricName
n -X- _ I-MetricName
- -X- _ I-MetricName
grams -X- _ I-MetricName
. -X- _ O
It -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
teachers -X- _ O
can -X- _ O
produce -X- _ O
more -X- _ O
concise -X- _ O
and -X- _ O
abstractive -X- _ O
summaries -X- _ O
, -X- _ O
which -X- _ O
matches -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ B-TaskName
abstractive -X- _ I-TaskName
summarization -X- _ I-TaskName
. -X- _ O
Are -X- _ O
these -X- _ O
pseudo -X- _ O
summaries -X- _ O
of -X- _ O
good -X- _ O
quality -X- _ O
? -X- _ O
set -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
. -X- _ O
Their -X- _ O
results -X- _ O
are -X- _ O
all -X- _ O
decent -X- _ O
and -X- _ O
close -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
( -X- _ O
at -X- _ O
least -X- _ O
for -X- _ O
ROUGE-1 -X- _ B-MetricName
and -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
) -X- _ O
. -X- _ O
Interestingly -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
λ -X- _ B-HyperparameterName
= -X- _ O
1.0 -X- _ B-HyperparameterValue
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
with -X- _ B-HyperparameterName
λ -X- _ I-HyperparameterName
= -X- _ O
2.0 -X- _ B-HyperparameterValue
is -X- _ O
worse -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
resulting -X- _ O
student -X- _ O
is -X- _ O
much -X- _ O
better -X- _ O
( -X- _ O
see -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
Perhaps -X- _ O
not -X- _ O
surprisingly -X- _ O
, -X- _ O
the -X- _ O
styles -X- _ O
of -X- _ O
summaries -X- _ O
from -X- _ O
students -X- _ O
are -X- _ O
similar -X- _ O
with -X- _ O
these -X- _ O
from -X- _ O
their -X- _ O
teachers -X- _ O
. -X- _ O
Concise -X- _ O
and -X- _ O
abstractive -X- _ O
teachers -X- _ O
lead -X- _ O
to -X- _ O
concise -X- _ O
and -X- _ O
abstractive -X- _ O
students -X- _ O
( -X- _ O
see -X- _ O
Table -X- _ O
6 -X- _ O
) -X- _ O
. -X- _ O
Conciseness -X- _ O
and -X- _ O
abstractiveness -X- _ O
are -X- _ O
good -X- _ O
properties -X- _ O
for -X- _ O
summarization -X- _ B-TaskName
, -X- _ O
which -X- _ O
however -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
the -X- _ O
case -X- _ O
for -X- _ O
other -X- _ O
generation -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
. -X- _ O
We -X- _ O
apply -X- _ O
PLATE -X- _ B-MethodName
to -X- _ O
the -X- _ O
WMT16 -X- _ B-DatasetName
( -X- _ O
Bojar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
English -X- _ B-TaskName
- -X- _ I-TaskName
German -X- _ I-TaskName
translation -X- _ I-TaskName
task -X- _ O
and -X- _ O
use -X- _ O
Transformer -X- _ B-MethodName
- -X- _ I-MethodName
big -X- _ I-MethodName
as -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
Transformer -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
as -X- _ O
the -X- _ O
student -X- _ O
. -X- _ O
With -X- _ O
λ -X- _ B-HyperparameterName
= -X- _ O
1.5 -X- _ B-HyperparameterValue
, -X- _ O
we -X- _ O
obtain -X- _ O
a -X- _ O
BLEU -X- _ B-MetricName
of -X- _ O
27.90 -X- _ B-MetricValue
, -X- _ O
while -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
the -X- _ O
regular -X- _ O
pseudo -X- _ O
- -X- _ O
labeling -X- _ O
is -X- _ O
27.79 -X- _ B-MetricValue
( -X- _ O
more -X- _ O
details -X- _ O
are -X- _ O
in -X- _ O
Appendix -X- _ O
A -X- _ O
) -X- _ O
. -X- _ O

Comparison -X- _ O
with -X- _ O
sampling -X- _ O
and -X- _ O
tuning -X- _ O
output -X- _ O
layer -X- _ O
temperature -X- _ O
Sampling -X- _ O
based -X- _ O
methods -X- _ O
can -X- _ O
produce -X- _ O
more -X- _ O
diverse -X- _ O
and -X- _ O
richer -X- _ O
outputs -X- _ O
than -X- _ O
its -X- _ O
beam -X- _ O
search -X- _ O
based -X- _ O
counterpart -X- _ O
and -X- _ O
has -X- _ O
been -X- _ O
proven -X- _ O
useful -X- _ O
in -X- _ O
back -X- _ B-TaskName
translation -X- _ I-TaskName
( -X- _ O
Edunov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
implement -X- _ O
the -X- _ O
sampling -X- _ O
method -X- _ O
in -X- _ O
Edunov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
Nucleus -X- _ O
Sampling -X- _ O
( -X- _ O
Holtzman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
more -X- _ O
advanced -X- _ O
sampling -X- _ O
method -X- _ O
, -X- _ O
to -X- _ O
generate -X- _ O
pseudo -X- _ O
labels -X- _ O
for -X- _ O
distillation -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
6 -X- _ I-MethodName
as -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
distillation -X- _ O
results -X- _ O
on -X- _ O
CNNDM -X- _ B-DatasetName
are -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
, -X- _ O
both -X- _ O
of -X- _ O
the -X- _ O
sampling -X- _ O
based -X- _ O
methods -X- _ O
above -X- _ O
perform -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
regular -X- _ O
beam -X- _ O
search -X- _ O
based -X- _ O
pseudolabeling -X- _ O
method -X- _ O
( -X- _ O
Regular -X- _ O
) -X- _ O
, -X- _ O
let -X- _ O
alone -X- _ O
ours -X- _ O
. -X- _ O
Besides -X- _ O
the -X- _ O
attention -X- _ B-HyperparameterName
temperatures -X- _ I-HyperparameterName
, -X- _ O
we -X- _ O
can -X- _ O
also -X- _ O
tune -X- _ O
the -X- _ O
temperature -X- _ B-HyperparameterName
T -X- _ B-HyperparameterName
in -X- _ O
the -X- _ O
decoder -X- _ O
output -X- _ O
softmax -X- _ O
layer -X- _ O
. -X- _ O
With -X- _ O
a -X- _ O
proper -X- _ O
T -X- _ B-HyperparameterName
( -X- _ O
i.e. -X- _ O
, -X- _ O
T -X- _ B-HyperparameterName
= -X- _ O
0.5 -X- _ B-HyperparameterValue
) -X- _ O
during -X- _ O
pseudo -X- _ O
label -X- _ O
generation -X- _ O
, -X- _ O
the -X- _ O
resulting -X- _ O
student -X- _ O
model -X- _ O
slightly -X- _ O
outperforms -X- _ O
the -X- _ O
baseline -X- _ O
student -X- _ O
model -X- _ O
with -X- _ O
regular -X- _ O
pseudo -X- _ O
labeling -X- _ O
method -X- _ O
on -X- _ O
ROUGE-2 -X- _ B-MetricName
/ -X- _ O
L -X- _ B-MetricName
( -X- _ O
see -X- _ O
Table -X- _ O
5 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
worse -X- _ O
than -X- _ O
PLATE -X- _ B-MethodName
λ=2.0 -X- _ I-MethodName
. -X- _ O
More -X- _ O
results -X- _ O
with -X- _ O
different -X- _ O
T -X- _ B-HyperparameterName
s -X- _ O
are -X- _ O
in -X- _ O
Appendix -X- _ O
C.Why -X- _ O
does -X- _ O
our -X- _ O
distillation -X- _ O
method -X- _ O
work -X- _ O
? -X- _ O
To -X- _ O
answer -X- _ O
this -X- _ O
question -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
try -X- _ O
to -X- _ O
analyze -X- _ O
the -X- _ O
reasons -X- _ O
from -X- _ O
both -X- _ O
the -X- _ O
external -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
summaries -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
internal -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
's -X- _ O
attention -X- _ O
mechanism -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
give -X- _ O
an -X- _ O
in -X- _ O
- -X- _ O
depth -X- _ O
explanation -X- _ O
. -X- _ O

Ablation -X- _ O
study -X- _ O
In -X- _ O
a -X- _ O
Transformer -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
three -X- _ O
types -X- _ O
of -X- _ O
attention -X- _ O
modules -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
encoder -X- _ O
selfattention -X- _ O
, -X- _ O
decoder -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
and -X- _ O
decoder -X- _ O
crossattention -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
can -X- _ O
scale -X- _ O
attention -X- _ B-HyperparameterName
temperatures -X- _ I-HyperparameterName
for -X- _ O
all -X- _ O
of -X- _ O
them -X- _ O
or -X- _ O
some -X- _ O
of -X- _ O
them -X- _ O
. -X- _ O
Let -X- _ O
λ -X- _ B-HyperparameterName
enc -X- _ I-HyperparameterName
, -X- _ O
λ -X- _ B-HyperparameterName
cross -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
λ -X- _ B-HyperparameterName
dec -X- _ I-HyperparameterName
denote -X- _ O
the -X- _ O
attention -X- _ B-HyperparameterName
temperature -X- _ I-HyperparameterName
coefficient -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
encoder -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
module -X- _ O
, -X- _ O
the -X- _ O
decoder -X- _ O
cross -X- _ O
- -X- _ O
attention -X- _ O
module -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
decoder -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
module -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
using -X- _ O
large -X- _ O
attention -X- _ B-HyperparameterName
temperature -X- _ I-HyperparameterName
coefficients -X- _ I-HyperparameterName
( -X- _ O
2.0 -X- _ B-HyperparameterValue
) -X- _ O
for -X- _ O
all -X- _ O
three -X- _ O
types -X- _ O
of -X- _ O
attention -X- _ O
modules -X- _ O
leads -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
result -X- _ O
. -X- _ O
When -X- _ O
setting -X- _ O
the -X- _ O
coefficient -X- _ B-HyperparameterName
of -X- _ O
the -X- _ O
cross -X- _ O
attention -X- _ O
module -X- _ O
to -X- _ B-HyperparameterName
λ -X- _ I-HyperparameterName
cross -X- _ I-HyperparameterName
= -X- _ O
1.0 -X- _ B-HyperparameterValue
, -X- _ O
the -X- _ O
ROUGE -X- _ B-MetricName
scores -X- _ O
drop -X- _ O
most -X- _ O
. -X- _ O
Perhaps -X- _ O
this -X- _ O
is -X- _ O
not -X- _ O
surprising -X- _ O
, -X- _ O
since -X- _ O
cross -X- _ O
attentions -X- _ O
are -X- _ O
directly -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
selection -X- _ O
of -X- _ O
document -X- _ O
contents -X- _ O
for -X- _ O
summarization -X- _ B-TaskName
. -X- _ O
Besides -X- _ O
, -X- _ O
the -X- _ O
attention -X- _ B-HyperparameterName
temperature -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
decoder -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
is -X- _ O
also -X- _ O
crucial -X- _ O
but -X- _ O
not -X- _ O
as -X- _ O
important -X- _ O
as -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
attention -X- _ O
( -X- _ O
see -X- _ O
the -X- _ O
fourth -X- _ O
row -X- _ O
) -X- _ O
. -X- _ O

Results -X- _ O
with -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
student -X- _ O
( -X- _ O
the -X- _ O
sixth -X- _ O
block -X- _ O
) -X- _ O
follow -X- _ O
a -X- _ O
similar -X- _ O
trend -X- _ O
, -X- _ O
although -X- _ O
the -X- _ O
improvements -X- _ O
are -X- _ O
smaller -X- _ O
. -X- _ O
It -X- _ O
may -X- _ O
because -X- _ O
the -X- _ O
model- -X- _ O

In -X- _ O
the -X- _ O
fifth -X- _ O
block -X- _ O
, -X- _ O
we -X- _ O
additionally -X- _ O
conduct -X- _ O
selfdistillation -X- _ O
experiments -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
focus -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
improves -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
on -X- _ O
CNNDM -X- _ B-DatasetName
; -X- _ O
ROUGE-2 -X- _ B-MetricName
/ -X- _ O
L -X- _ B-MetricName
scores -X- _ O
are -X- _ O
improved -X- _ O
on -X- _ O
XSum -X- _ B-DatasetName
; -X- _ O
while -X- _ O
on -X- _ O
NYT -X- _ B-DatasetName
, -X- _ O
there -X- _ O
are -X- _ O
improvements -X- _ O
on -X- _ O
ROUGE-1 -X- _ B-MetricName
/ -X- _ O
L. -X- _ B-MetricName

Results -X- _ O
of -X- _ O
our -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
3 -X- _ I-MethodName
and -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
6 -X- _ I-MethodName
student -X- _ O
models -X- _ O
are -X- _ O
in -X- _ O
the -X- _ O
third -X- _ O
and -X- _ O
fourth -X- _ O
block -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
results -X- _ O
of -X- _ O
students -X- _ O
trained -X- _ O
with -X- _ O
gold -X- _ O
labels -X- _ O
( -X- _ O
Gold -X- _ O
) -X- _ O
and -X- _ O
regular -X- _ O
pseudo -X- _ O
labels -X- _ O
( -X- _ O
Regular -X- _ O
) -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
pseudo -X- _ O
labels -X- _ O
with -X- _ O
higher -X- _ O
and -X- _ O
random -X- _ O
attention -X- _ O
temperatures -X- _ O
( -X- _ O
PLATE -X- _ B-MethodName
B12 -X- _ I-MethodName
- -X- _ I-MethodName
3 -X- _ I-MethodName
λ=1.5 -X- _ I-MethodName
, -X- _ O
PLATE -X- _ B-MethodName
B12 -X- _ I-MethodName
- -X- _ I-MethodName
3 -X- _ I-MethodName
λ=2.0 -X- _ I-MethodName
and -X- _ O
PLATE -X- _ B-MethodName
B12 -X- _ I-MethodName
- -X- _ I-MethodName
3 -X- _ I-MethodName
rnd -X- _ I-MethodName
) -X- _ O
. -X- _ O
PLATE -X- _ B-MethodName
B12 -X- _ I-MethodName
- -X- _ I-MethodName
3 -X- _ I-MethodName
λ=1.5 -X- _ I-MethodName
means -X- _ O
that -X- _ O
the -X- _ O
student -X- _ O
uses -X- _ O
attention -X- _ B-HyperparameterName
temperature -X- _ I-HyperparameterName
coefficient -X- _ I-HyperparameterName
λ -X- _ B-HyperparameterName
= -X- _ O
1.5 -X- _ B-HyperparameterValue
with -X- _ O
architecture -X- _ O
setting -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
3 -X- _ I-MethodName
. -X- _ O
PLATE -X- _ B-MethodName
B12 -X- _ I-MethodName
- -X- _ I-MethodName
3 -X- _ I-MethodName
rnd -X- _ I-MethodName
means -X- _ O
that -X- _ O
we -X- _ O
use -X- _ O
random -X- _ O
attention -X- _ B-HyperparameterName
temperature -X- _ I-HyperparameterName
of -X- _ O
λ -X- _ B-HyperparameterName
∼ -X- _ O
U -X- _ O
[ -X- _ O
1.0 -X- _ B-HyperparameterValue
, -X- _ O
2.0 -X- _ B-HyperparameterValue
] -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
using -X- _ O
pseudo -X- _ O
- -X- _ O
labeling -X- _ O
methods -X- _ O
with -X- _ O
higher -X- _ O
attention -X- _ B-HyperparameterName
temperatures -X- _ I-HyperparameterName
consistently -X- _ O
improves -X- _ O
over -X- _ O
its -X- _ O
counterpart -X- _ O
with -X- _ O
normal -X- _ O
attention -X- _ B-HyperparameterName
temperatures -X- _ I-HyperparameterName
( -X- _ O
Regular -X- _ O
) -X- _ O
across -X- _ O
all -X- _ O
three -X- _ O
datasets -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
them -X- _ O
are -X- _ O
almost -X- _ O
always -X- _ O
significant -X- _ O
measured -X- _ O
with -X- _ O
the -X- _ O
ROUGE -X- _ B-MetricName
script -X- _ O
5 -X- _ O
( -X- _ O
see -X- _ O
details -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
Interestingly -X- _ O
, -X- _ O
our -X- _ O
student -X- _ O
models -X- _ O
PLATE -X- _ B-MethodName
B12 -X- _ I-MethodName
- -X- _ I-MethodName
3 -X- _ I-MethodName
λ=2.0 -X- _ I-MethodName
and -X- _ O
PLATE -X- _ B-MethodName
B12 -X- _ I-MethodName
- -X- _ I-MethodName
6 -X- _ I-MethodName
λ=2.0 -X- _ I-MethodName
outperform -X- _ O
all -X- _ O
models -X- _ O
in -X- _ O
comparison -X- _ O
( -X- _ O
including -X- _ O
student -X- _ O
models -X- _ O
and -X- _ O
even -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
) -X- _ O
on -X- _ O
CNNDM -X- _ B-DatasetName
. -X- _ O
Our -X- _ O
best -X- _ O
performing -X- _ O
student -X- _ O
model -X- _ O
PLATE -X- _ B-MethodName
B12 -X- _ I-MethodName
- -X- _ I-MethodName
3 -X- _ I-MethodName
λ=1.5 -X- _ I-MethodName
outperforms -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
PL -X- _ I-MethodName
, -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
SFT -X- _ I-MethodName
, -X- _ O
and -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
KD -X- _ I-MethodName
on -X- _ O
XSum -X- _ B-DatasetName
. -X- _ O
Meanwhile -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
conceptually -X- _ O
simpler -X- _ O
and -X- _ O
can -X- _ O
further -X- _ O
be -X- _ O
combined -X- _ O
with -X- _ O
their -X- _ O
methods -X- _ O
with -X- _ O
additional -X- _ O
train- -X- _ O
ing -X- _ O
objectives -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
3.3 -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
propose -X- _ O
a -X- _ O
variant -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
, -X- _ O
which -X- _ O
employs -X- _ O
random -X- _ O
attention -X- _ B-HyperparameterName
temperatures -X- _ I-HyperparameterName
( -X- _ O
PLATE -X- _ B-MethodName
rnd -X- _ I-MethodName
in -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
though -X- _ O
random -X- _ O
temperature -X- _ B-HyperparameterName
based -X- _ O
method -X- _ O
is -X- _ O
not -X- _ O
as -X- _ O
good -X- _ O
as -X- _ O
our -X- _ O
best -X- _ O
fixed -X- _ O
- -X- _ O
temperature -X- _ B-HyperparameterName
method -X- _ O
, -X- _ O
it -X- _ O
in -X- _ O
general -X- _ O
produces -X- _ O
decent -X- _ O
results -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
recommend -X- _ O
using -X- _ O
this -X- _ O
method -X- _ O
when -X- _ O
the -X- _ O
computing -X- _ O
budget -X- _ O
is -X- _ O
limited -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
we -X- _ O
also -X- _ O
tried -X- _ O
more -X- _ O
extreme -X- _ O
λ -X- _ B-HyperparameterName
values -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Appendix -X- _ O
B -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
find -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
1.5 -X- _ B-HyperparameterValue
or -X- _ O
2.0 -X- _ B-HyperparameterValue
works -X- _ O
better -X- _ O
than -X- _ O
others -X- _ O
. -X- _ O

The -X- _ O
second -X- _ O
block -X- _ O
presents -X- _ O
results -X- _ O
of -X- _ O
student -X- _ O
models -X- _ O
. -X- _ O
Shleifer -X- _ O
and -X- _ O
Rush -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
compare -X- _ O
pseudolabeling -X- _ O
( -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
PL -X- _ I-MethodName
) -X- _ O
, -X- _ O
knowledge -X- _ O
distillation -X- _ O
using -X- _ O
both -X- _ O
output -X- _ O
and -X- _ O
intermediate -X- _ O
layers -X- _ O
( -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
KD -X- _ I-MethodName
) -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
shrink -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
( -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
SFT -X- _ I-MethodName
) -X- _ O
methods -X- _ O
. -X- _ O
They -X- _ O
also -X- _ O
use -X- _ O
BART -X- _ B-MethodName
as -X- _ O
teacher -X- _ O
models -X- _ O
. -X- _ O
Note -X- _ O
their -X- _ O
settings -X- _ O
of -X- _ O
student -X- _ O
models -X- _ O
are -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
6 -X- _ I-MethodName
on -X- _ O
CNNDM -X- _ B-DatasetName
and -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
3 -X- _ I-MethodName
on -X- _ O
XSum -X- _ B-DatasetName
. -X- _ O

Summaries -X- _ O
generated -X- _ O
by -X- _ O
abstractive -X- _ O
models -X- _ O
may -X- _ O
be -X- _ O
ungrammatical -X- _ O
or -X- _ O
unfaithful -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
document -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
measure -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
generated -X- _ O
summaries -X- _ O
by -X- _ O
eliciting -X- _ O
human -X- _ O
judgements -X- _ O
. -X- _ O
We -X- _ O
randomly -X- _ O
sample -X- _ O
50 -X- _ O
documents -X- _ O
from -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
CNNDM -X- _ B-DatasetName
. -X- _ O
12 -X- _ O
annotators -X- _ O
are -X- _ O
invited -X- _ O
( -X- _ O
they -X- _ O
are -X- _ O
either -X- _ O
native -X- _ O
English -X- _ O
speakers -X- _ O
or -X- _ O
graduate -X- _ O
students -X- _ O
with -X- _ O
IELTS -X- _ O
test -X- _ O
score -X- _ O
over -X- _ O
6.5 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
evaluation -X- _ O
, -X- _ O
participants -X- _ O
are -X- _ O
presented -X- _ O
with -X- _ O
a -X- _ O
document -X- _ O
and -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
outputs -X- _ O
by -X- _ O
different -X- _ O
models -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
asked -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
summaries -X- _ O
on -X- _ O
three -X- _ O
dimensions -X- _ O
: -X- _ O
fluency -X- _ O
( -X- _ O
is -X- _ O
the -X- _ O
summary -X- _ O
grammatically -X- _ O
correct -X- _ O
? -X- _ O
) -X- _ O
, -X- _ O
faithfulness -X- _ O
( -X- _ O
is -X- _ O
the -X- _ O
summary -X- _ O
faithful -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
document -X- _ O
? -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
coverage -X- _ O
( -X- _ O
does -X- _ O
the -X- _ O
summary -X- _ O
coverage -X- _ O
important -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
document -X- _ O
? -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
asked -X- _ O
to -X- _ O
rank -X- _ O
the -X- _ O
summaries -X- _ O
from -X- _ O
best -X- _ O
to -X- _ O
worst -X- _ O
as -X- _ O
a -X- _ O
way -X- _ O
of -X- _ O
determining -X- _ O
the -X- _ O
overall -X- _ O
quality -X- _ O
of -X- _ O
summaries -X- _ O
. -X- _ O
Each -X- _ O
document -X- _ O
is -X- _ O
ensured -X- _ O
to -X- _ O
be -X- _ O
annotated -X- _ O
by -X- _ O
3 -X- _ O
different -X- _ O
subjects -X- _ O
. -X- _ O
Our -X- _ O
main -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
block -X- _ O
includes -X- _ O
several -X- _ O
recent -X- _ O
abstractive -X- _ O
summarization -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
large -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Transformers -X- _ O
. -X- _ O
BERTSUM -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
and -X- _ O
Lapata -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
employs -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
its -X- _ O
encoder -X- _ O
and -X- _ O
uses -X- _ O
randomly -X- _ O
initialized -X- _ O
decoder -X- _ O
. -X- _ O
T5 -X- _ B-MethodName
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
PEGASUS -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
BART -X- _ B-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
are -X- _ O
three -X- _ O
popular -X- _ O
large -X- _ O
Seq2Seq -X- _ O
Transformer -X- _ O
models -X- _ O
with -X- _ O
different -X- _ O
pretraining -X- _ O
objectives -X- _ O
. -X- _ O
Our -X- _ O
own -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
version -X- _ O
of -X- _ O
BART -X- _ B-MethodName
( -X- _ O
BART -X- _ B-MethodName
( -X- _ I-MethodName
ours -X- _ I-MethodName
) -X- _ I-MethodName
) -X- _ O
is -X- _ O
comparable -X- _ O
or -X- _ O
slightly -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
reported -X- _ O
BART -X- _ B-MethodName
results -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
it -X- _ O
as -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
three -X- _ O
datasets -X- _ O
. -X- _ O

During -X- _ O
inference -X- _ O
, -X- _ O
as -X- _ O
common -X- _ O
wisdom -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
beam -X- _ O
search -X- _ O
. -X- _ O
The -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
, -X- _ O
length -X- _ B-HyperparameterName
penalty -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
minimal -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
are -X- _ O
4 -X- _ B-HyperparameterValue
, -X- _ O
2.0 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
55 -X- _ B-HyperparameterValue
on -X- _ O
CNNDM -X- _ B-DatasetName
; -X- _ O
6 -X- _ B-HyperparameterValue
, -X- _ O
0.1 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
1 -X- _ B-HyperparameterValue
on -X- _ O
XSum -X- _ B-DatasetName
; -X- _ O
and -X- _ O
4 -X- _ B-HyperparameterValue
, -X- _ O
0.7 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
80 -X- _ B-HyperparameterValue
on -X- _ B-DatasetName
NYT -X- _ I-DatasetName
, -X- _ O
respectively -X- _ O
. -X- _ O
All -X- _ O
our -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
8 -X- _ O
NVIDIA -X- _ O
V100 -X- _ O
GPUs -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
is -X- _ O
fairly -X- _ O
fast -X- _ O
. -X- _ O
Training -X- _ O
on -X- _ O
CNNDM -X- _ B-DatasetName
with -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
BART -X- _ B-MethodName
) -X- _ O
is -X- _ O
most -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
. -X- _ O
It -X- _ O
takes -X- _ O
about -X- _ O
45 -X- _ O
minutes -X- _ O
for -X- _ O
one -X- _ O
epoch -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
need -X- _ O
6 -X- _ B-HyperparameterValue
epochs -X- _ O
in -X- _ O
total -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
different -X- _ O
summarization -X- _ O
systems -X- _ O
using -X- _ O
ROUGE -X- _ B-MetricName
. -X- _ O
On -X- _ O
CNNDM -X- _ B-DatasetName
and -X- _ O
XSum -X- _ B-DatasetName
datasets -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
full -X- _ B-MetricName
- -X- _ I-MetricName
length -X- _ I-MetricName
F1 -X- _ I-MetricName
based -X- _ O
ROUGE-1 -X- _ B-MetricName
( -X- _ O
R1 -X- _ B-MetricName
) -X- _ O
, -X- _ O
ROUGE-2 -X- _ B-MetricName
( -X- _ O
R2 -X- _ B-MetricName
) -X- _ O
, -X- _ O
and -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
( -X- _ O
RL -X- _ B-MetricName
) -X- _ O
scores -X- _ O
. -X- _ O
Following -X- _ O
Durrett -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
; -X- _ O
Liu -X- _ O
and -X- _ O
Lapata -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
limited -X- _ O
- -X- _ O
length -X- _ O
recall -X- _ O
based -X- _ O
ROUGE-1 -X- _ B-MetricName
, -X- _ O
ROUGE-2 -X- _ B-MetricName
, -X- _ O
and -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
, -X- _ O
where -X- _ O
generated -X- _ O
summaries -X- _ O
are -X- _ O
truncated -X- _ O
to -X- _ O
the -X- _ O
lengths -X- _ O
of -X- _ O
gold -X- _ O
summaries -X- _ O
. -X- _ O
All -X- _ O
ROUGE -X- _ B-MetricName
scores -X- _ O
are -X- _ O
computed -X- _ O
using -X- _ O
the -X- _ O
ROUGE-1.5.5.pl -X- _ O
script -X- _ O
4 -X- _ O
. -X- _ O

Training -X- _ O
and -X- _ O
inference -X- _ O
Hyper -X- _ O
- -X- _ O
parameters -X- _ O
for -X- _ O
BART -X- _ B-MethodName
, -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
6 -X- _ I-MethodName
, -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
3 -X- _ I-MethodName
, -X- _ O
and -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
12 -X- _ I-MethodName
are -X- _ O
similar -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
all -X- _ O
models -X- _ O
are -X- _ O
optimized -X- _ O
using -X- _ O
Adam -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
with -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
= -X- _ O
0.9 -X- _ B-HyperparameterValue
, -X- _ O
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
= -X- _ O
0.999 -X- _ B-HyperparameterValue
. -X- _ O
Learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
are -X- _ O
tuned -X- _ O
on -X- _ O
validation -X- _ O
sets -X- _ O
( -X- _ O
choose -X- _ O
from -X- _ O
1e-5 -X- _ B-HyperparameterValue
, -X- _ O
3e-5 -X- _ B-HyperparameterValue
, -X- _ O
5e-5 -X- _ B-HyperparameterValue
, -X- _ O
7e-5 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
We -X- _ O
truncate -X- _ O
all -X- _ O
documents -X- _ O
and -X- _ O
summaries -X- _ O
to -X- _ O
1024 -X- _ B-HyperparameterValue
sub -X- _ O
- -X- _ O
word -X- _ O
tokens -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
around -X- _ O
80 -X- _ B-HyperparameterValue
documents -X- _ O
( -X- _ O
we -X- _ O
limit -X- _ O
the -X- _ O
max -X- _ B-HyperparameterName
number -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
tokens -X- _ I-HyperparameterName
on -X- _ O
each -X- _ O
GPU -X- _ O
to -X- _ O
2048 -X- _ B-HyperparameterValue
) -X- _ O
and -X- _ O
train -X- _ O
our -X- _ O
models -X- _ O
for -X- _ O
20,000/15,000/6,000 -X- _ B-HyperparameterValue
steps -X- _ O
with -X- _ O
500 -X- _ B-HyperparameterValue
warmup -X- _ O
steps -X- _ O
for -X- _ O
CNNDM -X- _ B-DatasetName
, -X- _ O
XSum -X- _ B-DatasetName
, -X- _ O
and -X- _ O
NYT -X- _ B-DatasetName
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
employ -X- _ O
a -X- _ O
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
of -X- _ O
0.01 -X- _ B-HyperparameterValue
. -X- _ O
For -X- _ O
Transformer -X- _ B-MethodName
, -X- _ O
the -X- _ O
hyperparameters -X- _ O
of -X- _ O
the -X- _ O
Adam -X- _ O
optimizer -X- _ O
is -X- _ O
a -X- _ O
bit -X- _ O
different -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
= -X- _ O
0.9 -X- _ B-HyperparameterValue
, -X- _ O
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
= -X- _ O
0.98 -X- _ B-HyperparameterValue
. -X- _ O
Learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
are -X- _ O
picked -X- _ O
from -X- _ O
1e-4 -X- _ B-HyperparameterValue
, -X- _ O
3e-4 -X- _ B-HyperparameterValue
, -X- _ O
5e-4 -X- _ B-HyperparameterValue
, -X- _ O
7e-4 -X- _ B-HyperparameterValue
accord -X- _ O
- -X- _ O
ing -X- _ O
to -X- _ O
validation -X- _ O
sets -X- _ O
. -X- _ O
The -X- _ O
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
0.0001 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
warmup -X- _ B-HyperparameterName
step -X- _ I-HyperparameterName
we -X- _ O
use -X- _ O
is -X- _ O
4000 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
train -X- _ B-MethodName
Transformer -X- _ I-MethodName
for -X- _ O
100 -X- _ B-HyperparameterValue
epochs -X- _ O
and -X- _ O
select -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
w.r.t -X- _ O
. -X- _ O
their -X- _ O
ROUGE -X- _ B-MetricName
scores -X- _ O
on -X- _ O
validation -X- _ O
sets -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
models -X- _ O
above -X- _ O
we -X- _ O
apply -X- _ O
a -X- _ O
label -X- _ B-HyperparameterName
smoothing -X- _ I-HyperparameterName
of -X- _ O
0.1 -X- _ B-HyperparameterValue
to -X- _ O
prevent -X- _ O
overfitting -X- _ O
( -X- _ O
Pereyra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
each -X- _ O
layer -X- _ O
is -X- _ O
1024 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
each -X- _ O
layer -X- _ O
contains -X- _ O
16 -X- _ B-HyperparameterValue
attention -X- _ O
heads -X- _ O
with -X- _ O
a -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
have -X- _ O
four -X- _ O
kinds -X- _ O
of -X- _ O
student -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
three -X- _ O
student -X- _ O
models -X- _ O
are -X- _ O
initialized -X- _ O
from -X- _ O
BART -X- _ B-MethodName
weights -X- _ O
( -X- _ O
therefore -X- _ O
, -X- _ O
their -X- _ O
hidden -X- _ O
sizes -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
that -X- _ O
of -X- _ O
BART -X- _ B-MethodName
) -X- _ O
. -X- _ O
All -X- _ O
the -X- _ O
three -X- _ O
students -X- _ O
have -X- _ O
the -X- _ O
12 -X- _ B-HyperparameterValue
layers -X- _ O
of -X- _ O
BART -X- _ B-MethodName
encoder -X- _ O
and -X- _ O
differ -X- _ O
in -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
decoder -X- _ O
layers -X- _ O
. -X- _ O
They -X- _ O
are -X- _ O
denoted -X- _ O
by -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
6 -X- _ I-MethodName
, -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
3 -X- _ I-MethodName
, -X- _ O
and -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
12 -X- _ I-MethodName
with -X- _ O
6 -X- _ B-HyperparameterValue
, -X- _ O
3 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
12 -X- _ B-HyperparameterValue
decoder -X- _ O
layers -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
For -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
6 -X- _ I-MethodName
( -X- _ O
or -X- _ O
BART -X- _ B-MethodName
12 -X- _ I-MethodName
- -X- _ I-MethodName
3 -X- _ I-MethodName
) -X- _ O
, -X- _ O
the -X- _ O
decoder -X- _ O
is -X- _ O
initialized -X- _ O
from -X- _ O
the -X- _ O
first -X- _ O
6 -X- _ B-HyperparameterValue
( -X- _ O
or -X- _ O
3 -X- _ B-HyperparameterValue
) -X- _ O
layers -X- _ O
or -X- _ O
the -X- _ O
maximally -X- _ O
spaced -X- _ O
6 -X- _ B-HyperparameterValue
( -X- _ O
or -X- _ O
3 -X- _ B-HyperparameterValue
) -X- _ O
layers -X- _ O
of -X- _ O
BART -X- _ B-MethodName
decoder -X- _ O
. -X- _ O
The -X- _ O
fourth -X- _ O
student -X- _ O
is -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
base -X- _ O
model -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
6 -X- _ O
layers -X- _ O
in -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
. -X- _ O
Each -X- _ O
layer -X- _ O
has -X- _ O
a -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
and -X- _ O
8 -X- _ O
attention -X- _ O
heads -X- _ O
. -X- _ O
This -X- _ O
student -X- _ O
is -X- _ O
randomly -X- _ O
initialized -X- _ O
and -X- _ O
denoted -X- _ O
by -X- _ O
Transformer -X- _ O
. -X- _ O
The -X- _ O
latency -X- _ O
statistics -X- _ O
( -X- _ O
Milliseconds -X- _ O
) -X- _ O
and -X- _ O
numbers -X- _ O
of -X- _ O
parameters -X- _ O
of -X- _ O
above -X- _ O
four -X- _ O
models -X- _ O
are -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

NYT -X- _ B-DatasetName
The -X- _ O
New -X- _ B-DatasetName
York -X- _ I-DatasetName
Times -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
NYT -X- _ B-DatasetName
; -X- _ O
Sandhaus -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
articles -X- _ O
published -X- _ O
by -X- _ O
New -X- _ O
York -X- _ O
Times -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
summaries -X- _ O
are -X- _ O
written -X- _ O
by -X- _ O
library -X- _ O
scientists -X- _ O
. -X- _ O
After -X- _ O
applying -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
processing -X- _ O
procedures -X- _ O
described -X- _ O
in -X- _ O
Durrett -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
; -X- _ O
Liu -X- _ O
and -X- _ O
Lapata -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
obtain -X- _ O
110,540 -X- _ O
articles -X- _ O
with -X- _ O
abstractive -X- _ O
summaries -X- _ O
. -X- _ O
The -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
constructed -X- _ O
by -X- _ O
including -X- _ O
the -X- _ O
9,076 -X- _ O
articles -X- _ O
published -X- _ O
after -X- _ O
January -X- _ O
1 -X- _ O
, -X- _ O
2007 -X- _ O
. -X- _ O
The -X- _ O
remaining -X- _ O
100,834 -X- _ O
articles -X- _ O
are -X- _ O
further -X- _ O
split -X- _ O
into -X- _ O
training -X- _ O
and -X- _ O
validation -X- _ O
sets -X- _ O
. -X- _ O
After -X- _ O
removing -X- _ O
articles -X- _ O
with -X- _ O
summaries -X- _ O
less -X- _ O
than -X- _ O
50 -X- _ O
words -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
final -X- _ O
dataset -X- _ O
with -X- _ O
38,264 -X- _ O
articles -X- _ O
for -X- _ O
training -X- _ O
; -X- _ O
4,002 -X- _ O
articles -X- _ O
for -X- _ O
validation -X- _ O
; -X- _ O
and -X- _ O
3,421 -X- _ O
articles -X- _ O
for -X- _ O
test -X- _ O
. -X- _ O
Teacher -X- _ O
/ -X- _ O
Student -X- _ O
model -X- _ O
settings -X- _ O
We -X- _ O
use -X- _ O
BART -X- _ B-MethodName
Large -X- _ I-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
as -X- _ O
our -X- _ O
teacher -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
12 -X- _ B-HyperparameterValue
layers -X- _ O
in -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
λ -X- _ B-HyperparameterName
= -X- _ O
1.5 -X- _ B-HyperparameterValue
or -X- _ O
λ -X- _ B-HyperparameterName
= -X- _ O
2.0 -X- _ B-HyperparameterValue
usually -X- _ O
works -X- _ O
well -X- _ O
in -X- _ O
practice -X- _ O
. -X- _ O
To -X- _ O
encourage -X- _ O
teacher -X- _ O
models -X- _ O
to -X- _ O
generate -X- _ O
pseudo -X- _ O
labels -X- _ O
with -X- _ O
more -X- _ O
diversity -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
propose -X- _ O
to -X- _ O
use -X- _ O
a -X- _ O
random -X- _ O
λ -X- _ B-HyperparameterName
for -X- _ O
each -X- _ O
input -X- _ O
document -X- _ O
( -X- _ O
λ -X- _ B-HyperparameterName
∼ -X- _ O
U -X- _ O
[ -X- _ O
a -X- _ B-HyperparameterName
, -X- _ O
b -X- _ B-HyperparameterName
] -X- _ O
) -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
U -X- _ O
[ -X- _ O
a -X- _ B-HyperparameterName
, -X- _ O
b -X- _ B-HyperparameterName
] -X- _ O
is -X- _ O
a -X- _ O
uniform -X- _ O
distribution -X- _ O
and -X- _ O
we -X- _ O
typically -X- _ O
set -X- _ O
a -X- _ B-HyperparameterName
= -X- _ O
1.0 -X- _ B-HyperparameterValue
and -X- _ O
b -X- _ B-HyperparameterName
= -X- _ O
2.0.We -X- _ B-HyperparameterValue
conduct -X- _ O
our -X- _ O
experiments -X- _ O
on -X- _ O
three -X- _ O
popular -X- _ O
document -X- _ O
summarization -X- _ O
datasets -X- _ O
: -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DailyMail -X- _ I-DatasetName
( -X- _ O
Hermann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
XSum -X- _ B-DatasetName
( -X- _ O
Narayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
New -X- _ B-DatasetName
York -X- _ I-DatasetName
Times -X- _ I-DatasetName
( -X- _ O
Sandhaus -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
datasets -X- _ O
are -X- _ O
tokenized -X- _ O
with -X- _ O
the -X- _ O
GPT-2 -X- _ B-MethodName
tokenizer -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
UTF-8 -X- _ B-MethodName
BPE -X- _ I-MethodName
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016).CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DailyMail -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
CNNDM -X- _ B-DatasetName
; -X- _ O
Hermann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
contains -X- _ O
online -X- _ O
news -X- _ O
articles -X- _ O
from -X- _ O
the -X- _ O
CNN -X- _ O
and -X- _ O
DailyMail -X- _ O
websites -X- _ O
paired -X- _ O
with -X- _ O
their -X- _ O
associated -X- _ O
highlights -X- _ O
as -X- _ O
reference -X- _ O
summaries -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
standard -X- _ O
pre -X- _ O
- -X- _ O
processing -X- _ O
steps -X- _ O
described -X- _ O
in -X- _ O
See -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
; -X- _ O
Liu -X- _ O
and -X- _ O
Lapata -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
3 -X- _ O
The -X- _ O
resulting -X- _ O
numbers -X- _ O
of -X- _ O
document -X- _ O
- -X- _ O
summary -X- _ O
pairs -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
validation -X- _ O
, -X- _ O
and -X- _ O
test -X- _ O
are -X- _ O
287,227 -X- _ O
, -X- _ O
13,368 -X- _ O
, -X- _ O
and -X- _ O
11,490 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
XSum -X- _ B-DatasetName
The -X- _ O
XSum -X- _ B-DatasetName
dataset -X- _ O
is -X- _ O
collected -X- _ O
by -X- _ O
harvesting -X- _ O
online -X- _ O
articles -X- _ O
from -X- _ O
the -X- _ O
BBC -X- _ O
with -X- _ O
single -X- _ O
sentence -X- _ O
summaries -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
professionally -X- _ O
written -X- _ O
. -X- _ O
The -X- _ O
summaries -X- _ O
are -X- _ O
extremely -X- _ O
abstractive -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
official -X- _ O
splits -X- _ O
of -X- _ O
Narayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
204,045 -X- _ O
articles -X- _ O
for -X- _ O
training -X- _ O
; -X- _ O
11,332 -X- _ O
articles -X- _ O
for -X- _ O
validation -X- _ O
; -X- _ O
and -X- _ O
11,334 -X- _ O
articles -X- _ O
for -X- _ O
test -X- _ O
. -X- _ O

Our -X- _ O
distillation -X- _ O
method -X- _ O
PLATE -X- _ O
works -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O
Assume -X- _ O
we -X- _ O
have -X- _ O
a -X- _ O
teacher -X- _ O
model -X- _ O
trained -X- _ O
with -X- _ O
τ -X- _ O
= -X- _ O
√ -X- _ O
d. -X- _ O
When -X- _ O
the -X- _ O
teacher -X- _ O
generates -X- _ O
pseudo -X- _ O
labels -X- _ O
with -X- _ O
beam -X- _ O
search -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
higher -X- _ O
attention -X- _ O
temperature -X- _ O
and -X- _ O
set -X- _ O
τ -X- _ O
= -X- _ O
√ -X- _ O
λ -X- _ B-HyperparameterName
d -X- _ O
where -X- _ O
λ -X- _ B-HyperparameterName
> -X- _ O
1 -X- _ B-HyperparameterValue
( -X- _ O
λ -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
attention -X- _ B-HyperparameterName
temperature -X- _ I-HyperparameterName
coefficient -X- _ I-HyperparameterName
) -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
we -X- _ O
only -X- _ O
change -X- _ O
the -X- _ O
teacher -X- _ O
's -X- _ O
attention -X- _ O
temperature -X- _ O
during -X- _ O
inference -X- _ O
time -X- _ O
. -X- _ O
When -X- _ O
we -X- _ O
train -X- _ O
our -X- _ O
student -X- _ O
model -X- _ O
with -X- _ O
pseudo -X- _ O
labels -X- _ O
, -X- _ O
we -X- _ O
still -X- _ O
use -X- _ O
a -X- _ O
normal -X- _ O
temperature -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
τ -X- _ O
= -X- _ O
√ -X- _ O
d -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
adjusting -X- _ O
the -X- _ O
student -X- _ O
's -X- _ O
attention -X- _ O
temperature -X- _ O
does -X- _ O
not -X- _ O
work -X- _ O
. -X- _ O
Probably -X- _ O
because -X- _ O
the -X- _ O
student -X- _ O
can -X- _ O
easily -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
scaled -X- _ O
attention -X- _ O
temperature -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
an -X- _ O
interesting -X- _ O
line -X- _ O
of -X- _ O
work -X- _ O
called -X- _ O
selfdistillation -X- _ O
or -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
( -X- _ O
Furlanello -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Xie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Deng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009;He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
identical -X- _ O
to -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
applied -X- _ O
in -X- _ O
selfdistillation -X- _ O
and -X- _ O
can -X- _ O
potentially -X- _ O
be -X- _ O
combined -X- _ O
with -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
distillation -X- _ O
methods -X- _ O
above -X- _ O
. -X- _ O
Abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
aims -X- _ O
to -X- _ O
rewrite -X- _ O
a -X- _ O
document -X- _ O
into -X- _ O
its -X- _ O
shorter -X- _ O
form -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
summary -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
typical -X- _ O
Seq2Seq -X- _ O
learning -X- _ O
problem -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
the -X- _ O
Seq2Seq -X- _ O
Transformer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
model -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
document -X- _ O
X -X- _ O
= -X- _ O
( -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
x -X- _ O
|X| -X- _ O
) -X- _ O
and -X- _ O
its -X- _ O
gold -X- _ O
summary -X- _ O
Y -X- _ O
= -X- _ O
( -X- _ O
y -X- _ O
1 -X- _ O
, -X- _ O
y -X- _ O
2 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
y -X- _ O
|Y -X- _ O
| -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
estimate -X- _ O
the -X- _ O
following -X- _ O
conditional -X- _ O
probability -X- _ O
: -X- _ O

In -X- _ O
Seq2Seq -X- _ O
learning -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
summarization -X- _ B-TaskName
, -X- _ O
we -X- _ O
can -X- _ O
apply -X- _ O
distillation -X- _ O
methods -X- _ O
above -X- _ O
to -X- _ O
each -X- _ O
step -X- _ O
of -X- _ O
sequence -X- _ O
model -X- _ O
predictions -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
sequence -X- _ O
- -X- _ O
level -X- _ O
knowledge -X- _ O
of -X- _ O
teacher -X- _ O
mod -X- _ O
- -X- _ O
els -X- _ O
is -X- _ O
not -X- _ O
well -X- _ O
utilized -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
Kim -X- _ O
and -X- _ O
Rush -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
introduce -X- _ O
a -X- _ O
sequence -X- _ O
- -X- _ O
level -X- _ O
knowledge -X- _ O
distillation -X- _ O
method -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
pseudo -X- _ O
- -X- _ O
labeling -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
pseudo -X- _ O
labels -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
using -X- _ O
beam -X- _ O
search -X- _ O
decoding -X- _ O
. -X- _ O
Kim -X- _ O
and -X- _ O
Rush -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
later -X- _ O
work -X- _ O
( -X- _ O
Kasai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Denkowski -X- _ O
and -X- _ O
Neubig -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
show -X- _ O
pseudo -X- _ O
- -X- _ O
labeling -X- _ O
achieves -X- _ O
competitive -X- _ O
performance -X- _ O
for -X- _ O
Seq2Seq -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
machine -X- _ O
translation -X- _ O
. -X- _ O
Shleifer -X- _ O
and -X- _ O
Rush -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
propose -X- _ O
the -X- _ O
shrink -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
( -X- _ O
SFT -X- _ O
) -X- _ O
approach -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
summarization -X- _ O
distillation -X- _ O
, -X- _ O
which -X- _ O
re -X- _ O
- -X- _ O
finetunes -X- _ O
a -X- _ O
teacher -X- _ O
model -X- _ O
with -X- _ O
some -X- _ O
layers -X- _ O
removed -X- _ O
, -X- _ O
and -X- _ O
they -X- _ O
show -X- _ O
SFT -X- _ O
outperforms -X- _ O
pseudo -X- _ O
- -X- _ O
labeling -X- _ O
and -X- _ O
a -X- _ O
modification -X- _ O
of -X- _ O
direct -X- _ O
knowledge -X- _ O
distillation -X- _ O
( -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
on -X- _ O
one -X- _ O
of -X- _ O
their -X- _ O
datasets -X- _ O
, -X- _ O
but -X- _ O
not -X- _ O
others -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
, -X- _ O
which -X- _ O
builds -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
pseudo -X- _ O
- -X- _ O
labeling -X- _ O
, -X- _ O
is -X- _ O
conceptually -X- _ O
simple -X- _ O
and -X- _ O
improves -X- _ O
pseudo -X- _ O
- -X- _ O
labeling -X- _ O
across -X- _ O
different -X- _ O
summarization -X- _ B-TaskName
datasets -X- _ O
. -X- _ O

Experiments -X- _ O
on -X- _ B-DatasetName
CNN -X- _ I-DatasetName
/ -X- _ I-DatasetName
DailyMail -X- _ I-DatasetName
, -X- _ O
XSum -X- _ B-DatasetName
, -X- _ O
and -X- _ O
New -X- _ B-DatasetName
York -X- _ I-DatasetName
Times -X- _ I-DatasetName
datasets -X- _ O
with -X- _ O
student -X- _ O
models -X- _ O
of -X- _ O
different -X- _ O
sizes -X- _ O
show -X- _ O
PLATE -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
vanilla -X- _ O
pseudo -X- _ O
- -X- _ O
labeling -X- _ O
methods -X- _ O
. -X- _ O
Further -X- _ O
empirical -X- _ O
analysis -X- _ O
shows -X- _ O
that -X- _ O
, -X- _ O
with -X- _ O
PLATE -X- _ B-MethodName
, -X- _ O
both -X- _ O
pseudo -X- _ O
summaries -X- _ O
generated -X- _ O
by -X- _ O
teacher -X- _ O
models -X- _ O
and -X- _ O
summaries -X- _ O
generated -X- _ O
by -X- _ O
student -X- _ O
models -X- _ O
are -X- _ O
shorter -X- _ O
and -X- _ O
more -X- _ O
abstractive -X- _ O
, -X- _ O
which -X- _ O
matches -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
abstractive -X- _ O
summarization -X- _ O
. -X- _ O
Large -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Seq2Seq -X- _ O
Transformer -X- _ O
models -X- _ O
largely -X- _ O
improve -X- _ O
results -X- _ O
of -X- _ O
generation -X- _ O
tasks -X- _ O
including -X- _ O
text -X- _ B-TaskName
summarization -X- _ I-TaskName
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Token -X- _ O
index -X- _ O
in -X- _ O
summary -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
models -X- _ O
are -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
using -X- _ O
unsupervised -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
objectives -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
T5 -X- _ B-MethodName
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
by -X- _ O
predicting -X- _ O
corrupted -X- _ O
text -X- _ O
spans -X- _ O
. -X- _ O
BART -X- _ B-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
employs -X- _ O
denoising -X- _ O
auto -X- _ O
- -X- _ O
encoding -X- _ O
objectives -X- _ O
such -X- _ O
as -X- _ O
text -X- _ O
infilling -X- _ O
and -X- _ O
sentence -X- _ O
permutation -X- _ O
during -X- _ O
its -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
The -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objective -X- _ O
of -X- _ O
PEGASUS -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
tailored -X- _ O
for -X- _ O
the -X- _ O
summarization -X- _ O
task -X- _ O
, -X- _ O
which -X- _ O
predicts -X- _ O
the -X- _ O
most -X- _ O
" -X- _ O
summary -X- _ O
worthy -X- _ O
" -X- _ O
sentences -X- _ O
in -X- _ O
a -X- _ O
document -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
aims -X- _ O
to -X- _ O
make -X- _ O
these -X- _ O
large -X- _ O
models -X- _ O
faster -X- _ O
. -X- _ O
In -X- _ O
knowledge -X- _ O
distillation -X- _ O
, -X- _ O
besides -X- _ O
learning -X- _ O
from -X- _ O
gold -X- _ O
labels -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
student -X- _ O
models -X- _ O
can -X- _ O
learn -X- _ O
from -X- _ O
soft -X- _ O
targets -X- _ O
( -X- _ O
Ba -X- _ O
and -X- _ O
Caruana -X- _ O
, -X- _ O
2014;Hinton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
intermediate -X- _ O
hidden -X- _ O
states -X- _ O
( -X- _ O
Romero -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
attentions -X- _ O
( -X- _ O
Zagoruyko -X- _ O
and -X- _ O
Komodakis -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
, -X- _ O
and -X- _ O
target -X- _ O
output -X- _ O
derivatives -X- _ O
( -X- _ O
Czarnecki -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
of -X- _ O
teacher -X- _ O
models -X- _ O
. -X- _ O
Recent -X- _ O
work -X- _ O
for -X- _ O
distillation -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Transformers -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
DistilBERT -X- _ B-MethodName
( -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
TinyBERT -X- _ B-MethodName
( -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
Mobile -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
of -X- _ I-MethodName
- -X- _ I-MethodName
Theseus -X- _ I-MethodName
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
, -X- _ O
MINILM -X- _ B-MethodName
) -X- _ O
focuses -X- _ O
on -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
GLUE -X- _ B-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
or -X- _ O
SQuAD -X- _ B-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
benchmarks -X- _ O
. -X- _ O
Most -X- _ O
methods -X- _ O
above -X- _ O
are -X- _ O
designed -X- _ O
for -X- _ O
classification -X- _ O
models -X- _ O
. -X- _ O

Based -X- _ O
on -X- _ O
the -X- _ O
observations -X- _ O
above -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
simple -X- _ O
method -X- _ O
called -X- _ B-MethodName
PLATE -X- _ I-MethodName
( -X- _ O
as -X- _ O
shorthand -X- _ O
for -X- _ O
Pseudo -X- _ B-MethodName
- -X- _ I-MethodName
labeling -X- _ I-MethodName
with -X- _ I-MethodName
Larger -X- _ I-MethodName
Attention -X- _ I-MethodName
TEmperature -X- _ I-MethodName
) -X- _ O
to -X- _ O
smooth -X- _ O
attention -X- _ O
distributions -X- _ O
of -X- _ O
teacher -X- _ O
models -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
re -X- _ O
- -X- _ O
scale -X- _ O
attention -X- _ O
weights -X- _ O
in -X- _ O
all -X- _ O
attention -X- _ O
modules -X- _ O
with -X- _ O
a -X- _ O
higher -X- _ O
temperature -X- _ O
, -X- _ O
which -X- _ O
leads -X- _ O
to -X- _ O
softer -X- _ O
attention -X- _ O
distributions -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
intuitively -X- _ O
shows -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
using -X- _ O
higher -X- _ O
attention -X- _ O
temperatures -X- _ O
. -X- _ O
Compared -X- _ O
with -X- _ O
the -X- _ O
left -X- _ O
graph -X- _ O
, -X- _ O
the -X- _ O
right -X- _ O
graph -X- _ O
with -X- _ O
higher -X- _ O
attention -X- _ O
temperature -X- _ O
has -X- _ O
shorter -X- _ O
lines -X- _ O
( -X- _ O
less -X- _ O
copy -X- _ O
bias -X- _ O
) -X- _ O
with -X- _ O
high -X- _ O
attention -X- _ O
weights -X- _ O
, -X- _ O
and -X- _ O
positions -X- _ O
of -X- _ O
high -X- _ O
attention -X- _ O
weights -X- _ O
extend -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
450 -X- _ O
words -X- _ O
( -X- _ O
less -X- _ O
leading -X- _ O
bias -X- _ O
) -X- _ O
. -X- _ O
Less -X- _ O
copy -X- _ O
bias -X- _ O
in -X- _ O
pseudo -X- _ O
summaries -X- _ O
encourages -X- _ O
student -X- _ O
models -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
abstractive -X- _ O
, -X- _ O
while -X- _ O
less -X- _ O
leading -X- _ O
bias -X- _ O
in -X- _ O
pseudo -X- _ O
summaries -X- _ O
encourages -X- _ O
student -X- _ O
models -X- _ O
to -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
longer -X- _ O
context -X- _ O
in -X- _ O
documents -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
attention -X- _ O
distributions -X- _ O
of -X- _ O
a -X- _ O
Seq2Seq -X- _ O
teacher -X- _ O
model -X- _ O
might -X- _ O
be -X- _ O
too -X- _ O
sharp -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
pseudo -X- _ O
labels -X- _ O
generated -X- _ O
from -X- _ O
it -X- _ O
are -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
for -X- _ O
student -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
summarization -X- _ B-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
1 -X- _ O
) -X- _ O
pseudo -X- _ O
summaries -X- _ O
generated -X- _ O
from -X- _ O
our -X- _ O
teacher -X- _ O
model -X- _ O
copy -X- _ O
more -X- _ O
continuous -X- _ O
text -X- _ O
spans -X- _ O
from -X- _ O
original -X- _ O
documents -X- _ O
than -X- _ O
reference -X- _ O
summaries -X- _ O
( -X- _ O
56 -X- _ B-MetricValue
% -X- _ I-MetricValue
4 -X- _ B-MetricName
- -X- _ I-MetricName
grams -X- _ I-MetricName
in -X- _ O
pseudo -X- _ O
summaries -X- _ O
and -X- _ O
15 -X- _ B-MetricValue
% -X- _ I-MetricValue
4 -X- _ B-MetricName
- -X- _ I-MetricName
grams -X- _ I-MetricName
in -X- _ O
reference -X- _ O
summaries -X- _ O
are -X- _ O
copied -X- _ O
from -X- _ O
their -X- _ O
original -X- _ O
documents -X- _ O
on -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DailyMail -X- _ I-DatasetName
dataset -X- _ O
) -X- _ O
; -X- _ O
2 -X- _ O
) -X- _ O
pseudo -X- _ O
summaries -X- _ O
tend -X- _ O
to -X- _ O
summarize -X- _ O
the -X- _ O
leading -X- _ O
part -X- _ O
of -X- _ O
a -X- _ O
document -X- _ O
( -X- _ O
measured -X- _ O
on -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DailyMail -X- _ I-DatasetName
, -X- _ O
74 -X- _ O
% -X- _ O
of -X- _ O
sentences -X- _ O
in -X- _ O
pseudo -X- _ O
summaries -X- _ O
and -X- _ O
64 -X- _ O
% -X- _ O
of -X- _ O
sentences -X- _ O
in -X- _ O
reference -X- _ O
summaries -X- _ O
are -X- _ O
from -X- _ O
the -X- _ O
leading -X- _ O
40 -X- _ O
% -X- _ O
sentences -X- _ O
in -X- _ O
original -X- _ O
documents -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
obtain -X- _ O
the -X- _ O
two -X- _ O
numbers -X- _ O
above -X- _ O
by -X- _ O
matching -X- _ O
each -X- _ O
sentence -X- _ O
in -X- _ O
a -X- _ O
summary -X- _ O
with -X- _ O
the -X- _ O
sentence -X- _ O
in -X- _ O
its -X- _ O
original -X- _ O
document -X- _ O
that -X- _ O
can -X- _ O
produce -X- _ O
maximum -X- _ O
ROUGE -X- _ B-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
score -X- _ O
between -X- _ O
them -X- _ O
. -X- _ O
We -X- _ O
call -X- _ O
the -X- _ O
two -X- _ O
biases -X- _ O
above -X- _ O
the -X- _ O
copy -X- _ O
bias -X- _ O
and -X- _ O
the -X- _ O
leading -X- _ O
bias -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
have -X- _ O
an -X- _ O
intuitive -X- _ O
feeling -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
a -X- _ O
rep -X- _ O
- -X- _ O
resentative -X- _ O
example -X- _ O
1 -X- _ O
and -X- _ O
visualize -X- _ O
its -X- _ O
cross -X- _ O
attention -X- _ O
weights -X- _ O
2 -X- _ O
( -X- _ O
see -X- _ O
the -X- _ O
left -X- _ O
graph -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
attention -X- _ O
weights -X- _ O
form -X- _ O
three -X- _ O
" -X- _ O
lines -X- _ O
" -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
very -X- _ O
time -X- _ O
the -X- _ O
decoder -X- _ O
predicts -X- _ O
the -X- _ O
next -X- _ O
word -X- _ O
, -X- _ O
its -X- _ O
attention -X- _ O
points -X- _ O
to -X- _ O
the -X- _ O
next -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
document -X- _ O
. -X- _ O
That -X- _ O
may -X- _ O
be -X- _ O
the -X- _ O
reason -X- _ O
why -X- _ O
multiple -X- _ O
continuous -X- _ O
spans -X- _ O
of -X- _ O
text -X- _ O
are -X- _ O
copied -X- _ O
. -X- _ O
Another -X- _ O
phenomenon -X- _ O
we -X- _ O
observe -X- _ O
is -X- _ O
that -X- _ O
all -X- _ O
high -X- _ O
- -X- _ O
value -X- _ O
attention -X- _ O
weights -X- _ O
( -X- _ O
in -X- _ O
deeper -X- _ O
color -X- _ O
) -X- _ O
concentrate -X- _ O
on -X- _ O
the -X- _ O
first -X- _ O
200 -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
document -X- _ O
, -X- _ O
which -X- _ O
reflects -X- _ O
the -X- _ O
leading -X- _ O
bias -X- _ O
. -X- _ O
In -X- _ O
either -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
attention -X- _ O
distribution -X- _ O
is -X- _ O
too -X- _ O
sharp -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
attention -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
next -X- _ O
word -X- _ O
position -X- _ O
or -X- _ O
the -X- _ O
leading -X- _ O
part -X- _ O
is -X- _ O
much -X- _ O
larger -X- _ O
than -X- _ O
other -X- _ O
positions -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
our -X- _ O
teacher -X- _ O
model -X- _ O
is -X- _ O
over -X- _ O
- -X- _ O
confident -X- _ O
. -X- _ O

Knowledge -X- _ O
distillation -X- _ O
is -X- _ O
a -X- _ O
class -X- _ O
of -X- _ O
methods -X- _ O
that -X- _ O
leverage -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
a -X- _ O
( -X- _ O
large -X- _ O
) -X- _ O
teacher -X- _ O
model -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
a -X- _ O
( -X- _ O
small -X- _ O
) -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
classification -X- _ O
tasks -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
typically -X- _ O
done -X- _ O
by -X- _ O
minimizing -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
predictions -X- _ O
( -X- _ O
Hinton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
to -X- _ O
Seq2Seq -X- _ O
models -X- _ O
, -X- _ O
an -X- _ O
effective -X- _ O
distillation -X- _ O
method -X- _ O
is -X- _ O
called -X- _ O
pseudo -X- _ O
- -X- _ O
labeling -X- _ O
( -X- _ O
Kim -X- _ O
and -X- _ O
Rush -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
generates -X- _ O
pseudo -X- _ O
summaries -X- _ O
for -X- _ O
all -X- _ O
documents -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
the -X- _ O
resulting -X- _ O
document -X- _ O
- -X- _ O
pseudo -X- _ O
- -X- _ O
summary -X- _ O
pairs -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O

Automatic -X- _ B-TaskName
document -X- _ I-TaskName
summarization -X- _ I-TaskName
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
rewriting -X- _ O
a -X- _ O
long -X- _ O
document -X- _ O
into -X- _ O
its -X- _ O
shorter -X- _ O
form -X- _ O
while -X- _ O
still -X- _ O
retaining -X- _ O
its -X- _ O
most -X- _ O
important -X- _ O
content -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
literature -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
mainly -X- _ O
two -X- _ O
kinds -X- _ O
of -X- _ O
methods -X- _ O
for -X- _ O
summarization -X- _ B-TaskName
: -X- _ O
extractive -X- _ B-TaskName
summarization -X- _ I-TaskName
and -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
( -X- _ O
Nenkova -X- _ O
and -X- _ O
McKeown -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
, -X- _ O
which -X- _ O
is -X- _ O
viewed -X- _ O
as -X- _ O
a -X- _ O
sequence -X- _ O
- -X- _ O
tosequence -X- _ O
( -X- _ O
Seq2Seq -X- _ O
) -X- _ O
learning -X- _ O
problem -X- _ O
, -X- _ O
since -X- _ O
recent -X- _ O
abstractive -X- _ O
models -X- _ O
outperform -X- _ O
their -X- _ O
extractive -X- _ O
counterparts -X- _ O
and -X- _ O
can -X- _ O
produce -X- _ O
more -X- _ O
concise -X- _ O
summaries -X- _ O
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Liu -X- _ O
and -X- _ O
Lapata -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Recent -X- _ O
progress -X- _ O
of -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
largely -X- _ O
relies -X- _ O
on -X- _ O
large -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Transformer -X- _ O
models -X- _ O
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Liu -X- _ O
and -X- _ O
Lapata -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
. -X- _ O
With -X- _ O
these -X- _ O
extremely -X- _ O
large -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
summarization -X- _ O
results -X- _ O
, -X- _ O
but -X- _ O
they -X- _ O
are -X- _ O
slow -X- _ O
for -X- _ O
online -X- _ O
inference -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
them -X- _ O
difficult -X- _ O
to -X- _ O
be -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
production -X- _ O
environment -X- _ O
even -X- _ O
with -X- _ O
cutting -X- _ O
- -X- _ O
edge -X- _ O
hardware -X- _ O
. -X- _ O
This -X- _ O
paper -X- _ O
aims -X- _ O
to -X- _ O
distill -X- _ O
these -X- _ O
large -X- _ O
Transformer -X- _ O
summarization -X- _ O
models -X- _ O
into -X- _ O
smaller -X- _ O
ones -X- _ O
with -X- _ O
minimal -X- _ O
loss -X- _ O
in -X- _ O
performance -X- _ O
. -X- _ O

LAVA -X- _ B-MethodName
( -X- _ O
Lubis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
reduces -X- _ O
the -X- _ O
action -X- _ O
space -X- _ O
of -X- _ O
policy -X- _ O
in -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
ToD -X- _ B-TaskName
, -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
latent -X- _ O
space -X- _ O
of -X- _ O
a -X- _ O
variational -X- _ O
model -X- _ O
with -X- _ O
an -X- _ O
informed -X- _ O
prior -X- _ O
. -X- _ O
The -X- _ O
work -X- _ O
use -X- _ O
variable -X- _ O
distribution -X- _ O
: -X- _ O
via -X- _ O
pretraining -X- _ O
, -X- _ O
to -X- _ O
obtain -X- _ O
an -X- _ O
informed -X- _ O
prior -X- _ O
, -X- _ O
and -X- _ O
uses -X- _ O
autoencoding -X- _ O
as -X- _ O
the -X- _ O
auxiliary -X- _ O
task -X- _ O
, -X- _ O
to -X- _ O
capture -X- _ O
generative -X- _ O
factors -X- _ O
of -X- _ O
dialogue -X- _ O
responses -X- _ O
. -X- _ O

MinTL -X- _ B-MethodName
- -X- _ I-MethodName
BART -X- _ I-MethodName
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
introduced -X- _ O
Levenshtein -X- _ O
belief -X- _ O
spans -X- _ O
framework -X- _ O
that -X- _ O
predicts -X- _ O
only -X- _ O
the -X- _ O
incremental -X- _ O
change -X- _ O
in -X- _ O
dialogue -X- _ O
state -X- _ O
per -X- _ O
turn -X- _ O
. -X- _ O
It -X- _ O
leverages -X- _ O
the -X- _ O
pretrained -X- _ O
T5 -X- _ B-MethodName
and -X- _ O
BART -X- _ B-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
backbone -X- _ O
for -X- _ O
model -X- _ O
architecture -X- _ O
. -X- _ O

Greedy -X- _ O
agent -X- _ O
: -X- _ O
In -X- _ O
certain -X- _ O
domains -X- _ O
, -X- _ O
the -X- _ O
agents -X- _ O
has -X- _ O
a -X- _ O
tendency -X- _ O
to -X- _ O
book -X- _ O
a -X- _ O
service -X- _ O
before -X- _ O
it -X- _ O
has -X- _ O
gathered -X- _ O
all -X- _ O
the -X- _ O
required -X- _ O
information -X- _ O
or -X- _ O
before -X- _ O
the -X- _ O
user -X- _ O
requested -X- _ O
or -X- _ O
agreed -X- _ O
for -X- _ O
booking -X- _ O
a -X- _ O
service -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
example -X- _ O
in -X- _ O
Fig -X- _ O
: -X- _ O
9 -X- _ O
demonstrate -X- _ O
this -X- _ O
behaviour -X- _ O
. -X- _ O
Here -X- _ O
the -X- _ O
user -X- _ O
has -X- _ O
requested -X- _ O
for -X- _ O
a -X- _ O
taxi -X- _ O
, -X- _ O
before -X- _ O
enough -X- _ O
information -X- _ O
such -X- _ O
as -X- _ O
destination -X- _ O
or -X- _ O
time -X- _ O
of -X- _ O
departure -X- _ O
are -X- _ O
gathered -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
books -X- _ O
the -X- _ O
taxi -X- _ O
. -X- _ O
This -X- _ O
happens -X- _ O
because -X- _ O
there -X- _ O
are -X- _ O
gaps -X- _ O
in -X- _ O
automatic -X- _ O
evaluation -X- _ O
metrics -X- _ O
. -X- _ O
A -X- _ O
low -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
and -X- _ O
relatively -X- _ O
high -X- _ O
inform -X- _ B-MetricName
and -X- _ O
success -X- _ B-MetricName
rate -X- _ I-MetricName
might -X- _ O
indicate -X- _ O
greedy -X- _ O
agent -X- _ O
behaviour -X- _ O
. -X- _ O
Other -X- _ O
reasons -X- _ O
for -X- _ O
low -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
includes -X- _ O
: -X- _ O
lack -X- _ O
of -X- _ O
diversity -X- _ O
in -X- _ O
the -X- _ O
responses -X- _ O
or -X- _ O
malformation -X- _ O
of -X- _ O
response -X- _ O
. -X- _ O

1 -X- _ O
) -X- _ O
Appropriateness -X- _ B-MetricName
: -X- _ O
Are -X- _ O
the -X- _ O
generated -X- _ O
responses -X- _ O
appropriate -X- _ O
for -X- _ O
the -X- _ O
given -X- _ O
context -X- _ O
in -X- _ O
the -X- _ O
dialogue -X- _ O
turn -X- _ O
? -X- _ O
2 -X- _ O
) -X- _ O
Fluency -X- _ B-MetricName
: -X- _ O
Are -X- _ O
the -X- _ O
generated -X- _ O
responses -X- _ O
coherent -X- _ O
and -X- _ O
comprehensible -X- _ O
? -X- _ O

This -X- _ O
is -X- _ O
very -X- _ O
similar -X- _ O
to -X- _ O
combined -X- _ O
score -X- _ O
used -X- _ O
in -X- _ O
evaluation -X- _ O
and -X- _ O
both -X- _ O
are -X- _ O
equivalent -X- _ O
when -X- _ O
λ -X- _ B-HyperparameterName
= -X- _ O
2 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
introduced -X- _ O
hyperparamter -X- _ O
λ -X- _ B-HyperparameterName
to -X- _ O
normalize -X- _ O
the -X- _ O
achievable -X- _ O
scale -X- _ O
of -X- _ O
BLEU -X- _ B-MetricName
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
success -X- _ B-MetricName
rate -X- _ I-MetricName
, -X- _ O
if -X- _ O
used -X- _ O
as -X- _ O
is -X- _ O
, -X- _ O
will -X- _ O
result -X- _ O
in -X- _ O
non -X- _ O
- -X- _ O
markovian -X- _ O
and -X- _ O
stochastic -X- _ O
per -X- _ O
turn -X- _ O
reward -X- _ O
function -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
the -X- _ O
reward -X- _ O
of -X- _ O
current -X- _ O
state -X- _ O
will -X- _ O
depend -X- _ O
on -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
future -X- _ O
states -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
use -X- _ O
a -X- _ O
soft -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
metric -X- _ O
M -X- _ B-MetricName
sof -X- _ I-MetricName
t -X- _ I-MetricName
, -X- _ O
where -X- _ O
the -X- _ O
success -X- _ B-MetricName
rate -X- _ I-MetricName
measures -X- _ O
a -X- _ O
fraction -X- _ O
of -X- _ O
requested -X- _ O
information -X- _ O
provided -X- _ O
in -X- _ O
a -X- _ O
dialogue -X- _ O
. -X- _ O
We -X- _ O
refer -X- _ O
the -X- _ O
original -X- _ O
metric -X- _ O
that -X- _ O
uses -X- _ O
the -X- _ O
discrete -X- _ O
variant -X- _ O
of -X- _ O
success -X- _ B-MetricName
rate -X- _ I-MetricName
as -X- _ O
M -X- _ B-MetricName
hard -X- _ I-MetricName
. -X- _ O
The -X- _ O
choice -X- _ O
of -X- _ O
action -X- _ O
in -X- _ O
reward -X- _ O
function -X- _ O
R(s -X- _ O
t -X- _ O
, -X- _ O
a -X- _ O
t -X- _ O
, -X- _ O
g -X- _ O
) -X- _ O
can -X- _ O
either -X- _ O
be -X- _ O
dialogue -X- _ B-TaskName
act -X- _ I-TaskName
or -X- _ O
generate -X- _ B-TaskName
response -X- _ I-TaskName
, -X- _ O
we -X- _ O
refer -X- _ O
corresponding -X- _ O
variants -X- _ O
of -X- _ O
metrics -X- _ O
as -X- _ O
M -X- _ B-MetricName
( -X- _ I-MetricName
act -X- _ I-MetricName
) -X- _ I-MetricName
and -X- _ O
M -X- _ B-MetricName
( -X- _ I-MetricName
resp -X- _ I-MetricName
) -X- _ I-MetricName
. -X- _ O
To -X- _ O
demonstrate -X- _ O
the -X- _ O
versatility -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
different -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
all -X- _ O
the -X- _ O
discussed -X- _ O
variants -X- _ O
of -X- _ O
the -X- _ O
metric -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
both -X- _ O
adaptation -X- _ O
of -X- _ O
our -X- _ O
methods -X- _ O
CASPI(DAMD -X- _ B-MethodName
) -X- _ I-MethodName
and -X- _ O
CASPI(MinTL -X- _ B-MethodName
) -X- _ I-MethodName
on -X- _ O
the -X- _ O
endto -X- _ O
- -X- _ O
end -X- _ O
dialogue -X- _ O
tasks -X- _ O
defined -X- _ O
by -X- _ O
MultiWoz2.0 -X- _ B-DatasetName
( -X- _ O
Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
tabulated -X- _ O
at -X- _ O
Table -X- _ O
:1 -X- _ O
. -X- _ O
CASPI(DAMD -X- _ B-MethodName
) -X- _ I-MethodName
with -X- _ O
its -X- _ O
light -X- _ O
weight -X- _ O
model -X- _ O
architecture -X- _ O
and -X- _ O
no -X- _ O
pretraining -X- _ O
on -X- _ O
any -X- _ O
external -X- _ O
corpus -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
( -X- _ O
Lubis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
out -X- _ O
perform -X- _ O
all -X- _ O
other -X- _ O
previous -X- _ O
methods -X- _ O
, -X- _ O
these -X- _ O
includes -X- _ O
methods -X- _ O
that -X- _ O
use -X- _ O
large -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
Hosseini -X- _ O
- -X- _ O
Asl -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
show -X- _ O
using -X- _ O
CASPI -X- _ B-MethodName
to -X- _ O
shepard -X- _ O
the -X- _ O
gradient -X- _ O
update -X- _ O
process -X- _ O
as -X- _ O
sample -X- _ O
weights -X- _ O
for -X- _ O
each -X- _ O
dialogue -X- _ O
turn -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
's -X- _ O
well -X- _ O
aligned -X- _ O
with -X- _ O
true -X- _ O
objective -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
CASPI(MinTL -X- _ B-MethodName
) -X- _ I-MethodName
with -X- _ O
its -X- _ O
robust -X- _ O
pretrained -X- _ O
model -X- _ O
out -X- _ O
performs -X- _ O
CASPI(DAMD -X- _ B-MethodName
) -X- _ I-MethodName
and -X- _ O
LAVA -X- _ B-MethodName
( -X- _ O
Lubis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
. -X- _ O
This -X- _ O
demonstrates -X- _ O
the -X- _ O
ease -X- _ O
of -X- _ O
adaptation -X- _ O
of -X- _ O
existing -X- _ O
methods -X- _ O
with -X- _ O
CASPI.Inverse -X- _ B-MethodName
reinforcement -X- _ O
learning -X- _ O
, -X- _ O
coupled -X- _ O
with -X- _ O
offpolicy -X- _ O
policy -X- _ O
learning -X- _ O
and -X- _ O
evaluation -X- _ O
are -X- _ O
proven -X- _ O
to -X- _ O
be -X- _ O
sample -X- _ O
efficient -X- _ O
( -X- _ O
Thomas -X- _ O
and -X- _ O
Brunskill -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
argue -X- _ O
CASPI -X- _ B-MethodName
is -X- _ O
competitive -X- _ O
with -X- _ O
other -X- _ O
sample -X- _ O
efficiency -X- _ O
techniques -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
data -X- _ B-MethodName
augmentation -X- _ I-MethodName
and -X- _ O
transfer -X- _ B-MethodName
learning -X- _ I-MethodName
as -X- _ O
performed -X- _ O
by -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
respectively -X- _ O
. -X- _ O
To -X- _ O
demonstrate -X- _ O
the -X- _ O
hypothesis -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
our -X- _ O
method -X- _ O
against -X- _ O
baseline -X- _ O
in -X- _ O
a -X- _ O
low -X- _ O
sample -X- _ O
complexity -X- _ O
regime -X- _ O
. -X- _ O
For -X- _ O
experimental -X- _ O
setup -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
low -X- _ O
resource -X- _ O
testing -X- _ O
strategy -X- _ O
from -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
5 -X- _ O
% -X- _ O
, -X- _ O
10 -X- _ O
% -X- _ O
, -X- _ O
and -X- _ O
20 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
and -X- _ O
compared -X- _ O
with -X- _ O
other -X- _ O
baselines -X- _ O
on -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
dialogue -X- _ O
task -X- _ O
, -X- _ O
Table -X- _ O
2 -X- _ O
list -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O
CASPI(MinTL -X- _ B-MethodName
) -X- _ I-MethodName
trained -X- _ O
only -X- _ O
on -X- _ O
20 -X- _ O
% -X- _ O
of -X- _ O
data -X- _ O
was -X- _ O
able -X- _ O
to -X- _ O
out -X- _ O
perform -X- _ O
previous -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
method -X- _ O
, -X- _ O
LAVA -X- _ B-MethodName
( -X- _ O
Lubis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
MINTL -X- _ B-MethodName
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
trained -X- _ O
on -X- _ O
100 -X- _ O
% -X- _ O
data -X- _ O
on -X- _ O
two -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
performance -X- _ O
metrics -X- _ O
. -X- _ O
This -X- _ O
goes -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
having -X- _ O
the -X- _ O
right -X- _ O
reward -X- _ O
function -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
budget -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
update -X- _ O
process -X- _ O
to -X- _ O
reach -X- _ O
the -X- _ O
true -X- _ O
objective -X- _ O
is -X- _ O
important -X- _ O
in -X- _ O
extremely -X- _ O
low -X- _ O
resource -X- _ O
setting -X- _ O
. -X- _ O
Automatic -X- _ O
evaluation -X- _ O
metrics -X- _ O
have -X- _ O
their -X- _ O
own -X- _ O
biases -X- _ O
. -X- _ O
True -X- _ O
objective -X- _ O
of -X- _ O
ToD -X- _ B-TaskName
is -X- _ O
human -X- _ B-MetricName
experience -X- _ I-MetricName
while -X- _ O
interacting -X- _ O
with -X- _ O
the -X- _ O
dialogue -X- _ O
systems -X- _ O
, -X- _ O
which -X- _ O
automatic -X- _ O
evaluation -X- _ O
metrics -X- _ O
might -X- _ O
fall -X- _ O
short -X- _ O
to -X- _ O
capture -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
we -X- _ O
conduct -X- _ O
human -X- _ O
evaluation -X- _ O
on -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
response -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
quality -X- _ O
by -X- _ O
the -X- _ O
following -X- _ O
criterias -X- _ O
: -X- _ O

For -X- _ O
the -X- _ O
pairwise -X- _ O
casual -X- _ O
reward -X- _ O
learning -X- _ O
network -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
three -X- _ B-HyperparameterValue
single -X- _ O
bi -X- _ O
- -X- _ O
LSTM -X- _ O
layers -X- _ O
, -X- _ O
one -X- _ O
each -X- _ O
to -X- _ O
encode -X- _ O
goal -X- _ O
, -X- _ O
belief -X- _ O
state -X- _ O
and -X- _ O
either -X- _ O
dialogue -X- _ O
act -X- _ O
or -X- _ O
response -X- _ O
sequences -X- _ O
at -X- _ O
each -X- _ O
dialogue -X- _ O
turn -X- _ O
on -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
sampled -X- _ O
roll -X- _ O
- -X- _ O
outs -X- _ O
pairs -X- _ O
, -X- _ O
τ -X- _ O
1 -X- _ O
and -X- _ O
τ -X- _ O
2 -X- _ O
. -X- _ O
The -X- _ O
three -X- _ O
encoded -X- _ O
representations -X- _ O
are -X- _ O
concatenate -X- _ O
and -X- _ O
are -X- _ O
fed -X- _ O
through -X- _ O
a -X- _ O
couple -X- _ O
of -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
layers -X- _ O
before -X- _ O
making -X- _ O
a -X- _ O
bounded -X- _ O
reward -X- _ O
prediction -X- _ O
R(s -X- _ O
t -X- _ O
, -X- _ O
a -X- _ O
t -X- _ O
, -X- _ O
g -X- _ O
) -X- _ O
∈ -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
] -X- _ O
for -X- _ O
each -X- _ O
turn -X- _ O
using -X- _ O
a -X- _ O
sigmoid -X- _ O
function -X- _ O
. -X- _ O
The -X- _ O
per -X- _ O
turn -X- _ O
rewards -X- _ O
are -X- _ O
summed -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
global -X- _ O
reward -X- _ O
R(τ -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
roll -X- _ O
- -X- _ O
out -X- _ O
τ -X- _ O
. -X- _ O
Using -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
dialogue -X- _ O
rewards -X- _ O
R(τ -X- _ O
1 -X- _ O
) -X- _ O
and -X- _ O
R(τ -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
probabilistic -X- _ O
preference -X- _ O
between -X- _ O
the -X- _ O
roll -X- _ O
- -X- _ O
outs -X- _ O
P -X- _ O
[ -X- _ O
τ -X- _ O
1 -X- _ O
≻ -X- _ O
τ -X- _ O
2 -X- _ O
] -X- _ O
either -X- _ O
by -X- _ O
standard -X- _ O
normalization -X- _ O
or -X- _ O
a -X- _ O
softmax -X- _ O
function -X- _ O
. -X- _ O
The -X- _ O
output -X- _ O
of -X- _ O
this -X- _ O
optimized -X- _ O
using -X- _ O
binary -X- _ O
crossentopy -X- _ O
loss -X- _ O
described -X- _ O
in -X- _ O
Eqn:4 -X- _ O
. -X- _ O
The -X- _ O
above -X- _ O
described -X- _ O
architecture -X- _ O
is -X- _ O
illustrated -X- _ O
in -X- _ O
Fig -X- _ O
: -X- _ O
10 -X- _ O
.To -X- _ O
evaluate -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
on -X- _ O
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
domain -X- _ I-DatasetName
Wizard -X- _ I-DatasetName
- -X- _ I-DatasetName
of -X- _ I-DatasetName
- -X- _ I-DatasetName
Oz -X- _ I-DatasetName
( -X- _ O
MultiWoz -X- _ B-DatasetName
) -X- _ O
( -X- _ O
Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
dataset -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
a -X- _ O
large -X- _ O
scale -X- _ O
multidomain -X- _ O
, -X- _ O
task -X- _ O
oriented -X- _ O
dataset -X- _ O
generated -X- _ O
by -X- _ O
human -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
human -X- _ O
conversation -X- _ O
, -X- _ O
where -X- _ O
one -X- _ O
participant -X- _ O
plays -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
a -X- _ O
user -X- _ O
while -X- _ O
the -X- _ O
other -X- _ O
plays -X- _ O
the -X- _ O
agent -X- _ O
. -X- _ O
The -X- _ O
conversations -X- _ O
are -X- _ O
between -X- _ O
a -X- _ O
tourist -X- _ O
and -X- _ O
a -X- _ O
clerk -X- _ O
at -X- _ O
an -X- _ O
information -X- _ O
center -X- _ O
. -X- _ O
The -X- _ O
conversations -X- _ O
span -X- _ O
across -X- _ O
7 -X- _ O
domains -X- _ O
including -X- _ O
attraction -X- _ O
, -X- _ O
hospital -X- _ O
, -X- _ O
hotel -X- _ O
, -X- _ O
police -X- _ O
, -X- _ O
restaurant -X- _ O
, -X- _ O
taxi -X- _ O
and -X- _ O
train -X- _ O
. -X- _ O
Each -X- _ O
dialogue -X- _ O
is -X- _ O
generated -X- _ O
by -X- _ O
users -X- _ O
with -X- _ O
a -X- _ O
defined -X- _ O
goal -X- _ O
which -X- _ O
may -X- _ O
cover -X- _ O
1 -X- _ O
- -X- _ O
5 -X- _ O
domains -X- _ O
with -X- _ O
a -X- _ O
maximum -X- _ O
of -X- _ O
13 -X- _ O
turns -X- _ O
in -X- _ O
a -X- _ O
conversation -X- _ O
. -X- _ O
The -X- _ O
dataset -X- _ O
has -X- _ O
10438 -X- _ O
dialogues -X- _ O
split -X- _ O
into -X- _ O
8438 -X- _ O
dialogues -X- _ O
for -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
1000 -X- _ O
dialogues -X- _ O
each -X- _ O
for -X- _ O
validation -X- _ O
and -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
represent -X- _ O
DB -X- _ O
results -X- _ O
as -X- _ O
one -X- _ O
- -X- _ O
hot -X- _ O
vectors -X- _ O
as -X- _ O
proposed -X- _ O
by -X- _ O
Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018b -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
reduce -X- _ O
surface -X- _ O
- -X- _ O
level -X- _ O
variability -X- _ O
in -X- _ O
the -X- _ O
responses -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
domain -X- _ O
- -X- _ O
adaptive -X- _ O
delexicalization -X- _ O
preprocess -X- _ O
- -X- _ O
ing -X- _ O
proposed -X- _ O
in -X- _ O
Wen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
proposed -X- _ O
in -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
We -X- _ O
generate -X- _ O
delexicalized -X- _ O
responses -X- _ O
with -X- _ O
placeholders -X- _ O
for -X- _ O
specific -X- _ O
values -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
filled -X- _ O
with -X- _ O
information -X- _ O
in -X- _ O
DST -X- _ O
and -X- _ O
database -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
on -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
dialogue -X- _ O
modeling -X- _ O
task -X- _ O
of -X- _ O
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
woz2.0 -X- _ I-DatasetName
( -X- _ O
Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
uses -X- _ O
three -X- _ O
evaluations -X- _ O
metrics -X- _ O
proposed -X- _ O
by -X- _ O
( -X- _ O
Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
include -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
inform -X- _ B-MetricName
ratemeasures -X- _ I-MetricName
the -X- _ O
fraction -X- _ O
of -X- _ O
dialogue -X- _ O
, -X- _ O
the -X- _ O
system -X- _ O
has -X- _ O
provided -X- _ O
the -X- _ O
correct -X- _ O
entity -X- _ O
, -X- _ O
2 -X- _ O
) -X- _ O
success -X- _ B-MetricName
rate -X- _ I-MetricName
-fraction -X- _ O
of -X- _ O
dialogues -X- _ O
, -X- _ O
the -X- _ O
system -X- _ O
has -X- _ O
answered -X- _ O
all -X- _ O
the -X- _ O
requested -X- _ O
information -X- _ O
and -X- _ O
3 -X- _ O
) -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
-measures -X- _ O
the -X- _ O
fluency -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
response -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
report -X- _ O
the -X- _ O
combined -X- _ O
score -X- _ O
( -X- _ O
Inf -X- _ B-MetricName
orm -X- _ I-MetricName
+ -X- _ O
Success -X- _ B-MetricName
) -X- _ O
× -X- _ O
0.5 -X- _ O
+ -X- _ O
BLEU -X- _ B-MetricName
proposed -X- _ O
by -X- _ O
Mehri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
the -X- _ O
numbers -X- _ O
of -X- _ O
CASPI -X- _ B-MethodName
reported -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
are -X- _ O
median -X- _ O
of -X- _ O
5 -X- _ B-HyperparameterValue
runs -X- _ O
with -X- _ O
different -X- _ O
seeds -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
metric -X- _ O
M -X- _ B-MetricName
used -X- _ O
in -X- _ O
pairwise -X- _ O
causal -X- _ O
reward -X- _ O
learning -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
following -X- _ O
: -X- _ O

MinTL -X- _ B-MethodName
does -X- _ O
n't -X- _ O
explicitly -X- _ O
predict -X- _ O
dialogue -X- _ B-TaskName
act -X- _ I-TaskName
. -X- _ O
Hence -X- _ O
we -X- _ O
only -X- _ O
use -X- _ O
the -X- _ O
deterministic -X- _ O
loss -X- _ O
, -X- _ O
L -X- _ O
det -X- _ O
directly -X- _ O
on -X- _ O
the -X- _ O
generated -X- _ O
response -X- _ O
and -X- _ O
for -X- _ O
DST -X- _ B-TaskName
we -X- _ O
retain -X- _ O
the -X- _ O
loss -X- _ O
as -X- _ O
is -X- _ O
from -X- _ O
MintTL -X- _ B-MethodName
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020).For -X- _ O
k -X- _ B-HyperparameterName
- -X- _ O
model -X- _ O
training -X- _ O
of -X- _ O
pairwise -X- _ O
casual -X- _ O
reward -X- _ O
learning -X- _ O
illustrated -X- _ O
in -X- _ O
Fig -X- _ O
: -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
chose -X- _ O
DAMD -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
model -X- _ O
for -X- _ O
it -X- _ O
's -X- _ O
light -X- _ O
weight -X- _ O
model -X- _ O
architecture -X- _ O
. -X- _ O
In -X- _ O
all -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ B-HyperparameterName
K -X- _ I-HyperparameterName
= -X- _ O
10 -X- _ B-HyperparameterValue
. -X- _ O

θ -X- _ O
: -X- _ O
= -X- _ O
θ -X- _ O
− -X- _ O
R(s -X- _ O
t -X- _ O
, -X- _ O
a -X- _ O
t -X- _ O
, -X- _ O
g)∇π -X- _ O
blackbox -X- _ O
( -X- _ O
a -X- _ O
t -X- _ O
|s -X- _ O
t -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
Hence -X- _ O
we -X- _ O
believe -X- _ O
our -X- _ O
pairwise -X- _ O
casual -X- _ O
reward -X- _ O
learning -X- _ O
and -X- _ O
associated -X- _ O
improvement -X- _ O
in -X- _ O
sample -X- _ O
efficiency -X- _ O
are -X- _ O
independent -X- _ O
of -X- _ O
model -X- _ O
architecture -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
we -X- _ O
choose -X- _ O
two -X- _ O
ToD -X- _ B-TaskName
methods -X- _ O
that -X- _ O
are -X- _ O
at -X- _ O
the -X- _ O
extremes -X- _ O
of -X- _ O
model -X- _ O
architecture -X- _ O
spectrum -X- _ O
1 -X- _ O
) -X- _ O
One -X- _ O
uses -X- _ O
a -X- _ O
light -X- _ O
weight -X- _ O
custom -X- _ O
model -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
Other -X- _ O
uses -X- _ O
a -X- _ O
large -X- _ O
standard -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
box -X- _ O
universal -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
neural -X- _ O
model -X- _ O
proposed -X- _ O
by -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
DAMD -X- _ B-MethodName
is -X- _ O
composed -X- _ O
of -X- _ O
three -X- _ O
seq2seq -X- _ O
generative -X- _ O
model -X- _ O
using -X- _ O
GRUs -X- _ O
. -X- _ O
The -X- _ O
three -X- _ O
seq2seq -X- _ O
models -X- _ O
are -X- _ O
one -X- _ O
each -X- _ O
for -X- _ O
belief -X- _ O
state -X- _ O
, -X- _ O
dialogue -X- _ O
act -X- _ O
and -X- _ O
response -X- _ O
generation -X- _ O
modules -X- _ O
. -X- _ O
An -X- _ O
attention -X- _ O
layers -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
attend -X- _ O
the -X- _ O
outputs -X- _ O
of -X- _ O
the -X- _ O
seq2seq -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
context -X- _ O
vector -X- _ O
of -X- _ O
previous -X- _ O
turn -X- _ O
for -X- _ O
copy -X- _ O
over -X- _ O
mechanism -X- _ O
. -X- _ O
The -X- _ O
outputs -X- _ O
of -X- _ O
these -X- _ O
attention -X- _ O
layer -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
representation -X- _ O
for -X- _ O
predicting -X- _ O
series -X- _ O
of -X- _ O
tokens -X- _ O
for -X- _ O
their -X- _ O
respective -X- _ O
modules -X- _ O
. -X- _ O
For -X- _ O
more -X- _ O
details -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
architecture -X- _ O
and -X- _ O
parameter -X- _ O
setting -X- _ O
refer -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
setting -X- _ O
we -X- _ O
use -X- _ O
both -X- _ O
stochastic -X- _ O
, -X- _ O
L -X- _ O
sto -X- _ O
and -X- _ O
deterministic -X- _ O
, -X- _ O
L -X- _ O
det -X- _ O
loss -X- _ O
functions -X- _ O
on -X- _ O
dialogue -X- _ B-TaskName
act -X- _ I-TaskName
. -X- _ O
For -X- _ O
DST -X- _ B-TaskName
and -X- _ O
response -X- _ B-TaskName
generation -X- _ I-TaskName
, -X- _ O
we -X- _ O
retain -X- _ O
the -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
as -X- _ O
is -X- _ O
from -X- _ O
DAMD -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019).On -X- _ O
the -X- _ O
other -X- _ O
extreme -X- _ O
of -X- _ O
model -X- _ O
complexity -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Task -X- _ O
oriented -X- _ O
Dialogue -X- _ O
model -X- _ O
, -X- _ O
MinTL -X- _ B-MethodName
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
MinTL -X- _ B-MethodName
uses -X- _ O
a -X- _ O
large -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
BART -X- _ B-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
BART -X- _ B-MethodName
use -X- _ O
as -X- _ O
a -X- _ O
standard -X- _ O
encoder -X- _ O
decoder -X- _ O
transformer -X- _ O
architecture -X- _ O
with -X- _ O
a -X- _ O
bidirectional -X- _ O
encoder -X- _ O
and -X- _ O
an -X- _ O
autoregressive -X- _ O
decoder -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
denoising -X- _ O
corrupt -X- _ O
documents -X- _ O
. -X- _ O
BART -X- _ B-MethodName
is -X- _ O
trained -X- _ O
using -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
loss -X- _ O
between -X- _ O
the -X- _ O
decoder -X- _ O
output -X- _ O
and -X- _ O
the -X- _ O
original -X- _ O
document -X- _ O
. -X- _ O
For -X- _ O
more -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
architecture -X- _ O
and -X- _ O
parameter -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
suggest -X- _ O
referring -X- _ O
to -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

2.We -X- _ O
propose -X- _ O
a -X- _ O
safe -X- _ O
policy -X- _ O
improvement -X- _ O
method -X- _ O
for -X- _ O
task -X- _ B-TaskName
oriented -X- _ I-TaskName
dialogue -X- _ I-TaskName
setting -X- _ O
that -X- _ O
guarantees -X- _ O
performance -X- _ O
against -X- _ O
a -X- _ O
baseline -X- _ O
. -X- _ O
By -X- _ O
use -X- _ O
of -X- _ O
these -X- _ O
two -X- _ O
methods -X- _ O
, -X- _ O
we -X- _ O
demonstrate -X- _ O
performance -X- _ O
and -X- _ O
sample -X- _ O
efficiency -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
release -X- _ O
of -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
, -X- _ O
multi -X- _ O
- -X- _ O
turn -X- _ O
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
Woz2.0 -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
, -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
flurry -X- _ O
of -X- _ O
recent -X- _ O
works -X- _ O
, -X- _ O
of -X- _ O
which -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
uses -X- _ O
data -X- _ O
augmentation -X- _ O
. -X- _ O
Rastogi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
Hosseini -X- _ O
- -X- _ O
Asl -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
frame -X- _ O
dialogue -X- _ O
policy -X- _ O
learning -X- _ O
as -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
task -X- _ O
. -X- _ O
Among -X- _ O
the -X- _ O
works -X- _ O
that -X- _ O
uses -X- _ O
reinforcement -X- _ O
learning -X- _ O
. -X- _ O
Mehri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
uses -X- _ O
supervised -X- _ O
learning -X- _ O
to -X- _ O
bootstrap -X- _ O
followed -X- _ O
by -X- _ O
RL -X- _ O
fine -X- _ O
tuning -X- _ O
, -X- _ O
whereas -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
uses -X- _ O
policy -X- _ O
gradient -X- _ O
on -X- _ O
latent -X- _ O
action -X- _ O
space -X- _ O
as -X- _ O
against -X- _ O
handcrafted -X- _ O
ones -X- _ O
. -X- _ O
Jaques -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
uses -X- _ O
Batch -X- _ O
- -X- _ O
RL -X- _ O
for -X- _ O
dialogue -X- _ O
policy -X- _ O
learning -X- _ O
. -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
first -X- _ O
to -X- _ O
argue -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
automated -X- _ O
evaluation -X- _ O
metrics -X- _ O
directly -X- _ O
as -X- _ O
reward -X- _ O
is -X- _ O
under -X- _ O
- -X- _ O
specified -X- _ O
for -X- _ O
ToD -X- _ B-TaskName
policy -X- _ O
learning -X- _ O
. -X- _ O
Recently -X- _ O
there -X- _ O
's -X- _ O
has -X- _ O
been -X- _ O
proliferation -X- _ O
in -X- _ O
use -X- _ O
of -X- _ O
large -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
based -X- _ O
systems -X- _ O
like -X- _ O
Hosseini -X- _ O
- -X- _ O
Asl -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
More -X- _ O
details -X- _ O
on -X- _ O
contrasting -X- _ O
the -X- _ O
merits -X- _ O
and -X- _ O
limitations -X- _ O
of -X- _ O
these -X- _ O
methods -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Sec -X- _ O
: -X- _ O
A.1 -X- _ O

1.We -X- _ O
introduce -X- _ O
pairwise -X- _ O
causal -X- _ O
reward -X- _ O
learning -X- _ O
to -X- _ O
learn -X- _ O
fine -X- _ O
grained -X- _ O
per -X- _ O
turn -X- _ O
reward -X- _ O
that -X- _ O
reason -X- _ O
the -X- _ O
intention -X- _ O
of -X- _ O
human -X- _ O
utterance -X- _ O
. -X- _ O

We -X- _ O
address -X- _ O
aforementioned -X- _ O
shortcomings -X- _ O
with -X- _ O
following -X- _ O
key -X- _ O
contributions -X- _ O
: -X- _ O

Offline -X- _ O
task -X- _ B-TaskName
- -X- _ I-TaskName
oriented -X- _ I-TaskName
dialogue -X- _ I-TaskName
( -X- _ O
ToD -X- _ B-TaskName
) -X- _ O
systems -X- _ O
involves -X- _ O
solving -X- _ O
disparate -X- _ O
tasks -X- _ O
of -X- _ O
belief -X- _ O
states -X- _ O
tracking -X- _ O
, -X- _ O
dialogue -X- _ O
policy -X- _ O
management -X- _ O
, -X- _ O
and -X- _ O
response -X- _ O
generation -X- _ O
. -X- _ O
Of -X- _ O
these -X- _ O
tasks -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
dialogue -X- _ O
policy -X- _ O
management -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
endto -X- _ O
- -X- _ O
end -X- _ O
performance -X- _ O
of -X- _ O
ToD. -X- _ O
The -X- _ O
need -X- _ O
for -X- _ O
sample -X- _ O
efficiency -X- _ O
is -X- _ O
key -X- _ O
for -X- _ O
learning -X- _ O
offline -X- _ O
task -X- _ O
- -X- _ O
oriented -X- _ O
dialogue -X- _ O
system -X- _ O
, -X- _ O
as -X- _ O
access -X- _ O
to -X- _ O
data -X- _ O
are -X- _ O
finite -X- _ O
and -X- _ O
expensive -X- _ O
. -X- _ O
Recent -X- _ O
advancements -X- _ O
in -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
reinforcement -X- _ O
learning -X- _ O
methods -X- _ O
that -X- _ O
uses -X- _ O
offline -X- _ O
data -X- _ O
as -X- _ O
against -X- _ O
a -X- _ O
simulator -X- _ O
has -X- _ O
proven -X- _ O
to -X- _ O
be -X- _ O
sample -X- _ O
efficient -X- _ O
( -X- _ O
Thomas -X- _ O
and -X- _ O
Brunskill -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
effective -X- _ O
use -X- _ O
of -X- _ O
these -X- _ O
techniques -X- _ O
are -X- _ O
hindered -X- _ O
by -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
ToD. -X- _ B-TaskName
For -X- _ O
instance -X- _ O
, -X- _ O
bias -X- _ O
correction -X- _ O
in -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
based -X- _ O
methods -X- _ O
usually -X- _ O
requires -X- _ O
estimation -X- _ O
of -X- _ O
behaviour -X- _ O
policy -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
state -X- _ O
of -X- _ O
Markov -X- _ O
Decision -X- _ O
Process -X- _ O
( -X- _ O
MDP -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
ToD -X- _ B-TaskName
, -X- _ O
per -X- _ O
- -X- _ O
turn -X- _ O
annotated -X- _ O
belief -X- _ O
- -X- _ O
state -X- _ O
does -X- _ O
not -X- _ O
capture -X- _ O
the -X- _ O
true -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
MDP -X- _ O
. -X- _ O
Example -X- _ O
of -X- _ O
such -X- _ O
annotated -X- _ O
belief -X- _ O
- -X- _ O
state -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Fig -X- _ O
: -X- _ O
1 -X- _ O
. -X- _ O
Latent -X- _ O
state -X- _ O
information -X- _ O
such -X- _ O
as -X- _ O
prosody -X- _ O
, -X- _ O
richness -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
and -X- _ O
among -X- _ O
others -X- _ O
induces -X- _ O
stochasticity -X- _ O
in -X- _ O
the -X- _ O
agents -X- _ O
response -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
these -X- _ O
short -X- _ O
comings -X- _ O
, -X- _ O
the -X- _ O
direct -X- _ O
use -X- _ O
of -X- _ O
automatic -X- _ O
evaluation -X- _ O
metric -X- _ O
as -X- _ O
reward -X- _ O
for -X- _ O
policy -X- _ O
learning -X- _ O
is -X- _ O
not -X- _ O
desirable -X- _ O
, -X- _ O
since -X- _ O
these -X- _ O
automatic -X- _ O
evaluation -X- _ O
metrics -X- _ O
are -X- _ O
often -X- _ O
for -X- _ O
the -X- _ O
entire -X- _ O
dialogue -X- _ O
and -X- _ O
not -X- _ O
per -X- _ O
turn -X- _ O
. -X- _ O
Hence -X- _ O
such -X- _ O
rewards -X- _ O
are -X- _ O
sparse -X- _ O
and -X- _ O
under -X- _ O
- -X- _ O
specified -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Use -X- _ O
of -X- _ O
under -X- _ O
- -X- _ O
specified -X- _ O
reward -X- _ O
will -X- _ O
often -X- _ O
lead -X- _ O
to -X- _ O
policy -X- _ O
that -X- _ O
suffers -X- _ O
from -X- _ O
high -X- _ O
variance -X- _ O
( -X- _ O
Agarwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Alternatively -X- _ O
use -X- _ O
of -X- _ O
imitation -X- _ O
learning -X- _ O
based -X- _ O
methods -X- _ O
falls -X- _ O
short -X- _ O
of -X- _ O
reasoning -X- _ O
on -X- _ O
the -X- _ O
outcome -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
demonstrated -X- _ O
in -X- _ O
Fig -X- _ O
: -X- _ O
1 -X- _ O
. -X- _ O
Turns#3 -X- _ O
and -X- _ O
# -X- _ O
2 -X- _ O
are -X- _ O
rich -X- _ O
in -X- _ O
semantic -X- _ O
information -X- _ O
and -X- _ O
Turn#3 -X- _ O
is -X- _ O
key -X- _ O
to -X- _ O
success -X- _ O
of -X- _ O
the -X- _ O
booking -X- _ O
process -X- _ O
. -X- _ O
While -X- _ O
Turn#4 -X- _ O
contributes -X- _ O
least -X- _ O
to -X- _ O
successful -X- _ O
outcome -X- _ O
. -X- _ O
Though -X- _ O
the -X- _ O
turns -X- _ O
have -X- _ O
varying -X- _ O
levels -X- _ O
of -X- _ O
importance -X- _ O
, -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
turns -X- _ O
are -X- _ O
treated -X- _ O
equally -X- _ O
in -X- _ O
imitation -X- _ O
learning -X- _ O
. -X- _ O
In -X- _ O
worst -X- _ O
case -X- _ O
, -X- _ O
turns -X- _ O
like -X- _ O
Turn#4 -X- _ O
will -X- _ O
appear -X- _ O
more -X- _ O
often -X- _ O
than -X- _ O
turns -X- _ O
Turn#2 -X- _ O
and -X- _ O
# -X- _ O
3 -X- _ O
in -X- _ O
a -X- _ O
ToD -X- _ B-TaskName
dataset -X- _ O
, -X- _ O
there -X- _ O
by -X- _ O
taking -X- _ O
greater -X- _ O
share -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
budget -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
fixing -X- _ O
the -X- _ O
parameter -X- _ O
of -X- _ O
PLM -X- _ O
during -X- _ O
training -X- _ O
on -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
HQA -X- _ I-DatasetName
as -X- _ O
initialized -X- _ O
by -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
. -X- _ O
The -X- _ O
performance -X- _ O
drops -X- _ O
to -X- _ O
EM -X- _ B-MetricName
48.5 -X- _ B-MetricValue
and -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
49.0 -X- _ B-MetricValue
. -X- _ O
Fixing -X- _ O
the -X- _ O
parameter -X- _ O
of -X- _ O
PLM -X- _ O
largely -X- _ O
impedes -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
L2I -X- _ I-MethodName
on -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
HQA -X- _ I-DatasetName
, -X- _ O
showing -X- _ O
that -X- _ O
encoding -X- _ O
factual -X- _ O
and -X- _ O
hypothetical -X- _ O
questions -X- _ O
requires -X- _ O
different -X- _ O
mechanisms -X- _ O
. -X- _ O
To -X- _ O
further -X- _ O
investigate -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
answering -X- _ O
factual -X- _ O
and -X- _ O
hypothetical -X- _ O
questions -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
L2I -X- _ I-MethodName
on -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
. -X- _ O
The -X- _ O
result -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
shows -X- _ O
that -X- _ O
training -X- _ O
on -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
HQA -X- _ I-DatasetName
causes -X- _ O
a -X- _ O
performance -X- _ O
drop -X- _ O
in -X- _ O
counting -X- _ O
, -X- _ O
span -X- _ O
and -X- _ O
multi -X- _ O
- -X- _ O
span -X- _ O
groups -X- _ O
of -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
, -X- _ O
and -X- _ O
performs -X- _ O
similar -X- _ O
on -X- _ O
the -X- _ O
in -X- _ O
arithmetic -X- _ O
group -X- _ O
. -X- _ O
We -X- _ O
conjecture -X- _ O
the -X- _ O
performance -X- _ O
drop -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
three -X- _ O
groups -X- _ O
is -X- _ O
because -X- _ O
the -X- _ O
question -X- _ B-TaskName
- -X- _ I-TaskName
answering -X- _ I-TaskName
label -X- _ O
in -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
HQA -X- _ I-DatasetName
under -X- _ O
the -X- _ O
same -X- _ O
c -X- _ O
and -X- _ O
q -X- _ O
is -X- _ O
different -X- _ O
from -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
. -X- _ O
However -X- _ O
, -X- _ O
for -X- _ O
arithmetic -X- _ O
questions -X- _ O
, -X- _ O
the -X- _ O
question -X- _ B-TaskName
- -X- _ I-TaskName
answering -X- _ I-TaskName
label -X- _ O
for -X- _ O
one -X- _ O
pair -X- _ O
of -X- _ O
c -X- _ O
and -X- _ O
q -X- _ O
remains -X- _ O
the -X- _ O
same -X- _ O
between -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
HQA -X- _ I-DatasetName
and -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
, -X- _ O
and -X- _ O
the -X- _ O
intervention -X- _ O
is -X- _ O
achieved -X- _ O
explicitly -X- _ O
by -X- _ O
deriving -X- _ O
operators -X- _ O
and -X- _ O
tagging -X- _ O
head -X- _ O
. -X- _ O

Figure -X- _ O
3(a -X- _ O
) -X- _ O
shows -X- _ O
the -X- _ O
validation -X- _ O
result -X- _ O
of -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
L2I -X- _ I-MethodName
as -X- _ O
increasing -X- _ O
the -X- _ O
matching -X- _ B-HyperparameterName
block -X- _ I-HyperparameterName
from -X- _ O
1 -X- _ B-HyperparameterValue
to -X- _ O
4 -X- _ B-HyperparameterValue
layers -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
Stacking -X- _ O
more -X- _ O
layers -X- _ O
does -X- _ O
not -X- _ O
always -X- _ O
bring -X- _ O
performance -X- _ O
gain -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
three -X- _ B-HyperparameterValue
layers -X- _ O
of -X- _ O
matching -X- _ O
block -X- _ O
achieve -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
L2I. -X- _ I-MethodName
The -X- _ O
result -X- _ O
indicates -X- _ O
that -X- _ O
three -X- _ B-HyperparameterValue
layers -X- _ O
should -X- _ O
be -X- _ O
sufficient -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
semantic -X- _ O
connection -X- _ O
across -X- _ O
the -X- _ O
context -X- _ O
, -X- _ O
question -X- _ O
and -X- _ O
assumption -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
reasonable -X- _ O
since -X- _ O
the -X- _ O
average -X- _ O
length -X- _ O
of -X- _ O
both -X- _ O
assumption -X- _ O
and -X- _ O
question -X- _ O
are -X- _ O
only -X- _ O
around -X- _ O
10 -X- _ O
words -X- _ O
( -X- _ O
cf -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O

As -X- _ O
to -X- _ O
operator -X- _ O
types -X- _ O
( -X- _ O
the -X- _ O
right -X- _ O
half -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
L2I -X- _ I-MethodName
achieves -X- _ O
imagination -X- _ O
on -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
operator -X- _ O
types -X- _ O
with -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
TAGOP -X- _ B-MethodName
, -X- _ O
yet -X- _ O
TAGOP -X- _ B-MethodName
can -X- _ O
only -X- _ O
achieve -X- _ O
imagination -X- _ O
on -X- _ O
a -X- _ O
few -X- _ O
operator -X- _ O
types -X- _ O
. -X- _ O
The -X- _ O
better -X- _ O
performance -X- _ O
of -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
L2I -X- _ I-MethodName
is -X- _ O
attributed -X- _ O
to -X- _ O
modeling -X- _ O
the -X- _ O
deriving -X- _ O
operations -X- _ O
as -X- _ O
specific -X- _ O
operators -X- _ O
. -X- _ O
We -X- _ O
thus -X- _ O
believe -X- _ O
that -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
L2I -X- _ I-MethodName
can -X- _ O
generalize -X- _ O
well -X- _ O
to -X- _ O
more -X- _ O
deriving -X- _ O
operations -X- _ O
by -X- _ O
simply -X- _ O
incorporating -X- _ O
the -X- _ O
operators -X- _ O
, -X- _ O
as -X- _ O
long -X- _ O
as -X- _ O
the -X- _ O
corresponding -X- _ O
training -X- _ O
questions -X- _ O
are -X- _ O
not -X- _ O
rare -X- _ O
. -X- _ O
This -X- _ O
result -X- _ O
thus -X- _ O
reflects -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
unified -X- _ O
operator -X- _ O
framework -X- _ O
adopted -X- _ O
by -X- _ O
the -X- _ O
L2I -X- _ B-MethodName
module -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Andor -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
Across -X- _ O
the -X- _ O
groups -X- _ O
, -X- _ O
TAGOP -X- _ B-MethodName
achieves -X- _ O
relatively -X- _ O
good -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
SWAP -X- _ O
group -X- _ O
, -X- _ O
which -X- _ O
replaces -X- _ O
the -X- _ O
target -X- _ O
fact -X- _ O
with -X- _ O
a -X- _ O
number -X- _ O
in -X- _ O
the -X- _ O
assumption -X- _ O
. -X- _ O
It -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
simplest -X- _ O
imagination -X- _ O
since -X- _ O
the -X- _ O
assumed -X- _ O
value -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
is -X- _ O
explicitly -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
assumption -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
the -X- _ O
result -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
NDR -X- _ B-TaskName
model -X- _ O
can -X- _ O
achieve -X- _ O
simple -X- _ O
counterfactual -X- _ O
thinking -X- _ O
by -X- _ O
learning -X- _ O
to -X- _ O
answer -X- _ O
hypothetical -X- _ O
questions -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
such -X- _ O
indirect -X- _ O
guidance -X- _ O
on -X- _ O
imagination -X- _ O
fails -X- _ O
on -X- _ O
the -X- _ O
groups -X- _ O
requiring -X- _ O
more -X- _ O
complex -X- _ O
imagination -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
requiring -X- _ O
add -X- _ O
or -X- _ O
minus -X- _ O
. -X- _ O
3 -X- _ O
) -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
L2I -X- _ I-MethodName
achieves -X- _ O
the -X- _ O
worst -X- _ O
performance -X- _ O
on -X- _ O
SWAP -X- _ O
MIN -X- _ O
NUM -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
merely -X- _ O
comparable -X- _ O
to -X- _ O
TAGOP -X- _ B-MethodName
. -X- _ O
We -X- _ O
suspect -X- _ O
the -X- _ O
reason -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
operation -X- _ O
of -X- _ O
SWAP -X- _ O
MIN -X- _ O
NUM -X- _ O
is -X- _ O
very -X- _ O
close -X- _ O
to -X- _ O
SWAP -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
confuse -X- _ O
the -X- _ O
deriving -X- _ O
head -X- _ O
when -X- _ O
making -X- _ O
classification -X- _ O
over -X- _ O
the -X- _ O
operators -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
worth -X- _ O
considering -X- _ O
the -X- _ O
operator -X- _ O
relation -X- _ O
in -X- _ O
the -X- _ O
deriving -X- _ O
head -X- _ O
in -X- _ O
the -X- _ O
future -X- _ O
. -X- _ O
Study -X- _ O
on -X- _ B-MethodName
L2I -X- _ I-MethodName
module -X- _ O
design -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
explore -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
network -X- _ O
architecture -X- _ O
on -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
L2I -X- _ B-MethodName
module -X- _ O
from -X- _ O
three -X- _ O
perspectives -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
module -X- _ B-HyperparameterName
depth -X- _ I-HyperparameterName
; -X- _ O
2 -X- _ O
) -X- _ O
configuration -X- _ O
of -X- _ O
the -X- _ O
matching -X- _ B-HyperparameterName
block -X- _ I-HyperparameterName
; -X- _ O
and -X- _ O
3 -X- _ O
) -X- _ O
the -X- _ O
setting -X- _ O
of -X- _ O
PLM -X- _ O
. -X- _ O

3 -X- _ O
) -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
TAGOP -X- _ B-MethodName
on -X- _ O
arithmetic -X- _ O
has -X- _ O
a -X- _ O
large -X- _ O
gap -X- _ O
with -X- _ O
other -X- _ O
types -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
arithmetic -X- _ O
questions -X- _ O
are -X- _ O
more -X- _ O
difficult -X- _ O
to -X- _ O
conduct -X- _ O
imagination -X- _ O
and -X- _ O
reasoning -X- _ O
even -X- _ O
though -X- _ O
arithmetic -X- _ O
makes -X- _ O
up -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
HQA -X- _ I-DatasetName
data -X- _ O
. -X- _ O
As -X- _ O
to -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
L2I -X- _ I-MethodName
, -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
arithmetic -X- _ O
question -X- _ O
and -X- _ O
other -X- _ O
types -X- _ O
of -X- _ O
question -X- _ O
largely -X- _ O
reduces -X- _ O
, -X- _ O
validating -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
learning -X- _ O
intervention -X- _ O
with -X- _ O
discrete -X- _ O
operators -X- _ O
and -X- _ O
neural -X- _ O
network -X- _ O
modules -X- _ O
. -X- _ O

Detailed -X- _ O
performance -X- _ O
. -X- _ O
To -X- _ O
further -X- _ O
investigate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
L2I -X- _ B-MethodName
module -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
a -X- _ O
detailed -X- _ O
comparison -X- _ O
between -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
L2I -X- _ I-MethodName
and -X- _ O
TAGOP -X- _ B-MethodName
w.r.t -X- _ O
. -X- _ O
the -X- _ O
discrete -X- _ O
operation -X- _ O
required -X- _ O
in -X- _ O
answering -X- _ O
the -X- _ O
question -X- _ O
or -X- _ O
counterfactual -X- _ O
thinking -X- _ O
. -X- _ O
We -X- _ O
group -X- _ O
the -X- _ O
questions -X- _ O
according -X- _ O
to -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
answer -X- _ O
type -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
operator -X- _ O
to -X- _ O
derive -X- _ O
the -X- _ O
intervention -X- _ O
. -X- _ O
Table -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
group -X- _ O
- -X- _ O
wise -X- _ O
It -X- _ O
should -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
the -X- _ O
separation -X- _ O
also -X- _ O
facilitates -X- _ O
the -X- _ O
generalization -X- _ O
to -X- _ O
new -X- _ O
operations -X- _ O
since -X- _ O
the -X- _ O
modules -X- _ O
can -X- _ O
be -X- _ O
separately -X- _ O
updated -X- _ O
. -X- _ O

Multi -X- _ O
- -X- _ O
iteration -X- _ O
derivation -X- _ O
. -X- _ O
In -X- _ O
causal -X- _ O
inference -X- _ O
, -X- _ O
a -X- _ O
rigorous -X- _ O
derivation -X- _ O
of -X- _ O
an -X- _ O
intervention -X- _ O
considers -X- _ O
the -X- _ O
successors -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
variable -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
finished -X- _ O
goods -X- _ O
in -X- _ O
2019 -X- _ O
affects -X- _ O
total -X- _ O
inventories -X- _ O
in -X- _ O
2019 -X- _ O
. -X- _ O
Currently -X- _ O
, -X- _ O
we -X- _ O
omit -X- _ O
the -X- _ O
following -X- _ O
iterations -X- _ O
in -X- _ O
Step -X- _ O
2 -X- _ O
of -X- _ O
L2I -X- _ B-MethodName
( -X- _ O
cf -X- _ O
. -X- _ O
Eq -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
not -X- _ O
all -X- _ O
successors -X- _ O
are -X- _ O
necessary -X- _ O
for -X- _ O
answering -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
answering -X- _ O
the -X- _ O
question -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
the -X- _ O
post -X- _ O
- -X- _ O
intervention -X- _ O
value -X- _ O
of -X- _ O
total -X- _ O
inventories -X- _ O
in -X- _ O
2019 -X- _ O
. -X- _ O
In -X- _ O
conventional -X- _ O
causal -X- _ O
inference -X- _ O
, -X- _ O
such -X- _ O
successors -X- _ O
will -X- _ O
also -X- _ O
be -X- _ O
omitted -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
local -X- _ O
surgery -X- _ O
principle -X- _ O
( -X- _ O
Pearl -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
believe -X- _ O
that -X- _ O
the -X- _ O
following -X- _ O
iterations -X- _ O
can -X- _ O
be -X- _ O
achieved -X- _ O
by -X- _ O
the -X- _ O
current -X- _ O
L2I -X- _ B-MethodName
module -X- _ O
in -X- _ O
an -X- _ O
iterative -X- _ O
manner -X- _ O
. -X- _ O
Assume -X- _ O
that -X- _ O
NDR -X- _ B-TaskName
model -X- _ O
equipped -X- _ O
with -X- _ O
L2I -X- _ B-MethodName
can -X- _ O
answer -X- _ O
the -X- _ O
hypothetical -X- _ O
questions -X- _ O
requiring -X- _ O
one -X- _ O
- -X- _ O
iteration -X- _ O
derivation -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
→ -X- _ O
c -X- _ O
i -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
thus -X- _ O
derive -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
successors -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
c -X- _ O
i -X- _ O
→ -X- _ O
c -X- _ O
j -X- _ O
) -X- _ O
by -X- _ O
forming -X- _ O
a -X- _ O
simple -X- _ O
hypothetical -X- _ O
question -X- _ O
: -X- _ O
" -X- _ O
What -X- _ O
c -X- _ O
j -X- _ O
would -X- _ O
be -X- _ O
if -X- _ O
c -X- _ O
i -X- _ O
is -X- _ O
c -X- _ O
i -X- _ O
? -X- _ O
" -X- _ O
and -X- _ O
answering -X- _ O
it -X- _ O
with -X- _ O
the -X- _ O
NDR -X- _ B-TaskName
model -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
HQA -X- _ I-DatasetName
dataset -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
following -X- _ O
questions -X- _ O
: -X- _ O
RQ1 -X- _ O
: -X- _ O
How -X- _ O
does -X- _ O
L2I -X- _ B-MethodName
perform -X- _ O
on -X- _ O
HQA -X- _ B-TaskName
? -X- _ O
RQ2 -X- _ O
: -X- _ O
What -X- _ O
factors -X- _ O
influ- -X- _ O
Compared -X- _ O
methods -X- _ O
. -X- _ O
To -X- _ O
validate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
L2I -X- _ B-MethodName
module -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
it -X- _ O
to -X- _ O
TAGOP -X- _ B-MethodName
, -X- _ O
obtaining -X- _ O
an -X- _ O
NDR -X- _ B-TaskName
model -X- _ O
for -X- _ O
HQA -X- _ B-TaskName
, -X- _ O
named -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
L2I. -X- _ I-MethodName
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
vanilla -X- _ O
TAGOP -X- _ B-MethodName
, -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
method -X- _ O
against -X- _ O
representative -X- _ O
methods -X- _ O
of -X- _ O
traditional -X- _ B-TaskName
QA -X- _ I-TaskName
, -X- _ O
numerical -X- _ B-TaskName
QA -X- _ I-TaskName
, -X- _ B-TaskName
tabular -X- _ I-TaskName
QA -X- _ I-TaskName
, -X- _ O
and -X- _ O
hybrid -X- _ B-TaskName
QA -X- _ I-TaskName
. -X- _ O
Besides -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
select -X- _ O
baselines -X- _ O
that -X- _ O
are -X- _ O
effective -X- _ O
for -X- _ O
learning -X- _ O
counterfactual -X- _ O
samples -X- _ O
. -X- _ O
The -X- _ O
baselines -X- _ O
are -X- _ O
: -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
RC -X- _ I-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
traditional -X- _ B-TaskName
QA -X- _ I-TaskName
method -X- _ O
that -X- _ O
selects -X- _ O
answer -X- _ O
spans -X- _ O
from -X- _ O
the -X- _ O
context -X- _ O
. -X- _ O
NumNet+ -X- _ B-MethodName
V2 -X- _ I-MethodName
( -X- _ O
Ran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
numerical -X- _ B-TaskName
QA -X- _ I-TaskName
method -X- _ O
with -X- _ O
numerically -X- _ O
- -X- _ O
aware -X- _ O
graph -X- _ O
neural -X- _ O
network -X- _ O
. -X- _ O
TAPAS -X- _ B-MethodName
- -X- _ I-MethodName
WTQ -X- _ I-MethodName
( -X- _ O
Herzig -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
tabular -X- _ B-TaskName
QA -X- _ I-TaskName
method -X- _ O
that -X- _ O
focuses -X- _ O
on -X- _ O
parsing -X- _ O
and -X- _ O
understanding -X- _ O
tables -X- _ O
, -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
over -X- _ O
tables -X- _ O
collected -X- _ O
from -X- _ O
Wikipedia -X- _ O
before -X- _ O
training -X- _ O
on -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
HQA -X- _ I-DatasetName
. -X- _ B-MethodName
HyBrider -X- _ I-MethodName
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020c -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
hybrid -X- _ B-TaskName
QA -X- _ I-TaskName
method -X- _ O
that -X- _ O
considers -X- _ O
the -X- _ O
connection -X- _ O
between -X- _ O
the -X- _ O
table -X- _ O
and -X- _ O
text -X- _ O
. -X- _ O
TAGOP -X- _ B-MethodName
, -X- _ O
a -X- _ O
hybrid -X- _ B-TaskName
QA -X- _ I-TaskName
method -X- _ O
that -X- _ O
performs -X- _ O
discrete -X- _ O
reasoning -X- _ O
over -X- _ O
both -X- _ O
the -X- _ O
tabular -X- _ O
and -X- _ O
textual -X- _ O
contexts -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
method -X- _ O
on -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
dataset -X- _ O
. -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
CLO -X- _ I-MethodName
, -X- _ O
incorporating -X- _ O
the -X- _ O
Contrastive -X- _ O
Learning -X- _ O
Objective -X- _ O
( -X- _ O
CLO -X- _ O
) -X- _ O
into -X- _ O
the -X- _ O
training -X- _ O
objective -X- _ O
of -X- _ O
TAGOP -X- _ B-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
in -X- _ O
learning -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
factual -X- _ O
and -X- _ O
counterfactual -X- _ O
samples -X- _ O
( -X- _ O
Liang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

3 -X- _ O
) -X- _ O
As -X- _ O
to -X- _ O
the -X- _ O
remaining -X- _ O
methods -X- _ O
, -X- _ O
their -X- _ O
performance -X- _ O
has -X- _ O
a -X- _ O
clear -X- _ O
gap -X- _ O
between -X- _ O
TAGOP -X- _ B-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
result -X- _ O
on -X- _ O
the -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
both -X- _ O
datasets -X- _ O
have -X- _ O
textual -X- _ O
and -X- _ O
tabular -X- _ O
texts -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
TAGOP -X- _ B-MethodName
to -X- _ O
perform -X- _ O
discrete -X- _ O
reasoning -X- _ O
across -X- _ O
hybrid -X- _ O
contexts -X- _ O
brings -X- _ O
significant -X- _ O
advantages -X- _ O
. -X- _ O
4 -X- _ O
) -X- _ O
The -X- _ O
performance -X- _ O
achieved -X- _ O
is -X- _ O
still -X- _ O
low -X- _ O
w.r.t -X- _ O
. -X- _ O
the -X- _ O
two -X- _ O
metrics -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
54.4→100 -X- _ B-MetricValue
) -X- _ O
, -X- _ O
showing -X- _ O
a -X- _ O
large -X- _ O
space -X- _ O
for -X- _ O
future -X- _ O
exploration -X- _ O
on -X- _ O
the -X- _ O
challenging -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
HQA -X- _ I-DatasetName
dataset -X- _ O
. -X- _ O

Parameter -X- _ O
settings -X- _ O
. -X- _ O
We -X- _ O
implement -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
L2I -X- _ I-MethodName
based -X- _ O
on -X- _ O
TAGOP -X- _ B-MethodName
4 -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
crossattention -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
to -X- _ O
3 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
fine -X- _ O
tune -X- _ O
from -X- _ O
TAGOP -X- _ B-MethodName
trained -X- _ O
on -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5e-5 -X- _ B-HyperparameterValue
, -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
gradient -X- _ B-HyperparameterName
accumulation -X- _ I-HyperparameterName
step -X- _ I-HyperparameterName
of -X- _ O
4 -X- _ B-HyperparameterValue
. -X- _ O
All -X- _ O
compared -X- _ O
methods -X- _ O
are -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
then -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
HQA -X- _ I-DatasetName
. -X- _ O
For -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
CLO -X- _ I-MethodName
, -X- _ O
we -X- _ O
conduct -X- _ O
max -X- _ O
pooling -X- _ O
for -X- _ O
H -X- _ O
and -X- _ O
adopt -X- _ O
cosine -X- _ B-MetricName
similarity -X- _ I-MetricName
as -X- _ O
the -X- _ O
distance -X- _ O
metric -X- _ O
. -X- _ O
We -X- _ O
select -X- _ O
the -X- _ O
corresponding -X- _ O
factual -X- _ O
question -X- _ O
as -X- _ O
the -X- _ O
positive -X- _ O
sample -X- _ O
and -X- _ O
a -X- _ O
randomly -X- _ O
selected -X- _ O
factual -X- _ O
question -X- _ O
as -X- _ O
the -X- _ O
negative -X- _ O
sample -X- _ O
. -X- _ O
The -X- _ O
weight -X- _ B-HyperparameterName
for -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
contrastive -X- _ I-HyperparameterName
loss -X- _ I-HyperparameterName
is -X- _ O
0.1.Overall -X- _ B-HyperparameterValue
performance -X- _ O
. -X- _ O
Table -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
compared -X- _ O
methods -X- _ O
on -X- _ O
the -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
HQA -X- _ I-DatasetName
dataset -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
L2I -X- _ I-MethodName
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
among -X- _ O
all -X- _ O
the -X- _ O
compared -X- _ O
methods -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
it -X- _ O
outperforms -X- _ O
the -X- _ O
best -X- _ O
baselines -X- _ O
by -X- _ O
19.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
19.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
EM -X- _ B-MetricName
and -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
, -X- _ O
respectively -X- _ O
. -X- _ O
Such -X- _ O
significant -X- _ O
performance -X- _ O
gain -X- _ O
validates -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
L2I -X- _ B-MethodName
module -X- _ O
and -X- _ O
reveal -X- _ O
the -X- _ O
rationality -X- _ O
of -X- _ O
modeling -X- _ O
counterfactual -X- _ O
thinking -X- _ O
as -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
module -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
CLO -X- _ I-MethodName
outperforms -X- _ O
TAGOP -X- _ B-MethodName
by -X- _ O
10.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
10.4 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
EM -X- _ B-MetricName
and -X- _ O
F -X- _ B-MetricName
1 -X- _ I-MetricName
. -X- _ O
The -X- _ O
only -X- _ O
difference -X- _ O
between -X- _ O
these -X- _ O
two -X- _ O
methods -X- _ O
is -X- _ O
that -X- _ O
TAGOP -X- _ B-MethodName
- -X- _ I-MethodName
CLO -X- _ I-MethodName
incorporates -X- _ O
an -X- _ O
extra -X- _ O
CLO -X- _ O
. -X- _ O
The -X- _ O
improvement -X- _ O
indicates -X- _ O
that -X- _ O
learning -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
factual -X- _ O
and -X- _ O
counterfactual -X- _ O
samples -X- _ O
with -X- _ O
CLO -X- _ O
provides -X- _ O
some -X- _ O
clue -X- _ O
for -X- _ O
counterfactual -X- _ O
imagination -X- _ O
, -X- _ O
yet -X- _ O
it -X- _ O
is -X- _ O
still -X- _ O
worse -X- _ O
than -X- _ O
directly -X- _ O
learning -X- _ O
to -X- _ O
imagine -X- _ O
with -X- _ O
neural -X- _ O
network -X- _ O
modules -X- _ O
. -X- _ O

wherep -X- _ O
j -X- _ O
∈ -X- _ O
{ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
} -X- _ O
denotes -X- _ O
the -X- _ O
label -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
fact -X- _ O
( -X- _ O
token -X- _ O
j -X- _ O
in -X- _ O
context -X- _ O
) -X- _ O
or -X- _ O
the -X- _ O
premise -X- _ O
( -X- _ O
token -X- _ O
j -X- _ O
in -X- _ O
assumption -X- _ O
) -X- _ O
; -X- _ O
andō -X- _ O
∈ -X- _ O
R -X- _ O
O -X- _ O
is -X- _ O
the -X- _ O
label -X- _ O
of -X- _ O
the -X- _ O
deriving -X- _ O
operator -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
C -X- _ O
for -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
label -X- _ O
construction).Readers -X- _ O
might -X- _ O
have -X- _ O
raised -X- _ O
the -X- _ O
following -X- _ O
two -X- _ O
concerns -X- _ O
for -X- _ O
L2I -X- _ B-MethodName
: -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
operators -X- _ O
defined -X- _ O
are -X- _ O
limited -X- _ O
, -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
operators -X- _ O
are -X- _ O
tailored -X- _ O
to -X- _ O
one -X- _ O
step -X- _ O
of -X- _ O
derivation -X- _ O
on -X- _ O
one -X- _ O
target -X- _ O
fact -X- _ O
. -X- _ O
Actually -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
common -X- _ O
approach -X- _ O
for -X- _ O
current -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
NDR -X- _ B-TaskName
models -X- _ O
to -X- _ O
apply -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
defined -X- _ O
operators -X- _ O
( -X- _ O
Ran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a;Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

• -X- _ O
Deriving -X- _ O
head -X- _ O
. -X- _ O
It -X- _ O
derives -X- _ O
the -X- _ O
intervention -X- _ O
result -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
fact -X- _ O
. -X- _ O
To -X- _ O
calculate -X- _ O
the -X- _ O
intervention -X- _ O
result -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
commonly -X- _ O
used -X- _ O
discrete -X- _ O
operators -X- _ O
such -X- _ O
as -X- _ O
SWAP -X- _ O
, -X- _ O
ADD -X- _ O
, -X- _ O
and -X- _ O
MINUS -X- _ O
( -X- _ O
cf -X- _ O
. -X- _ O
Appendix -X- _ O
B -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
model -X- _ O
the -X- _ O
derivation -X- _ O
as -X- _ O
making -X- _ O
a -X- _ O
choice -X- _ O
across -X- _ O
the -X- _ O
operators -X- _ O
and -X- _ O
tagging -X- _ O
the -X- _ O
premise -X- _ O
for -X- _ O
executing -X- _ O
the -X- _ O
operator -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
a -X- _ O
tagging -X- _ O
head -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
premise -X- _ O
and -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
way -X- _ O
classifier -X- _ O
for -X- _ O
choosing -X- _ O
operators -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
formulated -X- _ O
as -X- _ O
: -X- _ O
o -X- _ O
= -X- _ O
sof -X- _ O
tmax(MLP(h -X- _ O
CLS -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
o -X- _ O
∈ -X- _ O
R -X- _ B-HyperparameterName
O -X- _ I-HyperparameterName
is -X- _ O
a -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
operators -X- _ O
where -X- _ O
O -X- _ B-HyperparameterName
denotes -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
operators -X- _ I-HyperparameterName
. -X- _ O
h -X- _ O
CLS -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
CLS -X- _ O
token -X- _ O
in -X- _ O
H.Most -X- _ O
recent -X- _ O
NDR -X- _ B-TaskName
models -X- _ O
( -X- _ O
Ran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Andor -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a;Herzig -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
( -X- _ O
Dua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Suppose -X- _ O
we -X- _ O
have -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
labeled -X- _ O
questions -X- _ O
D -X- _ O
= -X- _ O
{ -X- _ O
< -X- _ O
ȳ -X- _ O
, -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
, -X- _ O
a -X- _ O
) -X- _ O
> -X- _ O
} -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
objective -X- _ O
can -X- _ O
be -X- _ O
abstracted -X- _ O
as -X- _ O
min -X- _ O
θ -X- _ O
D -X- _ O
QA -X- _ O
( -X- _ O
ȳ -X- _ O
, -X- _ O
f -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
, -X- _ O
a -X- _ O
) -X- _ O
) -X- _ O
where -X- _ O
θ -X- _ O
denotes -X- _ O
model -X- _ O
parameters -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
QA(• -X- _ O
) -X- _ O
measures -X- _ O
the -X- _ O
discrepancy -X- _ O
between -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
and -X- _ O
the -X- _ O
predicted -X- _ O
answers -X- _ O
which -X- _ O
can -X- _ O
have -X- _ O
different -X- _ O
formats -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
the -X- _ O
cross -X- _ B-MetricName
- -X- _ I-MetricName
entropy -X- _ I-MetricName
( -X- _ O
CE -X- _ B-MetricName
) -X- _ O
loss -X- _ O
over -X- _ O
the -X- _ O
operand -X- _ O
look -X- _ O
- -X- _ O
up -X- _ O
and -X- _ O
the -X- _ O
CE -X- _ B-MetricName
loss -X- _ O
over -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
discrete -X- _ O
operation -X- _ O
( -X- _ O
Herzig -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
When -X- _ O
applying -X- _ O
L2I -X- _ B-MethodName
to -X- _ O
an -X- _ O
existing -X- _ O
NDR -X- _ B-TaskName
method -X- _ O
, -X- _ O
we -X- _ O
keep -X- _ O
its -X- _ O
question -X- _ O
- -X- _ O
answering -X- _ O
objective -X- _ O
unchanged -X- _ O
. -X- _ O
To -X- _ O
optimize -X- _ O
the -X- _ O
L2I -X- _ B-MethodName
module -X- _ O
, -X- _ O
we -X- _ O
incorporate -X- _ O
supervision -X- _ O
on -X- _ O
the -X- _ O
classifiers -X- _ O
in -X- _ O
the -X- _ O
tagging -X- _ O
head -X- _ O
and -X- _ O
deriving -X- _ O
head -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O

Module -X- _ O
Design -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
- -X- _ O
step -X- _ O
formulation -X- _ O
, -X- _ O
we -X- _ O
then -X- _ O
design -X- _ O
the -X- _ O
L2I -X- _ B-MethodName
module -X- _ O
as -X- _ O
neural -X- _ O
network -X- _ O
operations -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
two -X- _ O
considerations -X- _ O
for -X- _ O
the -X- _ O
module -X- _ O
design -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
module -X- _ O
should -X- _ O
recognize -X- _ O
the -X- _ O
semantic -X- _ O
connection -X- _ O
between -X- _ O
the -X- _ O
assumption -X- _ O
and -X- _ O
the -X- _ O
context -X- _ O
, -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
module -X- _ O
should -X- _ O
uniformly -X- _ O
support -X- _ O
various -X- _ O
discrete -X- _ O
operations -X- _ O
to -X- _ O
enable -X- _ O
accurate -X- _ O
derivation -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
devise -X- _ O
four -X- _ O
key -X- _ O
building -X- _ O
blocks -X- _ O
for -X- _ O
the -X- _ O
L2I -X- _ B-MethodName
module -X- _ O
: -X- _ O
• -X- _ O
Encoder -X- _ O
. -X- _ O
It -X- _ O
projects -X- _ O
the -X- _ O
raw -X- _ O
content -X- _ O
into -X- _ O
latent -X- _ O
representation -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
the -X- _ O
recent -X- _ O
research -X- _ O
on -X- _ O
NDR -X- _ B-TaskName
, -X- _ O
we -X- _ O
employ -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
PLM -X- _ O
) -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
RoBERTa -X- _ B-MethodName
, -X- _ O
as -X- _ O
the -X- _ O
encoder -X- _ O
to -X- _ O
learn -X- _ O
an -X- _ O
overall -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
, -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
assumption -X- _ O
; -X- _ O

Two -X- _ O
- -X- _ O
step -X- _ O
Formulation -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
step -X- _ O
formulation -X- _ O
of -X- _ O
counterfactual -X- _ O
thinking -X- _ O
for -X- _ O
HQA -X- _ B-TaskName
to -X- _ O
perform -X- _ O
the -X- _ O
identification -X- _ O
and -X- _ O
derivation -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O

We -X- _ O
conduct -X- _ O
a -X- _ O
pilot -X- _ O
study -X- _ O
on -X- _ O
the -X- _ O
generalization -X- _ O
ability -X- _ O
of -X- _ O
existing -X- _ O
NDR -X- _ B-TaskName
models -X- _ O
on -X- _ O
hypothetical -X- _ O
questions -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
TAGOP -X- _ B-MethodName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
model -X- _ O
on -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
( -X- _ O
see -X- _ O
detailed -X- _ O
settings -X- _ O
in -X- _ O
Section -X- _ O
4.1 -X- _ O
) -X- _ O
by -X- _ O
training -X- _ O
on -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
and -X- _ O
testing -X- _ O
on -X- _ B-DatasetName
TAT -X- _ I-DatasetName
- -X- _ I-DatasetName
HQA -X- _ I-DatasetName
. -X- _ O
In -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
the -X- _ O
huge -X- _ O
performance -X- _ O
drop -X- _ O
shows -X- _ O
that -X- _ O
even -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
NDR -X- _ B-TaskName
model -X- _ O
lacks -X- _ O
counterfactual -X- _ O
thinking -X- _ O
ability -X- _ O
. -X- _ O
We -X- _ O
aim -X- _ O
to -X- _ O
empower -X- _ O
NDR -X- _ B-TaskName
models -X- _ O
with -X- _ O
counterfactual -X- _ O
thinking -X- _ O
ability -X- _ O
. -X- _ O
Firstly -X- _ O
, -X- _ O
we -X- _ O
decide -X- _ O
to -X- _ O
choose -X- _ O
the -X- _ O
approach -X- _ O
of -X- _ O
explicitly -X- _ O
modeling -X- _ O
discrete -X- _ O
operations -X- _ O
, -X- _ O
since -X- _ O
existing -X- _ O
NDR -X- _ B-TaskName
solutions -X- _ O
have -X- _ O
demonstrated -X- _ O
its -X- _ O
superiority -X- _ O
( -X- _ O
Dua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Ran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Herzig -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
devise -X- _ O
a -X- _ O
Learning -X- _ O
to -X- _ O
Imagine -X- _ O
module -X- _ O
to -X- _ O
model -X- _ O
counterfactual -X- _ O
thinking -X- _ O
( -X- _ O
Section -X- _ O
3.1 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
incorporate -X- _ O
the -X- _ O
L2I -X- _ B-MethodName
module -X- _ O
( -X- _ O
Section -X- _ O
3.2 -X- _ O
) -X- _ O
into -X- _ O
existing -X- _ O
NRD -X- _ B-TaskName
methods -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
discussion -X- _ O
about -X- _ O
potential -X- _ O
extensions -X- _ O
( -X- _ O
Section -X- _ O
3.3).Functionally -X- _ O
speaking -X- _ O
, -X- _ O
the -X- _ O
L2I -X- _ B-MethodName
module -X- _ O
aims -X- _ O
to -X- _ O
construct -X- _ O
a -X- _ O
counterfactual -X- _ O
context -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
factual -X- _ O
context -X- _ O
and -X- _ O
the -X- _ O
assumption -X- _ O
. -X- _ O
We -X- _ O
formulate -X- _ O
it -X- _ O
as -X- _ O
: -X- _ O
c -X- _ O
= -X- _ O
g(c -X- _ O
, -X- _ O
a -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
counterfactual -X- _ O
context -X- _ O
c -X- _ O
is -X- _ O
the -X- _ O
status -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
c -X- _ O
after -X- _ O
the -X- _ O
assumption -X- _ O
a -X- _ O
is -X- _ O
executed -X- _ O
. -X- _ O
Resorting -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
of -X- _ O
causality -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
expressed -X- _ O
as -X- _ O
the -X- _ O
do -X- _ O
- -X- _ O
operation -X- _ O
that -X- _ O
intervenes -X- _ O
a -X- _ O
variable -X- _ O
to -X- _ O
execute -X- _ O
the -X- _ O
assumption -X- _ O
and -X- _ O
the -X- _ O
action -X- _ O
to -X- _ O
derive -X- _ O
the -X- _ O
outcome -X- _ O
of -X- _ O
the -X- _ O
intervention -X- _ O
3 -X- _ O
( -X- _ O
Pearl -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
key -X- _ O
to -X- _ O
achieving -X- _ O
counterfactual -X- _ O
thinking -X- _ O
in -X- _ O
NDR -X- _ B-TaskName
lies -X- _ O
in -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
parsing -X- _ O
the -X- _ O
assumption -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
target -X- _ O
fact -X- _ O
to -X- _ O
intervene -X- _ O
; -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
deriving -X- _ O
the -X- _ O
assumed -X- _ O
value -X- _ O
to -X- _ O
construct -X- _ O
the -X- _ O
counterfactual -X- _ O
context -X- _ O
. -X- _ O
Taking -X- _ O
the -X- _ O
hypothetical -X- _ O
question -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
as -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
an -X- _ O
ideal -X- _ O
L2I -X- _ B-MethodName
should -X- _ O
recognize -X- _ O
the -X- _ O
target -X- _ O
variable -X- _ O
( -X- _ O
finished -X- _ O
goods -X- _ O
in -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
identify -X- _ O
the -X- _ O
corresponding -X- _ O
fact -X- _ O
( -X- _ O
$ -X- _ O
133,682 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
replace -X- _ O
the -X- _ O
fact -X- _ O
with -X- _ O
the -X- _ O
assumed -X- _ O
value -X- _ O
( -X- _ O
$ -X- _ O
132,935 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
facilitate -X- _ O
the -X- _ O
evaluation -X- _ O
of -X- _ B-TaskName
HQA -X- _ I-TaskName
and -X- _ O
diagnose -X- _ O
counterfactual -X- _ O
thinking -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
an -X- _ O
HQA -X- _ B-TaskName
dataset -X- _ O
based -X- _ O
on -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
QA -X- _ B-TaskName
dataset -X- _ O
with -X- _ O
a -X- _ O
mix -X- _ O
of -X- _ O
tabular -X- _ O
and -X- _ O
textual -X- _ O
context -X- _ O
extracted -X- _ O
from -X- _ O
financial -X- _ O
reports -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
previous -X- _ O
work -X- _ O
on -X- _ O
constructing -X- _ O
counterfactual -X- _ O
samples -X- _ O
( -X- _ O
Kaushik -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
recruit -X- _ O
college -X- _ O
students -X- _ O
with -X- _ O
finance -X- _ O
- -X- _ O
related -X- _ O
majors -X- _ O
to -X- _ O
imagine -X- _ O
an -X- _ O
intervention -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
factual -X- _ O
question -X- _ O
and -X- _ O
context -X- _ O
from -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
which -X- _ O
involves -X- _ O
numerical -X- _ O
thinking -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
a -X- _ O
change -X- _ O
of -X- _ O
number -X- _ O
. -X- _ O
Then -X- _ O
they -X- _ O
phrase -X- _ O
the -X- _ O
intervention -X- _ O
into -X- _ O
an -X- _ O
assumption -X- _ O
, -X- _ O
forming -X- _ O
a -X- _ O
" -X- _ O
what -X- _ O
if -X- _ O
" -X- _ O
type -X- _ O
of -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
calculate -X- _ O
the -X- _ O
answer -X- _ O
( -X- _ O
see -X- _ O
an -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
ensure -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
the -X- _ O
phrasing -X- _ O
, -X- _ O
annotators -X- _ O
are -X- _ O
free -X- _ O
to -X- _ O
generate -X- _ O
various -X- _ O
phrasing -X- _ O
of -X- _ O
the -X- _ O
assumption -X- _ O
, -X- _ O
and -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
restriction -X- _ O
on -X- _ O
the -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
assumption -X- _ O
. -X- _ O
Usually -X- _ O
, -X- _ O
the -X- _ O
assumption -X- _ O
appears -X- _ O
either -X- _ O
before -X- _ O
of -X- _ O
after -X- _ O
the -X- _ O
factual -X- _ O
question -X- _ O
. -X- _ O
Each -X- _ O
hypothetical -X- _ O
question -X- _ O
is -X- _ O
related -X- _ O
to -X- _ O
one -X- _ O
factual -X- _ O
question -X- _ O
from -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
, -X- _ O
but -X- _ O
each -X- _ O
factual -X- _ O
question -X- _ O
in -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
is -X- _ O
not -X- _ O
guaranteed -X- _ O
to -X- _ O
have -X- _ O
one -X- _ O
hypothetical -X- _ O
question -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
quality -X- _ O
control -X- _ O
approaches -X- _ O
of -X- _ O
annotator -X- _ O
training -X- _ O
and -X- _ O
two -X- _ O
- -X- _ O
round -X- _ O
validation -X- _ O
in -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
to -X- _ O
guarantee -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
hypothetical -X- _ O
questions -X- _ O
. -X- _ O
Following -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
, -X- _ O
the -X- _ O
hypothetical -X- _ O
questions -X- _ O
are -X- _ O
also -X- _ O
labeled -X- _ O
with -X- _ O
four -X- _ O
answer -X- _ O
types -X- _ O
: -X- _ O
arithmetic -X- _ O
, -X- _ O
span -X- _ O
, -X- _ O
count -X- _ O
, -X- _ O
and -X- _ O
multi -X- _ O
- -X- _ O
span -X- _ O
, -X- _ O
three -X- _ O
types -X- _ O
of -X- _ O
answer -X- _ O
sources -X- _ O
: -X- _ O
table -X- _ O
, -X- _ O
text -X- _ O
and -X- _ O
table -X- _ O
- -X- _ O
text -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
derivation -X- _ O
on -X- _ O
how -X- _ O
the -X- _ O
answer -X- _ O
is -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
context -X- _ O
. -X- _ O
In -X- _ O
total -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
8,283 -X- _ O
hypothetical -X- _ O
questions -X- _ O
, -X- _ O
naming -X- _ O
it -X- _ O
as -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
HQA -X- _ I-DatasetName
. -X- _ O
The -X- _ O
statistics -X- _ O
of -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
HQA -X- _ I-DatasetName
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
split -X- _ O
of -X- _ O
training -X- _ O
, -X- _ O
testing -X- _ O
and -X- _ O
validation -X- _ O
set -X- _ O
of -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
construct -X- _ O
a -X- _ O
challenging -X- _ O
HQA -X- _ B-TaskName
dataset -X- _ O
and -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
performance -X- _ O
validates -X- _ O
the -X- _ O
rationality -X- _ O
and -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ B-MethodName
L2I.In -X- _ I-MethodName
the -X- _ O
general -X- _ O
setting -X- _ O
of -X- _ O
machine -X- _ O
reading -X- _ O
comprehension -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
answer -X- _ O
a -X- _ O
question -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
facts -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
context -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
function -X- _ O
y -X- _ O
= -X- _ O
f -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
y -X- _ O
, -X- _ O
q -X- _ O
, -X- _ O
and -X- _ O
c -X- _ O
are -X- _ O
the -X- _ O
word -X- _ O
list -X- _ O
representing -X- _ O
the -X- _ O
answer -X- _ O
, -X- _ O
the -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
context -X- _ O
2 -X- _ O
respectively -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
studies -X- _ O
a -X- _ O
new -X- _ O
and -X- _ O
more -X- _ O
challenging -X- _ O
task -X- _ O
that -X- _ O
focuses -X- _ O
on -X- _ O
hypothetical -X- _ O
question -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
a -X- _ O
hypothetical -X- _ O
question -X- _ O
includes -X- _ O
an -X- _ O
assumption -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
if -X- _ O
the -X- _ O
amount -X- _ O
in -X- _ O
2019 -X- _ O
was -X- _ O
$ -X- _ O
132,935 -X- _ O
thousand -X- _ O
instead -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
target -X- _ O
of -X- _ O
HQA -X- _ B-TaskName
is -X- _ O
to -X- _ O
learn -X- _ O
y -X- _ O
= -X- _ O
f -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
c -X- _ O
, -X- _ O
a -X- _ O
) -X- _ O
where -X- _ O
a -X- _ O
denotes -X- _ O
the -X- _ O
assumption -X- _ O
. -X- _ O
The -X- _ O
existence -X- _ O
of -X- _ O
an -X- _ O
assumption -X- _ O
calls -X- _ O
for -X- _ O
the -X- _ O
imagination -X- _ O
of -X- _ O
a -X- _ O
counterfactual -X- _ O
context -X- _ O
before -X- _ O
inferring -X- _ O
the -X- _ O
answer -X- _ O
, -X- _ O
pushing -X- _ O
the -X- _ O
NDR -X- _ B-TaskName
model -X- _ O
to -X- _ O
grasp -X- _ O
both -X- _ O
semantic -X- _ O
understanding -X- _ O
and -X- _ O
counterfactual -X- _ O
thinking -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
devise -X- _ O
the -X- _ O
L2I -X- _ B-MethodName
module -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
designed -X- _ O
as -X- _ O
neural -X- _ O
network -X- _ O
operations -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
seamlessly -X- _ O
incorporated -X- _ O
into -X- _ O
the -X- _ O
NDR -X- _ B-TaskName
model -X- _ O
for -X- _ O
answering -X- _ O
hypothetical -X- _ O
questions -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
light -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
modeling -X- _ O
counterfactual -X- _ O
thinking -X- _ O
as -X- _ O
neural -X- _ O
network -X- _ O
modules -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
seamlessly -X- _ O
incorporated -X- _ O
into -X- _ O
existing -X- _ O
NDR -X- _ B-TaskName
models -X- _ O
. -X- _ O
One -X- _ O
straightforward -X- _ O
solution -X- _ O
is -X- _ O
to -X- _ O
model -X- _ O
counterfactual -X- _ O
thinking -X- _ O
as -X- _ O
a -X- _ O
generation -X- _ O
procedure -X- _ O
with -X- _ O
the -X- _ O
fact -X- _ O
and -X- _ O
assumption -X- _ O
as -X- _ O
inputs -X- _ O
by -X- _ O
using -X- _ O
a -X- _ O
generation -X- _ O
model -X- _ O
such -X- _ O
as -X- _ O
GPT -X- _ B-MethodName
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
such -X- _ O
uncontrollable -X- _ O
model -X- _ O
( -X- _ O
Zou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
can -X- _ O
hardly -X- _ O
generate -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
context -X- _ O
for -X- _ O
two -X- _ O
reasons -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
context -X- _ O
is -X- _ O
more -X- _ O
complex -X- _ O
than -X- _ O
plain -X- _ O
text -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
include -X- _ O
a -X- _ O
table -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
; -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
NDR -X- _ B-TaskName
requires -X- _ O
a -X- _ O
precise -X- _ O
context -X- _ O
with -X- _ O
the -X- _ O
correct -X- _ O
numbers -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
$ -X- _ O
132,935 -X- _ O
for -X- _ O
the -X- _ O
finished -X- _ O
goods -X- _ O
in -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
resort -X- _ O
to -X- _ O
an -X- _ O
alternative -X- _ O
approach -X- _ O
: -X- _ O
constructing -X- _ O
the -X- _ O
counterfactual -X- _ O
( -X- _ O
Pearl -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
where -X- _ O
the -X- _ O
target -X- _ O
variable -X- _ O
is -X- _ O
intervened -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
hypothetical -X- _ O
condition -X- _ O
to -X- _ O
infer -X- _ O
a -X- _ O
counterfactual -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
Learning -X- _ O
to -X- _ O
Imagine -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
counterfactual -X- _ O
thinking -X- _ O
is -X- _ O
implemented -X- _ O
with -X- _ O
two -X- _ O
intervening -X- _ O
steps -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
identifying -X- _ O
the -X- _ O
facts -X- _ O
to -X- _ O
intervene -X- _ O
, -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
deriving -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
intervention -X- _ O
. -X- _ O
To -X- _ O
pursue -X- _ O
accurate -X- _ O
context -X- _ O
, -X- _ O
we -X- _ O
derive -X- _ O
the -X- _ O
intervention -X- _ O
with -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
discrete -X- _ O
operators -X- _ O
such -X- _ O
as -X- _ O
SWAP -X- _ O
and -X- _ O
ADD -X- _ O
for -X- _ O
imagination -X- _ O
. -X- _ O
To -X- _ O
evaluate -X- _ O
the -X- _ O
counterfactual -X- _ O
thinking -X- _ O
ability -X- _ O
, -X- _ O
we -X- _ O
recruit -X- _ O
volunteers -X- _ O
with -X- _ O
domain -X- _ O
expertise -X- _ O
to -X- _ O
construct -X- _ O
an -X- _ O
HQA -X- _ B-TaskName
dataset -X- _ O
based -X- _ O
on -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
by -X- _ O
posting -X- _ O
an -X- _ O
assumption -X- _ O
for -X- _ O
each -X- _ O
original -X- _ O
question -X- _ O
, -X- _ O
named -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
HQA -X- _ I-DatasetName
. -X- _ O
We -X- _ O
apply -X- _ O
L2I -X- _ B-MethodName
to -X- _ O
TAGOP -X- _ B-MethodName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
obtain -X- _ O
a -X- _ O
promising -X- _ O
solution -X- _ O
for -X- _ O
HQA -X- _ B-TaskName
. -X- _ O
In -X- _ O
summary -X- _ O
, -X- _ O
the -X- _ O
main -X- _ O
contributions -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

• -X- _ O
We -X- _ O
highlight -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
counterfactual -X- _ O
thinking -X- _ O
in -X- _ O
NDR -X- _ B-TaskName
and -X- _ O
formulate -X- _ O
counterfactual -X- _ O
thinking -X- _ O
as -X- _ O
an -X- _ O
intervening -X- _ O
procedure -X- _ O
to -X- _ O
achieve -X- _ O
precise -X- _ O
imagination -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
extend -X- _ O
NDR -X- _ B-TaskName
to -X- _ O
hypothetical -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
( -X- _ O
HQA -X- _ B-TaskName
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
question -X- _ O
consists -X- _ O
of -X- _ O
an -X- _ O
assumption -X- _ O
beyond -X- _ O
the -X- _ O
context -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
ability -X- _ O
of -X- _ O
HQA -X- _ B-TaskName
will -X- _ O
undoubtedly -X- _ O
enhance -X- _ O
the -X- _ O
practical -X- _ O
use -X- _ O
of -X- _ O
NDR -X- _ B-TaskName
due -X- _ O
to -X- _ O
the -X- _ O
universality -X- _ O
of -X- _ O
hypothetical -X- _ O
questions -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
current -X- _ B-TaskName
NDR -X- _ I-TaskName
models -X- _ O
face -X- _ O
severe -X- _ O
generalization -X- _ O
failure -X- _ O
on -X- _ O
hypothetical -X- _ O
questions -X- _ O
. -X- _ O
An -X- _ O
empirical -X- _ O
evidence -X- _ O
on -X- _ O
such -X- _ O
vulnerability -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
model -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
encounters -X- _ O
a -X- _ O
sharp -X- _ O
performance -X- _ O
drop -X- _ O
( -X- _ O
F1 -X- _ O
score -X- _ O
drops -X- _ O
from -X- _ O
68.6 -X- _ O
% -X- _ O
to -X- _ O
3.8 -X- _ O
% -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
TAT -X- _ B-DatasetName
- -X- _ I-DatasetName
QA -X- _ I-DatasetName
dataset -X- _ O
when -X- _ O
changing -X- _ O
the -X- _ O
questions -X- _ O
to -X- _ O
be -X- _ O
hypothetical -X- _ O
by -X- _ O
adding -X- _ O
a -X- _ O
related -X- _ O
assumption -X- _ O
( -X- _ O
see -X- _ O
details -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
, -X- _ O
Table -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
postulate -X- _ O
that -X- _ O
the -X- _ O
failure -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
unable -X- _ O
of -X- _ O
imagining -X- _ O
the -X- _ O
counterfactual -X- _ O
context -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
assumption -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
pursue -X- _ O
such -X- _ B-TaskName
reasoning -X- _ I-TaskName
ability -X- _ O
, -X- _ O
we -X- _ O
resort -X- _ O
to -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
counterfactual -X- _ O
thinking -X- _ O
( -X- _ O
Pearl -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
from -X- _ O
the -X- _ O
theory -X- _ O
of -X- _ O
causality -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
imagine -X- _ O
and -X- _ O
reason -X- _ O
over -X- _ O
unseen -X- _ O
cases -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
seen -X- _ O
facts -X- _ O
and -X- _ O
counterfactual -X- _ O
assumptions -X- _ O
. -X- _ O

Neural -X- _ B-TaskName
discrete -X- _ I-TaskName
reasoning -X- _ I-TaskName
( -X- _ O
Dua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
an -X- _ O
emerging -X- _ O
technique -X- _ O
for -X- _ O
machine -X- _ O
reading -X- _ O
comprehension -X- _ O
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
which -X- _ O
aims -X- _ O
at -X- _ O
answering -X- _ O
numerical -X- _ O
questions -X- _ O
from -X- _ O
textual -X- _ O
( -X- _ O
Dua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
hybrid -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
context -X- _ O
1 -X- _ O
. -X- _ O
NDR -X- _ B-TaskName
combines -X- _ O
deep -X- _ O
neural -X- _ O
network -X- _ O
with -X- _ O
discrete -X- _ B-TaskName
and -X- _ I-TaskName
symbolic -X- _ I-TaskName
reasoning -X- _ I-TaskName
( -X- _ O
e.g. -X- _ O
, -X- _ O
addition -X- _ B-TaskName
, -X- _ O
sorting -X- _ B-TaskName
, -X- _ O
or -X- _ O
counting -X- _ B-TaskName
) -X- _ O
( -X- _ O
Dua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
enables -X- _ O
the -X- _ O
comprehension -X- _ O
of -X- _ O
complex -X- _ O
contexts -X- _ O
and -X- _ O
compositional -X- _ O
questions -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
critical -X- _ O
for -X- _ O
many -X- _ O
practical -X- _ O
applications -X- _ O
such -X- _ O
as -X- _ O
automatic -X- _ O
diagnosis -X- _ O
( -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
robo -X- _ O
- -X- _ O
advisor -X- _ O
( -X- _ O
Fisch -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Existing -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ B-TaskName
NDR -X- _ I-TaskName
models -X- _ O
implement -X- _ O
the -X- _ O
nu -X- _ B-TaskName
- -X- _ I-TaskName
merical -X- _ I-TaskName
reasoning -X- _ I-TaskName
process -X- _ O
as -X- _ O
neural -X- _ O
network -X- _ O
modules -X- _ O
( -X- _ O
Ran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Herzig -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
a -X- _ O
graph -X- _ O
neural -X- _ O
network -X- _ O
for -X- _ O
sorting -X- _ O
( -X- _ O
Ran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
quantified -X- _ B-TaskName
reproducibility -X- _ I-TaskName
assessment -X- _ I-TaskName
( -X- _ O
QRA -X- _ B-TaskName
) -X- _ O
, -X- _ O
an -X- _ O
approach -X- _ O
that -X- _ O
is -X- _ O
directly -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
concepts -X- _ O
and -X- _ O
definitions -X- _ O
of -X- _ O
metrology -X- _ O
, -X- _ O
adopting -X- _ O
the -X- _ O
latter -X- _ O
exactly -X- _ O
as -X- _ O
they -X- _ O
are -X- _ O
, -X- _ O
and -X- _ O
yields -X- _ O
assessments -X- _ O
of -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
similarity -X- _ O
between -X- _ O
numerical -X- _ O
results -X- _ O
and -X- _ O
between -X- _ O
the -X- _ O
studies -X- _ O
that -X- _ O
produced -X- _ O
them -X- _ O
. -X- _ O
We -X- _ O
start -X- _ O
below -X- _ O
with -X- _ O
the -X- _ O
concepts -X- _ O
and -X- _ O
definitions -X- _ O
that -X- _ O
QRA -X- _ B-TaskName
is -X- _ O
based -X- _ O
on -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
the -X- _ O
framework -X- _ O
( -X- _ O
Section -X- _ O
3.2 -X- _ O
) -X- _ O
and -X- _ O
steps -X- _ O
in -X- _ O
applying -X- _ O
it -X- _ O
in -X- _ O
practice -X- _ O
( -X- _ O
Section -X- _ O
3.3).The -X- _ O
International -X- _ O
Vocabulary -X- _ O
of -X- _ O
Metrology -X- _ O
( -X- _ O
VIM -X- _ O
) -X- _ O
( -X- _ O
JCGM -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
defines -X- _ O
repeatability -X- _ O
and -X- _ O
reproducibility -X- _ O
as -X- _ O
follows -X- _ O
( -X- _ O
defined -X- _ O
terms -X- _ O
in -X- _ O
bold -X- _ O
, -X- _ O
see -X- _ O
VIM -X- _ O
for -X- _ O
subsidiary -X- _ O
defined -X- _ O
terms -X- _ O
): -X- _ O

According -X- _ O
to -X- _ O
the -X- _ O
ACM -X- _ O
's -X- _ O
definitions -X- _ O
( -X- _ O
Association -X- _ O
for -X- _ O
Computing -X- _ O
Machinery -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
results -X- _ O
have -X- _ O
been -X- _ O
reproduced -X- _ O
if -X- _ O
obtained -X- _ O
in -X- _ O
a -X- _ O
different -X- _ O
study -X- _ O
by -X- _ O
a -X- _ O
different -X- _ O
team -X- _ O
using -X- _ O
artifacts -X- _ O
supplied -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
the -X- _ O
original -X- _ O
authors -X- _ O
, -X- _ O
and -X- _ O
replicated -X- _ O
if -X- _ O
obtained -X- _ O
in -X- _ O
a -X- _ O
different -X- _ O
study -X- _ O
by -X- _ O
a -X- _ O
different -X- _ O
team -X- _ O
using -X- _ O
artifacts -X- _ O
not -X- _ O
supplied -X- _ O
by -X- _ O
the -X- _ O
original -X- _ O
authors -X- _ O
. -X- _ O
The -X- _ O
ACM -X- _ O
originally -X- _ O
had -X- _ O
these -X- _ O
definitions -X- _ O
the -X- _ O
other -X- _ O
way -X- _ O
around -X- _ O
until -X- _ O
asked -X- _ O
by -X- _ O
ISO -X- _ O
to -X- _ O
bring -X- _ O
them -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
the -X- _ O
scientific -X- _ O
standard -X- _ O
( -X- _ O
ibid -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O

Despite -X- _ O
this -X- _ O
growing -X- _ O
body -X- _ O
of -X- _ O
research -X- _ O
, -X- _ O
no -X- _ O
consensus -X- _ O
has -X- _ O
emerged -X- _ O
about -X- _ O
standards -X- _ O
, -X- _ O
terminology -X- _ O
and -X- _ O
definitions -X- _ O
. -X- _ O
Particularly -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
most -X- _ O
frequently -X- _ O
used -X- _ O
terms -X- _ O
, -X- _ O
reproducibility -X- _ O
and -X- _ O
replicability -X- _ O
, -X- _ O
multiple -X- _ O
divergent -X- _ O
definitions -X- _ O
are -X- _ O
in -X- _ O
use -X- _ O
, -X- _ O
variously -X- _ O
conditioned -X- _ O
on -X- _ O
same -X- _ O
vs. -X- _ O
different -X- _ O
teams -X- _ O
, -X- _ O
methods -X- _ O
, -X- _ O
artifacts -X- _ O
, -X- _ O
code -X- _ O
, -X- _ O
and -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
for -X- _ O
Rougier -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
reproducing -X- _ O
a -X- _ O
result -X- _ O
means -X- _ O
running -X- _ O
the -X- _ O
same -X- _ O
code -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
and -X- _ O
obtaining -X- _ O
the -X- _ O
same -X- _ O
result -X- _ O
, -X- _ O
while -X- _ O
replicating -X- _ O
the -X- _ O
result -X- _ O
is -X- _ O
writing -X- _ O
and -X- _ O
running -X- _ O
new -X- _ O
code -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
information -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
original -X- _ O
publication -X- _ O
. -X- _ O
For -X- _ O
Wieling -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
reproducibility -X- _ O
is -X- _ O
achieving -X- _ O
the -X- _ O
same -X- _ O
results -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
and -X- _ O
methods -X- _ O
. -X- _ O

Reproducibility -X- _ O
more -X- _ O
generally -X- _ O
is -X- _ O
becoming -X- _ O
more -X- _ O
of -X- _ O
a -X- _ O
research -X- _ O
focus -X- _ O
. -X- _ O
There -X- _ O
have -X- _ O
been -X- _ O
several -X- _ O
workshops -X- _ O
and -X- _ O
initiatives -X- _ O
on -X- _ O
reproducibility -X- _ O
, -X- _ O
including -X- _ O
workshops -X- _ O
at -X- _ O
ICML -X- _ O
2017 -X- _ O
and -X- _ O
2018 -X- _ O
, -X- _ O
the -X- _ O
reproducibility -X- _ O
challenge -X- _ O
at -X- _ O
ICLR -X- _ O
2018 -X- _ O
and -X- _ O
2019 -X- _ O
, -X- _ O
and -X- _ O
at -X- _ O
NeurIPS -X- _ O
2019 -X- _ O
and -X- _ O
2020 -X- _ O
, -X- _ O
the -X- _ O
RE -X- _ O
- -X- _ O
PROLANG -X- _ O
( -X- _ O
Branco -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
initiative -X- _ O
at -X- _ O
LREC -X- _ O
2020 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
ReproGen -X- _ O
shared -X- _ O
task -X- _ O
on -X- _ O
reproducibility -X- _ O
in -X- _ O
NLG -X- _ O
( -X- _ O
Belz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
describe -X- _ O
a -X- _ O
method -X- _ O
for -X- _ O
quantified -X- _ B-TaskName
reproducibility -X- _ I-TaskName
assessment -X- _ I-TaskName
( -X- _ O
QRA -X- _ B-TaskName
) -X- _ O
directly -X- _ O
derived -X- _ O
from -X- _ O
standard -X- _ O
concepts -X- _ O
and -X- _ O
definitions -X- _ O
from -X- _ O
metrology -X- _ O
which -X- _ O
addresses -X- _ O
the -X- _ O
above -X- _ O
issues -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
test -X- _ O
it -X- _ O
on -X- _ O
diverse -X- _ O
sets -X- _ O
of -X- _ O
NLP -X- _ O
results -X- _ O
. -X- _ O
Following -X- _ O
a -X- _ O
review -X- _ O
of -X- _ O
related -X- _ O
research -X- _ O
( -X- _ O
Section -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
method -X- _ O
( -X- _ O
Section -X- _ O
3 -X- _ O
) -X- _ O
, -X- _ O
tests -X- _ O
and -X- _ O
results -X- _ O
( -X- _ O
Section -X- _ O
4 -X- _ O
) -X- _ O
, -X- _ O
discuss -X- _ O
method -X- _ O
and -X- _ O
results -X- _ O
( -X- _ O
Section -X- _ O
5 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
finish -X- _ O
with -X- _ O
some -X- _ O
conclusions -X- _ O
( -X- _ O
Section -X- _ O
6).The -X- _ O
situation -X- _ O
memorably -X- _ O
caricatured -X- _ O
by -X- _ O
Pedersen -X- _ O
( -X- _ O
2008 -X- _ O
) -X- _ O
still -X- _ O
happens -X- _ O
all -X- _ O
the -X- _ O
time -X- _ O
: -X- _ O
you -X- _ O
download -X- _ O
some -X- _ O
code -X- _ O
you -X- _ O
read -X- _ O
about -X- _ O
in -X- _ O
a -X- _ O
paper -X- _ O
and -X- _ O
liked -X- _ O
the -X- _ O
sound -X- _ O
of -X- _ O
, -X- _ O
you -X- _ O
run -X- _ O
it -X- _ O
on -X- _ O
the -X- _ O
data -X- _ O
provided -X- _ O
, -X- _ O
only -X- _ O
to -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
not -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
reported -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
, -X- _ O
in -X- _ O
fact -X- _ O
they -X- _ O
are -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
worse -X- _ O
( -X- _ O
Belz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
. -X- _ O
When -X- _ O
both -X- _ O
data -X- _ O
and -X- _ O
code -X- _ O
are -X- _ O
provided -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
potential -X- _ O
causes -X- _ O
of -X- _ O
such -X- _ O
differences -X- _ O
is -X- _ O
limited -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
NLP -X- _ O
field -X- _ O
has -X- _ O
shared -X- _ O
increasingly -X- _ O
detailed -X- _ O
information -X- _ O
about -X- _ O
system -X- _ O
, -X- _ O
dependencies -X- _ O
and -X- _ O
evaluation -X- _ O
to -X- _ O
chase -X- _ O
down -X- _ O
sources -X- _ O
of -X- _ O
differences -X- _ O
. -X- _ O
Sharing -X- _ O
code -X- _ O
and -X- _ O
data -X- _ O
together -X- _ O
with -X- _ O
detailed -X- _ O
information -X- _ O
about -X- _ O
them -X- _ O
is -X- _ O
now -X- _ O
expected -X- _ O
as -X- _ O
standard -X- _ O
, -X- _ O
and -X- _ O
checklists -X- _ O
and -X- _ O
datasheets -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
to -X- _ O
standardise -X- _ O
information -X- _ O
sharing -X- _ O
( -X- _ O
Pineau -X- _ O
, -X- _ O
2020;Shimorina -X- _ O
and -X- _ O
Belz -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Being -X- _ O
able -X- _ O
to -X- _ O
assess -X- _ O
reproducibility -X- _ O
of -X- _ O
results -X- _ O
objectively -X- _ O
and -X- _ O
comparably -X- _ O
is -X- _ O
important -X- _ O
not -X- _ O
only -X- _ O
to -X- _ O
establish -X- _ O
that -X- _ O
results -X- _ O
are -X- _ O
valid -X- _ O
, -X- _ O
but -X- _ O
to -X- _ O
provide -X- _ O
evidence -X- _ O
about -X- _ O
which -X- _ O
methods -X- _ O
have -X- _ O
better -X- _ O
/ -X- _ O
worse -X- _ O
reproducibility -X- _ O
and -X- _ O
what -X- _ O
may -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
changed -X- _ O
to -X- _ O
improve -X- _ O
reproducibility -X- _ O
. -X- _ O
To -X- _ O
do -X- _ O
this -X- _ O
, -X- _ O
assessment -X- _ O
has -X- _ O
to -X- _ O
be -X- _ O
done -X- _ O
in -X- _ O
a -X- _ O
way -X- _ O
that -X- _ O
is -X- _ O
also -X- _ O
comparable -X- _ O
across -X- _ O
reproduction -X- _ O
studies -X- _ O
of -X- _ O
different -X- _ O
original -X- _ O
studies -X- _ O
, -X- _ O
e.g. -X- _ O
to -X- _ O
develop -X- _ O
common -X- _ O
expectations -X- _ O
of -X- _ O
how -X- _ O
similar -X- _ O
original -X- _ O
and -X- _ O
reproduction -X- _ B-TaskName
results -X- _ O
should -X- _ O
be -X- _ O
for -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
system -X- _ O
, -X- _ O
task -X- _ O
and -X- _ O
evaluation -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
no -X- _ O
standard -X- _ O
way -X- _ O
of -X- _ O
going -X- _ O
about -X- _ O
a -X- _ O
reproduction -X- _ B-TaskName
study -X- _ O
in -X- _ O
NLP -X- _ O
, -X- _ O
and -X- _ O
different -X- _ O
reproduction -X- _ B-TaskName
studies -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
original -X- _ O
set -X- _ O
of -X- _ O
results -X- _ O
can -X- _ O
differ -X- _ O
substantially -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
their -X- _ O
similarity -X- _ O
in -X- _ O
system -X- _ O
and/or -X- _ O
evaluation -X- _ O
design -X- _ O
( -X- _ O
as -X- _ O
is -X- _ O
the -X- _ O
case -X- _ O
with -X- _ O
the -X- _ O
Vajjala -X- _ O
and -X- _ O
Rama -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
reproductions -X- _ O
, -X- _ O
see -X- _ O
Section -X- _ O
4 -X- _ O
for -X- _ O
details -X- _ O
) -X- _ O
. -X- _ O
Other -X- _ O
things -X- _ O
being -X- _ O
equal -X- _ O
, -X- _ O
a -X- _ O
more -X- _ O
similar -X- _ O
reproduction -X- _ O
can -X- _ O
be -X- _ O
expected -X- _ O
to -X- _ O
produce -X- _ O
more -X- _ O
similar -X- _ O
results -X- _ O
, -X- _ O
and -X- _ O
such -X- _ O
( -X- _ O
dis)similarities -X- _ O
should -X- _ O
be -X- _ O
factored -X- _ O
into -X- _ O
reproduction -X- _ O
analysis -X- _ O
and -X- _ O
conclusions -X- _ O
, -X- _ O
but -X- _ O
NLP -X- _ O
lacks -X- _ O
a -X- _ O
method -X- _ O
for -X- _ O
doing -X- _ O
so -X- _ O
. -X- _ O

This -X- _ O
framing -X- _ O
, -X- _ O
whether -X- _ O
the -X- _ O
same -X- _ O
conclusions -X- _ O
can -X- _ O
be -X- _ O
drawn -X- _ O
, -X- _ O
involves -X- _ O
subjective -X- _ O
judgments -X- _ O
and -X- _ O
different -X- _ O
researchers -X- _ O
can -X- _ O
come -X- _ O
to -X- _ O
contradictory -X- _ O
con -X- _ O
- -X- _ O
clusions -X- _ O
: -X- _ O
e.g. -X- _ O
the -X- _ O
four -X- _ O
papers -X- _ O
( -X- _ O
Arhiliuc -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Bestgen -X- _ O
, -X- _ O
2020;Caines -X- _ O
and -X- _ O
Buttery -X- _ O
, -X- _ O
2020;Huber -X- _ O
and -X- _ O
Çöltekin -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
reproducing -X- _ O
Vajjala -X- _ O
and -X- _ O
Rama -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
in -X- _ O
REPROLANG -X- _ O
all -X- _ O
report -X- _ O
similarly -X- _ O
large -X- _ O
differences -X- _ O
, -X- _ O
but -X- _ O
only -X- _ O
Arhiliuc -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
conclude -X- _ O
that -X- _ O
reproduction -X- _ O
was -X- _ O
unsuccessful -X- _ O
. -X- _ O

To -X- _ O
answer -X- _ O
this -X- _ O
question -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
specific -X- _ O
system -X- _ O
, -X- _ O
typically -X- _ O
( -X- _ O
Wieling -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Arhiliuc -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Popović -X- _ O
and -X- _ O
Belz -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
an -X- _ O
original -X- _ O
study -X- _ O
is -X- _ O
selected -X- _ O
and -X- _ O
repeated -X- _ O
more -X- _ O
or -X- _ O
less -X- _ O
closely -X- _ O
, -X- _ O
before -X- _ O
comparing -X- _ O
the -X- _ O
results -X- _ O
obtained -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
study -X- _ O
with -X- _ O
those -X- _ O
obtained -X- _ O
in -X- _ O
the -X- _ O
repeat -X- _ O
, -X- _ O
and -X- _ O
deciding -X- _ O
whether -X- _ O
the -X- _ O
two -X- _ O
sets -X- _ O
of -X- _ O
results -X- _ O
are -X- _ O
similar -X- _ O
enough -X- _ O
to -X- _ O
support -X- _ O
the -X- _ O
same -X- _ O
conclusions -X- _ O
. -X- _ O

Reproduction -X- _ B-TaskName
studies -X- _ O
are -X- _ O
becoming -X- _ O
more -X- _ O
common -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
first -X- _ O
shared -X- _ O
tasks -X- _ O
being -X- _ O
organised -X- _ O
, -X- _ O
including -X- _ O
RE -X- _ B-MethodName
- -X- _ I-MethodName
PROLANG -X- _ I-MethodName
( -X- _ O
Branco -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
ReproGen -X- _ B-MethodName
( -X- _ O
Belz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
NLP -X- _ O
, -X- _ O
reproduction -X- _ O
studies -X- _ O
generally -X- _ O
address -X- _ O
the -X- _ O
following -X- _ O
question -X- _ O
: -X- _ O
if -X- _ O
we -X- _ O
create -X- _ O
and/or -X- _ O
evaluate -X- _ O
this -X- _ O
system -X- _ O
multiple -X- _ O
times -X- _ O
, -X- _ O
will -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
same -X- _ O
results -X- _ O
? -X- _ O

This -X- _ O
paper -X- _ O
describes -X- _ O
and -X- _ O
tests -X- _ O
a -X- _ O
method -X- _ O
for -X- _ O
carrying -X- _ O
out -X- _ O
quantified -X- _ B-TaskName
reproducibility -X- _ I-TaskName
assessment -X- _ I-TaskName
( -X- _ O
QRA -X- _ B-TaskName
) -X- _ O
that -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
concepts -X- _ O
and -X- _ O
definitions -X- _ O
from -X- _ O
metrology -X- _ O
. -X- _ O
QRA -X- _ B-TaskName
produces -X- _ O
a -X- _ O
single -X- _ O
score -X- _ O
estimating -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
reproducibility -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
system -X- _ O
and -X- _ O
evaluation -X- _ O
measure -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
the -X- _ O
scores -X- _ O
from -X- _ O
, -X- _ O
and -X- _ O
differences -X- _ O
between -X- _ O
, -X- _ O
different -X- _ O
reproductions -X- _ O
. -X- _ O
We -X- _ O
test -X- _ O
QRA -X- _ B-TaskName
on -X- _ O
18 -X- _ O
system -X- _ O
and -X- _ O
evaluation -X- _ O
measure -X- _ O
combinations -X- _ O
( -X- _ O
involving -X- _ O
diverse -X- _ O
NLP -X- _ O
tasks -X- _ O
and -X- _ O
types -X- _ O
of -X- _ O
evaluation -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
which -X- _ O
we -X- _ O
have -X- _ O
the -X- _ O
original -X- _ O
results -X- _ O
and -X- _ O
one -X- _ O
to -X- _ O
seven -X- _ O
reproduction -X- _ O
results -X- _ O
. -X- _ O
The -X- _ O
proposed -X- _ O
QRA -X- _ B-TaskName
method -X- _ O
produces -X- _ O
degree -X- _ B-MetricName
- -X- _ I-MetricName
of -X- _ I-MetricName
- -X- _ I-MetricName
reproducibility -X- _ I-MetricName
scores -X- _ O
that -X- _ O
are -X- _ O
comparable -X- _ O
across -X- _ O
multiple -X- _ O
reproductions -X- _ O
not -X- _ O
only -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
, -X- _ O
but -X- _ O
of -X- _ O
different -X- _ O
original -X- _ O
studies -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
facilitates -X- _ O
insights -X- _ O
into -X- _ O
causes -X- _ O
of -X- _ O
variation -X- _ O
between -X- _ O
reproductions -X- _ O
, -X- _ O
and -X- _ O
allows -X- _ O
conclusions -X- _ O
to -X- _ O
be -X- _ O
drawn -X- _ O
about -X- _ O
what -X- _ O
changes -X- _ O
to -X- _ O
system -X- _ O
and/or -X- _ O
evaluation -X- _ O
design -X- _ O
might -X- _ O
lead -X- _ O
to -X- _ O
improved -X- _ O
reproducibility -X- _ O
. -X- _ O

Speech -X- _ B-TaskName
translation -X- _ I-TaskName
( -X- _ O
ST -X- _ B-TaskName
) -X- _ O
aims -X- _ O
at -X- _ O
translating -X- _ O
from -X- _ O
source -X- _ O
language -X- _ O
speech -X- _ O
into -X- _ O
target -X- _ O
language -X- _ O
text -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
widely -X- _ O
helpful -X- _ O
in -X- _ O
various -X- _ O
scenarios -X- _ O
such -X- _ O
as -X- _ O
conference -X- _ O
speeches -X- _ O
, -X- _ O
business -X- _ O
meetings -X- _ O
, -X- _ O
crossborder -X- _ O
customer -X- _ O
service -X- _ O
, -X- _ O
and -X- _ O
overseas -X- _ O
travel -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
two -X- _ O
kinds -X- _ O
of -X- _ O
application -X- _ O
scenarios -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
streaming -X- _ O
translation -X- _ O
and -X- _ O
the -X- _ O
streaming -X- _ O
one -X- _ O
. -X- _ O
The -X- _ O
non -X- _ O
- -X- _ O
streaming -X- _ O
models -X- _ O
can -X- _ O
listen -X- _ O
to -X- _ O
the -X- _ O
complete -X- _ O
utterances -X- _ O
at -X- _ O
one -X- _ O
time -X- _ O
and -X- _ O
then -X- _ O
generate -X- _ O
the -X- _ O
translation -X- _ O
afterward -X- _ O
. -X- _ O
While -X- _ O
, -X- _ O
the -X- _ O
streaming -X- _ O
models -X- _ O
need -X- _ O
to -X- _ O
balance -X- _ O
the -X- _ O
latency -X- _ O
and -X- _ O
quality -X- _ O
and -X- _ O
generate -X- _ O
translations -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
partial -X- _ O
utterance -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O

( -X- _ O
1 -X- _ O
) -X- _ O
Source -X- _ O
How -X- _ O
to -X- _ O
find -X- _ O
proper -X- _ O
moments -X- _ O
to -X- _ O
generate -X- _ O
partial -X- _ O
sentence -X- _ O
translation -X- _ O
given -X- _ O
a -X- _ O
streaming -X- _ O
speech -X- _ O
input -X- _ O
? -X- _ O
Existing -X- _ O
approaches -X- _ O
waitingand -X- _ O
- -X- _ O
translating -X- _ O
for -X- _ O
a -X- _ O
fixed -X- _ O
duration -X- _ O
often -X- _ O
break -X- _ O
the -X- _ O
acoustic -X- _ O
units -X- _ O
in -X- _ O
speech -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
boundaries -X- _ O
between -X- _ O
acoustic -X- _ O
units -X- _ O
in -X- _ O
speech -X- _ O
are -X- _ O
not -X- _ O
even -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
MoSST -X- _ B-MethodName
, -X- _ O
a -X- _ O
simple -X- _ O
yet -X- _ O
effective -X- _ O
method -X- _ O
for -X- _ O
translating -X- _ B-TaskName
streaming -X- _ I-TaskName
speech -X- _ I-TaskName
content -X- _ I-TaskName
. -X- _ O
Given -X- _ O
a -X- _ O
usually -X- _ O
long -X- _ O
speech -X- _ O
sequence -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
an -X- _ O
efficient -X- _ O
monotonic -X- _ O
segmentation -X- _ O
module -X- _ O
inside -X- _ O
an -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
model -X- _ O
to -X- _ O
accumulate -X- _ O
acoustic -X- _ O
information -X- _ O
incrementally -X- _ O
and -X- _ O
detect -X- _ O
proper -X- _ O
speech -X- _ O
unit -X- _ O
boundaries -X- _ O
for -X- _ O
the -X- _ O
input -X- _ O
in -X- _ O
speech -X- _ B-TaskName
translation -X- _ I-TaskName
task -X- _ O
. -X- _ O
Experiments -X- _ O
on -X- _ O
multiple -X- _ O
translation -X- _ O
directions -X- _ O
of -X- _ O
the -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
dataset -X- _ O
show -X- _ O
that -X- _ O
MoSST -X- _ B-MethodName
outperforms -X- _ O
existing -X- _ O
methods -X- _ O
and -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
between -X- _ O
translation -X- _ O
quality -X- _ O
( -X- _ O
BLEU -X- _ B-MetricName
) -X- _ O
and -X- _ O
latency -X- _ O
. -X- _ O
Our -X- _ O
code -X- _ O
is -X- _ O
available -X- _ O
at -X- _ O
https://github -X- _ O
. -X- _ O
com -X- _ O
/ -X- _ O
dqqcasia -X- _ O
/ -X- _ O
mosst -X- _ B-MethodName
. -X- _ O
* -X- _ O
Equal -X- _ O
contribution -X- _ O
. -X- _ O
† -X- _ O
Work -X- _ O
is -X- _ O
done -X- _ O
while -X- _ O
at -X- _ O
ByteDance -X- _ O
. -X- _ O

EN -X- _ O
: -X- _ O
Do -X- _ O
you -X- _ O
know -X- _ O
that -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
intense -X- _ O
pleasures -X- _ O
of -X- _ O
travel -X- _ O
and -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
delights -X- _ O
of -X- _ O
ethnographic -X- _ O
research -X- _ O
is -X- _ O
the -X- _ O
opportunity -X- _ O
to -X- _ O
live -X- _ O
amongst -X- _ O
those -X- _ O
who -X- _ O
have -X- _ O
not -X- _ O
forgotten -X- _ O
the -X- _ O
old -X- _ O
ways -X- _ O
, -X- _ O
who -X- _ O
still -X- _ O
feel -X- _ O
their -X- _ O
past -X- _ O
in -X- _ O
the -X- _ O
wind -X- _ O
, -X- _ O
touch -X- _ O
it -X- _ O
in -X- _ O
stones -X- _ O
polished -X- _ O
by -X- _ O
rain -X- _ O
, -X- _ O
taste -X- _ O
it -X- _ O
in -X- _ O
the -X- _ O
bitter -X- _ O
leaves -X- _ O
of -X- _ O
plants -X- _ O
. -X- _ O

Paraphrasing -X- _ B-TaskName
, -X- _ O
Transliteration -X- _ B-TaskName
, -X- _ O
and -X- _ O
Title -X- _ B-TaskName
Generation -X- _ I-TaskName
Output -X- _ O
. -X- _ O
Tables -X- _ O
D.3 -X- _ O
, -X- _ O
D.4 -X- _ O
, -X- _ O
and -X- _ O
D.5 -X- _ O
each -X- _ O
shows -X- _ O
two -X- _ O
output -X- _ O
samples -X- _ O
from -X- _ O
our -X- _ O
paraphrasing -X- _ B-TaskName
, -X- _ O
transliteration -X- _ B-TaskName
, -X- _ O
and -X- _ O
title -X- _ B-TaskName
generation -X- _ I-TaskName
models -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
In -X- _ O
each -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
samples -X- _ O
are -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
, -X- _ O
informative -X- _ O
, -X- _ O
and -X- _ O
fluent -X- _ O
. -X- _ O
Our -X- _ O
paraphrase -X- _ O
samples -X- _ O
also -X- _ O
tightly -X- _ O
capture -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
sentences -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Source -X- _ O
: -X- _ O
: -X- _ O
MSA -X- _ O
Target -X- _ O
: -X- _ O

( -X- _ O
3 -X- _ O
) -X- _ O
We -X- _ O
run -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
lingual -X- _ O
semantic -X- _ O
similarity -X- _ O
model -X- _ O
from -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
Arabic -X- _ O
machine -X- _ O
translated -X- _ O
sentences -X- _ O
and -X- _ O
the -X- _ O
human -X- _ O
translation -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
original -X- _ O
Arabic -X- _ O
sentences -X- _ O
from -X- _ O
OPUS -X- _ B-DatasetName
) -X- _ O
, -X- _ O
keeping -X- _ O
only -X- _ O
sentences -X- _ O
with -X- _ O
an -X- _ O
arbitrary -X- _ O
semantic -X- _ B-HyperparameterName
similarity -X- _ I-HyperparameterName
score -X- _ I-HyperparameterName
between -X- _ O
0.70 -X- _ B-HyperparameterValue
and -X- _ O
0.99 -X- _ B-HyperparameterValue
. -X- _ O
This -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
filter -X- _ O
out -X- _ O
identical -X- _ O
sentence -X- _ O
pairs -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
similarity -X- _ B-HyperparameterName
score -X- _ I-HyperparameterName
= -X- _ O
1 -X- _ B-HyperparameterValue
) -X- _ O
and -X- _ O
those -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
good -X- _ O
translations -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
those -X- _ O
with -X- _ O
a -X- _ O
semantic -X- _ B-HyperparameterName
similarity -X- _ I-HyperparameterName
score -X- _ I-HyperparameterName
< -X- _ O
0.70 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
maximize -X- _ O
syntactic -X- _ O
and -X- _ O
lexical -X- _ O
diversity -X- _ O
of -X- _ O
the -X- _ O
pairs -X- _ O
of -X- _ O
paraphrased -X- _ O
sentences -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
an -X- _ O
analysis -X- _ O
based -X- _ O
on -X- _ O
word -X- _ O
overlap -X- _ O
between -X- _ O
the -X- _ O
semantically -X- _ O
similar -X- _ O
pair -X- _ O
sentences -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
step -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
perform -X- _ O
a -X- _ O
manual -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
identifying -X- _ O
sentences -X- _ B-HyperparameterName
with -X- _ I-HyperparameterName
unigram -X- _ I-HyperparameterName
token -X- _ I-HyperparameterName
overlap -X- _ I-HyperparameterName
between -X- _ O
35 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
and -X- _ O
70 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
as -X- _ O
sufficiently -X- _ O
distinct -X- _ O
paraphrase -X- _ O
pairs -X- _ O
. -X- _ O
This -X- _ O
gives -X- _ O
us -X- _ O
122 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
paraphrase -X- _ B-HyperparameterName
pairs -X- _ I-HyperparameterName
. -X- _ O
We -X- _ O
split -X- _ O
these -X- _ O
sentence -X- _ B-HyperparameterName
pairs -X- _ I-HyperparameterName
into -X- _ O
116 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
for -X- _ O
training -X- _ O
and -X- _ O
6 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
for -X- _ O
validation -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
describe -X- _ O
the -X- _ O
ARGEN -X- _ B-DatasetName
MT -X- _ I-DatasetName
datasets -X- _ O
splits -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
evaluation -X- _ O
results -X- _ O
in -X- _ O
validation -X- _ O
datasets -X- _ O
. -X- _ O
Jordanian -X- _ O
dialect -X- _ O
translated -X- _ O
into -X- _ O
English -X- _ O
. -X- _ O
In -X- _ O
both -X- _ O
cases -X- _ O
, -X- _ O
our -X- _ O
models -X- _ O
not -X- _ O
only -X- _ O
handle -X- _ O
the -X- _ O
dialects -X- _ O
but -X- _ O
also -X- _ O
their -X- _ O
use -X- _ O
in -X- _ O
code -X- _ O
- -X- _ O
switched -X- _ O
contexts -X- _ O
better -X- _ O
than -X- _ O
mT5 -X- _ B-MethodName
. -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
translate -X- _ O
the -X- _ O
English -X- _ O
sentences -X- _ O
using -X- _ O
a -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
in -X- _ O
- -X- _ O
house -X- _ O
English→Arabic -X- _ O
MT -X- _ B-TaskName
model -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
run -X- _ O
an -X- _ O
in -X- _ O
- -X- _ O
house -X- _ O
MSA -X- _ O
- -X- _ O
dialect -X- _ O
classifier -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
1 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
data -X- _ B-HyperparameterName
sample -X- _ I-HyperparameterName
. -X- _ O
The -X- _ O
classifier -X- _ O
predicts -X- _ O
an -X- _ O
overriding -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
( -X- _ O
99.83 -X- _ O
% -X- _ O
) -X- _ O
as -X- _ O
MSA -X- _ O
. -X- _ O
We -X- _ O
again -X- _ O
manually -X- _ O
inspect -X- _ O
∼ -X- _ O
100 -X- _ B-MetricName
samples -X- _ B-HyperparameterName
from -X- _ O
the -X- _ O
small -X- _ O
fraction -X- _ O
predicted -X- _ O
as -X- _ O
dialects -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
0.17 -X- _ O
% -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
we -X- _ O
find -X- _ O
some -X- _ O
of -X- _ O
these -X- _ O
to -X- _ O
be -X- _ O
actual -X- _ O
dialectal -X- _ O
text -X- _ O
( -X- _ O
usually -X- _ O
short -X- _ O
belonging -X- _ O
to -X- _ O
either -X- _ O
Egyptian -X- _ O
or -X- _ O
Saudi -X- _ O
dialects -X- _ O
) -X- _ O
from -X- _ O
web -X- _ O
fora -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
cases -X- _ O
the -X- _ O
text -X- _ O
is -X- _ O
simply -X- _ O
names -X- _ O
of -X- _ O
soap -X- _ O
operas -X- _ O
or -X- _ O
advertisements -X- _ O
. -X- _ O
Our -X- _ O
own -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
Twitter -X- _ O
, -X- _ O
in -X- _ O
comparison -X- _ O
, -X- _ O
involve -X- _ O
much -X- _ O
more -X- _ O
dialectal -X- _ O
content -X- _ O
( -X- _ O
28.39 -X- _ O
% -X- _ O
as -X- _ O
listed -X- _ O
in -X- _ O
§ -X- _ O
2.1 -X- _ O
) -X- _ O
. -X- _ O
Baselines -X- _ O
. -X- _ O
For -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
training -X- _ O
data -X- _ O
as -X- _ O
our -X- _ O
new -X- _ O
models -X- _ O
. -X- _ O
These -X- _ O
include -X- _ O
the -X- _ O
multilingual -X- _ O
sequenceto -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
mT5 -X- _ B-MethodName
( -X- _ O
Xue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
powerful -X- _ O
Arabic -X- _ O
- -X- _ O
specific -X- _ O
BERT -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
MARBERT -X- _ B-MethodName
( -X- _ O
Abdul -X- _ O
- -X- _ O
Mageed -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
MARBERT -X- _ B-MethodName
achieves -X- _ O
the -X- _ O
SOTA -X- _ O
22 -X- _ O
across -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
6 -X- _ O
cluster -X- _ O
tasks -X- _ O
of -X- _ O
ARLUE -X- _ B-DatasetName
, -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
ARLUE -X- _ B-DatasetName
score -X- _ O
. -X- _ O
Settings -X- _ O
and -X- _ O
Evaluation -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
our -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
language -X- _ O
understanding -X- _ O
benchmark -X- _ O
, -X- _ O
AR -X- _ B-DatasetName
- -X- _ I-DatasetName
LUE -X- _ I-DatasetName
, -X- _ O
under -X- _ O
two -X- _ O
settings -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
single -X- _ O
task -X- _ O
learning -X- _ O
and -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
results -X- _ O
on -X- _ O
all -X- _ O
the -X- _ O
task -X- _ O
clusters -X- _ O
included -X- _ O
in -X- _ O
ARLUE -X- _ B-DatasetName
except -X- _ O
for -X- _ O
NER -X- _ B-TaskName
which -X- _ O
is -X- _ O
a -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
task -X- _ O
that -X- _ O
is -X- _ O
not -X- _ O
straightforward -X- _ O
with -X- _ O
the -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
set -X- _ O
up -X- _ O
we -X- _ O
adopt -X- _ O
. -X- _ O
Table -X- _ O
B.2 -X- _ O
shows -X- _ O
our -X- _ O
evaluation -X- _ O
results -X- _ O
using -X- _ O
the -X- _ O
relevant -X- _ O
metric -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
. -X- _ O
Abdul -X- _ O
- -X- _ O
Mageed -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
introduced -X- _ O
ARLUE -X- _ B-DatasetName
score -X- _ O
, -X- _ O
a -X- _ O
metric -X- _ O
used -X- _ O
to -X- _ O
score -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
multiple -X- _ O
datasets -X- _ O
. -X- _ O
AR -X- _ B-DatasetName
- -X- _ I-DatasetName
LUE -X- _ I-DatasetName
score -X- _ O
is -X- _ O
a -X- _ O
simply -X- _ O
macro -X- _ O
- -X- _ O
average -X- _ O
of -X- _ O
the -X- _ O
different -X- _ O
scores -X- _ O
across -X- _ O
all -X- _ O
task -X- _ O
clusters -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
task -X- _ O
is -X- _ O
weighted -X- _ O
equally -X- _ O
following -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
compute -X- _ O
the -X- _ O
ARLUE -X- _ B-DatasetName
score -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
overall -X- _ O
macro -X- _ O
- -X- _ O
average -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
our -X- _ O
three -X- _ O
models -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
AraT5 -X- _ B-MethodName
MSA -X- _ I-MethodName
, -X- _ O
AraT5 -X- _ B-MethodName
Tw -X- _ I-MethodName
, -X- _ O
and -X- _ O
AraT5 -X- _ B-MethodName
) -X- _ O
and -X- _ O
the -X- _ O
baseline -X- _ O
( -X- _ O
mT5 -X- _ B-MethodName
) -X- _ O
. -X- _ O
Single -X- _ O
Task -X- _ O
. -X- _ O
We -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
our -X- _ O
three -X- _ O
models -X- _ O
and -X- _ O
22 -X- _ O
MARBERT -X- _ B-MethodName
outperform -X- _ O
both -X- _ O
multilingual -X- _ O
encoder -X- _ O
- -X- _ O
only -X- _ O
Transformers -X- _ O
mBERT -X- _ B-MethodName
, -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
RBase -X- _ I-MethodName
, -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
RLarge -X- _ I-MethodName
, -X- _ O
and -X- _ O
Arabicspecific -X- _ O
BERT -X- _ O
- -X- _ O
based -X- _ O
AraBERT -X- _ B-MethodName
( -X- _ O
Antoun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
AR -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
Abdul -X- _ O
- -X- _ O
Mageed -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
mT5 -X- _ B-MethodName
individually -X- _ O
on -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
six -X- _ O
tasks -X- _ O
of -X- _ O
AR -X- _ B-DatasetName
- -X- _ I-DatasetName
LUE -X- _ I-DatasetName
. -X- _ O
We -X- _ O
typically -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
in -X- _ O
all -X- _ O
our -X- _ O
experiments -X- _ O
) -X- _ O
identify -X- _ O
the -X- _ O
best -X- _ O
checkpoint -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
report -X- _ O
its -X- _ O
performance -X- _ O
on -X- _ O
both -X- _ O
development -X- _ O
and -X- _ O
test -X- _ O
data -X- _ O
. -X- _ O
As -X- _ O
Table -X- _ O
B.2 -X- _ O
shows -X- _ O
, -X- _ O
our -X- _ O
AraT5 -X- _ B-MethodName
model -X- _ O
achieves -X- _ O
the -X- _ O
highest -X- _ O
AR -X- _ B-DatasetName
- -X- _ I-DatasetName
LUE -X- _ I-DatasetName
score -X- _ O
( -X- _ O
77.52 -X- _ B-MetricValue
) -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
AraT5 -X- _ B-MethodName
MSA -X- _ I-MethodName
( -X- _ O
77.50 -X- _ B-MetricValue
) -X- _ O
and -X- _ O
AraT5 -X- _ B-MethodName
TW -X- _ I-MethodName
( -X- _ O
75.33 -X- _ B-MetricValue
) -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
all -X- _ O
our -X- _ O
models -X- _ O
outperform -X- _ O
mT5 -X- _ B-MethodName
and -X- _ O
the -X- _ O
MARBERT -X- _ B-MethodName
( -X- _ O
SOTA -X- _ O
) -X- _ O
by -X- _ O
∼ -X- _ O
+2.74 -X- _ B-MetricValue
and -X- _ O
∼ -X- _ O
+1 -X- _ B-MetricValue
ARLUE -X- _ B-MetricName
score -X- _ I-MetricName
points -X- _ I-MetricName
, -X- _ O
respectively -X- _ O
. -X- _ O
Multitask -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
investigate -X- _ O
multitask -X- _ O
learning -X- _ O
( -X- _ O
Caruana -X- _ O
, -X- _ O
1997;Ruder -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
with -X- _ O
our -X- _ O
AraT5 -X- _ B-MethodName
models -X- _ O
. -X- _ O
This -X- _ O
approach -X- _ O
consists -X- _ O
of -X- _ O
training -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
multiple -X- _ O
tasks -X- _ O
simultaneously -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
its -X- _ O
parameters -X- _ O
are -X- _ O
shared -X- _ O
across -X- _ O
all -X- _ O
tasks -X- _ O
) -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
eventually -X- _ O
improve -X- _ O
performance -X- _ O
on -X- _ O
each -X- _ O
individual -X- _ O
task -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
our -X- _ O
models -X- _ O
on -X- _ O
many -X- _ O
tasks -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
using -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
The -X- _ O
three -X- _ O
dialect -X- _ O
datasets -X- _ O
: -X- _ O
ARLUE -X- _ B-DatasetName
Dia -X- _ I-DatasetName
- -X- _ I-DatasetName
B -X- _ I-DatasetName
, -X- _ O
ARLUE -X- _ B-DatasetName
Dia -X- _ I-DatasetName
- -X- _ I-DatasetName
R -X- _ I-DatasetName
, -X- _ O
and -X- _ O
ARLUE -X- _ B-DatasetName
Dia -X- _ I-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
and -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
the -X- _ O
social -X- _ O
meaning -X- _ O
datasets -X- _ O
of -X- _ O
ARLUE -X- _ B-DatasetName
SM -X- _ I-DatasetName
. -X- _ O
Table -X- _ O
B -X- _ O
.3 -X- _ O
and -X- _ O
Table -X- _ O
B.4 -X- _ O
show -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
experiments -X- _ O
for -X- _ O
dialect -X- _ O
settings -X- _ O
and -X- _ O
social -X- _ O
meaning -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Our -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
training -X- _ O
outperforms -X- _ O
single -X- _ O
task -X- _ O
models -X- _ O
in -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
dialects -X- _ O
experiments -X- _ O
( -X- _ O
n=7 -X- _ O
out -X- _ O
of -X- _ O
9 -X- _ O
experiments -X- _ O
, -X- _ O
77.78 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
tasks -X- _ O
) -X- _ O
and -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
social -X- _ O
meaning -X- _ O
tasks -X- _ O
( -X- _ O
n=18 -X- _ O
out -X- _ O
of -X- _ O
36 -X- _ O
experiments -X- _ O
, -X- _ O
50 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
tasks -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
are -X- _ O
promising -X- _ O
, -X- _ O
and -X- _ O
hence -X- _ O
we -X- _ O
plan -X- _ O
to -X- _ O
further -X- _ O
investigate -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
with -X- _ O
our -X- _ O
new -X- _ O
models -X- _ O
in -X- _ O
the -X- _ O
future -X- _ O
. -X- _ O
AraPara -X- _ B-MethodName
. -X- _ O
is -X- _ O
a -X- _ O
new -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
Arabic -X- _ O
paraphrasing -X- _ O
dataset -X- _ O
we -X- _ O
create -X- _ O
using -X- _ O
English -X- _ O
- -X- _ O
Arabic -X- _ O
parallel -X- _ O
OPUS -X- _ B-DatasetName
data -X- _ O
( -X- _ O
Tiedemann -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
ensure -X- _ O
highquality -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
four -X- _ O
careful -X- _ O
steps -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
pick -X- _ O
1 -X- _ O
million -X- _ O
English -X- _ O
- -X- _ O
Arabic -X- _ O
parallel -X- _ O
sentences -X- _ O
from -X- _ O
OPUS -X- _ B-DatasetName
( -X- _ O
Tiedemann -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
covering -X- _ O
the -X- _ O
different -X- _ O
domains -X- _ O
. -X- _ O

AraT5 -X- _ B-MethodName
Models -X- _ O
Release -X- _ O
. -X- _ O
All -X- _ O
our -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
are -X- _ O
publicly -X- _ O
available -X- _ O
for -X- _ O
non -X- _ O
- -X- _ O
malicious -X- _ O
use -X- _ O
. -X- _ O
We -X- _ O
acknowledge -X- _ O
our -X- _ O
models -X- _ O
may -X- _ O
still -X- _ O
be -X- _ O
misused -X- _ O
in -X- _ O
real -X- _ O
world -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
hope -X- _ O
the -X- _ O
models -X- _ O
will -X- _ O
be -X- _ O
deployed -X- _ O
in -X- _ O
domains -X- _ O
such -X- _ O
as -X- _ O
education -X- _ O
, -X- _ O
disaster -X- _ O
management -X- _ O
, -X- _ O
health -X- _ O
, -X- _ O
recreation -X- _ O
, -X- _ O
travel -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
in -X- _ O
socially -X- _ O
beneficial -X- _ O
ways -X- _ O
. -X- _ O
These -X- _ O
meaningful -X- _ O
potential -X- _ O
use -X- _ O
cases -X- _ O
are -X- _ O
behind -X- _ O
our -X- _ O
decision -X- _ O
to -X- _ O
release -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O
A -X- _ O
A -X- _ O
Study -X- _ O
of -X- _ O
Arabic -X- _ O
mC4 -X- _ B-DatasetName
Data -X- _ O
Quality -X- _ O
Xue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
train -X- _ O
mT5 -X- _ B-MethodName
on -X- _ O
the -X- _ O
mC4 -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
They -X- _ O
report -X- _ O
57B -X- _ B-HyperparameterValue
Arabic -X- _ B-HyperparameterName
tokens -X- _ I-HyperparameterName
( -X- _ O
almost -X- _ O
double -X- _ O
our -X- _ O
token -X- _ O
size -X- _ O
) -X- _ O
from -X- _ O
53 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
webpages -X- _ B-HyperparameterName
, -X- _ O
making -X- _ O
1.66 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
all -X- _ O
mT5 -X- _ B-MethodName
data -X- _ O
. -X- _ O
For -X- _ O
our -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
sample -X- _ O
1 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
paragraphs -X- _ B-HyperparameterName
from -X- _ O
the -X- _ O
Arabic -X- _ O
part -X- _ O
of -X- _ O
mC4 -X- _ B-DatasetName
. -X- _ O
We -X- _ O
use -X- _ O
paragraphs -X- _ O
rather -X- _ O
than -X- _ O
whole -X- _ O
documents -X- _ O
for -X- _ O
a -X- _ O
more -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
analysis -X- _ O
that -X- _ O
is -X- _ O
more -X- _ O
comparable -X- _ O
to -X- _ O
our -X- _ O
own -X- _ O
data -X- _ O
( -X- _ O
especially -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
Twitter -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
perform -X- _ O
language -X- _ O
identification -X- _ O
using -X- _ O
CLD3 -X- _ O
( -X- _ O
McCandless -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
a -X- _ O
sizable -X- _ O
amount -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
data -X- _ I-HyperparameterName
( -X- _ O
i.e. -X- _ O
, -X- _ O
13.59 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
to -X- _ O
be -X- _ O
non -X- _ O
- -X- _ O
Arabic -X- _ O
( -X- _ O
mostly -X- _ O
English -X- _ O
or -X- _ O
French -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
manually -X- _ O
inspect -X- _ O
∼ -X- _ O
100 -X- _ O
random -X- _ O
samples -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
predicted -X- _ O
as -X- _ O
non -X- _ O
- -X- _ O
Arabic -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
these -X- _ O
are -X- _ O
mostly -X- _ O
either -X- _ O
non -X- _ O
- -X- _ O
linguistic -X- _ O
content -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
java -X- _ O
- -X- _ O
script -X- _ O
or -X- _ O
HTML -X- _ O
code -X- _ O
) -X- _ O
or -X- _ O
non -X- _ O
- -X- _ O
Arabic -X- _ O
text -X- _ O
. -X- _ O
The -X- _ O
non -X- _ O
- -X- _ O
Arabic -X- _ O
text -X- _ O
is -X- _ O
sometimes -X- _ O
foreign -X- _ O
language -X- _ O
advertising -X- _ O
or -X- _ O
even -X- _ O
full -X- _ O
translation -X- _ O
of -X- _ O
the -X- _ O
Arabic -X- _ O
text -X- _ O
in -X- _ O
some -X- _ O
cases -X- _ O
. -X- _ O
In -X- _ O
many -X- _ O
cases -X- _ O
, -X- _ O
non -X- _ O
- -X- _ O
Arabic -X- _ O
is -X- _ O
also -X- _ O
boilerplate -X- _ O
text -X- _ O
such -X- _ O
as -X- _ O
that -X- _ O
in -X- _ O
web -X- _ O
fora -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
no -X- _ O
samples -X- _ O
of -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
Arabic -X- _ O
included -X- _ O
real -X- _ O
code -X- _ O
- -X- _ O
switching -X- _ O
. -X- _ O

Table -X- _ O
7 -X- _ O
: -X- _ O
CS -X- _ O
sentences -X- _ O
with -X- _ O
their -X- _ O
English -X- _ O
/ -X- _ O
French -X- _ O
translations -X- _ O
using -X- _ O
our -X- _ O
Models -X- _ O
and -X- _ O
mT5 -X- _ B-MethodName
. -X- _ O
Data -X- _ O
samples -X- _ O
are -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
Dev -X- _ O
datasets -X- _ O
. -X- _ O
Green -X- _ O
refers -X- _ O
to -X- _ O
good -X- _ O
translation -X- _ O
. -X- _ O
Red -X- _ O
refers -X- _ O
to -X- _ O
problematic -X- _ O
translation -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
perform -X- _ O
qualitative -X- _ O
analyses -X- _ O
of -X- _ O
the -X- _ O
outputs -X- _ O
of -X- _ O
several -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
, -X- _ O
including -X- _ O
as -X- _ O
to -X- _ O
length -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
MT -X- _ I-HyperparameterName
source -X- _ I-HyperparameterName
data -X- _ I-HyperparameterName
( -X- _ O
Appendix -X- _ O
D -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
our -X- _ O
analyses -X- _ O
are -X- _ O
for -X- _ O
the -X- _ O
following -X- _ O
tasks -X- _ O
: -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
, -X- _ O
code -X- _ B-TaskName
- -X- _ I-TaskName
switched -X- _ I-TaskName
translation -X- _ I-TaskName
, -X- _ O
paraphrasing -X- _ B-TaskName
, -X- _ O
transliteration -X- _ B-TaskName
, -X- _ O
and -X- _ O
news -X- _ B-TaskName
title -X- _ I-TaskName
generation -X- _ I-TaskName
. -X- _ O
MT -X- _ B-TaskName
Model -X- _ O
. -X- _ O
Paraphrasing -X- _ B-TaskName
, -X- _ O
Transliteration -X- _ B-TaskName
, -X- _ O
and -X- _ O
Title -X- _ B-TaskName
Generation -X- _ I-TaskName
. -X- _ O
Each -X- _ O
of -X- _ O
Tables -X- _ O
D.3 -X- _ O
, -X- _ O
D.4 -X- _ O
, -X- _ O
and -X- _ O
D.5 -X- _ O
( -X- _ O
Appendix -X- _ O
D -X- _ O
) -X- _ O
shows -X- _ O
two -X- _ O
output -X- _ O
samples -X- _ O
from -X- _ O
our -X- _ O
paraphrasing -X- _ B-TaskName
, -X- _ O
transliteration -X- _ B-TaskName
, -X- _ O
and -X- _ O
title -X- _ B-TaskName
generation -X- _ I-TaskName
models -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
In -X- _ O
each -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
samples -X- _ O
are -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
, -X- _ O
informative -X- _ O
, -X- _ O
and -X- _ O
fluent -X- _ O
. -X- _ O
Our -X- _ O
paraphrase -X- _ O
samples -X- _ O
also -X- _ O
tightly -X- _ O
capture -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
sentences -X- _ O
. -X- _ O
Multilingual -X- _ O
LMs -X- _ O
. -X- _ O
mBERT -X- _ B-MethodName
is -X- _ O
the -X- _ O
multilingual -X- _ O
version -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
an -X- _ O
encoder -X- _ O
model -X- _ O
with -X- _ O
bidirectional -X- _ O
representations -X- _ O
from -X- _ O
Transformers -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
denoising -X- _ O
objective -X- _ O
. -X- _ O
mBERT -X- _ B-MethodName
is -X- _ O
trained -X- _ O
on -X- _ O
Wikipedia -X- _ B-DatasetName
for -X- _ O
104 -X- _ B-HyperparameterValue
languages -X- _ B-HyperparameterName
, -X- _ O
including -X- _ O
Arabic -X- _ O
. -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
also -X- _ O
a -X- _ O
Transformer -X- _ O
- -X- _ O
based -X- _ O
multilingual -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
more -X- _ O
than -X- _ O
2 -X- _ O
TB -X- _ O
of -X- _ O
CommonCrawl -X- _ B-DatasetName
( -X- _ O
CC -X- _ B-DatasetName
) -X- _ O
data -X- _ O
in -X- _ O
100 -X- _ B-HyperparameterValue
languages -X- _ B-HyperparameterName
, -X- _ O
including -X- _ O
Arabic -X- _ O
( -X- _ O
2.9B -X- _ O
tokens -X- _ O
) -X- _ O
. -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
model -X- _ O
uses -X- _ O
the -X- _ O
same -X- _ O
masking -X- _ O
objective -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
but -X- _ O
not -X- _ O
the -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
. -X- _ O
mT5 -X- _ B-MethodName
( -X- _ O
Xue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
multilingual -X- _ O
version -X- _ O
of -X- _ O
Textto -X- _ B-MethodName
- -X- _ I-MethodName
Text -X- _ I-MethodName
Transfer -X- _ I-MethodName
Transformer -X- _ I-MethodName
model -X- _ I-MethodName
( -X- _ O
T5 -X- _ B-MethodName
) -X- _ O
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
As -X- _ O
we -X- _ O
have -X- _ O
demonstrated -X- _ O
, -X- _ O
our -X- _ O
resulting -X- _ O
models -X- _ O
are -X- _ O
better -X- _ O
equipped -X- _ O
to -X- _ O
power -X- _ O
applications -X- _ O
involving -X- _ O
several -X- _ O
varieties -X- _ O
of -X- _ O
Arabic -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
code -X- _ O
- -X- _ O
switched -X- _ O
language -X- _ O
use -X- _ O
involving -X- _ O
Arabic -X- _ O
. -X- _ O
From -X- _ O
this -X- _ O
perspective -X- _ O
, -X- _ O
we -X- _ O
hope -X- _ O
they -X- _ O
add -X- _ O
to -X- _ O
ongoing -X- _ O
efforts -X- _ O
in -X- _ O
the -X- _ O
community -X- _ O
to -X- _ O
design -X- _ O
models -X- _ O
that -X- _ O
are -X- _ O
fairer -X- _ O
and -X- _ O
more -X- _ O
representative -X- _ O
. -X- _ O
ARGEN -X- _ B-DatasetName
Benchmark -X- _ O
Release -X- _ O
. -X- _ O
We -X- _ O
design -X- _ O
AR -X- _ B-DatasetName
- -X- _ I-DatasetName
GEN -X- _ I-DatasetName
using -X- _ O
both -X- _ O
existing -X- _ O
datasets -X- _ O
and -X- _ O
new -X- _ O
datasets -X- _ O
that -X- _ O
we -X- _ O
create -X- _ O
for -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
accompanying -X- _ O
GitHub -X- _ O
repository -X- _ O
, -X- _ O
we -X- _ O
link -X- _ O
to -X- _ O
all -X- _ O
existing -X- _ O
publicly -X- _ O
available -X- _ O
components -X- _ O
of -X- _ O
the -X- _ O
benchmark -X- _ O
with -X- _ O
standard -X- _ O
splits -X- _ O
from -X- _ O
source -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
components -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
acquired -X- _ O
from -X- _ O
data -X- _ O
organizations -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
released -X- _ O
all -X- _ O
the -X- _ O
new -X- _ O
datasets -X- _ O
we -X- _ O
have -X- _ O
developed -X- _ O
. -X- _ O
While -X- _ O
we -X- _ O
have -X- _ O
prioritized -X- _ O
standardizing -X- _ O
evaluation -X- _ O
on -X- _ O
as -X- _ O
many -X- _ O
unified -X- _ O
and -X- _ O
consolidated -X- _ O
datasets -X- _ O
and -X- _ O
tasks -X- _ O
as -X- _ O
possible -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
report -X- _ O
performance -X- _ O
on -X- _ O
individual -X- _ O
test -X- _ O
sets -X- _ O
so -X- _ O
as -X- _ O
to -X- _ O
enable -X- _ O
the -X- _ O
community -X- _ O
to -X- _ O
replicate -X- _ O
our -X- _ O
work -X- _ O
even -X- _ O
on -X- _ O
particular -X- _ O
parts -X- _ O
or -X- _ O
tasks -X- _ O
of -X- _ O
ARGEN -X- _ B-DatasetName
if -X- _ O
they -X- _ O
so -X- _ O
wish -X- _ O
. -X- _ O

Code -X- _ O
- -X- _ O
Switching -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
study -X- _ O
code -X- _ O
- -X- _ O
switching -X- _ O
in -X- _ O
both -X- _ O
our -X- _ O
Twitter -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
the -X- _ O
Arabic -X- _ O
part -X- _ O
of -X- _ O
mC4 -X- _ B-DatasetName
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
while -X- _ O
our -X- _ O
Twitter -X- _ B-DatasetName
data -X- _ O
involves -X- _ O
natural -X- _ O
code -X- _ O
- -X- _ O
switching -X- _ O
( -X- _ O
∼ -X- _ O
4 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
sequences -X- _ B-HyperparameterName
) -X- _ O
, -X- _ O
codeswitching -X- _ O
in -X- _ O
Arabic -X- _ O
mC4 -X- _ B-DatasetName
is -X- _ O
very -X- _ O
rare -X- _ O
. -X- _ O
This -X- _ O
explains -X- _ O
the -X- _ O
strong -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
AraT5 -X- _ B-MethodName
Tw -X- _ I-MethodName
model -X- _ O
on -X- _ O
the -X- _ O
natural -X- _ O
code -X- _ B-TaskName
- -X- _ I-TaskName
switched -X- _ I-TaskName
translation -X- _ I-TaskName
data -X- _ O
on -X- _ O
French -X- _ O
. -X- _ O
We -X- _ O
conjecture -X- _ O
that -X- _ O
mT5 -X- _ B-MethodName
good -X- _ O
performance -X- _ O
on -X- _ O
English -X- _ O
code -X- _ O
- -X- _ O
switched -X- _ O
data -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
it -X- _ O
being -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
very -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
English -X- _ O
rather -X- _ O
than -X- _ O
natural -X- _ O
code -X- _ O
- -X- _ O
switching -X- _ O
. -X- _ O
We -X- _ O
were -X- _ O
inquisitive -X- _ O
how -X- _ O
MT -X- _ B-TaskName
models -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
our -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
compare -X- _ O
to -X- _ O
mT5 -X- _ B-MethodName
under -X- _ O
different -X- _ O
length -X- _ O
conditions -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Source -X- _ O
: -X- _ O
J'aime -X- _ O
une -X- _ O
vidéo -X- _ O
Episode -X- _ O
1 -X- _ O
-4 -X- _ O
: -X- _ O
ALG -X- _ O
- -X- _ O
FR -X- _ O
Target -X- _ O
: -X- _ O
FR -X- _ O
: -X- _ O
J -X- _ O
' -X- _ O
aime -X- _ O
une -X- _ O
vidéo -X- _ O
Episode -X- _ O
1 -X- _ O
-ma -X- _ O
chère -X- _ O
belle -X- _ O
- -X- _ O
mère -X- _ O
4 -X- _ O
mT5 -X- _ O
J -X- _ O
' -X- _ O
aime -X- _ O
une -X- _ O
v -X- _ O
- -X- _ O
Chère -X- _ O
nièce -X- _ O
4.J'aime -X- _ O
une -X- _ O
vidéo -X- _ O
Episode -X- _ O
1 -X- _ O
-ma -X- _ O
chère -X- _ O
tante -X- _ O
4.J'aime -X- _ O
une -X- _ O
vidéo -X- _ O
1 -X- _ O
-Ma -X- _ O
chère -X- _ O
soeur -X- _ O
4.J'aime -X- _ O
une -X- _ O
vidéo -X- _ O
1 -X- _ O
-Ma -X- _ O
chère -X- _ O
bébé -X- _ O

As -X- _ O
pointed -X- _ O
out -X- _ O
earlier -X- _ O
, -X- _ O
Kreutzer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
find -X- _ O
systematic -X- _ O
issues -X- _ O
with -X- _ O
data -X- _ O
representing -X- _ O
several -X- _ O
languages -X- _ O
( -X- _ O
including -X- _ O
Arabic -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
mC4 -X- _ B-DatasetName
dataset -X- _ O
on -X- _ O
which -X- _ O
mT5 -X- _ B-MethodName
is -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
a -X- _ O
data -X- _ O
quality -X- _ O
study -X- _ O
confirming -X- _ O
the -X- _ O
findings -X- _ O
of -X- _ O
Kreutzer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
find -X- _ O
Arabic -X- _ O
mC4 -X- _ B-DatasetName
data -X- _ O
to -X- _ O
be -X- _ O
less -X- _ O
geographically -X- _ O
diverse -X- _ O
than -X- _ O
our -X- _ O
Twitter -X- _ B-DatasetName
pretraining -X- _ O
data -X- _ O
( -X- _ O
described -X- _ O
in -X- _ O
§ -X- _ O
2.1 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
mC4 -X- _ B-DatasetName
data -X- _ O
study -X- _ O
is -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O

Our -X- _ O
results -X- _ O
confirm -X- _ O
the -X- _ O
utility -X- _ O
of -X- _ O
dedicated -X- _ O
language -X- _ O
models -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
multilingual -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
mT5 -X- _ B-MethodName
( -X- _ O
101 -X- _ O
+ -X- _ O
languages -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
AraT5 -X- _ B-MethodName
model -X- _ O
outperforms -X- _ O
mT5 -X- _ B-MethodName
, -X- _ O
even -X- _ O
though -X- _ O
it -X- _ O
is -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
49 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
less -X- _ O
data -X- _ B-HyperparameterName
( -X- _ O
see -X- _ O
§ -X- _ O
2.1 -X- _ O
) -X- _ O
. -X- _ O
One -X- _ O
reason -X- _ O
might -X- _ O
be -X- _ O
that -X- _ O
massively -X- _ O
multilingual -X- _ O
models -X- _ O
are -X- _ O
more -X- _ O
prone -X- _ O
to -X- _ O
suffering -X- _ O
from -X- _ O
capacity -X- _ O
issues -X- _ O
. -X- _ O
Data -X- _ O
quality -X- _ O
is -X- _ O
another -X- _ O
challenge -X- _ O
for -X- _ O
multilingual -X- _ O
models -X- _ O
. -X- _ O

We -X- _ O
report -X- _ O
results -X- _ O
in -X- _ O
For -X- _ O
the -X- _ O
two -X- _ O
ARGEN -X- _ B-DatasetName
ST -X- _ I-DatasetName
datasets -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
and -X- _ O
identify -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
Train -X- _ O
and -X- _ O
Dev -X- _ O
splits -X- _ O
of -X- _ O
WikiLingua -X- _ B-DatasetName
( -X- _ O
Faisal -X- _ O
Ladhak -X- _ O
and -X- _ O
McKeown -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
test -X- _ O
on -X- _ O
all -X- _ O
EASC -X- _ B-DatasetName
and -X- _ O
the -X- _ O
Test -X- _ O
of -X- _ O
Wik -X- _ B-DatasetName
- -X- _ I-DatasetName
iLingua -X- _ I-DatasetName
. -X- _ O
We -X- _ O
report -X- _ O
different -X- _ O
ROUGE -X- _ B-MetricName
scores -X- _ O
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
Table -X- _ O
shows -X- _ O
, -X- _ O
AraT5 -X- _ B-MethodName
Tw -X- _ I-MethodName
acquires -X- _ O
best -X- _ O
results -X- _ O
on -X- _ O
WikiLingua -X- _ B-DatasetName
data -X- _ O
, -X- _ O
while -X- _ O
mT5 -X- _ B-MethodName
outperforms -X- _ O
us -X- _ O
on -X- _ O
EASC -X- _ B-DatasetName
( -X- _ O
we -X- _ O
hypothesize -X- _ O
since -X- _ O
EASC -X- _ B-DatasetName
is -X- _ O
older -X- _ O
data -X- _ O
that -X- _ O
is -X- _ O
likely -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
mC4 -X- _ B-DatasetName
on -X- _ O
which -X- _ O
mT5 -X- _ B-MethodName
was -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
) -X- _ O
. -X- _ O
On -X- _ O
both -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
establish -X- _ O
new -X- _ O
SOTA -X- _ O
( -X- _ O
both -X- _ O
with -X- _ O
our -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
and -X- _ O
mT5).For -X- _ B-MethodName
both -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
all -X- _ O
our -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
Train -X- _ O
splits -X- _ O
of -X- _ O
ARGEN -X- _ B-DatasetName
NTG -X- _ I-DatasetName
and -X- _ O
ARGEN -X- _ B-DatasetName
QG -X- _ I-DatasetName
, -X- _ O
respectively -X- _ O
. -X- _ O
As -X- _ O
Table -X- _ O
6 -X- _ O
shows -X- _ O
, -X- _ O
all -X- _ O
our -X- _ O
models -X- _ O
outperform -X- _ O
mT5 -X- _ B-MethodName
on -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
tasks -X- _ O
. -X- _ O
AraT5 -X- _ B-MethodName
MSA -X- _ I-MethodName
excels -X- _ O
with -X- _ O
20.61 -X- _ B-MetricValue
% -X- _ I-MetricValue
BLEU -X- _ B-MetricName
on -X- _ O
ARGEN -X- _ B-DatasetName
NTG -X- _ I-DatasetName
and -X- _ O
AraT5 -X- _ B-MethodName
is -X- _ O
at -X- _ O
16.99 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
ARGEN -X- _ B-DatasetName
QG -X- _ I-DatasetName
.For -X- _ O
the -X- _ O
paraphrasing -X- _ B-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
and -X- _ O
validate -X- _ O
on -X- _ O
our -X- _ O
new -X- _ O
AraPra -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
blind -X- _ O
- -X- _ O
test -X- _ O
on -X- _ O
both -X- _ O
APB -X- _ B-DatasetName
and -X- _ O
ASEP -X- _ B-DatasetName
datasets -X- _ O
( -X- _ O
described -X- _ O
in -X- _ O
§ -X- _ O
3.6 -X- _ O
) -X- _ O
. -X- _ O
5.1 -X- _ O
Multilingual -X- _ O
vs. -X- _ O
Dedicated -X- _ O
Models -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
our -X- _ O
AraT5 -X- _ B-MethodName
model -X- _ O
outperforms -X- _ O
even -X- _ O
the -X- _ O
S2S -X- _ O
model -X- _ O
trained -X- _ O
with -X- _ O
5X -X- _ O
more -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
completeness -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
provide -X- _ O
the -X- _ O
current -X- _ O
SOTA -X- _ O
on -X- _ O
each -X- _ O
of -X- _ O
our -X- _ O
datasets -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
compare -X- _ O
our -X- _ O
results -X- _ O
to -X- _ O
SOTA -X- _ O
since -X- _ O
these -X- _ O
are -X- _ O
acquired -X- _ O
by -X- _ O
models -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
much -X- _ O
larger -X- _ O
datasets -X- _ O
than -X- _ O
ours -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
Sajjad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
exploit -X- _ O
∼ -X- _ O
42 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
parralel -X- _ B-HyperparameterName
sentences -X- _ I-HyperparameterName
to -X- _ O
train -X- _ O
their -X- _ O
models -X- _ O
. -X- _ O
To -X- _ O
limit -X- _ O
GPU -X- _ O
needs -X- _ O
during -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
especially -X- _ O
given -X- _ O
the -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
process -X- _ O
typical -X- _ O
of -X- _ O
T5 -X- _ B-MethodName
models -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
full -X- _ O
amounts -X- _ O
of -X- _ O
available -X- _ O
parallel -X- _ O
data -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
future -X- _ O
we -X- _ O
plan -X- _ O
to -X- _ O
compare -X- _ O
our -X- _ O
models -X- _ O
under -X- _ O
the -X- _ O
full -X- _ O
data -X- _ O
setting -X- _ O
. -X- _ O
X -X- _ O
→ -X- _ O
Arabic -X- _ O
. -X- _ O
Our -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
not -X- _ O
pretrained -X- _ O
on -X- _ O
foreign -X- _ O
data -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
include -X- _ O
vocabulary -X- _ O
from -X- _ O
11 -X- _ B-HyperparameterValue
foreign -X- _ B-HyperparameterName
languages -X- _ I-HyperparameterName
. -X- _ O
Our -X- _ O
X -X- _ O
→ -X- _ O
Arabic -X- _ O
experiments -X- _ O
here -X- _ O
are -X- _ O
hence -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
( -X- _ O
from -X- _ O
the -X- _ O
perspective -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
) -X- _ O
. -X- _ O
Table -X- _ O
4.2 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
AraT5 -X- _ B-MethodName
MSA -X- _ I-MethodName
and -X- _ O
mT5 -X- _ B-MethodName
on -X- _ O
OPUS -X- _ B-DatasetName
- -X- _ I-DatasetName
X -X- _ I-DatasetName
- -X- _ I-DatasetName
Ara -X- _ I-DatasetName
. -X- _ O
16 -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
outperforms -X- _ O
mT5 -X- _ B-MethodName
in -X- _ O
the -X- _ O
four -X- _ O
X -X- _ O
→ -X- _ O
Arabic -X- _ O
sub -X- _ O
- -X- _ O
tasks -X- _ O
with -X- _ O
an -X- _ O
average -X- _ O
of -X- _ O
+1.12 -X- _ B-MetricValue
and -X- _ O
+0.86 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
points -X- _ O
on -X- _ O
Dev -X- _ O
and -X- _ O
Test -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
natural -X- _ O
codeswitched -X- _ B-TaskName
translation -X- _ I-TaskName
( -X- _ O
CST -X- _ B-TaskName
) -X- _ O
test -X- _ O
sets -X- _ O
that -X- _ O
we -X- _ O
manually -X- _ O
created -X- _ O
, -X- _ O
ALG -X- _ O
- -X- _ O
FR→FR -X- _ O
and -X- _ O
JOR -X- _ O
- -X- _ O
EN→EN -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
evaluate -X- _ O
on -X- _ O
our -X- _ O
two -X- _ O
synthetic -X- _ O
CST -X- _ O
datasets -X- _ O
, -X- _ O
MSA -X- _ B-DatasetName
- -X- _ I-DatasetName
EN -X- _ I-DatasetName
and -X- _ O
MSA -X- _ B-DatasetName
- -X- _ I-DatasetName
FR -X- _ I-DatasetName
, -X- _ O
one -X- _ O
time -X- _ O
with -X- _ O
EN -X- _ O
/ -X- _ O
FR -X- _ O
as -X- _ O
target -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
MSA -X- _ O
- -X- _ O
EN→EN -X- _ O
) -X- _ O
and -X- _ O
another -X- _ O
with -X- _ O
MSA -X- _ O
as -X- _ O
target -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
MSA -X- _ O
- -X- _ O
EN→MSA -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
our -X- _ O
three -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
mT5 -X- _ B-MethodName
on -X- _ O
the -X- _ O
OPUS -X- _ B-DatasetName
- -X- _ I-DatasetName
X -X- _ I-DatasetName
- -X- _ I-DatasetName
Ara -X- _ I-DatasetName
segments -X- _ O
involving -X- _ O
English -X- _ O
and -X- _ O
French -X- _ O
( -X- _ O
each -X- _ O
with -X- _ O
1 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
parallel -X- _ B-HyperparameterName
sentences -X- _ I-HyperparameterName
, -X- _ O
described -X- _ O
in -X- _ O
§ -X- _ O
3.1.2 -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
both -X- _ O
directions -X- _ O
. -X- _ O
Since -X- _ O
these -X- _ O
MT -X- _ B-TaskName
models -X- _ O
are -X- _ O
only -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
parallel -X- _ O
monolingual -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
refer -X- _ O
to -X- _ O
these -X- _ O
experiments -X- _ O
as -X- _ O
zeroshot -X- _ O
. -X- _ O
We -X- _ O
test -X- _ O
these -X- _ O
models -X- _ O
on -X- _ O
both -X- _ O
our -X- _ O
natural -X- _ O
and -X- _ O
synthetic -X- _ O
code -X- _ O
- -X- _ O
switched -X- _ O
data -X- _ O
( -X- _ O
described -X- _ O
in -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
. -X- _ O

Fine -X- _ O
- -X- _ O
tuned -X- _ O
mT5 -X- _ B-MethodName
is -X- _ O
our -X- _ O
second -X- _ O
baseline -X- _ O
baseline -X- _ O
II -X- _ O
. -X- _ O
Arabic -X- _ O
→ -X- _ O
English -X- _ O
. -X- _ O
Results -X- _ O
of -X- _ O
ARGEN -X- _ B-DatasetName
MT -X- _ I-DatasetName
are -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
Results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
models -X- _ O
achieve -X- _ O
best -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
in -X- _ O
37 -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
42 -X- _ O
tests -X- _ O
splits -X- _ O
. -X- _ O
AraT5 -X- _ B-MethodName
MSA -X- _ I-MethodName
acquires -X- _ O
best -X- _ O
results -X- _ O
in -X- _ O
32 -X- _ O
of -X- _ O
these -X- _ O
test -X- _ O
splits -X- _ O
, -X- _ O
outperforming -X- _ O
all -X- _ O
the -X- _ O
baselines -X- _ O
( -X- _ O
S2S -X- _ B-MethodName
2 -X- _ I-MethodName
M -X- _ I-MethodName
) -X- _ O
, -X- _ O
( -X- _ O
S2S -X- _ B-MethodName
10 -X- _ I-MethodName
M -X- _ I-MethodName
) -X- _ O
, -X- _ O
and -X- _ O
mT5 -X- _ B-MethodName
with -X- _ O
+5.25 -X- _ B-MetricValue
, -X- _ O
+4.99 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
+0.45 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
points -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
are -X- _ O
striking -X- _ O
since -X- _ O
our -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
Arabic -X- _ O
data -X- _ O
only -X- _ O
( -X- _ O
although -X- _ O
they -X- _ O
include -X- _ O
English -X- _ O
vocabulary -X- _ O
and -X- _ O
marginal -X- _ O
amounts -X- _ O
of -X- _ O
code -X- _ O
- -X- _ O
switching -X- _ O
; -X- _ O
see -X- _ O
§ -X- _ O
2.1 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
even -X- _ O
under -X- _ O
this -X- _ O
arguably -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
, -X- _ O
15 -X- _ O
the -X- _ O
models -X- _ O
perform -X- _ O
very -X- _ O
well -X- _ O
. -X- _ O

These -X- _ O
are -X- _ O
MSR -X- _ B-DatasetName
- -X- _ I-DatasetName
Paraphrase -X- _ I-DatasetName
( -X- _ O
510 -X- _ B-HyperparameterValue
pairs -X- _ B-HyperparameterName
) -X- _ O
, -X- _ O
MSR -X- _ B-DatasetName
- -X- _ I-DatasetName
Video -X- _ I-DatasetName
( -X- _ O
368 -X- _ B-HyperparameterValue
pairs -X- _ B-HyperparameterName
) -X- _ O
, -X- _ O
and -X- _ O
SMTeuroparl -X- _ B-DatasetName
( -X- _ O
203 -X- _ B-HyperparameterValue
pairs -X- _ B-HyperparameterName
) -X- _ O
. -X- _ O
The -X- _ O
pairs -X- _ O
are -X- _ O
labeled -X- _ O
with -X- _ O
a -X- _ O
similarity -X- _ O
score -X- _ O
on -X- _ O
a -X- _ O
scale -X- _ O
from -X- _ O
0 -X- _ O
to -X- _ O
5 -X- _ O
. -X- _ O
For -X- _ O
our -X- _ O
purpose -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
keep -X- _ O
sentence -X- _ O
pairs -X- _ O
with -X- _ O
a -X- _ O
semantic -X- _ O
similarity -X- _ O
score -X- _ O
≥ -X- _ O
3.5 -X- _ O
which -X- _ O
gives -X- _ O
us -X- _ O
603 -X- _ B-HyperparameterValue
pairs -X- _ B-HyperparameterName
. -X- _ O
We -X- _ O
merge -X- _ O
and -X- _ O
shuffle -X- _ O
all -X- _ O
three -X- _ O
ASEP -X- _ B-DatasetName
datasets -X- _ O
for -X- _ O
our -X- _ O
use -X- _ O
. -X- _ O
Arabic -X- _ B-DatasetName
Paraphrasing -X- _ I-DatasetName
Benchmark -X- _ I-DatasetName
( -X- _ O
APB -X- _ B-DatasetName
) -X- _ O
. -X- _ O
APB -X- _ B-DatasetName
is -X- _ O
created -X- _ O
by -X- _ O
Alian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
consists -X- _ O
of -X- _ O
1 -X- _ B-HyperparameterValue
, -X- _ I-HyperparameterValue
010 -X- _ I-HyperparameterValue
Arabic -X- _ B-HyperparameterName
sentence -X- _ I-HyperparameterName
pairs -X- _ I-HyperparameterName
that -X- _ O
are -X- _ O
collected -X- _ O
from -X- _ O
different -X- _ O
Arabic -X- _ O
books -X- _ O
. -X- _ O
Paraphrasing -X- _ B-TaskName
was -X- _ O
performed -X- _ O
manually -X- _ O
using -X- _ O
six -X- _ O
transformation -X- _ O
procedures -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
addition -X- _ O
, -X- _ O
deletion -X- _ O
, -X- _ O
expansion -X- _ O
, -X- _ O
permutation -X- _ O
, -X- _ O
reduction -X- _ O
, -X- _ O
and -X- _ O
replacement).Transliteration -X- _ B-TaskName
involves -X- _ O
mapping -X- _ O
a -X- _ O
text -X- _ O
written -X- _ O
with -X- _ O
orthographic -X- _ O
symbols -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
script -X- _ O
into -X- _ O
another -X- _ O
( -X- _ O
Beesley -X- _ O
, -X- _ O
1998 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
BOLT -X- _ B-DatasetName
Egyptian -X- _ I-DatasetName
Arabic -X- _ I-DatasetName
SMS -X- _ I-DatasetName
/ -X- _ I-DatasetName
Chat -X- _ I-DatasetName
and -X- _ I-DatasetName
Transliteration -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
13 -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
naturally -X- _ O
- -X- _ O
occurring -X- _ O
chat -X- _ O
and -X- _ O
short -X- _ O
messages -X- _ O
( -X- _ O
SMS -X- _ O
) -X- _ O
from -X- _ O
Egyptian -X- _ O
native -X- _ O
speakers -X- _ O
. -X- _ O
The -X- _ O
messages -X- _ O
( -X- _ O
sources -X- _ O
) -X- _ O
were -X- _ O
natively -X- _ O
written -X- _ O
in -X- _ O
either -X- _ O
romanized -X- _ O
Arabizi -X- _ O
or -X- _ O
Egyptian -X- _ O
Arabic -X- _ O
orthography -X- _ O
. -X- _ O
The -X- _ O
target -X- _ O
is -X- _ O
the -X- _ O
Egyptian -X- _ O
transliteration -X- _ O
of -X- _ O
these -X- _ O
message -X- _ O
. -X- _ O
14 -X- _ O
For -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
split -X- _ O
proposed -X- _ O
by -X- _ O
Shazal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
( -X- _ O
58.9 -X- _ O
K -X- _ O
for -X- _ O
Train -X- _ O
and -X- _ O
5.4 -X- _ O
K -X- _ O
for -X- _ O
Dev -X- _ O
and -X- _ O
Test -X- _ O
each -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
refer -X- _ O
to -X- _ O
this -X- _ O
dataset -X- _ O
as -X- _ O
ARGEN -X- _ B-DatasetName
TR -X- _ I-DatasetName
.Baselines -X- _ O
and -X- _ O
Procedure -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
models -X- _ O
to -X- _ O
models -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
with -X- _ O
mT5 -X- _ B-MethodName
using -X- _ O
the -X- _ O
same -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
for -X- _ O
MT -X- _ B-TaskName
, -X- _ O
we -X- _ O
compare -X- _ O
to -X- _ O
a -X- _ O
vanilla -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
( -X- _ O
S2S -X- _ O
) -X- _ O
Transformer -X- _ B-MethodName
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
as -X- _ O
implemented -X- _ O
in -X- _ O
Fairseq -X- _ O
( -X- _ O
Ott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
models -X- _ O
and -X- _ O
baselines -X- _ O
, -X- _ O
across -X- _ O
all -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
identify -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
respective -X- _ O
Dev -X- _ O
data -X- _ O
and -X- _ O
blind -X- _ O
- -X- _ O
test -X- _ O
it -X- _ O
on -X- _ O
Test -X- _ O
data -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
rule -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
on -X- _ O
both -X- _ O
Dev -X- _ O
and -X- _ O
Test -X- _ O
sets -X- _ O
. -X- _ O
All -X- _ O
our -X- _ O
Dev -X- _ O
results -X- _ O
are -X- _ O
in -X- _ O
Section -X- _ O
C.2 -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
two -X- _ O
S2S -X- _ B-MethodName
Transformers -X- _ I-MethodName
models -X- _ O
on -X- _ O
2 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
( -X- _ O
S2S -X- _ B-MethodName
2 -X- _ I-MethodName
M -X- _ I-MethodName
) -X- _ O
and -X- _ O
10 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
( -X- _ O
S2S -X- _ B-MethodName
10 -X- _ I-MethodName
M -X- _ I-MethodName
) -X- _ O
MSA -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
English -X- _ I-HyperparameterName
parallel -X- _ I-HyperparameterName
sentences -X- _ I-HyperparameterName
extracted -X- _ O
from -X- _ O
OPUS -X- _ B-DatasetName
. -X- _ O
We -X- _ O
take -X- _ O
these -X- _ O
two -X- _ O
models -X- _ O
as -X- _ O
our -X- _ O
baseline -X- _ O
I. -X- _ O
We -X- _ O
also -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
our -X- _ O
three -X- _ O
models -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
mT5 -X- _ B-MethodName
on -X- _ O
the -X- _ O
same -X- _ O
OPUS -X- _ B-DatasetName
2 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
MSA -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
English -X- _ I-HyperparameterName
parallel -X- _ I-HyperparameterName
sentences -X- _ I-HyperparameterName
used -X- _ O
for -X- _ O
baseline -X- _ O
I. -X- _ O

An -X- _ O
abstractive -X- _ O
summarization -X- _ O
dataset -X- _ O
in -X- _ O
18 -X- _ B-HyperparameterValue
languages -X- _ B-HyperparameterName
, -X- _ O
including -X- _ O
Arabic -X- _ O
( -X- _ O
Faisal -X- _ O
Ladhak -X- _ O
and -X- _ O
McKeown -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
contains -X- _ O
articles -X- _ O
and -X- _ O
their -X- _ O
summaries -X- _ O
from -X- _ O
WikiHow -X- _ O
. -X- _ O
11 -X- _ O
The -X- _ O
Arabic -X- _ O
part -X- _ O
includes -X- _ O
summaries -X- _ O
for -X- _ O
29.2 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
articles -X- _ B-HyperparameterName
, -X- _ O
which -X- _ O
we -X- _ O
split -X- _ O
into -X- _ O
80 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
Train -X- _ B-HyperparameterName
( -X- _ O
23.4 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
) -X- _ O
, -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
Dev -X- _ B-HyperparameterName
( -X- _ O
2.9 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
) -X- _ O
, -X- _ O
and -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
Test -X- _ B-HyperparameterName
( -X- _ O
2.9K).The -X- _ B-HyperparameterValue
purpose -X- _ O
of -X- _ O
the -X- _ O
news -X- _ B-TaskName
title -X- _ I-TaskName
generation -X- _ I-TaskName
( -X- _ O
NTG -X- _ B-TaskName
) -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
produce -X- _ O
proper -X- _ O
news -X- _ O
article -X- _ O
titles -X- _ O
( -X- _ O
Liang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
introduce -X- _ O
NTG -X- _ B-TaskName
as -X- _ O
a -X- _ O
new -X- _ O
task -X- _ O
for -X- _ O
Arabic -X- _ B-TaskName
language -X- _ I-TaskName
generation -X- _ I-TaskName
. -X- _ O
Given -X- _ O
an -X- _ O
article -X- _ O
, -X- _ O
a -X- _ O
title -X- _ O
generation -X- _ O
model -X- _ O
needs -X- _ O
to -X- _ O
output -X- _ O
a -X- _ O
short -X- _ O
grammatical -X- _ O
sequence -X- _ O
of -X- _ O
words -X- _ O
suited -X- _ O
to -X- _ O
the -X- _ O
article -X- _ O
content -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
ARGEN -X- _ B-DatasetName
NTG -X- _ I-DatasetName
, -X- _ O
a -X- _ O
novel -X- _ O
NTG -X- _ O
dataset -X- _ O
exploiting -X- _ O
120 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
articles -X- _ B-HyperparameterName
along -X- _ O
with -X- _ O
their -X- _ O
titles -X- _ O
extracted -X- _ O
from -X- _ O
AraNews -X- _ O
( -X- _ O
Nagoudi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
12 -X- _ O
We -X- _ O
only -X- _ O
include -X- _ O
titles -X- _ O
with -X- _ O
at -X- _ O
least -X- _ O
three -X- _ O
words -X- _ O
in -X- _ O
this -X- _ O
dataset -X- _ O
. -X- _ O
We -X- _ O
split -X- _ O
ARGEN -X- _ B-DatasetName
NTG -X- _ I-DatasetName
data -X- _ O
into -X- _ O
80 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
Train -X- _ B-HyperparameterName
( -X- _ O
93.3 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
) -X- _ O
, -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
Dev -X- _ B-HyperparameterName
( -X- _ O
11.7 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
) -X- _ O
, -X- _ O
and -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
Test -X- _ B-HyperparameterName
( -X- _ O
11.7 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
) -X- _ O
. -X- _ O
Details -X- _ O
about -X- _ O
ARGEN -X- _ B-DatasetName
NTG -X- _ I-DatasetName
are -X- _ O
in -X- _ O
Table -X- _ O
C.1 -X- _ O
( -X- _ O
Appendix -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
sample -X- _ O
of -X- _ O
a -X- _ O
news -X- _ O
article -X- _ O
from -X- _ O
our -X- _ O
Test -X- _ O
split -X- _ O
and -X- _ O
example -X- _ O
titles -X- _ O
generated -X- _ O
by -X- _ O
our -X- _ O
models -X- _ O
are -X- _ O
in -X- _ O
Table -X- _ O
D.5 -X- _ O
( -X- _ O
Appendix).In -X- _ O
the -X- _ O
question -X- _ B-TaskName
generation -X- _ I-TaskName
( -X- _ O
QG -X- _ B-TaskName
) -X- _ O
task -X- _ O
, -X- _ O
a -X- _ O
question -X- _ O
is -X- _ O
produced -X- _ O
for -X- _ O
a -X- _ O
passage -X- _ O
( -X- _ O
Gehrmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
absence -X- _ O
of -X- _ O
an -X- _ O
Arabic -X- _ O
QG -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
a -X- _ O
new -X- _ O
Arabic -X- _ O
QG -X- _ O
dataset -X- _ O
( -X- _ O
ARGEN -X- _ B-DatasetName
QG -X- _ I-DatasetName
) -X- _ O
using -X- _ O
a -X- _ O
publicly -X- _ O
available -X- _ O
Arabic -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
( -X- _ O
QA -X- _ B-TaskName
) -X- _ O
resource -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
Kriangchaivech -X- _ O
and -X- _ O
Wangperawong -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
who -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
simple -X- _ O
questions -X- _ O
relevant -X- _ O
to -X- _ O
passages -X- _ O
and -X- _ O
answers -X- _ O
extracted -X- _ O
from -X- _ O
SQuAD -X- _ B-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
ARGEN -X- _ B-DatasetName
QG -X- _ I-DatasetName
by -X- _ O
extracting -X- _ O
96 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
( -X- _ B-HyperparameterName
passage -X- _ I-HyperparameterName
, -X- _ I-HyperparameterName
answer -X- _ I-HyperparameterName
, -X- _ I-HyperparameterName
and -X- _ I-HyperparameterName
question -X- _ I-HyperparameterName
) -X- _ I-HyperparameterName
triplets -X- _ I-HyperparameterName
from -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
The -X- _ O
Arabic -X- _ O
QA -X- _ O
dataset -X- _ O
ARCD -X- _ B-DatasetName
( -X- _ O
Mozannar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
three -X- _ O
multi -X- _ O
- -X- _ O
lingual -X- _ O
QA -X- _ O
datasets -X- _ O
: -X- _ O
XTREME -X- _ B-DatasetName
benchmark -X- _ O
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
MLQA -X- _ B-DatasetName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
XQuAD -X- _ B-DatasetName
( -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
TyDi -X- _ B-DatasetName
QA -X- _ I-DatasetName
( -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020).The -X- _ O
main -X- _ O
goal -X- _ O
of -X- _ O
this -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
produce -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
Arabic -X- _ O
sentence -X- _ O
a -X- _ O
paraphrase -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
meaning -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
build -X- _ O
our -X- _ O
paraphrasing -X- _ B-TaskName
benchmark -X- _ O
component -X- _ O
( -X- _ O
ARGEN -X- _ B-DatasetName
PPH -X- _ I-DatasetName
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
following -X- _ O
three -X- _ O
datasets -X- _ O
: -X- _ O
AraPara -X- _ B-DatasetName
. -X- _ O
We -X- _ O
introduce -X- _ O
AraPara -X- _ B-DatasetName
, -X- _ O
a -X- _ O
new -X- _ O
multidomain -X- _ O
Arabic -X- _ O
paraphrasing -X- _ O
dataset -X- _ O
we -X- _ O
create -X- _ O
using -X- _ O
English -X- _ O
- -X- _ O
Arabic -X- _ O
parallel -X- _ O
OPUS -X- _ B-DatasetName
data -X- _ O
( -X- _ O
Tiedemann -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
AraPara -X- _ B-DatasetName
covers -X- _ O
several -X- _ O
domains -X- _ O
such -X- _ O
as -X- _ O
news -X- _ O
, -X- _ O
religion -X- _ O
, -X- _ O
politics -X- _ O
, -X- _ O
movies -X- _ O
, -X- _ O
and -X- _ O
technology -X- _ O
. -X- _ O
To -X- _ O
create -X- _ O
a -X- _ O
high -X- _ O
quality -X- _ O
machine -X- _ O
generated -X- _ O
paraphrase -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
four -X- _ O
careful -X- _ O
steps -X- _ O
involving -X- _ O
human -X- _ O
validation -X- _ O
( -X- _ O
more -X- _ O
details -X- _ O
are -X- _ O
offered -X- _ O
in -X- _ O
Appendix -X- _ O
C.1 -X- _ O
) -X- _ O
. -X- _ O
AraPara -X- _ B-DatasetName
consists -X- _ O
of -X- _ O
122 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
paraphrase -X- _ B-HyperparameterName
pairs -X- _ I-HyperparameterName
. -X- _ O
We -X- _ O
only -X- _ O
use -X- _ O
AraPara -X- _ B-DatasetName
for -X- _ O
model -X- _ O
development -X- _ O
, -X- _ O
and -X- _ O
hence -X- _ O
we -X- _ O
split -X- _ O
it -X- _ O
into -X- _ O
116 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
Train -X- _ B-HyperparameterName
and -X- _ O
6 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
Dev -X- _ B-HyperparameterName
. -X- _ O
Arabic -X- _ B-DatasetName
SemEval -X- _ I-DatasetName
Paraphrasing -X- _ I-DatasetName
( -X- _ O
ASEP -X- _ B-DatasetName
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
create -X- _ O
a -X- _ O
new -X- _ O
Arabic -X- _ O
paraphrasing -X- _ O
dataset -X- _ O
using -X- _ O
three -X- _ O
existing -X- _ O
Arabic -X- _ O
semantic -X- _ O
similarity -X- _ O
datasets -X- _ O
released -X- _ O
during -X- _ O
SemEval -X- _ O
2017 -X- _ O
( -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
JOR -X- _ B-DatasetName
- -X- _ I-DatasetName
CST -X- _ I-DatasetName
. -X- _ O
This -X- _ O
is -X- _ O
collected -X- _ O
from -X- _ O
Jordanian -X- _ O
Twitter -X- _ O
and -X- _ O
consists -X- _ O
of -X- _ O
code -X- _ O
- -X- _ O
switched -X- _ O
Arabic -X- _ O
- -X- _ O
English -X- _ O
posts -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
manually -X- _ O
translate -X- _ O
into -X- _ O
monolingual -X- _ O
English -X- _ O
. -X- _ O
Each -X- _ O
of -X- _ O
ALG -X- _ O
- -X- _ O
CST -X- _ O
and -X- _ O
JOR -X- _ B-DatasetName
- -X- _ I-DatasetName
CST -X- _ I-DatasetName
comprises -X- _ O
300 -X- _ B-HyperparameterValue
tweets -X- _ B-HyperparameterName
( -X- _ O
total=600 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
Human -X- _ O
translation -X- _ O
is -X- _ O
performed -X- _ O
by -X- _ O
one -X- _ O
native -X- _ O
speaker -X- _ O
from -X- _ O
each -X- _ O
dialect -X- _ O
with -X- _ O
seminative -X- _ O
English -X- _ O
/ -X- _ O
French -X- _ O
fluency -X- _ O
. -X- _ O
Synthetic -X- _ B-DatasetName
Code -X- _ I-DatasetName
- -X- _ I-DatasetName
Switched -X- _ I-DatasetName
Data -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
multilingual -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
mBART -X- _ B-DatasetName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
create -X- _ O
synthetic -X- _ O
code -X- _ O
- -X- _ O
switched -X- _ O
data -X- _ O
following -X- _ O
Jawahar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
exploit -X- _ O
the -X- _ O
UN -X- _ O
multi -X- _ O
- -X- _ O
parallel -X- _ O
data -X- _ O
( -X- _ O
Ziemski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
using -X- _ O
the -X- _ O
Arabic -X- _ O
- -X- _ O
English -X- _ O
and -X- _ O
Arabic -X- _ O
- -X- _ O
French -X- _ O
test -X- _ O
splits -X- _ O
( -X- _ O
4 -X- _ O
, -X- _ O
000 -X- _ O
sentences -X- _ O
each -X- _ O
, -X- _ O
described -X- _ O
in -X- _ O
§ -X- _ O
3.1 -X- _ O
) -X- _ O
to -X- _ O
generate -X- _ O
our -X- _ O
two -X- _ O
code -X- _ O
- -X- _ O
switched -X- _ O
test -X- _ O
sets -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
MSA -X- _ B-DatasetName
- -X- _ I-DatasetName
EN -X- _ I-DatasetName
and -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
MSA -X- _ B-DatasetName
- -X- _ I-DatasetName
FR -X- _ I-DatasetName
. -X- _ O
In -X- _ O
each -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
mBART -X- _ B-MethodName
to -X- _ O
translate -X- _ O
∼ -X- _ O
30 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
random -X- _ O
Arabic -X- _ B-HyperparameterName
n -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
grams -X- _ I-HyperparameterName
into -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
English -X- _ O
or -X- _ O
French).To -X- _ O
WikiLingua -X- _ B-DatasetName
. -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
IWSLT -X- _ B-DatasetName
Corpus -X- _ I-DatasetName
. -X- _ O
Several -X- _ O
Arabic -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
English -X- _ O
parallel -X- _ O
datasets -X- _ O
were -X- _ O
released -X- _ O
during -X- _ O
IWSLT -X- _ B-DatasetName
evaluation -X- _ O
campaigns -X- _ O
( -X- _ O
Federico -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012;Cettolo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013Cettolo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2014Cettolo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2016 -X- _ O
. -X- _ O
The -X- _ O
datasets -X- _ O
are -X- _ O
mainly -X- _ O
extracted -X- _ O
from -X- _ O
transcriptions -X- _ O
of -X- _ O
TED -X- _ O
talks -X- _ O
between -X- _ O
2010 -X- _ O
and -X- _ O
2016 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
QCRI -X- _ O
Educational -X- _ O
Domain -X- _ O
Corpus -X- _ O
( -X- _ O
QED -X- _ O
2016 -X- _ O
) -X- _ O
( -X- _ O
Abdelali -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
AraBench -X- _ B-DatasetName
Datasets -X- _ O
. -X- _ O
Sajjad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
introduce -X- _ O
AraBench -X- _ O
, -X- _ O
an -X- _ O
evaluation -X- _ O
suite -X- _ O
for -X- _ O
MSA -X- _ O
and -X- _ O
dialectal -X- _ O
Arabic -X- _ O
to -X- _ O
English -X- _ O
MT -X- _ O
consisting -X- _ O
of -X- _ O
five -X- _ O
publicly -X- _ O
available -X- _ O
datasets -X- _ O
: -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
ADPT -X- _ B-DatasetName
: -X- _ O
Arabic -X- _ B-DatasetName
- -X- _ I-DatasetName
Dialect -X- _ I-DatasetName
/ -X- _ I-DatasetName
English -X- _ I-DatasetName
Parallel -X- _ I-DatasetName
Text -X- _ I-DatasetName
( -X- _ O
Zbib -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
MADAR -X- _ B-DatasetName
: -X- _ O
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
Arabic -X- _ I-DatasetName
Dialect -X- _ I-DatasetName
Applications -X- _ I-DatasetName
and -X- _ I-DatasetName
Resources -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Bouamor -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
QAraC -X- _ B-DatasetName
: -X- _ O
Qatari -X- _ B-DatasetName
- -X- _ I-DatasetName
English -X- _ I-DatasetName
speech -X- _ I-DatasetName
corpus -X- _ I-DatasetName
( -X- _ O
Elmahdy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
Bible -X- _ B-DatasetName
: -X- _ O
The -X- _ O
English -X- _ O
Bible -X- _ O
translated -X- _ O
into -X- _ O
MSA -X- _ O
, -X- _ O
Moroccan -X- _ O
, -X- _ O
and -X- _ O
Tunisian -X- _ O
Arabic -X- _ O
dialects -X- _ O
. -X- _ O
9 -X- _ O
For -X- _ O
all -X- _ O
these -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
splits -X- _ O
as -X- _ O
Sajjad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
To -X- _ O
investigate -X- _ O
ability -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
to -X- _ O
generate -X- _ O
Arabic -X- _ O
starting -X- _ O
from -X- _ O
foreign -X- _ O
languages -X- _ O
in -X- _ O
our -X- _ O
vocabulary -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
an -X- _ O
X→Arabic -X- _ O
benchmark -X- _ O
of -X- _ O
four -X- _ B-HyperparameterValue
languages -X- _ B-HyperparameterName
( -X- _ O
English -X- _ O
, -X- _ O
French -X- _ O
, -X- _ O
German -X- _ O
, -X- _ O
and -X- _ O
Russian -X- _ O
) -X- _ O
by -X- _ O
extracting -X- _ O
parallel -X- _ O
data -X- _ O
from -X- _ O
OPUS -X- _ B-DatasetName
( -X- _ O
Tiedemann -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
language -X- _ O
, -X- _ O
we -X- _ O
pick -X- _ O
1 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
sentences -X- _ B-HyperparameterName
for -X- _ O
training -X- _ O
and -X- _ O
5 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
sentences -X- _ B-HyperparameterName
for -X- _ O
each -X- _ O
of -X- _ O
development -X- _ O
and -X- _ O
test -X- _ O
splits -X- _ O
. -X- _ O
This -X- _ O
gives -X- _ O
us -X- _ O
our -X- _ O
seventh -X- _ O
ARGEN -X- _ B-DatasetName
MT -X- _ I-DatasetName
dataset -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
OPUS -X- _ B-DatasetName
- -X- _ I-DatasetName
X -X- _ I-DatasetName
- -X- _ I-DatasetName
Ara -X- _ I-DatasetName
. -X- _ O
There -X- _ O
is -X- _ O
rising -X- _ O
interest -X- _ O
in -X- _ O
translating -X- _ O
code -X- _ O
- -X- _ O
switched -X- _ O
data -X- _ O
( -X- _ O
Nagoudi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
purpose -X- _ O
here -X- _ O
is -X- _ O
to -X- _ O
translate -X- _ O
Arabic -X- _ O
text -X- _ O
involving -X- _ O
code -X- _ O
- -X- _ O
switching -X- _ O
from -X- _ O
a -X- _ O
foreign -X- _ O
language -X- _ O
into -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
that -X- _ O
foreign -X- _ O
language -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
into -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
MSA -X- _ O
. -X- _ O
Hence -X- _ O
we -X- _ O
create -X- _ O
ARGEN -X- _ B-DatasetName
CST -X- _ I-DatasetName
, -X- _ O
our -X- _ O
code -X- _ O
- -X- _ O
switched -X- _ O
translation -X- _ O
benchmark -X- _ O
component -X- _ O
, -X- _ O
using -X- _ O
four -X- _ B-HyperparameterValue
sub -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
test -X- _ I-HyperparameterName
sets -X- _ I-HyperparameterName
. -X- _ O
Two -X- _ B-HyperparameterValue
of -X- _ O
these -X- _ O
are -X- _ O
natural -X- _ B-HyperparameterName
and -X- _ O
two -X- _ B-HyperparameterValue
are -X- _ O
synthetic -X- _ B-HyperparameterName
, -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
Natural -X- _ B-DatasetName
Code -X- _ I-DatasetName
- -X- _ I-DatasetName
Switched -X- _ I-DatasetName
Data -X- _ O
. -X- _ O
We -X- _ O
create -X- _ O
two -X- _ O
human -X- _ O
written -X- _ O
( -X- _ O
natural -X- _ O
) -X- _ O
code -X- _ O
- -X- _ O
switched -X- _ O
parallel -X- _ O
datasets -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
ALG -X- _ B-DatasetName
- -X- _ I-DatasetName
CST -X- _ I-DatasetName
. -X- _ O
This -X- _ O
is -X- _ O
collected -X- _ O
from -X- _ O
Algerian -X- _ O
Twitter -X- _ O
and -X- _ O
consists -X- _ O
of -X- _ O
code -X- _ O
- -X- _ O
switched -X- _ O
Arabic -X- _ O
- -X- _ O
French -X- _ O
posts -X- _ O
. -X- _ O
We -X- _ O
translate -X- _ O
these -X- _ O
manually -X- _ O
into -X- _ O
monolingual -X- _ O
French -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
also -X- _ O
linguistically -X- _ O
diverse -X- _ O
as -X- _ O
it -X- _ O
covers -X- _ O
both -X- _ O
MSA -X- _ O
and -X- _ O
various -X- _ O
Arabic -X- _ O
dialects -X- _ O
, -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
Arabizi -X- _ O
( -X- _ O
romanized -X- _ O
Arabic -X- _ O
in -X- _ O
the -X- _ O
TS -X- _ B-TaskName
task -X- _ O
) -X- _ O
and -X- _ O
codeswitching -X- _ O
( -X- _ O
in -X- _ O
the -X- _ O
CST -X- _ B-TaskName
task -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
now -X- _ O
describe -X- _ O
each -X- _ O
component -X- _ O
of -X- _ O
ARGEN.To -X- _ B-DatasetName
design -X- _ O
the -X- _ O
MT -X- _ B-TaskName
component -X- _ O
of -X- _ O
ARGEN -X- _ B-DatasetName
, -X- _ O
ARGEN -X- _ B-DatasetName
MT -X- _ I-DatasetName
, -X- _ O
we -X- _ O
consolidate -X- _ O
7 -X- _ B-HyperparameterValue
unique -X- _ O
datasets -X- _ B-HyperparameterName
with -X- _ O
46 -X- _ B-HyperparameterValue
different -X- _ O
test -X- _ B-HyperparameterName
splits -X- _ I-HyperparameterName
. -X- _ O
The -X- _ O
datasets -X- _ O
come -X- _ O
from -X- _ O
both -X- _ O
MSA -X- _ O
and -X- _ O
Arabic -X- _ O
dialects -X- _ O
, -X- _ O
and -X- _ O
range -X- _ O
between -X- _ O
600 -X- _ B-HyperparameterValue
- -X- _ O
138 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
sentences -X- _ B-HyperparameterName
( -X- _ O
details -X- _ O
in -X- _ O
Table -X- _ O
C.2 -X- _ O
in -X- _ O
Appendix -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
introduce -X- _ O
each -X- _ O
dataset -X- _ O
briefly -X- _ O
here.(1 -X- _ O
) -X- _ O
United -X- _ B-DatasetName
Nations -X- _ I-DatasetName
Parallel -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
. -X- _ O
Ziemski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
introduce -X- _ O
this -X- _ O
parallel -X- _ O
corpus -X- _ O
of -X- _ O
man -X- _ O
- -X- _ O
ually -X- _ O
translated -X- _ O
UN -X- _ O
documents -X- _ O
covering -X- _ O
the -X- _ O
six -X- _ O
official -X- _ O
UN -X- _ O
languages -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
Arabic -X- _ O
, -X- _ O
Chinese -X- _ O
, -X- _ O
English -X- _ O
, -X- _ O
French -X- _ O
, -X- _ O
Russian -X- _ O
, -X- _ O
and -X- _ O
Spanish -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
corpus -X- _ O
consists -X- _ O
of -X- _ O
development -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
only -X- _ O
, -X- _ O
each -X- _ O
of -X- _ O
which -X- _ O
comprise -X- _ O
4 -X- _ B-HyperparameterValue
, -X- _ I-HyperparameterValue
000 -X- _ I-HyperparameterValue
sentences -X- _ B-HyperparameterName
that -X- _ O
are -X- _ O
one -X- _ O
- -X- _ O
toone -X- _ O
alignments -X- _ O
across -X- _ O
all -X- _ O
official -X- _ O
languages -X- _ O
. -X- _ O

Our -X- _ O
combined -X- _ O
MSA -X- _ O
and -X- _ O
Twitter -X- _ O
data -X- _ O
make -X- _ O
up -X- _ O
29B -X- _ B-HyperparameterValue
tokens -X- _ B-HyperparameterName
, -X- _ O
and -X- _ O
hence -X- _ O
is -X- _ O
∼ -X- _ O
49 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
less -X- _ O
than -X- _ O
Arabic -X- _ B-HyperparameterName
tokens -X- _ I-HyperparameterName
on -X- _ O
which -X- _ O
mT5 -X- _ B-MethodName
is -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
( -X- _ O
57B -X- _ B-HyperparameterValue
Arabic -X- _ B-HyperparameterName
tokens -X- _ I-HyperparameterName
) -X- _ O
. -X- _ O
More -X- _ O
information -X- _ O
about -X- _ O
our -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
is -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
MSA -X- _ O
Vs -X- _ O
. -X- _ O
Dialect -X- _ O
Distribution -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
analyze -X- _ O
MSA -X- _ O
- -X- _ O
dialect -X- _ O
distribution -X- _ O
in -X- _ O
our -X- _ O
Twitter -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
run -X- _ O
the -X- _ O
binary -X- _ O
( -X- _ O
MSA -X- _ O
- -X- _ O
dialect -X- _ O
) -X- _ O
classifier -X- _ O
introduced -X- _ O
in -X- _ O
Abdul -X- _ O
- -X- _ O
Mageed -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020b -X- _ O
) -X- _ O
on -X- _ O
a -X- _ O
random -X- _ O
sample -X- _ O
of -X- _ O
100 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
tweets -X- _ B-HyperparameterName
. -X- _ O
We -X- _ O
find -X- _ O
the -X- _ O
data -X- _ O
to -X- _ O
involve -X- _ O
28.39 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
predicted -X- _ O
dialect -X- _ B-HyperparameterName
tweets -X- _ O
and -X- _ O
71.61 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
predicted -X- _ O
MSA -X- _ B-HyperparameterName
. -X- _ O
We -X- _ O
also -X- _ O
acquire -X- _ O
country -X- _ O
- -X- _ O
level -X- _ O
dialect -X- _ O
labels -X- _ O
using -X- _ O
an -X- _ O
in -X- _ O
- -X- _ O
house -X- _ O
strong -X- _ O
classifier -X- _ O
on -X- _ O
the -X- _ O
dialectal -X- _ O
portion -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
∼ -X- _ O
28.39 -X- _ B-HyperparameterValue
millions -X- _ I-HyperparameterValue
tweets -X- _ B-HyperparameterName
) -X- _ O
, -X- _ O
finding -X- _ O
dialectal -X- _ O
tweets -X- _ O
to -X- _ O
be -X- _ O
truly -X- _ O
geographically -X- _ O
diverse -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
Naturally -X- _ O
- -X- _ O
Occurring -X- _ O
Code -X- _ O
- -X- _ O
Switching -X- _ O
. -X- _ O
Using -X- _ O
1 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
random -X- _ O
tweets -X- _ B-HyperparameterName
from -X- _ O
our -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
an -X- _ O
analysis -X- _ O
of -X- _ O
code -X- _ O
- -X- _ O
switching -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
simple -X- _ O
string -X- _ O
matching -X- _ O
to -X- _ O
identify -X- _ O
Arabic -X- _ O
and -X- _ O
run -X- _ O
the -X- _ O
CLD3 -X- _ O
language -X- _ O
ID -X- _ O
tool -X- _ O
4 -X- _ O
on -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
Arabic -X- _ O
string -X- _ O
sequences -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
the -X- _ O
data -X- _ O
to -X- _ O
have -X- _ O
4.14 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
non -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
Arabic -X- _ I-HyperparameterName
. -X- _ O
These -X- _ O
turn -X- _ O
out -X- _ O
to -X- _ O
be -X- _ O
almost -X- _ O
always -X- _ O
natural -X- _ O
code -X- _ O
- -X- _ O
switching -X- _ O
involving -X- _ O
many -X- _ O
foreign -X- _ O
languages -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
English -X- _ O
, -X- _ O
French -X- _ O
, -X- _ O
Korean -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
remove -X- _ O
diacritics -X- _ O
and -X- _ O
replace -X- _ O
URLs -X- _ O
and -X- _ O
user -X- _ O
mentions -X- _ O
with -X- _ O
< -X- _ O
URL -X- _ O
> -X- _ O
and -X- _ O
< -X- _ O
USER -X- _ O
> -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
clean -X- _ O
the -X- _ O
data -X- _ O
by -X- _ O
removing -X- _ O
HTML -X- _ O
tags -X- _ O
, -X- _ O
elongation -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
hash -X- _ O
signs -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
we -X- _ O
reduce -X- _ O
repetitive -X- _ O
characters -X- _ O
, -X- _ O
emojis -X- _ O
, -X- _ O
and -X- _ O
emoticons -X- _ O
to -X- _ O
one -X- _ O
. -X- _ O
To -X- _ O
create -X- _ O
our -X- _ O
language -X- _ O
model -X- _ O
vocabulary -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
Sentence -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
Piece -X- _ I-HyperparameterValue
( -X- _ O
Kudo -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
encode -X- _ O
text -X- _ O
as -X- _ O
WordPiece -X- _ O
tokens -X- _ O
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
with -X- _ O
110 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
Word -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
Pieces -X- _ I-HyperparameterName
. -X- _ O
To -X- _ O
allow -X- _ O
for -X- _ O
further -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
( -X- _ O
and/or -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
) -X- _ O
on -X- _ O
additional -X- _ O
languages -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
our -X- _ O
vocabulary -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
70 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
MSA -X- _ B-HyperparameterName
sentences -X- _ I-HyperparameterName
, -X- _ O
200 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
Arabic -X- _ B-HyperparameterName
twitter -X- _ I-HyperparameterName
data -X- _ I-HyperparameterName
, -X- _ O
15 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
sentences -X- _ B-HyperparameterName
from -X- _ I-HyperparameterName
Wikipedia -X- _ I-HyperparameterName
English -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
5 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
sentences -X- _ B-HyperparameterName
from -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
Wikipedia -X- _ I-HyperparameterName
of -X- _ O
10 -X- _ O
other -X- _ O
languages -X- _ O
( -X- _ O
Bulgarian -X- _ O
, -X- _ O
French -X- _ O
, -X- _ O
German -X- _ O
, -X- _ O
Greek -X- _ O
, -X- _ O
Italian -X- _ O
, -X- _ O
Portuguese -X- _ O
, -X- _ O
Russian -X- _ O
, -X- _ O
Spanish -X- _ O
, -X- _ O
Turkish -X- _ O
, -X- _ O
Czech -X- _ O
) -X- _ O
. -X- _ O
5 -X- _ O
In -X- _ O
§ -X- _ O
3.1.2 -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
parallel -X- _ O
data -X- _ O
from -X- _ O
four -X- _ O
of -X- _ O
these -X- _ O
languages -X- _ O
on -X- _ O
which -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
our -X- _ O
models -X- _ O
for -X- _ O
X→Arabic -X- _ O
MT -X- _ O
. -X- _ O
Our -X- _ O
respective -X- _ O
results -X- _ O
( -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
4.2 -X- _ O
) -X- _ O
demonstrate -X- _ O
the -X- _ O
utility -X- _ O
of -X- _ O
including -X- _ O
foreign -X- _ O
vocabulary -X- _ O
in -X- _ O
our -X- _ O
models -X- _ O
. -X- _ O
Model -X- _ O
Architecture -X- _ O
. -X- _ O
We -X- _ O
leverage -X- _ O
our -X- _ O
unlabeled -X- _ O
MSA -X- _ B-DatasetName
and -X- _ O
Twitter -X- _ B-DatasetName
data -X- _ O
described -X- _ O
in -X- _ O
§ -X- _ O
2.1 -X- _ O
to -X- _ O
pretrain -X- _ O
three -X- _ O
models -X- _ O
: -X- _ O
AraT5 -X- _ B-MethodName
MSA -X- _ I-MethodName
on -X- _ O
MSA -X- _ B-DatasetName
data -X- _ O
, -X- _ O
AraT5 -X- _ B-MethodName
TW -X- _ I-MethodName
on -X- _ O
twitter -X- _ B-DatasetName
data -X- _ O
, -X- _ O
and -X- _ O
AraT5 -X- _ B-MethodName
on -X- _ O
both -X- _ O
MSA -X- _ B-DatasetName
and -X- _ O
twitter -X- _ B-DatasetName
data -X- _ O
using -X- _ O
the -X- _ O
T5 -X- _ B-MethodName
Base -X- _ O
encoderdecoder -X- _ O
architecture -X- _ O
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Each -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
components -X- _ O
is -X- _ O
similar -X- _ O
in -X- _ O
size -X- _ O
and -X- _ O
configuration -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
Base -X- _ I-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
12 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
each -X- _ O
with -X- _ O
12 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
768 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
. -X- _ O
In -X- _ O
total -X- _ O
, -X- _ O
this -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
model -X- _ O
with -X- _ O
∼ -X- _ O
220 -X- _ O
million -X- _ O
parameters -X- _ O
. -X- _ O
6 -X- _ O
Objective -X- _ O
. -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
T5 -X- _ B-MethodName
Base -X- _ I-MethodName
using -X- _ O
a -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
( -X- _ O
denoising -X- _ O
) -X- _ O
objective -X- _ O
. -X- _ O
The -X- _ O
main -X- _ O
idea -X- _ O
is -X- _ O
to -X- _ O
feed -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
masked -X- _ O
( -X- _ O
corrupted -X- _ O
) -X- _ O
versions -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
sentence -X- _ O
, -X- _ O
and -X- _ O
train -X- _ O
it -X- _ O
to -X- _ O
reconstruct -X- _ O
the -X- _ O
original -X- _ O
sequence -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
BERT -X- _ B-MethodName
's -X- _ O
objective -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
denoising -X- _ O
objective -X- _ O
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
works -X- _ O
by -X- _ O
randomly -X- _ O
sampling -X- _ O
and -X- _ O
dropping -X- _ O
out -X- _ O
15 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
. -X- _ O
All -X- _ O
consecutive -X- _ O
spans -X- _ O
of -X- _ O
dropped -X- _ O
- -X- _ O
out -X- _ O
tokens -X- _ O
are -X- _ O
then -X- _ O
replaced -X- _ O
by -X- _ O
a -X- _ O
single -X- _ O
sentinel -X- _ O
token -X- _ O
. -X- _ O
Pre -X- _ O
- -X- _ O
Training -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
three -X- _ O
of -X- _ O
our -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.01 -X- _ B-HyperparameterValue
, -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
128 -X- _ B-HyperparameterValue
sequences -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
, -X- _ O
except -X- _ O
for -X- _ O
AraT5 -X- _ B-MethodName
TW -X- _ I-MethodName
where -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
is -X- _ O
128 -X- _ B-HyperparameterValue
. -X- _ O
7 -X- _ O
We -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
each -X- _ O
model -X- _ O
for -X- _ O
1 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
. -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
of -X- _ O
each -X- _ O
model -X- _ O
took -X- _ O
∼ -X- _ O
80 -X- _ O
days -X- _ O
on -X- _ O
one -X- _ O
Google -X- _ O
Cloud -X- _ O
TPU -X- _ B-HyperparameterName
with -X- _ O
8 -X- _ O
cores -X- _ O
( -X- _ O
v3.8 -X- _ B-HyperparameterValue
) -X- _ O
from -X- _ O
TensorFlow -X- _ O
Research -X- _ O
Cloud -X- _ O
( -X- _ O
TFRC -X- _ O
) -X- _ O
. -X- _ O
8 -X- _ O
We -X- _ O
now -X- _ O
introduce -X- _ O
our -X- _ O
language -X- _ B-TaskName
generation -X- _ I-TaskName
and -X- _ O
understating -X- _ B-TaskName
benchmarks -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
evaluate -X- _ O
our -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
our -X- _ O
new -X- _ O
benchmark -X- _ O
for -X- _ O
Arabic -X- _ B-TaskName
language -X- _ I-TaskName
generation -X- _ I-TaskName
evaluation -X- _ O
ARGEN -X- _ B-DatasetName
. -X- _ O
It -X- _ O
includes -X- _ O
19 -X- _ B-HyperparameterValue
different -X- _ O
datasets -X- _ B-HyperparameterName
with -X- _ O
59 -X- _ B-HyperparameterValue
test -X- _ B-HyperparameterName
splits -X- _ I-HyperparameterName
and -X- _ O
covers -X- _ O
seven -X- _ B-HyperparameterValue
tasks -X- _ B-HyperparameterName
: -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
( -X- _ O
MT -X- _ B-TaskName
) -X- _ O
, -X- _ O
codeswitched -X- _ B-TaskName
translation -X- _ I-TaskName
( -X- _ O
CST -X- _ B-TaskName
) -X- _ O
, -X- _ O
text -X- _ B-TaskName
summarization -X- _ I-TaskName
( -X- _ O
TS -X- _ B-TaskName
) -X- _ O
, -X- _ O
news -X- _ B-TaskName
title -X- _ I-TaskName
generation -X- _ I-TaskName
( -X- _ O
NGT -X- _ B-TaskName
) -X- _ O
, -X- _ O
question -X- _ B-TaskName
generation -X- _ I-TaskName
( -X- _ O
QG -X- _ B-TaskName
) -X- _ O
, -X- _ O
transliteration -X- _ B-TaskName
( -X- _ O
TR -X- _ B-TaskName
) -X- _ O
, -X- _ O
and -X- _ O
paraphrasing -X- _ B-TaskName
( -X- _ O
PPH -X- _ B-TaskName
) -X- _ O
. -X- _ O
As -X- _ O
such -X- _ O
, -X- _ O
ARGEN -X- _ B-DatasetName
has -X- _ O
wide -X- _ O
- -X- _ O
coverage -X- _ O
both -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
tasks -X- _ I-HyperparameterName
and -X- _ O
datasets -X- _ B-HyperparameterName
. -X- _ O

AraNews -X- _ B-DatasetName
( -X- _ O
Nagoudi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
El -X- _ B-DatasetName
- -X- _ I-DatasetName
Khair -X- _ I-DatasetName
El -X- _ I-DatasetName
- -X- _ I-DatasetName
Khair -X- _ I-DatasetName
( -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
Gigaword -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
OSCAR -X- _ O
( -X- _ O
Suárez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
OSIAN -X- _ B-DatasetName
( -X- _ O
Zeroual -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
Wikipedia -X- _ B-DatasetName
Arabic -X- _ I-DatasetName
, -X- _ O
and -X- _ O
Hindawi -X- _ B-DatasetName
Books -X- _ I-DatasetName
. -X- _ O
3 -X- _ O
Twitter -X- _ B-DatasetName
Data -X- _ I-DatasetName
. -X- _ O
We -X- _ O
randomly -X- _ O
sample -X- _ O
1.5B -X- _ B-HyperparameterValue
Arabic -X- _ O
tweets -X- _ B-HyperparameterName
( -X- _ O
178 -X- _ B-HyperparameterValue
GB -X- _ I-HyperparameterValue
) -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
in -X- _ O
- -X- _ O
house -X- _ O
dataset -X- _ O
of -X- _ O
∼ -X- _ O
10B -X- _ B-HyperparameterValue
tweets -X- _ B-HyperparameterName
. -X- _ O
We -X- _ O
use -X- _ O
string -X- _ O
matching -X- _ O
to -X- _ O
only -X- _ O
include -X- _ O
tweets -X- _ O
with -X- _ O
at -X- _ O
least -X- _ O
3 -X- _ B-HyperparameterValue
Arabic -X- _ B-HyperparameterName
words -X- _ I-HyperparameterName
, -X- _ O
regardless -X- _ O
whether -X- _ O
the -X- _ O
tweet -X- _ O
has -X- _ O
non -X- _ O
- -X- _ O
Arabic -X- _ O
string -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O

( -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
introduce -X- _ O
three -X- _ O
powerful -X- _ O
variants -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
transformer -X- _ O
( -X- _ O
T5 -X- _ B-MethodName
) -X- _ O
model -X- _ O
dedicated -X- _ O
to -X- _ O
Modern -X- _ O
Standard -X- _ O
Arabic -X- _ O
( -X- _ O
MSA -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
Arabic -X- _ O
dialects -X- _ O
. -X- _ O
We -X- _ O
include -X- _ O
in -X- _ O
our -X- _ O
vocabulary -X- _ O
11 -X- _ B-HyperparameterValue
languages -X- _ B-HyperparameterName
other -X- _ I-HyperparameterName
than -X- _ I-HyperparameterName
Arabic -X- _ I-HyperparameterName
( -X- _ O
e.g. -X- _ O
, -X- _ O
English -X- _ O
, -X- _ O
French -X- _ O
, -X- _ O
German -X- _ O
, -X- _ O
Russian -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
also -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
evaluate -X- _ O
our -X- _ O
models -X- _ O
under -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
conditions -X- _ O
involving -X- _ O
these -X- _ O
languages -X- _ O
. -X- _ O

The -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
paper -X- _ O
is -X- _ O
organized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
Section -X- _ O
2 -X- _ O
describes -X- _ O
our -X- _ O
Arabic -X- _ O
pre -X- _ O
- -X- _ O
tained -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
ARGEN -X- _ B-DatasetName
, -X- _ O
our -X- _ O
new -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
generation -X- _ I-TaskName
benchmark -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
our -X- _ O
models -X- _ O
on -X- _ O
ARGEN -X- _ B-DatasetName
in -X- _ O
Section -X- _ O
4 -X- _ O
. -X- _ O
Section -X- _ O
5 -X- _ O
is -X- _ O
an -X- _ O
analysis -X- _ O
and -X- _ O
discussion -X- _ O
of -X- _ O
our -X- _ O
results -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
6 -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
related -X- _ O
work -X- _ O
. -X- _ O
We -X- _ O
conclude -X- _ O
in -X- _ O
Section -X- _ O
7 -X- _ O
. -X- _ O
We -X- _ O
now -X- _ O
introduce -X- _ O
our -X- _ O
new -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
70 -X- _ B-HyperparameterValue
GB -X- _ I-HyperparameterValue
of -X- _ O
MSA -X- _ B-DatasetName
text -X- _ I-DatasetName
( -X- _ O
7.1B -X- _ B-HyperparameterValue
tokens -X- _ B-HyperparameterName
) -X- _ O
from -X- _ O
the -X- _ O
following -X- _ O
sources -X- _ O
: -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
unified -X- _ O
benchmark -X- _ O
for -X- _ O
ARabic -X- _ B-TaskName
natural -X- _ I-TaskName
language -X- _ I-TaskName
GEeneration -X- _ I-TaskName
( -X- _ O
ARGEN -X- _ B-DatasetName
) -X- _ O
composed -X- _ O
of -X- _ O
seven -X- _ O
tasks -X- _ O
: -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
, -X- _ O
code -X- _ B-TaskName
- -X- _ I-TaskName
switched -X- _ I-TaskName
text -X- _ I-TaskName
translation -X- _ I-TaskName
, -X- _ O
summarization -X- _ B-TaskName
, -X- _ O
news -X- _ B-TaskName
title -X- _ I-TaskName
generation -X- _ I-TaskName
, -X- _ O
question -X- _ B-TaskName
generation -X- _ I-TaskName
, -X- _ O
paraphrasing -X- _ B-TaskName
, -X- _ O
and -X- _ O
transliteration -X- _ B-TaskName
. -X- _ O
ARGEN -X- _ B-DatasetName
is -X- _ O
collected -X- _ O
from -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
19 -X- _ O
datasets -X- _ O
, -X- _ O
including -X- _ O
9 -X- _ O
new -X- _ O
datasets -X- _ O
proposed -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
To -X- _ O
show -X- _ O
the -X- _ O
utility -X- _ O
of -X- _ O
our -X- _ O
new -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
them -X- _ O
on -X- _ O
ARGEN -X- _ B-DatasetName
under -X- _ O
both -X- _ O
full -X- _ O
and -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
conditions -X- _ O
. -X- _ O
Our -X- _ O
models -X- _ O
set -X- _ O
new -X- _ O
SOTA -X- _ O
on -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
datasets -X- _ O
in -X- _ O
all -X- _ O
seven -X- _ O
tasks -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
Although -X- _ O
the -X- _ O
main -X- _ O
focus -X- _ O
of -X- _ O
our -X- _ O
work -X- _ O
is -X- _ O
language -X- _ B-TaskName
generation -X- _ I-TaskName
, -X- _ O
we -X- _ O
also -X- _ O
show -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
on -X- _ O
Arabic -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
by -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
our -X- _ O
new -X- _ O
models -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
, -X- _ O
recently -X- _ O
proposed -X- _ O
Arabic -X- _ O
language -X- _ O
understanding -X- _ O
benchmark -X- _ O
. -X- _ O
Again -X- _ O
, -X- _ O
our -X- _ O
models -X- _ O
establish -X- _ O
new -X- _ O
SOTA -X- _ O
on -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
language -X- _ B-TaskName
understanding -X- _ I-TaskName
tasks -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
investigate -X- _ O
that -X- _ O
memory -X- _ O
imitation -X- _ O
improves -X- _ O
the -X- _ O
learning -X- _ O
of -X- _ O
model -X- _ O
initialization -X- _ O
via -X- _ O
another -X- _ O
criterion -X- _ O
I(θ -X- _ O
; -X- _ O
[ -X- _ O
D -X- _ O
q -X- _ O
, -X- _ O
M]|D -X- _ O
q -X- _ O
) -X- _ O
> -X- _ O
0 -X- _ O
following -X- _ O
Yao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
criterion -X- _ O
guarantees -X- _ O
that -X- _ O
the -X- _ O
additional -X- _ O
memory -X- _ O
knowledge -X- _ O
contributes -X- _ O
to -X- _ O
updating -X- _ O
the -X- _ O
initialization -X- _ O
in -X- _ O
the -X- _ O
outer -X- _ O
loop -X- _ O
. -X- _ O
SinceTransfer -X- _ O
learning -X- _ O
with -X- _ O
a -X- _ O
unified -X- _ O
Transformer -X- _ O
framework -X- _ O
( -X- _ O
T5 -X- _ B-MethodName
) -X- _ O
that -X- _ O
converts -X- _ O
all -X- _ O
language -X- _ O
problems -X- _ O
into -X- _ O
a -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
format -X- _ O
was -X- _ O
recently -X- _ O
proposed -X- _ O
as -X- _ O
a -X- _ O
simple -X- _ O
and -X- _ O
effective -X- _ O
transfer -X- _ O
learning -X- _ O
approach -X- _ O
. -X- _ O
Although -X- _ O
a -X- _ O
multilingual -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
T5 -X- _ B-MethodName
model -X- _ O
( -X- _ O
mT5 -X- _ B-MethodName
) -X- _ O
was -X- _ O
also -X- _ O
introduced -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
clear -X- _ O
how -X- _ O
well -X- _ O
it -X- _ O
can -X- _ O
fare -X- _ O
on -X- _ O
non -X- _ O
- -X- _ O
English -X- _ O
tasks -X- _ O
involving -X- _ O
diverse -X- _ O
data -X- _ O
. -X- _ O
To -X- _ O
investigate -X- _ O
this -X- _ O
question -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
mT5 -X- _ B-MethodName
on -X- _ O
a -X- _ O
language -X- _ O
with -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
dialects -X- _ O
- -X- _ O
Arabic -X- _ O
. -X- _ O
For -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
novel -X- _ O
benchmark -X- _ O
for -X- _ O
ARabic -X- _ B-TaskName
language -X- _ I-TaskName
GENeration -X- _ I-TaskName
( -X- _ O
ARGEN -X- _ B-DatasetName
) -X- _ O
, -X- _ O
covering -X- _ O
seven -X- _ O
important -X- _ O
tasks -X- _ O
. -X- _ O
For -X- _ O
model -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
three -X- _ O
powerful -X- _ O
Arabic -X- _ O
T5 -X- _ O
- -X- _ O
style -X- _ O
models -X- _ O
and -X- _ O
evaluate -X- _ O
them -X- _ O
on -X- _ O
ARGEN -X- _ B-DatasetName
. -X- _ O
Although -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
∼ -X- _ O
49 -X- _ O
% -X- _ O
less -X- _ O
data -X- _ O
, -X- _ O
our -X- _ O
new -X- _ O
models -X- _ O
perform -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
mT5 -X- _ B-MethodName
on -X- _ O
all -X- _ O
ARGEN -X- _ B-DatasetName
tasks -X- _ O
( -X- _ O
in -X- _ O
52 -X- _ O
out -X- _ O
of -X- _ O
59 -X- _ O
test -X- _ O
sets -X- _ O
) -X- _ O
and -X- _ O
set -X- _ O
several -X- _ O
new -X- _ O
SOTAs -X- _ O
. -X- _ O
Our -X- _ O
models -X- _ O
also -X- _ O
establish -X- _ O
new -X- _ O
SOTA -X- _ O
on -X- _ O
the -X- _ O
recently -X- _ O
- -X- _ O
proposed -X- _ O
, -X- _ O
large -X- _ O
Arabic -X- _ B-DatasetName
language -X- _ I-DatasetName
understanding -X- _ I-DatasetName
evaluation -X- _ I-DatasetName
benchmark -X- _ O
ARLUE -X- _ B-DatasetName
( -X- _ O
Abdul -X- _ O
- -X- _ O
Mageed -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
models -X- _ O
are -X- _ O
publicly -X- _ O
available -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
link -X- _ O
to -X- _ O
individual -X- _ O
ARGEN -X- _ B-TaskName
datasets -X- _ O
through -X- _ O
our -X- _ O
public -X- _ O
repository -X- _ O
. -X- _ O
1 -X- _ O

Our -X- _ O
main -X- _ O
contributions -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
offer -X- _ O
the -X- _ O
first -X- _ O
comparison -X- _ O
of -X- _ O
the -X- _ O
mT5 -X- _ B-MethodName
model -X- _ O
to -X- _ O
similar -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
models -X- _ O
dedicated -X- _ O
to -X- _ O
Arabic -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
Arabic -X- _ O
as -X- _ O
our -X- _ O
context -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
large -X- _ O
set -X- _ O
of -X- _ O
diverse -X- _ O
varieties -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
its -X- _ O
wide -X- _ O
use -X- _ O
on -X- _ O
social -X- _ O
media -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
aims -X- _ O
at -X- _ O
uncovering -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
mT5 -X- _ B-MethodName
can -X- _ O
serve -X- _ O
Arabic -X- _ O
's -X- _ O
different -X- _ O
varieties -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
also -X- _ O
meets -X- _ O
an -X- _ O
existing -X- _ O
need -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Transformer -X- _ O
- -X- _ O
based -X- _ O
sequenceto -X- _ O
- -X- _ O
sequence -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
while -X- _ O
several -X- _ O
BERT -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
for -X- _ O
Arabic -X- _ O
( -X- _ O
Antoun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Abdul -X- _ O
- -X- _ O
Mageed -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021;Inoue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
no -X- _ O
such -X- _ O
attempts -X- _ O
have -X- _ O
been -X- _ O
made -X- _ O
to -X- _ O
create -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
models -X- _ O
that -X- _ O
we -X- _ O
know -X- _ O
of -X- _ O
. -X- _ O
Another -X- _ O
motivation -X- _ O
for -X- _ O
our -X- _ O
work -X- _ O
is -X- _ O
absence -X- _ O
of -X- _ O
an -X- _ O
evaluation -X- _ O
benchmark -X- _ O
for -X- _ O
Arabic -X- _ B-TaskName
language -X- _ I-TaskName
generation -X- _ I-TaskName
tasks -X- _ O
. -X- _ O
Apart -X- _ O
from -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
where -X- _ O
researchers -X- _ O
are -X- _ O
starting -X- _ O
to -X- _ O
propose -X- _ O
benchmarks -X- _ O
such -X- _ O
as -X- _ O
AraBench -X- _ B-DatasetName
( -X- _ O
Sajjad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
benchmarks -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
methodically -X- _ O
measure -X- _ O
Arabic -X- _ B-TaskName
natural -X- _ I-TaskName
language -X- _ I-TaskName
generation -X- _ I-TaskName
performance -X- _ O
. -X- _ O

Due -X- _ O
to -X- _ O
their -X- _ O
remarkable -X- _ O
ability -X- _ O
to -X- _ O
transfer -X- _ O
knowledge -X- _ O
from -X- _ O
unlabeled -X- _ O
data -X- _ O
to -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Transformer -X- _ O
- -X- _ O
based -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
emerged -X- _ O
as -X- _ O
important -X- _ O
components -X- _ O
of -X- _ O
modern -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
systems -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
the -X- _ O
unified -X- _ O
framework -X- _ O
that -X- _ O
converts -X- _ O
all -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
language -X- _ O
problems -X- _ O
into -X- _ O
a -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
format -X- _ O
presented -X- _ O
through -X- _ O
the -X- _ O
T5 -X- _ B-MethodName
model -X- _ O
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
attractive -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
its -X- _ O
simplicity -X- _ O
, -X- _ O
this -X- _ O
approach -X- _ O
is -X- _ O
effective -X- _ O
since -X- _ O
it -X- _ O
allows -X- _ O
knowledge -X- _ O
transfer -X- _ O
from -X- _ O
high -X- _ O
- -X- _ O
resource -X- _ O
to -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
tasks -X- _ O
without -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
changing -X- _ O
model -X- _ O
architecture -X- _ O
. -X- _ O
Unlike -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
encoders -X- _ O
only -X- _ O
, -X- _ O
the -X- _ O
T5 -X- _ B-MethodName
model -X- _ O
is -X- _ O
an -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
that -X- _ O
can -X- _ O
naturally -X- _ O
be -X- _ O
employed -X- _ O
for -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
generation -X- _ I-TaskName
. -X- _ O
Although -X- _ O
the -X- _ O
T5 -X- _ B-MethodName
model -X- _ O
, -X- _ O
originally -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
for -X- _ O
English -X- _ O
, -X- _ O
was -X- _ O
recently -X- _ O
extended -X- _ O
to -X- _ O
the -X- _ O
multilingual -X- _ O
setting -X- _ O
as -X- _ O
mT5 -X- _ B-MethodName
( -X- _ O
Xue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
clear -X- _ O
how -X- _ O
suited -X- _ O
it -X- _ O
is -X- _ O
to -X- _ O
individual -X- _ O
languages -X- _ O
( -X- _ O
and -X- _ O
varieties -X- _ O
of -X- _ O
these -X- _ O
languages -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
systematic -X- _ O
issues -X- _ O
have -X- _ O
been -X- _ O
discovered -X- _ O
in -X- _ O
multilingual -X- _ O
corpora -X- _ O
on -X- _ O
which -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
trained -X- _ O
( -X- _ O
Kreutzer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
absence -X- _ O
of -X- _ O
comparisons -X- _ O
with -X- _ O
monolingual -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
that -X- _ O
serve -X- _ O
different -X- _ O
non -X- _ O
- -X- _ O
English -X- _ O
contexts -X- _ O
, -X- _ O
it -X- _ O
remains -X- _ O
unknown -X- _ O
how -X- _ O
multilingual -X- _ O
models -X- _ O
really -X- _ O
fare -X- _ O
against -X- _ O
languagespecific -X- _ O
models -X- _ O
. -X- _ O

where -X- _ O
the -X- _ O
last -X- _ O
inequality -X- _ O
holds -X- _ O
due -X- _ O
toŶ -X- _ O
q -X- _ O
is -X- _ O
dependent -X- _ O
on -X- _ O
M. -X- _ O

Then -X- _ O
the -X- _ O
equation -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
will -X- _ O
become -X- _ O
to -X- _ O

since -X- _ O
p(Ŷ -X- _ O
q -X- _ O
, -X- _ O
Z -X- _ O
) -X- _ O
does -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
the -X- _ O
variable -X- _ O
M. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
just -X- _ O
write -X- _ O
EŶ -X- _ O
q -X- _ O
, -X- _ O
Z -X- _ O
, -X- _ O
M -X- _ O
as -X- _ O
E -X- _ O
for -X- _ O
short -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
trivially -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O

For -X- _ O
short -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
notation -X- _ O
Z -X- _ O
= -X- _ O
( -X- _ O
X -X- _ O
q -X- _ O
, -X- _ O
X -X- _ O
s -X- _ O
, -X- _ O
Y -X- _ O
s -X- _ O
, -X- _ O
θ -X- _ O
) -X- _ O
to -X- _ O
denote -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
variables -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
can -X- _ O
rewrite -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
as -X- _ O

Human -X- _ B-MetricName
Evaluation -X- _ I-MetricName
We -X- _ O
conduct -X- _ O
human -X- _ O
evaluation -X- _ O
following -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
considering -X- _ O
two -X- _ O
aspects -X- _ O
Quality -X- _ O
and -X- _ O
Consistency -X- _ O
where -X- _ O
five -X- _ O
welleducated -X- _ O
volunteers -X- _ O
annotate -X- _ O
250 -X- _ B-HyperparameterValue
generated -X- _ B-HyperparameterName
responses -X- _ I-HyperparameterName
for -X- _ O
each -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
annotators -X- _ O
score -X- _ O
each -X- _ O
response -X- _ O
from -X- _ O
two -X- _ O
aspects -X- _ O
: -X- _ O
Quality -X- _ B-MetricName
and -X- _ O
Consistency -X- _ B-MetricName
in -X- _ O
a -X- _ O
3 -X- _ O
- -X- _ O
point -X- _ O
scale -X- _ O
: -X- _ O
2 -X- _ B-MetricValue
for -X- _ O
good -X- _ O
, -X- _ O
1 -X- _ B-MetricValue
for -X- _ O
fair -X- _ O
, -X- _ O
and -X- _ O
0 -X- _ B-MetricValue
for -X- _ O
bad -X- _ O
. -X- _ O
Quality -X- _ B-MetricName
measures -X- _ O
coherence -X- _ O
, -X- _ O
fluency -X- _ O
, -X- _ O
and -X- _ O
informativeness -X- _ O
. -X- _ O
Consistency -X- _ B-MetricName
measures -X- _ O
the -X- _ O
task -X- _ O
consistency -X- _ O
between -X- _ O
the -X- _ O
generated -X- _ O
responses -X- _ O
and -X- _ O
the -X- _ O
person -X- _ O
's -X- _ O
persona -X- _ O
description -X- _ O
. -X- _ O
Experimental -X- _ O
Setup -X- _ O
. -X- _ O
We -X- _ O
utilize -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
encoder -X- _ O
. -X- _ O
We -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
off -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
shelf -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
task -X- _ O
following -X- _ O
( -X- _ O
Dopierre -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
as -X- _ O
it -X- _ O
greatly -X- _ O
improves -X- _ O
embeddings -X- _ O
' -X- _ O
quality -X- _ O
. -X- _ O
The -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
then -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
initialization -X- _ O
for -X- _ O
all -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Adam -X- _ B-HyperparameterValue
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
optimizer -X- _ B-HyperparameterName
for -X- _ O
both -X- _ O
inner -X- _ O
and -X- _ O
outer -X- _ O
loop -X- _ O
update -X- _ O
with -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
2e -X- _ B-HyperparameterValue
−5 -X- _ I-HyperparameterValue
and -X- _ O
1e -X- _ B-HyperparameterValue
−5 -X- _ I-HyperparameterValue
respectively -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
set -X- _ O
β -X- _ B-HyperparameterName
= -X- _ O
0.2 -X- _ B-HyperparameterValue
in -X- _ O
Eqn -X- _ O
. -X- _ O
5 -X- _ O
, -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
neighbors -X- _ I-HyperparameterName
N -X- _ B-HyperparameterName
= -X- _ O
20 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
local -X- _ I-HyperparameterName
adaptation -X- _ I-HyperparameterName
steps -X- _ I-HyperparameterName
L -X- _ B-HyperparameterName
= -X- _ O
5.To -X- _ B-HyperparameterValue
measure -X- _ O
whether -X- _ O
MemIML -X- _ B-MethodName
improves -X- _ O
the -X- _ O
learned -X- _ O
model -X- _ O
initialization -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
an -X- _ O
experiment -X- _ O
that -X- _ O
does -X- _ O
not -X- _ O
incorporate -X- _ O
the -X- _ O
memory -X- _ O
module -X- _ O
during -X- _ O
meta -X- _ O
- -X- _ O
testing -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
β -X- _ B-HyperparameterName
= -X- _ O
1 -X- _ B-HyperparameterValue
in -X- _ O
Eq -X- _ O
. -X- _ O
5 -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
sentiment -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ O
. -X- _ O
Research -X- _ O
on -X- _ O
this -X- _ O
paper -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
Hong -X- _ O
Kong -X- _ O
Research -X- _ O
Grants -X- _ O
Council -X- _ O
( -X- _ O
Grant -X- _ O
No -X- _ O
. -X- _ O
16204920 -X- _ O
) -X- _ O
and -X- _ O
National -X- _ O
Natural -X- _ O
Science -X- _ O
Foundation -X- _ O
of -X- _ O
China -X- _ O
( -X- _ O
Grant -X- _ O
No -X- _ O
. -X- _ O
62106275).Proof -X- _ O
of -X- _ O
inequality -X- _ O
in -X- _ O
Eqn -X- _ O
. -X- _ O
6 -X- _ O
. -X- _ O
We -X- _ O
check -X- _ O
the -X- _ O
validity -X- _ O
of -X- _ O
memory -X- _ O
imitation -X- _ O
by -X- _ O
examining -X- _ O
whether -X- _ O
the -X- _ O
criterion -X- _ O
in -X- _ O
Section -X- _ O
4.4 -X- _ O
is -X- _ O
met -X- _ O
. -X- _ O
We -X- _ O
check -X- _ O
the -X- _ O
increase -X- _ O
of -X- _ O
mutual -X- _ B-MetricName
information -X- _ I-MetricName
between -X- _ O
predictions -X- _ O
of -X- _ O
query -X- _ O
sets -X- _ O
with -X- _ O
the -X- _ O
provided -X- _ O
support -X- _ O
- -X- _ O
set -X- _ O
information -X- _ O
after -X- _ O
augmented -X- _ O
with -X- _ O
the -X- _ O
memory -X- _ O
information -X- _ O
M. -X- _ O

Proof -X- _ O
. -X- _ O
Experimental -X- _ O
Setup -X- _ O
. -X- _ O
We -X- _ O
implement -X- _ O
our -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
transformer -X- _ O
( -X- _ O
Dehghani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
with -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Glove -X- _ B-HyperparameterValue
embedding -X- _ B-HyperparameterName
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
following -X- _ O
( -X- _ O
Madotto -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
hidden -X- _ B-HyperparameterName
dimensions -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
LSTM -X- _ I-HyperparameterName
unit -X- _ I-HyperparameterName
are -X- _ O
set -X- _ O
to -X- _ O
1024 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
neighbors -X- _ I-HyperparameterName
N -X- _ B-HyperparameterName
= -X- _ O
10 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
local -X- _ I-HyperparameterName
adaptation -X- _ I-HyperparameterName
steps -X- _ I-HyperparameterName
L -X- _ B-HyperparameterName
= -X- _ O
20 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
follow -X- _ O
all -X- _ O
other -X- _ O
hyperparameter -X- _ O
settings -X- _ O
in -X- _ O
Madotto -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
): -X- _ O
we -X- _ O
use -X- _ O
SGD -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
inner -X- _ O
loop -X- _ O
training -X- _ O
and -X- _ O
Adam -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
outer -X- _ O
loop -X- _ O
update -X- _ O
with -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
0.01 -X- _ B-HyperparameterValue
and -X- _ O
0.0003 -X- _ B-HyperparameterValue
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
as -X- _ O
16 -X- _ B-HyperparameterValue
and -X- _ O
use -X- _ O
beam -X- _ O
search -X- _ O
with -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
5 -X- _ B-HyperparameterValue
. -X- _ O

all -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
training -X- _ O
tasks -X- _ O
satisfy -X- _ O
this -X- _ O
criterion -X- _ O
, -X- _ O
the -X- _ O
generalization -X- _ O
ability -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
initialization -X- _ O
improves -X- _ O
. -X- _ O

Removing -X- _ O
the -X- _ O
value -X- _ O
predictor -X- _ O
means -X- _ O
directly -X- _ O
using -X- _ O
the -X- _ O
memory -X- _ O
output -X- _ O
without -X- _ O
a -X- _ O
learnable -X- _ O
network -X- _ O
. -X- _ O
Its -X- _ O
results -X- _ O
are -X- _ O
not -X- _ O
too -X- _ O
bad -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
the -X- _ O
memory -X- _ O
module -X- _ O
helps -X- _ O
to -X- _ O
mitigate -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
problem -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
usage -X- _ O
simply -X- _ O
aggre -X- _ O
- -X- _ O
gates -X- _ O
the -X- _ O
support -X- _ O
set -X- _ O
information -X- _ O
into -X- _ O
the -X- _ O
query -X- _ O
set -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
as -X- _ O
precise -X- _ O
as -X- _ O
learning -X- _ O
the -X- _ O
information -X- _ O
required -X- _ O
by -X- _ O
the -X- _ O
query -X- _ O
set -X- _ O
itself -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
still -X- _ O
inferior -X- _ O
to -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
Removing -X- _ O
Local -X- _ O
adaptation -X- _ O
means -X- _ O
we -X- _ O
only -X- _ O
use -X- _ O
the -X- _ O
global -X- _ O
value -X- _ O
predictor -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
memory -X- _ O
output -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
crucial -X- _ O
to -X- _ O
the -X- _ O
value -X- _ O
predictor -X- _ O
since -X- _ O
removing -X- _ O
it -X- _ O
from -X- _ O
the -X- _ O
value -X- _ O
predictor -X- _ O
results -X- _ O
in -X- _ O
an -X- _ O
even -X- _ O
worse -X- _ O
performance -X- _ O
than -X- _ O
removing -X- _ O
the -X- _ O
value -X- _ O
predictor -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
the -X- _ O
significant -X- _ O
drop -X- _ O
in -X- _ O
task -X- _ O
consistency -X- _ O
( -X- _ O
C -X- _ B-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
) -X- _ O
shows -X- _ O
that -X- _ O
local -X- _ O
adaptation -X- _ O
contributes -X- _ O
a -X- _ O
lot -X- _ O
to -X- _ O
making -X- _ O
the -X- _ O
model -X- _ O
adaptive -X- _ O
to -X- _ O
specific -X- _ O
tasks -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
learns -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
each -X- _ O
query -X- _ O
- -X- _ O
set -X- _ O
sample -X- _ O
. -X- _ O
Memory -X- _ B-HyperparameterName
Size -X- _ I-HyperparameterName
. -X- _ O
In -X- _ O
Table -X- _ O
4 -X- _ O
and -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
the -X- _ O
variants -X- _ O
of -X- _ O
our -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
memory -X- _ O
module -X- _ O
of -X- _ O
different -X- _ O
sizes -X- _ O
. -X- _ O
We -X- _ O
control -X- _ O
the -X- _ O
memory -X- _ O
size -X- _ O
through -X- _ O
|M -X- _ O
| -X- _ O
= -X- _ O
store -X- _ O
ratio -X- _ O
× -X- _ O
|D -X- _ O
s -X- _ O
| -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
maintain -X- _ O
high -X- _ O
performance -X- _ O
even -X- _ O
with -X- _ O
only -X- _ O
a -X- _ O
20 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
memory -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
by -X- _ O
storing -X- _ O
diverse -X- _ O
and -X- _ O
representative -X- _ O
samples -X- _ O
of -X- _ O
support -X- _ O
sets -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
stored -X- _ O
samples -X- _ O
increases -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
performance -X- _ O
is -X- _ O
improved -X- _ O
since -X- _ O
it -X- _ O
provides -X- _ O
more -X- _ O
information -X- _ O
for -X- _ O
the -X- _ O
inference -X- _ O
of -X- _ O
query -X- _ O
samples -X- _ O
and -X- _ O
the -X- _ O
optimization -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
initialization -X- _ O
. -X- _ O
Storing -X- _ O
all -X- _ O
the -X- _ O
encountered -X- _ O
samples -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
with -X- _ O
store -X- _ O
ratio -X- _ O
100 -X- _ O
% -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
memory -X- _ O
instead -X- _ O
introduces -X- _ O
some -X- _ O
noise -X- _ O
that -X- _ O
damages -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
Number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
Neighbors -X- _ I-HyperparameterName
. -X- _ O
We -X- _ O
also -X- _ O
investigate -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
different -X- _ O
numbers -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
neighbors -X- _ I-HyperparameterName
for -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
and -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
In -X- _ O
both -X- _ O
datasets -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
performs -X- _ O
better -X- _ O
with -X- _ O
a -X- _ O
larger -X- _ O
number -X- _ O
of -X- _ O
neighbors -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
neighbors -X- _ B-HyperparameterName
is -X- _ I-HyperparameterName
too -X- _ I-HyperparameterName
large -X- _ I-HyperparameterName
, -X- _ O
the -X- _ O
model -X- _ O
retrieves -X- _ O
some -X- _ O
dissimilar -X- _ O
slots -X- _ O
from -X- _ O
the -X- _ O
memory -X- _ O
module -X- _ O
. -X- _ O
These -X- _ O
dissimilar -X- _ O
slots -X- _ O
bring -X- _ O
much -X- _ O
noise -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
the -X- _ O
predictions -X- _ O
of -X- _ O
query -X- _ O
samples -X- _ O
inaccurate -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
two -X- _ O
generated -X- _ O
cases -X- _ O
in -X- _ O
personalized -X- _ O
dialog -X- _ O
in -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
tackle -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
problem -X- _ O
of -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
for -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
and -X- _ O
generation -X- _ B-TaskName
applications -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
MemIML -X- _ B-MethodName
to -X- _ O
enhance -X- _ O
the -X- _ O
dependence -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
support -X- _ O
sets -X- _ O
for -X- _ O
task -X- _ O
adaptation -X- _ O
. -X- _ O
MemIML -X- _ B-MethodName
introduces -X- _ O
a -X- _ O
memory -X- _ O
module -X- _ O
storing -X- _ O
the -X- _ O
information -X- _ O
of -X- _ O
support -X- _ O
sets -X- _ O
, -X- _ O
and -X- _ O
propose -X- _ O
an -X- _ O
imitation -X- _ O
module -X- _ O
to -X- _ O
better -X- _ O
leverage -X- _ O
the -X- _ O
support -X- _ O
set -X- _ O
information -X- _ O
by -X- _ O
imitating -X- _ O
the -X- _ O
behaviors -X- _ O
of -X- _ O
the -X- _ O
memory -X- _ O
. -X- _ O
Both -X- _ O
empirical -X- _ O
and -X- _ O
theoretical -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
MemIML -X- _ B-MethodName
effectively -X- _ O
alleviates -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
problem -X- _ O
. -X- _ O
The -X- _ O
dialogues -X- _ O
may -X- _ O
lead -X- _ O
to -X- _ O
the -X- _ O
leakage -X- _ O
of -X- _ O
personal -X- _ O
privacy -X- _ O
information -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
the -X- _ O
data -X- _ O
source -X- _ O
we -X- _ O
use -X- _ O
is -X- _ O
from -X- _ O
a -X- _ O
published -X- _ O
dataset -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
involve -X- _ O
privacy -X- _ O
issues -X- _ O
for -X- _ O
the -X- _ O
data -X- _ O
collection -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
method -X- _ O
does -X- _ O
not -X- _ O
include -X- _ O
inference -X- _ O
or -X- _ O
judgments -X- _ O
about -X- _ O
individuals -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
generate -X- _ O
any -X- _ O
discriminatory -X- _ O
, -X- _ O
insulting -X- _ O
responses -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
validates -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
and -X- _ O
baseline -X- _ O
models -X- _ O
on -X- _ O
human -X- _ B-MetricName
evaluation -X- _ I-MetricName
which -X- _ O
involves -X- _ O
manual -X- _ O
labor -X- _ O
. -X- _ O
We -X- _ O
hire -X- _ O
five -X- _ O
annotators -X- _ O
to -X- _ O
score -X- _ O
750 -X- _ B-HyperparameterValue
generated -X- _ B-HyperparameterName
sentences -X- _ I-HyperparameterName
in -X- _ O
total -X- _ O
( -X- _ O
250 -X- _ B-HyperparameterValue
sentences -X- _ B-HyperparameterName
for -X- _ O
each -X- _ O
model -X- _ O
we -X- _ O
evaluate -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
hourly -X- _ O
pay -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
15 -X- _ O
US$ -X- _ O
per -X- _ O
person -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
higher -X- _ O
than -X- _ O
the -X- _ O
local -X- _ O
statutory -X- _ O
minimum -X- _ O
wage -X- _ O
. -X- _ O

Overall -X- _ O
Performance -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
measured -X- _ O
by -X- _ O
the -X- _ O
mean -X- _ O
accuracy -X- _ O
of -X- _ O
meta -X- _ O
- -X- _ O
testing -X- _ O
tasks -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
, -X- _ O
MemIML -X- _ B-MethodName
outperforms -X- _ O
all -X- _ O
competing -X- _ O
approaches -X- _ O
including -X- _ O
nonmeta -X- _ O
- -X- _ O
learning -X- _ O
, -X- _ O
metric -X- _ O
- -X- _ O
based -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
, -X- _ O
and -X- _ O
optimization -X- _ O
- -X- _ O
based -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
methods -X- _ O
. -X- _ O
Particularly -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
surpasses -X- _ O
the -X- _ O
current -X- _ O
solutions -X- _ O
to -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
problem -X- _ O
( -X- _ O
MR -X- _ B-MethodName
- -X- _ I-MethodName
MAML -X- _ I-MethodName
, -X- _ O
Meta -X- _ B-MethodName
- -X- _ I-MethodName
Aug -X- _ I-MethodName
, -X- _ O
MetaMix -X- _ B-MethodName
) -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
more -X- _ O
effective -X- _ O
compared -X- _ O
to -X- _ O
regularization -X- _ O
and -X- _ O
textual -X- _ O
augmentation -X- _ O
. -X- _ O
In -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
gaps -X- _ O
of -X- _ O
the -X- _ O
losses -X- _ O
on -X- _ O
query -X- _ O
sets -X- _ O
between -X- _ O
pre -X- _ O
- -X- _ O
update -X- _ O
θ -X- _ O
( -X- _ O
before -X- _ O
training -X- _ O
on -X- _ O
support -X- _ O
sets -X- _ O
) -X- _ O
In -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
, -X- _ O
MemIML -X- _ B-MethodName
has -X- _ O
large -X- _ O
gaps -X- _ O
between -X- _ O
θ -X- _ O
and -X- _ O
θ -X- _ O
i -X- _ O
, -X- _ O
implying -X- _ O
that -X- _ O
θ -X- _ O
i -X- _ O
better -X- _ O
leverages -X- _ O
support -X- _ O
sets -X- _ O
when -X- _ O
adapting -X- _ O
to -X- _ O
new -X- _ O
tasks -X- _ O
and -X- _ O
thus -X- _ O
alleviates -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
issue -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
ablation -X- _ O
studies -X- _ O
to -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
each -X- _ O
component -X- _ O
. -X- _ O
Removing -X- _ O
Similarity -X- _ O
- -X- _ O
Search -X- _ O
means -X- _ O
the -X- _ O
memory -X- _ O
reading -X- _ O
operation -X- _ O
randomly -X- _ O
outputs -X- _ O
memory -X- _ O
slots -X- _ O
instead -X- _ O
of -X- _ O
searching -X- _ O
for -X- _ O
similar -X- _ O
memory -X- _ O
slots -X- _ O
. -X- _ O
This -X- _ O
variant -X- _ O
underperforms -X- _ O
MemIML -X- _ B-MethodName
, -X- _ O
indicating -X- _ O
that -X- _ O
similar -X- _ O
samples -X- _ O
stored -X- _ O
in -X- _ O
the -X- _ O
memory -X- _ O
provide -X- _ O
more -X- _ O
useful -X- _ O
information -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O

Baselines -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
methods -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
baselines -X- _ O
: -X- _ O
Fine -X- _ O
- -X- _ O
tune -X- _ O
: -X- _ O
We -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
support -X- _ O
set -X- _ O
of -X- _ O
metatesting -X- _ O
tasks -X- _ O
( -X- _ O
non -X- _ O
- -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
method -X- _ O
) -X- _ O
as -X- _ O
in -X- _ O
Appendix -X- _ O
. -X- _ O
B.2 -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
five -X- _ O
metric -X- _ O
- -X- _ O
based -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
baselines -X- _ O
: -X- _ O
Matching -X- _ B-MethodName
Net -X- _ I-MethodName
( -X- _ O
Vinyals -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
Prototypical -X- _ B-MethodName
Net -X- _ I-MethodName
( -X- _ O
Snell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
Proto -X- _ O
+ -X- _ O
+ -X- _ O
, -X- _ O
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
Relation -X- _ B-MethodName
Net -X- _ I-MethodName
( -X- _ O
Sung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Induction -X- _ B-MethodName
Net -X- _ I-MethodName
( -X- _ O
Geng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
apply -X- _ O
an -X- _ O
optimization -X- _ O
- -X- _ O
based -X- _ O
baseline -X- _ O
( -X- _ O
MAML -X- _ B-MethodName
) -X- _ O
( -X- _ O
Finn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
implement -X- _ O
some -X- _ O
approaches -X- _ O
tackling -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
problem -X- _ O
based -X- _ O
on -X- _ O
MAML -X- _ B-MethodName
: -X- _ O
MR -X- _ B-MethodName
- -X- _ I-MethodName
MAML -X- _ I-MethodName
( -X- _ O
Yin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
MetaMix -X- _ B-MethodName
, -X- _ O
( -X- _ O
Yao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
Meta -X- _ B-MethodName
- -X- _ I-MethodName
Aug -X- _ I-MethodName
( -X- _ O
Rajendran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
ARSC -X- _ B-DatasetName
( -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
contains -X- _ O
English -X- _ O
reviews -X- _ O
of -X- _ O
23 -X- _ B-HyperparameterValue
types -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
Amazon -X- _ I-HyperparameterName
products -X- _ I-HyperparameterName
, -X- _ O
where -X- _ O
each -X- _ O
product -X- _ O
consists -X- _ O
of -X- _ O
three -X- _ B-HyperparameterValue
different -X- _ B-HyperparameterName
binary -X- _ I-HyperparameterName
classification -X- _ I-HyperparameterName
tasks -X- _ I-HyperparameterName
. -X- _ O
Following -X- _ O
Geng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
12 -X- _ B-HyperparameterValue
tasks -X- _ B-HyperparameterName
from -X- _ O
4 -X- _ B-HyperparameterValue
domains -X- _ B-HyperparameterName
( -X- _ O
Books -X- _ O
, -X- _ O
DVD -X- _ O
, -X- _ O
Electronics -X- _ O
, -X- _ O
Kitchen -X- _ O
) -X- _ O
for -X- _ O
meta -X- _ O
- -X- _ O
testing -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
support -X- _ O
sets -X- _ O
of -X- _ O
these -X- _ O
tasks -X- _ O
are -X- _ O
fixed -X- _ O
( -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

• -X- _ O
Quality -X- _ O
: -X- _ O
BLEU -X- _ B-MetricName
- -X- _ I-MetricName
n -X- _ I-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
CIDEr -X- _ B-MetricName
( -X- _ O
Vedantam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
, -X- _ O
and -X- _ O
ROUGE -X- _ B-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
measures -X- _ O
the -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
matching -X- _ O
between -X- _ O
the -X- _ O
generated -X- _ O
response -X- _ O
and -X- _ O
ground -X- _ O
truth -X- _ O
. -X- _ O
PPL -X- _ B-MetricName
( -X- _ O
perplexity -X- _ B-MetricName
) -X- _ O
measures -X- _ O
the -X- _ O
sentence -X- _ O
fluency -X- _ O
. -X- _ O
• -X- _ O
Diversity -X- _ O
. -X- _ O
Dist -X- _ B-MetricName
- -X- _ I-MetricName
n -X- _ I-MetricName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
evaluates -X- _ O
the -X- _ O
response -X- _ O
diversity -X- _ O
by -X- _ O
counting -X- _ O
unique -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
. -X- _ O
• -X- _ O
Consistency -X- _ O
: -X- _ O
C -X- _ B-MetricName
score -X- _ I-MetricName
( -X- _ O
Madotto -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
measures -X- _ O
the -X- _ O
consistency -X- _ O
between -X- _ O
the -X- _ O
generated -X- _ O
responses -X- _ O
and -X- _ O
persona -X- _ O
descriptions -X- _ O
through -X- _ O
a -X- _ O
pretrained -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
model -X- _ O
. -X- _ O
Overall -X- _ O
Performance -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1.Fine -X- _ O
- -X- _ O
tune -X- _ O
outperforms -X- _ O
Base -X- _ O
Model -X- _ O
in -X- _ O
all -X- _ O
metrics -X- _ O
, -X- _ O
which -X- _ O
verifies -X- _ O
that -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
data -X- _ O
is -X- _ O
helpful -X- _ O
to -X- _ O
its -X- _ O
performance -X- _ O
on -X- _ O
specific -X- _ O
tasks -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
Fine -X- _ O
- -X- _ O
tune -X- _ O
, -X- _ O
MAML -X- _ B-MethodName
behaves -X- _ O
better -X- _ O
on -X- _ O
diversity -X- _ O
and -X- _ O
consistency -X- _ O
but -X- _ O
behaves -X- _ O
worse -X- _ O
on -X- _ O
quality -X- _ O
. -X- _ O
Pretraining -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
perplexity -X- _ B-MetricName
( -X- _ O
lowest -X- _ O
PPL -X- _ B-MetricName
) -X- _ O
as -X- _ O
shown -X- _ O
by -X- _ O
Base -X- _ O
Model -X- _ O
and -X- _ O
Fine -X- _ O
- -X- _ O
tune -X- _ O
. -X- _ O
We -X- _ O
analyze -X- _ O
that -X- _ O
it -X- _ O
's -X- _ O
because -X- _ O
pretraining -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
considerable -X- _ O
degree -X- _ O
of -X- _ O
fluency -X- _ O
in -X- _ O
their -X- _ O
generated -X- _ O
utterances -X- _ O
and -X- _ O
is -X- _ O
careless -X- _ O
about -X- _ O
each -X- _ O
task -X- _ O
's -X- _ O
specific -X- _ O
information -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
low -X- _ O
consistency -X- _ O
with -X- _ O
tasks -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
, -X- _ O
MemIML -X- _ B-MethodName
, -X- _ O
performs -X- _ O
the -X- _ O
best -X- _ O
in -X- _ O
most -X- _ O
aspects -X- _ O
, -X- _ O
including -X- _ O
quality -X- _ O
, -X- _ O
diversity -X- _ O
, -X- _ O
and -X- _ O
task -X- _ O
consistency -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
MemIML -X- _ B-MethodName
significantly -X- _ O
improves -X- _ O
MR -X- _ B-MethodName
- -X- _ I-MethodName
MAML -X- _ I-MethodName
in -X- _ O
alleviating -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
issue -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
memory -X- _ O
imitation -X- _ O
is -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
only -X- _ O
regularizing -X- _ O
model -X- _ O
initialization -X- _ O
. -X- _ O
Dataset -X- _ O
. -X- _ O
Amazon -X- _ B-DatasetName
Review -X- _ I-DatasetName
sentiment -X- _ I-DatasetName
classification -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
ARSC -X- _ B-DatasetName
) -X- _ O
( -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
contains -X- _ O
69 -X- _ B-HyperparameterValue
tasks -X- _ B-HyperparameterName
in -X- _ O
total -X- _ O
. -X- _ O
Following -X- _ O
( -X- _ O
Geng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
a -X- _ O
2 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
way -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
- -X- _ I-HyperparameterValue
shot -X- _ I-HyperparameterValue
meta -X- _ O
- -X- _ O
learning -X- _ O
with -X- _ O
57 -X- _ B-HyperparameterValue
tasks -X- _ B-HyperparameterName
for -X- _ O
meta -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
12 -X- _ B-HyperparameterValue
tasks -X- _ B-HyperparameterName
for -X- _ O
meta -X- _ O
- -X- _ O
testing -X- _ O
. -X- _ O

The -X- _ O
procedure -X- _ O
of -X- _ O
meta -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
meta -X- _ O
- -X- _ O
testing -X- _ O
are -X- _ O
almost -X- _ O
the -X- _ O
same -X- _ O
except -X- _ O
that -X- _ O
meta -X- _ O
- -X- _ O
testing -X- _ O
does -X- _ O
not -X- _ O
optimize -X- _ O
the -X- _ O
learned -X- _ O
model -X- _ O
initialization -X- _ O
θ -X- _ O
and -X- _ O
the -X- _ O
initial -X- _ O
parameter -X- _ O
ω -X- _ O
of -X- _ O
the -X- _ O
value -X- _ O
predictor -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
task -X- _ O
T -X- _ O
t -X- _ O
in -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
testing -X- _ O
phase -X- _ O
, -X- _ O
MemIML -X- _ B-MethodName
also -X- _ O
adapts -X- _ O
θ -X- _ O
to -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
parameters -X- _ O
θ -X- _ O
i -X- _ O
in -X- _ O
the -X- _ O
inner -X- _ O
- -X- _ O
loop -X- _ O
and -X- _ O
constructs -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
memory -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
outer -X- _ O
- -X- _ O
loop -X- _ O
, -X- _ O
MemIML -X- _ B-MethodName
retrieves -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
pairs -X- _ O
from -X- _ O
the -X- _ O
memory -X- _ O
to -X- _ O
conduct -X- _ O
local -X- _ O
adaptation -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
initial -X- _ O
parameter -X- _ O
ω -X- _ O
. -X- _ O
The -X- _ O
estimated -X- _ O
valueV -X- _ O
q -X- _ O
t -X- _ O
from -X- _ O
local -X- _ O
adaptation -X- _ O
helps -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
final -X- _ O
outputŶ -X- _ O
q -X- _ O
t -X- _ O
.Experiments -X- _ O
on -X- _ O
personalized -X- _ B-TaskName
dialogue -X- _ I-TaskName
generation -X- _ I-TaskName
and -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
sentiment -X- _ B-TaskName
classification -X- _ I-TaskName
verify -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
and -X- _ I-TaskName
classification -X- _ I-TaskName
, -X- _ O
respectively -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
use -X- _ O
Persona -X- _ B-DatasetName
- -X- _ I-DatasetName
Chat -X- _ I-DatasetName
and -X- _ O
ARSC -X- _ B-DatasetName
datasets -X- _ O
. -X- _ O
Dataset -X- _ O
. -X- _ O
Following -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
Persona -X- _ B-DatasetName
- -X- _ I-DatasetName
chat -X- _ I-DatasetName
( -X- _ O
Madotto -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
Metrics -X- _ O
. -X- _ O
Automatic -X- _ O
evaluation -X- _ O
has -X- _ O
three -X- _ O
aspects -X- _ O
, -X- _ O

I(Ŷ -X- _ O
q -X- _ O
i -X- _ O
; -X- _ O
[ -X- _ O
D -X- _ O
s -X- _ O
i -X- _ O
, -X- _ O
M -X- _ O
i -X- _ O
] -X- _ O
| -X- _ O
θ -X- _ O
, -X- _ O
X -X- _ O
q -X- _ O
i -X- _ O
) -X- _ O
> -X- _ O
I(Ŷ -X- _ O
q -X- _ O
i -X- _ O
; -X- _ O
D -X- _ O
s -X- _ O
i -X- _ O
| -X- _ O
θ -X- _ O
, -X- _ O
X -X- _ O
q -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
In -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
( -X- _ O
shown -X- _ O
in -X- _ O
Alg -X- _ O
. -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
MemIML -X- _ B-MethodName
first -X- _ O
constructs -X- _ O
an -X- _ O
empty -X- _ O
memory -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
and -X- _ O
then -X- _ O
follows -X- _ O
the -X- _ O
bi -X- _ O
- -X- _ O
level -X- _ O
optimization -X- _ O
process -X- _ O
of -X- _ O
MAML -X- _ B-MethodName
. -X- _ O
In -X- _ O
the -X- _ O
inner -X- _ O
loop -X- _ O
, -X- _ O
MemIML -X- _ B-MethodName
adapts -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
initialization -X- _ O
θ -X- _ O
to -X- _ O
taskspecific -X- _ O
parameters -X- _ O
via -X- _ O
training -X- _ O
on -X- _ O
the -X- _ O
support -X- _ O
set -X- _ O
. -X- _ O
At -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
, -X- _ O
from -X- _ O
each -X- _ O
support -X- _ O
- -X- _ O
set -X- _ O
sample -X- _ O
, -X- _ O
MemIML -X- _ B-MethodName
obtains -X- _ O
a -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
pair -X- _ O
and -X- _ O
determines -X- _ O
whether -X- _ O
to -X- _ O
write -X- _ O
it -X- _ O
into -X- _ O
the -X- _ O
memory -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
MemIML -X- _ B-MethodName
conducts -X- _ O
the -X- _ O
global -X- _ O
optimization -X- _ O
of -X- _ O
the -X- _ O
value -X- _ O
predictor -X- _ O
over -X- _ O
these -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
pairs -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
outer -X- _ O
loop -X- _ O
, -X- _ O
each -X- _ O
sample -X- _ O
of -X- _ O
the -X- _ O
query -X- _ O
set -X- _ O
reads -X- _ O
the -X- _ O
memory -X- _ O
to -X- _ O
retrieve -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
memory -X- _ O
slots -X- _ O
. -X- _ O
Local -X- _ O
adaptation -X- _ O
fine -X- _ O
- -X- _ O
tunes -X- _ O
the -X- _ O
value -X- _ O
predictor -X- _ O
on -X- _ O
those -X- _ O
retrieved -X- _ O
slots -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
the -X- _ O
adapted -X- _ O
value -X- _ O
predictor -X- _ O
estimates -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
each -X- _ O
query -X- _ O
sample -X- _ O
and -X- _ O
uses -X- _ O
it -X- _ O
to -X- _ O
augment -X- _ O
the -X- _ O
learning -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
initialization -X- _ O
. -X- _ O
The -X- _ O
total -X- _ B-HyperparameterName
loss -X- _ I-HyperparameterName
function -X- _ I-HyperparameterName
in -X- _ O
the -X- _ O
inner -X- _ O
loop -X- _ O
is -X- _ O
L -X- _ B-HyperparameterName
total -X- _ I-HyperparameterName
= -X- _ O
L -X- _ B-HyperparameterValue
base -X- _ I-HyperparameterValue
+ -X- _ I-HyperparameterValue
L -X- _ I-HyperparameterValue
rec -X- _ I-HyperparameterValue
, -X- _ O
where -X- _ O

L -X- _ B-HyperparameterName
base -X- _ I-HyperparameterName
= -X- _ O
L(f -X- _ O
( -X- _ O
X -X- _ O
s -X- _ O
) -X- _ O
, -X- _ O
Y -X- _ O
s -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
cross -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
entropy -X- _ I-HyperparameterValue
loss -X- _ B-HyperparameterName
. -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
criterion -X- _ O
similar -X- _ O
to -X- _ O
( -X- _ O
Yao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
validity -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
for -X- _ O
tackling -X- _ O
this -X- _ O
problem -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
task -X- _ O
T -X- _ O
i -X- _ O
= -X- _ O
{ -X- _ O
D -X- _ O
s -X- _ O
i -X- _ O
, -X- _ O
D -X- _ O
q -X- _ O
i -X- _ O
} -X- _ O
, -X- _ O
the -X- _ O
criterion -X- _ O
aims -X- _ O
to -X- _ O
mitigate -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
by -X- _ O
enhancing -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
dependence -X- _ O
on -X- _ O
the -X- _ O
support -X- _ O
set -X- _ O
D -X- _ O
s -X- _ O
i -X- _ O
, -X- _ O
i.e. -X- _ O
increasing -X- _ O
the -X- _ O
mutual -X- _ B-MetricName
information -X- _ I-MetricName
between -X- _ O
support -X- _ O
set -X- _ O
andŶ -X- _ O
q -X- _ O
i -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
6 -X- _ O
) -X- _ O
where -X- _ O
M -X- _ O
i -X- _ O
means -X- _ O
additional -X- _ O
memory -X- _ O
information -X- _ O
we -X- _ O
provide -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
support -X- _ O
sets -X- _ O
information -X- _ O
to -X- _ O
augment -X- _ O
the -X- _ O
inference -X- _ O
of -X- _ O
the -X- _ O
sample -X- _ O
X -X- _ O
q -X- _ O
i -X- _ O
in -X- _ O
D -X- _ O
q -X- _ O
i -X- _ O
. -X- _ O
We -X- _ O
demonstrate -X- _ O
our -X- _ O
method -X- _ O
MemIML -X- _ B-MethodName
meets -X- _ O
the -X- _ O
above -X- _ O
criterion -X- _ O
( -X- _ O
See -X- _ O
details -X- _ O
in -X- _ O
Appendix -X- _ O
. -X- _ O
A. -X- _ O
) -X- _ O
. -X- _ O

Following -X- _ O
Yin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
mutual -X- _ B-MetricName
information -X- _ I-MetricName
I(Ŷ -X- _ O
q -X- _ O
i -X- _ O
; -X- _ O
D -X- _ O
s -X- _ O
i -X- _ O
|θ -X- _ O
, -X- _ O
X -X- _ O
q -X- _ O
i -X- _ O
) -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
level -X- _ O
of -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
. -X- _ O
When -X- _ O
the -X- _ O
learned -X- _ O
model -X- _ O
ignores -X- _ O
support -X- _ O
sets -X- _ O
to -X- _ O
predict -X- _ O
query -X- _ O
sets -X- _ O
, -X- _ O
I(Ŷ -X- _ O
q -X- _ O
i -X- _ O
; -X- _ O
D -X- _ O
s -X- _ O
i -X- _ O
) -X- _ O
|θ -X- _ O
, -X- _ O
X -X- _ O
q -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
0 -X- _ O
occurs -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
the -X- _ O
complete -X- _ O
memorization -X- _ O
overfitting -X- _ O
in -X- _ O
metalearning -X- _ O
( -X- _ O
Yin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
lower -X- _ O
mutual -X- _ B-MetricName
information -X- _ I-MetricName
means -X- _ O
more -X- _ O
serious -X- _ O
memorization -X- _ O
overfitting -X- _ O
issues -X- _ O
. -X- _ O

Update -X- _ O
θ -X- _ O
← -X- _ O
θ -X- _ O
− -X- _ O
α4∇ -X- _ B-HyperparameterName
θ -X- _ O
T -X- _ O
i -X- _ O
∼p(T -X- _ O
) -X- _ O
L -X- _ O
base -X- _ O
T -X- _ O
i -X- _ O
, -X- _ O
θ -X- _ O
i -X- _ O
( -X- _ O
Ŷ -X- _ O
q -X- _ O
, -X- _ O
Y -X- _ O
q -X- _ O
) -X- _ O
We -X- _ O
theoretically -X- _ O
investigate -X- _ O
how -X- _ O
our -X- _ O
method -X- _ O
helps -X- _ O
to -X- _ O
alleviate -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
problem -X- _ O
. -X- _ O

ω -X- _ O
q -X- _ O
j -X- _ O
← -X- _ O
ω -X- _ O
− -X- _ O
α3∇ωL -X- _ B-HyperparameterName
loc -X- _ O
# -X- _ O
Local -X- _ O
adaptation -X- _ O
14 -X- _ O
: -X- _ O
V -X- _ O
q -X- _ O
j -X- _ O
= -X- _ O
g -X- _ O
ω -X- _ O
q -X- _ O
j -X- _ O
( -X- _ O
K -X- _ O
q -X- _ O
j -X- _ O
) -X- _ O
# -X- _ O
Predict -X- _ O

Retrieve -X- _ O
N -X- _ B-HyperparameterName
nearest -X- _ O
neighbors -X- _ O
of -X- _ O
K -X- _ O
q -X- _ O
j -X- _ O
from -X- _ O
Mi -X- _ O
. -X- _ O

Obtain -X- _ O
the -X- _ O
keys -X- _ O
K -X- _ O
q -X- _ O
j -X- _ O
for -X- _ O
each -X- _ O
sample -X- _ O
X -X- _ O
q -X- _ O
j -X- _ O
12 -X- _ O
: -X- _ O

where -X- _ O
β -X- _ B-HyperparameterName
balancesỸ -X- _ O
q -X- _ O
j -X- _ O
andV -X- _ O
q -X- _ O
j -X- _ O
. -X- _ O
Notice -X- _ O
that -X- _ O
the -X- _ O
interpolation -X- _ O
not -X- _ O
only -X- _ O
works -X- _ O
on -X- _ O
the -X- _ O
prediction -X- _ O
output -X- _ O
but -X- _ O
also -X- _ O
guides -X- _ O
the -X- _ O
training -X- _ O
via -X- _ O
gradient -X- _ O
descent -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
interpolated -X- _ O
output -X- _ O
. -X- _ O
We -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
interpolation -X- _ O
in -X- _ O
Appendix -X- _ O
. -X- _ O
C. -X- _ O
Mi -X- _ O
← -X- _ O
{ -X- _ O
< -X- _ O
K -X- _ O
s -X- _ O
l -X- _ O
, -X- _ O
V -X- _ O
s -X- _ O
l -X- _ O
> -X- _ O
} -X- _ O
N -X- _ O
s -X- _ O
l=1 -X- _ O
# -X- _ O
Write -X- _ O
memory -X- _ O
8 -X- _ O
: -X- _ O
ω -X- _ O
← -X- _ O
ω -X- _ O
− -X- _ O
α1∇ωL -X- _ B-HyperparameterName
rec -X- _ O
# -X- _ O
Global -X- _ O
optimization -X- _ O
9 -X- _ O
: -X- _ O
θ -X- _ O
i -X- _ O
← -X- _ O
θ -X- _ O
− -X- _ O
α2∇ -X- _ B-HyperparameterName
θ -X- _ O
L -X- _ O
base -X- _ O
# -X- _ O
Learn -X- _ O
θ -X- _ O
i -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
2 -X- _ O
10 -X- _ O
: -X- _ O
for -X- _ O
( -X- _ O
X -X- _ O
q -X- _ O
j -X- _ O
, -X- _ O
Y -X- _ O
q -X- _ O
j -X- _ O
) -X- _ O
in -X- _ O
D -X- _ O
q -X- _ O
i -X- _ O
do -X- _ O
11 -X- _ O
: -X- _ O

Y -X- _ O
q -X- _ O
j -X- _ O
= -X- _ O
βỸ -X- _ B-HyperparameterName
q -X- _ O
j -X- _ O
+ -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
β)V -X- _ B-HyperparameterName
q -X- _ O
j -X- _ O
( -X- _ O
5 -X- _ O

Multi -X- _ O
- -X- _ O
domain -X- _ O
Sentiment -X- _ B-TaskName
Classification -X- _ I-TaskName
. -X- _ O
The -X- _ O
base -X- _ O
model -X- _ O
is -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
fully -X- _ O
- -X- _ O
connected -X- _ O
network -X- _ O
. -X- _ O
Each -X- _ O
sample -X- _ O
consists -X- _ O
of -X- _ O
an -X- _ O
input -X- _ O
sentence -X- _ O
and -X- _ O
a -X- _ O
sentiment -X- _ O
label -X- _ O
( -X- _ O
ground -X- _ O
truth -X- _ O
) -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
memory -X- _ O
value -X- _ O
V -X- _ O
s -X- _ O
l -X- _ O
is -X- _ O
the -X- _ O
sentiment -X- _ O
label -X- _ O
. -X- _ O
To -X- _ O
leverageV -X- _ O
q -X- _ O
j -X- _ O
, -X- _ O
we -X- _ O
interpolate -X- _ O
it -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
base -X- _ O
modelỸ -X- _ O
q -X- _ O
j -X- _ O
aŝ -X- _ O

Personalized -X- _ B-TaskName
Dialogue -X- _ I-TaskName
Generation -X- _ I-TaskName
. -X- _ O
The -X- _ O
base -X- _ O
model -X- _ O
is -X- _ O
the -X- _ O
transformer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
consisting -X- _ O
of -X- _ O
an -X- _ O
encoder -X- _ O
and -X- _ O
a -X- _ O
decoder -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
task -X- _ O
, -X- _ O
each -X- _ O
sample -X- _ O
consists -X- _ O
of -X- _ O
an -X- _ O
input -X- _ O
utterance -X- _ O
and -X- _ O
a -X- _ O
ground -X- _ O
truth -X- _ O
utterance -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
value -X- _ O
V -X- _ O
s -X- _ O
l -X- _ O
stored -X- _ O
in -X- _ O
the -X- _ O
memory -X- _ O
is -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
utterance -X- _ O
Y -X- _ O
s -X- _ O
l -X- _ O
of -X- _ O
a -X- _ O
support -X- _ O
- -X- _ O
set -X- _ O
sample -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
embedded -X- _ O
by -X- _ O
the -X- _ O
key -X- _ O
network -X- _ O
followed -X- _ O
by -X- _ O
an -X- _ O
LSTM -X- _ O
( -X- _ O
Hochreiter -X- _ O
and -X- _ O
Schmidhuber -X- _ O
, -X- _ O
1997 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
LSTM -X- _ O
is -X- _ O
optimized -X- _ O
with -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
. -X- _ O
Thê -X- _ O
V -X- _ O
q -X- _ O
j -X- _ O
, -X- _ O
concatenated -X- _ O
with -X- _ O
the -X- _ O
encoder -X- _ O
outputs -X- _ O
, -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
new -X- _ O
input -X- _ O
for -X- _ O
the -X- _ O
decoder -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
acquire -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
a -X- _ O
query -X- _ O
- -X- _ O
set -X- _ O
sample -X- _ O
viâ -X- _ O
Y -X- _ O
q -X- _ O
j -X- _ O
= -X- _ O
Decoder([V -X- _ O
q -X- _ O
j -X- _ O
; -X- _ O
Encoder(X -X- _ O
q -X- _ O
j -X- _ O
) -X- _ O
] -X- _ O
) -X- _ O
. -X- _ O

where -X- _ O
the -X- _ O
adapted -X- _ O
parameters -X- _ O
ω -X- _ O
q -X- _ O
j -X- _ O
are -X- _ O
discarded -X- _ O
thereafter -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
does -X- _ O
not -X- _ O
back -X- _ O
- -X- _ O
propagate -X- _ O
throughV -X- _ O
q -X- _ O
j -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
sense -X- _ O
, -X- _ O
besides -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
parameter -X- _ O
θ -X- _ O
i -X- _ O
provided -X- _ O
by -X- _ O
MAML -X- _ B-MethodName
, -X- _ O
there -X- _ O
will -X- _ O
also -X- _ O
be -X- _ O
ω -X- _ O
q -X- _ O
j -X- _ O
learned -X- _ O
from -X- _ O
support -X- _ O
sets -X- _ O
specific -X- _ O
to -X- _ O
each -X- _ O
query -X- _ O
- -X- _ O
set -X- _ O
sample -X- _ O
. -X- _ O
This -X- _ O
guarantees -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
relies -X- _ O
more -X- _ O
on -X- _ O
support -X- _ O
sets -X- _ O
for -X- _ O
task -X- _ O
adaptation -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
( -X- _ O
right -X- _ O
part -X- _ O
) -X- _ O
illustrates -X- _ O
the -X- _ O
mechanism -X- _ O
of -X- _ O
local -X- _ O
adaptation -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
part -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
elaborate -X- _ O
on -X- _ O
two -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
applications -X- _ O
in -X- _ O
NLP -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
and -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
) -X- _ O
to -X- _ O
solve -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
problem -X- _ O
of -X- _ O
MAML -X- _ B-MethodName
. -X- _ O
The -X- _ O
model -X- _ O
structures -X- _ O
of -X- _ O
these -X- _ O
applications -X- _ O
are -X- _ O
basically -X- _ O
the -X- _ O
same -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
following -X- _ O
three -X- _ O
points -X- _ O
: -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
, -X- _ O
the -X- _ O
way -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
value -X- _ O
V -X- _ O
s -X- _ O
l -X- _ O
stored -X- _ O
in -X- _ O
the -X- _ O
memory -X- _ O
module -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
way -X- _ O
to -X- _ O
leverage -X- _ O
the -X- _ O
outputV -X- _ O
q -X- _ O
j -X- _ O
of -X- _ O
Sec -X- _ O
. -X- _ O
4.2 -X- _ O
. -X- _ O

V -X- _ O
q -X- _ O
j -X- _ O
= -X- _ O
g -X- _ O
ω -X- _ O
q -X- _ O
j -X- _ O
( -X- _ O
K -X- _ O
q -X- _ O
j -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O

is -X- _ O
the -X- _ O
memory -X- _ O
reading -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
query -X- _ O
- -X- _ O
set -X- _ O
sample -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
factor -X- _ O
γ -X- _ B-HyperparameterName
restricts -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
ω -X- _ O
q -X- _ O
j -X- _ O
and -X- _ O
ω -X- _ O
. -X- _ O
Minimizing -X- _ O
the -X- _ O
second -X- _ O
term -X- _ O
encourages -X- _ O
g -X- _ O
ω -X- _ O
q -X- _ O
j -X- _ O
to -X- _ O
better -X- _ O
estimate -X- _ O
the -X- _ O
retrieved -X- _ O
memory -X- _ O
values -X- _ O
{ -X- _ O
V -X- _ O
s -X- _ O
l -X- _ O
} -X- _ O
N -X- _ O
l=1 -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
can -X- _ O
acquire -X- _ O
the -X- _ O
locally -X- _ O
adapted -X- _ O
value -X- _ O
prediction -X- _ O
network -X- _ O
g -X- _ O
ω -X- _ O
q -X- _ O
j -X- _ O
with -X- _ O
parameters -X- _ O
ω -X- _ O
q -X- _ O
j -X- _ O
= -X- _ O
arg -X- _ O
miñ -X- _ O
ω -X- _ O
L -X- _ O
loc -X- _ O
( -X- _ O
ω -X- _ O
) -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
query -X- _ O
- -X- _ O
sample -X- _ O
key -X- _ O
K -X- _ O
q -X- _ O
j -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
thus -X- _ O
predict -X- _ O
its -X- _ O
associated -X- _ O
value -X- _ O
aŝ -X- _ O

L -X- _ O
loc -X- _ O
= -X- _ O
γ -X- _ O
ω -X- _ O
− -X- _ O
ω -X- _ O
2 -X- _ O
2 -X- _ O
+ -X- _ O
1 -X- _ O
N -X- _ O
N -X- _ O
l=1 -X- _ O
L -X- _ O
rec -X- _ O
ω -X- _ O
( -X- _ O
V -X- _ O
s -X- _ O
l -X- _ O
, -X- _ O
V -X- _ O
s -X- _ O
l -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Here -X- _ O
, -X- _ O
V -X- _ O
s -X- _ O
l -X- _ O
= -X- _ O
gω(K -X- _ O
s -X- _ O
l -X- _ O
) -X- _ O
, -X- _ O
{ -X- _ O
K -X- _ O
s -X- _ O
l -X- _ O
, -X- _ O
V -X- _ O
s -X- _ O
l -X- _ O
} -X- _ O
N -X- _ O
l=1 -X- _ O

Local -X- _ O
Adaptation -X- _ O
. -X- _ O
To -X- _ O
make -X- _ O
the -X- _ O
value -X- _ O
predictor -X- _ O
adaptive -X- _ O
to -X- _ O
each -X- _ O
query -X- _ O
- -X- _ O
set -X- _ O
sample -X- _ O
X -X- _ O
q -X- _ O
j -X- _ O
, -X- _ O
inspired -X- _ O
by -X- _ O
( -X- _ O
Sprechmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
local -X- _ O
adaptation -X- _ O
that -X- _ O
fine -X- _ O
- -X- _ O
tunes -X- _ O
the -X- _ O
global -X- _ O
value -X- _ O
predictor -X- _ O
g -X- _ O
ω -X- _ O
to -X- _ O
get -X- _ O
an -X- _ O
adapted -X- _ O
one -X- _ O
with -X- _ O
parameters -X- _ O
ω -X- _ O
q -X- _ O
j -X- _ O
. -X- _ O
The -X- _ O
local -X- _ O
adaptation -X- _ O
only -X- _ O
works -X- _ O
when -X- _ O
predicting -X- _ O
X -X- _ O
q -X- _ O
j -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
initial -X- _ O
parameters -X- _ O
ω -X- _ O
from -X- _ O
the -X- _ O
global -X- _ O
optimization -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
several -X- _ O
gradient -X- _ O
descent -X- _ O
steps -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
loss -X- _ O
L -X- _ O
loc -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
: -X- _ O

Global -X- _ O
Optimization -X- _ O
. -X- _ O
To -X- _ O
obtain -X- _ O
the -X- _ O
taskindependent -X- _ O
global -X- _ O
parameters -X- _ O
ω -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
value -X- _ O
predictor -X- _ O
over -X- _ O
constructed -X- _ O
keys -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
as -X- _ O
inputs -X- _ O
) -X- _ O
and -X- _ O
values -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
as -X- _ O
outputs -X- _ O
) -X- _ O
from -X- _ O
support -X- _ O
- -X- _ O
set -X- _ O
samples -X- _ O
of -X- _ O
all -X- _ O
tasks -X- _ O
. -X- _ O
The -X- _ O
global -X- _ O
optimization -X- _ O
keeps -X- _ O
updating -X- _ O
in -X- _ O
the -X- _ O
whole -X- _ O
meta -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
. -X- _ O

The -X- _ O
training -X- _ O
procedure -X- _ O
includes -X- _ O
the -X- _ O
global -X- _ O
optimization -X- _ O
shared -X- _ O
across -X- _ O
tasks -X- _ O
and -X- _ O
the -X- _ O
local -X- _ O
adaptation -X- _ O
for -X- _ O
each -X- _ O
specific -X- _ O
task -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
train -X- _ O
the -X- _ O
value -X- _ O
predictor -X- _ O
with -X- _ O
samples -X- _ O
from -X- _ O
support -X- _ O
sets -X- _ O
of -X- _ O
all -X- _ O
tasks -X- _ O
. -X- _ O
After -X- _ O
feeding -X- _ O
the -X- _ O
memory -X- _ O
reading -X- _ O
output -X- _ O
of -X- _ O
a -X- _ O
query -X- _ O
- -X- _ O
set -X- _ O
sample -X- _ O
to -X- _ O
this -X- _ O
network -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
local -X- _ O
adaptation -X- _ O
and -X- _ O
employ -X- _ O
the -X- _ O
adapted -X- _ O
network -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
value -X- _ O
for -X- _ O
the -X- _ O
query -X- _ O
sample -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
two -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
layer -X- _ I-HyperparameterValue
fully -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
connected -X- _ I-HyperparameterName
network -X- _ I-HyperparameterName
g -X- _ B-HyperparameterName
ω -X- _ I-HyperparameterName
with -X- _ O
parameters -X- _ O
ω -X- _ O
to -X- _ O
build -X- _ O
the -X- _ O
mapping -X- _ O
. -X- _ O
The -X- _ O
value -X- _ O
predictor -X- _ O
is -X- _ O
learned -X- _ O
over -X- _ O
constructed -X- _ O
keyvalue -X- _ O
pairs -X- _ O
of -X- _ O
support -X- _ O
sets -X- _ O
across -X- _ O
all -X- _ O
tasks -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
key -X- _ O
K -X- _ O
q -X- _ O
j -X- _ O
of -X- _ O
a -X- _ O
query -X- _ O
- -X- _ O
set -X- _ O
sample -X- _ O
input -X- _ O
X -X- _ O
q -X- _ O
j -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
then -X- _ O
estimate -X- _ O
its -X- _ O
associated -X- _ O
value -X- _ O
asV -X- _ O
q -X- _ O
j -X- _ O
.To -X- _ O
train -X- _ O
the -X- _ O
value -X- _ O
predictor -X- _ O
, -X- _ O
we -X- _ O
minimize -X- _ O
the -X- _ O
reconstruction -X- _ B-HyperparameterName
loss -X- _ I-HyperparameterName
L -X- _ B-HyperparameterName
rec -X- _ I-HyperparameterName
ω -X- _ I-HyperparameterName
( -X- _ O
V -X- _ O
, -X- _ O
V -X- _ O
) -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
predicted -X- _ O
values -X- _ O
as -X- _ O
close -X- _ O
as -X- _ O
possible -X- _ O
to -X- _ O
values -X- _ O
constructed -X- _ O
from -X- _ O
the -X- _ O
ground -X- _ O
truths -X- _ O
of -X- _ O
support -X- _ O
- -X- _ O
set -X- _ O
samples -X- _ O
, -X- _ O
where -X- _ O
L -X- _ B-HyperparameterName
rec -X- _ I-HyperparameterName
ω -X- _ I-HyperparameterName
is -X- _ O
the -X- _ O
cross -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
entropy -X- _ I-HyperparameterValue
loss -X- _ B-HyperparameterName
if -X- _ O
the -X- _ O
value -X- _ O
V -X- _ O
is -X- _ O
a -X- _ O
label -X- _ O
and -X- _ O
is -X- _ O
the -X- _ O
mean -X- _ O
square -X- _ O
loss -X- _ O
if -X- _ O
V -X- _ O
is -X- _ O
a -X- _ O
vector -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
imitation -X- _ O
module -X- _ O
is -X- _ O
customized -X- _ O
for -X- _ O
each -X- _ O
query -X- _ O
- -X- _ O
set -X- _ O
sample -X- _ O
, -X- _ O
which -X- _ O
facilitates -X- _ O
better -X- _ O
capture -X- _ O
of -X- _ O
specific -X- _ O
task -X- _ O
information -X- _ O
than -X- _ O
directly -X- _ O
using -X- _ O
the -X- _ O
memory -X- _ O
reading -X- _ O
output -X- _ O
, -X- _ O
especially -X- _ O
when -X- _ O
tasks -X- _ O
are -X- _ O
versatile -X- _ O
. -X- _ O
The -X- _ O
reason -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
similarity -X- _ O
measurement -X- _ O
of -X- _ O
previous -X- _ O
memory -X- _ O
reading -X- _ O
operations -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
fixed -X- _ O
BERT -X- _ B-MethodName
representations -X- _ O
, -X- _ O
which -X- _ O
ignores -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
information -X- _ O
. -X- _ O
In -X- _ O
MemIML -X- _ B-MethodName
, -X- _ O
the -X- _ O
proposed -X- _ O
value -X- _ O
predictor -X- _ O
aims -X- _ O
to -X- _ O
build -X- _ O
a -X- _ O
mapping -X- _ O
from -X- _ O
keys -X- _ O
to -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
memory -X- _ O
module -X- _ O
mentioned -X- _ O
in -X- _ O
Sec -X- _ O
. -X- _ O
4.1 -X- _ O
. -X- _ O
The -X- _ O
input -X- _ O
of -X- _ O
the -X- _ O
value -X- _ O
predictor -X- _ O
is -X- _ O
a -X- _ O
key -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
key -X- _ O
network -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
the -X- _ O
associated -X- _ O
value -X- _ O
. -X- _ O

Memory -X- _ O
Reading -X- _ O
obtains -X- _ O
information -X- _ O
from -X- _ O
memory -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
. -X- _ O
The -X- _ O
input -X- _ O
is -X- _ O
the -X- _ O
sentence -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
sample -X- _ O
in -X- _ O
query -X- _ O
sets -X- _ O
encoded -X- _ O
by -X- _ O
the -X- _ O
key -X- _ O
network -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
the -X- _ O
memory -X- _ O
slots -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
query -X- _ O
sample -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
key -X- _ O
representation -X- _ O
K -X- _ O
q -X- _ O
j -X- _ O
of -X- _ O
a -X- _ O
sample -X- _ O
X -X- _ O
q -X- _ O
j -X- _ O
∈ -X- _ O
D -X- _ O
q -X- _ O
i -X- _ O
, -X- _ O
we -X- _ O
retrieve -X- _ O
the -X- _ O
top -X- _ O
N -X- _ B-HyperparameterName
most -X- _ O
similar -X- _ O
slots -X- _ O
from -X- _ O
its -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
memory -X- _ O
M -X- _ O
i -X- _ O
. -X- _ O
The -X- _ O
similarity -X- _ B-HyperparameterName
is -X- _ O
measured -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
Euclidean -X- _ B-HyperparameterValue
distance -X- _ I-HyperparameterValue
between -X- _ O
K -X- _ O
q -X- _ O
j -X- _ O
and -X- _ O
each -X- _ O
key -X- _ O
K -X- _ O
s -X- _ O
l -X- _ O
in -X- _ O
the -X- _ O
memory -X- _ O
slots -X- _ O
. -X- _ O
The -X- _ O
retrieved -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
pairs -X- _ O
{ -X- _ O
K -X- _ O
s -X- _ O
l -X- _ O
, -X- _ O
V -X- _ O
s -X- _ O
l -X- _ O
} -X- _ O
N -X- _ O
l=1 -X- _ O
act -X- _ O
as -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
memory -X- _ O
reading -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
better -X- _ O
leverage -X- _ O
the -X- _ O
retrieved -X- _ O
memory -X- _ O
and -X- _ O
enhance -X- _ O
the -X- _ O
dependence -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
support -X- _ O
sets -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
imitation -X- _ O
module -X- _ O
to -X- _ O
encourage -X- _ O
the -X- _ O
imitation -X- _ O
of -X- _ O
support -X- _ O
sets -X- _ O
behaviors -X- _ O
when -X- _ O
making -X- _ O
predictions -X- _ O
on -X- _ O
query -X- _ O
sets -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
sample -X- _ O
X -X- _ O
q -X- _ O
j -X- _ O
in -X- _ O
the -X- _ O
query -X- _ O
set -X- _ O
, -X- _ O
the -X- _ O
inputs -X- _ O
of -X- _ O
the -X- _ O
imitation -X- _ O
module -X- _ O
are -X- _ O
the -X- _ O
key -X- _ O
K -X- _ O
q -X- _ O
j -X- _ O
and -X- _ O
its -X- _ O
retrieved -X- _ O
N -X- _ O
memory -X- _ O
slots -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
the -X- _ O
predicted -X- _ O
valueV -X- _ O
q -X- _ O
j -X- _ O
for -X- _ O
X -X- _ O
q -X- _ O
j -X- _ O
. -X- _ O
To -X- _ O
achieve -X- _ O
the -X- _ O
imitation -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
value -X- _ O
predictor -X- _ O
that -X- _ O
can -X- _ O
model -X- _ O
the -X- _ O
behaviors -X- _ O
of -X- _ O
supportset -X- _ O
samples -X- _ O
( -X- _ O
i.e. -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
matching -X- _ O
) -X- _ O
stored -X- _ O
in -X- _ O
the -X- _ O
memory -X- _ O
. -X- _ O
For -X- _ O
estimating -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
each -X- _ O
query -X- _ O
- -X- _ O
set -X- _ O
sample -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
local -X- _ O
adaptation -X- _ O
on -X- _ O
the -X- _ O
value -X- _ O
predictor -X- _ O
to -X- _ O
adapt -X- _ O
the -X- _ O
matching -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
memory -X- _ O
module -X- _ O
M -X- _ O
i -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
diversity -X- _ O
score -X- _ O
as -X- _ O
S(M -X- _ O
i -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
stored -X- _ O
keys -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
a -X- _ O
more -X- _ O
diverse -X- _ O
memory -X- _ O
gets -X- _ O
a -X- _ O
higher -X- _ O
diversity -X- _ O
score -X- _ O
. -X- _ O
When -X- _ O
the -X- _ O
memory -X- _ O
is -X- _ O
not -X- _ O
full -X- _ O
, -X- _ O
we -X- _ O
directly -X- _ O
write -X- _ O
support -X- _ O
- -X- _ O
set -X- _ O
samples -X- _ O
without -X- _ O
selection -X- _ O
; -X- _ O
otherwise -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
diversity -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
memory -X- _ O
and -X- _ O
scores -X- _ O
after -X- _ O
every -X- _ O
old -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
pair -X- _ O
is -X- _ O
replaced -X- _ O
with -X- _ O
a -X- _ O
new -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
pair -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
old -X- _ O
pair -X- _ O
with -X- _ O
the -X- _ O
new -X- _ O
one -X- _ O
where -X- _ O
the -X- _ O
replacement -X- _ O
can -X- _ O
maximize -X- _ O
the -X- _ O
diversity -X- _ O
score -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
the -X- _ O
memory -X- _ O
we -X- _ O
build -X- _ O
can -X- _ O
carry -X- _ O
more -X- _ O
distinguishable -X- _ O
and -X- _ O
representative -X- _ O
information -X- _ O
and -X- _ O
efficiently -X- _ O
utilize -X- _ O
the -X- _ O
storage -X- _ O
space -X- _ O
. -X- _ O

) -X- _ O
. -X- _ O
To -X- _ O
build -X- _ O
these -X- _ O
memory -X- _ O
slots -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
samples -X- _ O
from -X- _ O
support -X- _ O
sets -X- _ O
and -X- _ O
write -X- _ O
their -X- _ O
information -X- _ O
into -X- _ O
the -X- _ O
memory -X- _ O
. -X- _ O
The -X- _ O
sample -X- _ O
selection -X- _ O
is -X- _ O
according -X- _ O
to -X- _ O
a -X- _ O
diversity -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
based -X- _ I-HyperparameterValue
selection -X- _ B-HyperparameterName
criterion -X- _ I-HyperparameterName
( -X- _ O
Xie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
to -X- _ O
ensure -X- _ O
the -X- _ O
diversity -X- _ O
and -X- _ O
representativeness -X- _ O
of -X- _ O
the -X- _ O
memory -X- _ O
content -X- _ O
. -X- _ O
The -X- _ O
detailed -X- _ O
description -X- _ O
of -X- _ O
this -X- _ O
criterion -X- _ O
is -X- _ O
in -X- _ O
Appendix -X- _ O
. -X- _ O
D. -X- _ O

{ -X- _ O
K -X- _ O
s -X- _ O
l -X- _ O
, -X- _ O
V -X- _ O
s -X- _ O
l -X- _ O
} -X- _ O
N -X- _ O
i -X- _ O
l=1 -X- _ O

Key -X- _ B-HyperparameterName
Network -X- _ I-HyperparameterName
represents -X- _ O
a -X- _ O
sample -X- _ O
with -X- _ O
a -X- _ O
vector -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
frozen -X- _ B-HyperparameterValue
pre -X- _ I-HyperparameterValue
- -X- _ I-HyperparameterValue
trained -X- _ I-HyperparameterValue
BERT -X- _ I-HyperparameterValue
model -X- _ I-HyperparameterValue
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
key -X- _ B-HyperparameterName
network -X- _ I-HyperparameterName
. -X- _ O
The -X- _ O
input -X- _ O
of -X- _ O
the -X- _ O
key -X- _ B-HyperparameterName
network -X- _ I-HyperparameterName
is -X- _ O
the -X- _ O
sample -X- _ O
input -X- _ O
sentence -X- _ O
X -X- _ O
s -X- _ O
j -X- _ O
∈ -X- _ O
D -X- _ O
s -X- _ O
i -X- _ O
( -X- _ O
X -X- _ O
q -X- _ O
j -X- _ O
∈ -X- _ O
D -X- _ O
q -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
the -X- _ O
encoded -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
token -X- _ O
( -X- _ O
i.e. -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
. -X- _ O
The -X- _ O
acquired -X- _ O
representation -X- _ O
is -X- _ O
regarded -X- _ O
as -X- _ O
the -X- _ O
key -X- _ O
K -X- _ O
s -X- _ O
j -X- _ O
for -X- _ O
X -X- _ O
s -X- _ O
j -X- _ O
( -X- _ O
K -X- _ O
q -X- _ O
j -X- _ O
for -X- _ O
X -X- _ O
q -X- _ O
j -X- _ O
) -X- _ O
. -X- _ O
Memory -X- _ O
Writing -X- _ O
constructs -X- _ O
the -X- _ O
memory -X- _ O
using -X- _ O
the -X- _ O
information -X- _ O
of -X- _ O
samples -X- _ O
in -X- _ O
the -X- _ O
support -X- _ O
set -X- _ O
D -X- _ O
s -X- _ O
i -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
task -X- _ O
T -X- _ O
i -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
memory -X- _ O
M -X- _ O
i -X- _ O
consists -X- _ O
of -X- _ O
N -X- _ O
i -X- _ O
memory -X- _ O
slots -X- _ O
( -X- _ O
i.e. -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
pairs -X- _ O

where -X- _ O
α -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
inner -X- _ B-HyperparameterName
loop -X- _ I-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
. -X- _ O
During -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
testing -X- _ O
stage -X- _ O
, -X- _ O
the -X- _ O
learned -X- _ O
initialization -X- _ O
θ -X- _ O
* -X- _ O
is -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
support -X- _ O
set -X- _ O
D -X- _ O
s -X- _ O
t -X- _ O
for -X- _ O
task -X- _ O
T -X- _ O
t -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
resulting -X- _ O
model -X- _ O
is -X- _ O
evaluated -X- _ O
on -X- _ O
the -X- _ O
query -X- _ O
set -X- _ O
D -X- _ O
q -X- _ O
t -X- _ O
with -X- _ O
the -X- _ O
post -X- _ O
- -X- _ O
update -X- _ O
parameters -X- _ O
θ -X- _ O
t -X- _ O
.To -X- _ O
alleviate -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
issue -X- _ O
in -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
MemIML -X- _ B-MethodName
, -X- _ O
which -X- _ O
includes -X- _ O
a -X- _ O
memory -X- _ O
module -X- _ O
and -X- _ O
an -X- _ O
imitation -X- _ O
module -X- _ O
on -X- _ O
the -X- _ O
grounds -X- _ O
of -X- _ O
a -X- _ O
base -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
memory -X- _ O
module -X- _ O
is -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
, -X- _ O
recording -X- _ O
the -X- _ O
mapping -X- _ O
behaviors -X- _ O
between -X- _ O
inputs -X- _ O
and -X- _ O
outputs -X- _ O
of -X- _ O
support -X- _ O
sets -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
. -X- _ O
The -X- _ O
imitation -X- _ O
module -X- _ O
is -X- _ O
shared -X- _ O
across -X- _ O
tasks -X- _ O
and -X- _ O
predicts -X- _ O
values -X- _ O
for -X- _ O
each -X- _ O
query -X- _ O
- -X- _ O
set -X- _ O
sample -X- _ O
by -X- _ O
dynamically -X- _ O
imitating -X- _ O
the -X- _ O
memory -X- _ O
construction -X- _ O
. -X- _ O
The -X- _ O
acquired -X- _ O
support -X- _ O
set -X- _ O
information -X- _ O
leveraged -X- _ O
by -X- _ O
the -X- _ O
imitation -X- _ O
module -X- _ O
augments -X- _ O
the -X- _ O
model -X- _ O
initialization -X- _ O
learning -X- _ O
, -X- _ O
enhancing -X- _ O
the -X- _ O
dependence -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
task -X- _ O
adaptation -X- _ O
on -X- _ O
support -X- _ O
sets -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
shows -X- _ O
our -X- _ O
model -X- _ O
architecture -X- _ O
. -X- _ O
We -X- _ O
design -X- _ O
a -X- _ O
memory -X- _ O
module -X- _ O
M -X- _ O
i -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
T -X- _ O
i -X- _ O
and -X- _ O
incorporate -X- _ O
it -X- _ O
in -X- _ O
the -X- _ O
MAML -X- _ B-MethodName
framework -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
fully -X- _ O
leverage -X- _ O
information -X- _ O
from -X- _ O
support -X- _ O
sets -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
pairs -X- _ O
from -X- _ O
support -X- _ O
- -X- _ O
set -X- _ O
samples -X- _ O
and -X- _ O
store -X- _ O
them -X- _ O
in -X- _ O
the -X- _ O
memory -X- _ O
module -X- _ O
. -X- _ O
The -X- _ O
key -X- _ O
is -X- _ O
the -X- _ O
sentence -X- _ O
representation -X- _ O
of -X- _ O
a -X- _ O
sample -X- _ O
input -X- _ O
from -X- _ O
support -X- _ O
sets -X- _ O
obtained -X- _ O
from -X- _ O
an -X- _ O
introduced -X- _ O
key -X- _ O
network -X- _ O
. -X- _ O
The -X- _ O
corresponding -X- _ O
value -X- _ O
is -X- _ O
constructed -X- _ O
to -X- _ O
store -X- _ O
the -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
sample -X- _ O
output -X- _ O
( -X- _ O
ground -X- _ O
truth -X- _ O
) -X- _ O
as -X- _ O
in -X- _ O
Sec -X- _ O
. -X- _ O
4.3 -X- _ O
: -X- _ O
in -X- _ O
NLG -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
the -X- _ O
value -X- _ O
is -X- _ O
the -X- _ O
sentence -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
sentence -X- _ O
; -X- _ O
in -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
the -X- _ O
value -X- _ O
is -X- _ O
the -X- _ O
one -X- _ O
hot -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
class -X- _ O
label -X- _ O
( -X- _ O
a -X- _ O
scalar -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
sample -X- _ O
. -X- _ O
Our -X- _ O
memory -X- _ O
has -X- _ O
two -X- _ O
operations -X- _ O
: -X- _ O
memory -X- _ O
writing -X- _ O
that -X- _ O
constructs -X- _ O
the -X- _ O
memory -X- _ O
and -X- _ O
memory -X- _ O
reading -X- _ O
that -X- _ O
acquires -X- _ O
information -X- _ O
from -X- _ O
memory -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
following -X- _ O
, -X- _ O
we -X- _ O
elaborate -X- _ O
on -X- _ O
these -X- _ O
contents -X- _ O
in -X- _ O
detail -X- _ O
. -X- _ O

θ -X- _ O
* -X- _ O
= -X- _ O
min -X- _ O
θ -X- _ O
E -X- _ O
T -X- _ O
i -X- _ O
∼p(T -X- _ O
) -X- _ O
L -X- _ O
f -X- _ O
θ -X- _ O
i -X- _ O
( -X- _ O
X -X- _ O
q -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
Y -X- _ O
q -X- _ O
i -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
s.t -X- _ O
. -X- _ O
θ -X- _ O
i -X- _ O
= -X- _ O
θ -X- _ O
− -X- _ O
α∇ -X- _ B-HyperparameterName
θ -X- _ O
L -X- _ O
( -X- _ O
f -X- _ O
θ -X- _ O
( -X- _ O
X -X- _ O
s -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
Y -X- _ O
s -X- _ O
i -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O

, -X- _ O
where -X- _ O
X -X- _ O
and -X- _ O
Y -X- _ O
denote -X- _ O
the -X- _ O
input -X- _ O
and -X- _ O
ground -X- _ O
truth -X- _ O
of -X- _ O
a -X- _ O
sample -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
During -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
, -X- _ O
a -X- _ O
taskspecific -X- _ O
( -X- _ O
a.k.a -X- _ O
. -X- _ O
, -X- _ O
post -X- _ O
- -X- _ O
update -X- _ O
) -X- _ O
model -X- _ O
f -X- _ O
θ -X- _ O
i -X- _ O
is -X- _ O
first -X- _ O
obtained -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
T -X- _ O
i -X- _ O
via -X- _ O
gradient -X- _ O
descent -X- _ O
over -X- _ O
its -X- _ O
support -X- _ O
set -X- _ O
D -X- _ O
s -X- _ O
i -X- _ O
. -X- _ O
Then -X- _ O
MAML -X- _ B-MethodName
updates -X- _ O
its -X- _ O
initialization -X- _ O
( -X- _ O
a.k.a -X- _ O
. -X- _ O
, -X- _ O
pre -X- _ O
- -X- _ O
update -X- _ O
) -X- _ O
θ -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
f -X- _ O
θ -X- _ O
i -X- _ O
on -X- _ O
the -X- _ O
query -X- _ O
set -X- _ O
D -X- _ O
q -X- _ O
i -X- _ O
as -X- _ O
in -X- _ O
Eq.1 -X- _ O
: -X- _ O

D -X- _ O
s -X- _ O
i -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
X -X- _ O
s -X- _ O
j -X- _ O
, -X- _ O
Y -X- _ O
s -X- _ O
j -X- _ O
) -X- _ O
} -X- _ O
N -X- _ O
s -X- _ O
j=1 -X- _ O
and -X- _ O
a -X- _ O
query -X- _ O
set -X- _ O
D -X- _ O
q -X- _ O
i -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
X -X- _ O
q -X- _ O
j -X- _ O
, -X- _ O
Y -X- _ O
q -X- _ O
j -X- _ O
) -X- _ O
} -X- _ O
N -X- _ O
q -X- _ O
j=1 -X- _ O

Memory -X- _ O
mechanism -X- _ O
has -X- _ O
proven -X- _ O
to -X- _ O
be -X- _ O
powerful -X- _ O
for -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
learning -X- _ O
( -X- _ O
Geng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Santoro -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Munkhdalai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Current -X- _ O
methods -X- _ O
either -X- _ O
refine -X- _ O
representations -X- _ O
stored -X- _ O
in -X- _ O
the -X- _ O
memory -X- _ O
( -X- _ O
Ramalho -X- _ O
and -X- _ O
Garnelo -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
or -X- _ O
refining -X- _ O
parameters -X- _ O
using -X- _ O
the -X- _ O
memory -X- _ O
( -X- _ O
Munkhdalai -X- _ O
and -X- _ O
Yu -X- _ O
, -X- _ O
2017;Cai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
NLP -X- _ O
domain -X- _ O
, -X- _ O
some -X- _ O
methods -X- _ O
store -X- _ O
encoded -X- _ O
contextual -X- _ O
information -X- _ O
into -X- _ O
a -X- _ O
memory -X- _ O
Holla -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Geng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
propose -X- _ O
a -X- _ O
memory -X- _ O
induction -X- _ O
module -X- _ O
with -X- _ O
a -X- _ O
dynamic -X- _ O
routing -X- _ O
algorithm -X- _ O
for -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
. -X- _ O
Munkhdalai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
augment -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
an -X- _ O
external -X- _ O
memory -X- _ O
by -X- _ O
learning -X- _ O
a -X- _ O
neural -X- _ O
memory -X- _ O
. -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
reuse -X- _ O
learned -X- _ O
features -X- _ O
stored -X- _ O
in -X- _ O
the -X- _ O
memory -X- _ O
on -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
slot -X- _ B-TaskName
tagging -X- _ I-TaskName
. -X- _ O
We -X- _ O
first -X- _ O
formulate -X- _ O
model -X- _ B-MethodName
- -X- _ I-MethodName
agnostic -X- _ I-MethodName
meta -X- _ I-MethodName
- -X- _ I-MethodName
learning -X- _ I-MethodName
( -X- _ O
MAML -X- _ B-MethodName
) -X- _ O
( -X- _ O
Finn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
denote -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
used -X- _ O
in -X- _ O
MAML -X- _ B-MethodName
as -X- _ O
f -X- _ O
θ -X- _ O
and -X- _ O
assume -X- _ O
each -X- _ O
task -X- _ O
T -X- _ O
i -X- _ O
sampled -X- _ O
from -X- _ O
a -X- _ O
task -X- _ O
distribution -X- _ O
p(T -X- _ O
) -X- _ O
associates -X- _ O
with -X- _ O
a -X- _ O
dataset -X- _ O
D -X- _ O
i -X- _ O
. -X- _ O
Each -X- _ O
dataset -X- _ O
D -X- _ O
i -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
support -X- _ O
set -X- _ O

External -X- _ O
Memory -X- _ O
for -X- _ O
Few -X- _ O
- -X- _ O
shot -X- _ O
Learning -X- _ O
. -X- _ O

Memorization -X- _ O
overfitting -X- _ O
of -X- _ O
Meta -X- _ O
- -X- _ O
learning -X- _ O
. -X- _ O
Meta -X- _ O
- -X- _ O
learning -X- _ O
algorithms -X- _ O
suffer -X- _ O
from -X- _ O
memorization -X- _ O
overfitting -X- _ O
. -X- _ O
Yin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
build -X- _ O
an -X- _ O
information -X- _ O
bottleneck -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
while -X- _ O
this -X- _ O
approach -X- _ O
decreases -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
with -X- _ O
this -X- _ O
passive -X- _ O
regularization -X- _ O
. -X- _ O
Rajendran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
inject -X- _ O
random -X- _ O
noise -X- _ O
to -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
of -X- _ O
both -X- _ O
support -X- _ O
and -X- _ O
query -X- _ O
sets -X- _ O
, -X- _ O
while -X- _ O
little -X- _ O
extra -X- _ O
knowledge -X- _ O
is -X- _ O
introduced -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
good -X- _ O
initialization -X- _ O
. -X- _ O
Yao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
address -X- _ O
overfitting -X- _ O
issues -X- _ O
by -X- _ O
augmenting -X- _ O
meta -X- _ O
- -X- _ O
training -X- _ O
tasks -X- _ O
through -X- _ O
mixing -X- _ O
up -X- _ O
support -X- _ O
and -X- _ O
query -X- _ O
sets -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
such -X- _ O
augmentation -X- _ O
for -X- _ O
text -X- _ O
needs -X- _ O
to -X- _ O
be -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
assumption -X- _ O
of -X- _ O
keeping -X- _ O
the -X- _ O
label -X- _ O
and -X- _ O
the -X- _ O
data -X- _ O
distribution -X- _ O
unchanged -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
often -X- _ O
not -X- _ O
true -X- _ O
in -X- _ O
practice -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
regularization -X- _ O
and -X- _ O
data -X- _ O
augmentation -X- _ O
, -X- _ O
we -X- _ O
leverage -X- _ O
the -X- _ O
support -X- _ O
sets -X- _ O
information -X- _ O
stored -X- _ O
in -X- _ O
the -X- _ O
memory -X- _ O
to -X- _ O
augment -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
. -X- _ O

The -X- _ O
contributions -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
are -X- _ O
: -X- _ O
Meta -X- _ O
- -X- _ O
Learning -X- _ O
. -X- _ O
Meta -X- _ O
- -X- _ O
Learning -X- _ O
aims -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
learning -X- _ O
algorithm -X- _ O
itself -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
previously -X- _ O
learned -X- _ O
experience -X- _ O
( -X- _ O
Thrun -X- _ O
and -X- _ O
Pratt -X- _ O
, -X- _ O
1998;Hospedales -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
general -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
three -X- _ O
categories -X- _ O
of -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
methods -X- _ O
: -X- _ O
model -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
, -X- _ O
( -X- _ O
Santoro -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Obamuyide -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
which -X- _ O
depend -X- _ O
on -X- _ O
the -X- _ O
particular -X- _ O
model -X- _ O
design -X- _ O
to -X- _ O
facilitate -X- _ O
fast -X- _ O
learning -X- _ O
; -X- _ O
metric -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
, -X- _ O
( -X- _ O
Vinyals -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Snell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Geng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
which -X- _ O
encode -X- _ O
samples -X- _ O
into -X- _ O
an -X- _ O
embedding -X- _ O
space -X- _ O
and -X- _ O
classify -X- _ O
them -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
learned -X- _ O
distance -X- _ O
metric -X- _ O
; -X- _ O
optimization -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
( -X- _ O
Finn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Mi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
that -X- _ O
learn -X- _ O
a -X- _ O
wellgeneralized -X- _ O
model -X- _ O
initialization -X- _ O
which -X- _ O
allows -X- _ O
for -X- _ O
fast -X- _ O
adaptation -X- _ O
to -X- _ O
new -X- _ O
tasks -X- _ O
. -X- _ O
For -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
scenarios -X- _ O
in -X- _ O
NLP -X- _ O
, -X- _ O
optimization -X- _ O
- -X- _ O
based -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
methods -X- _ O
achieved -X- _ O
promising -X- _ O
results -X- _ O
on -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
personalized -X- _ O
dialog -X- _ B-TaskName
generation -X- _ I-TaskName
( -X- _ O
Madotto -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
, -X- _ O
lowresource -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
( -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Sharaf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
slot -X- _ B-TaskName
tagging -X- _ I-TaskName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
so -X- _ O
on -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
Memory -X- _ B-MethodName
- -X- _ I-MethodName
Imitation -X- _ I-MethodName
Meta -X- _ I-MethodName
- -X- _ I-MethodName
Learning -X- _ I-MethodName
( -X- _ O
MemIML -X- _ B-MethodName
) -X- _ O
method -X- _ O
that -X- _ O
forces -X- _ O
query -X- _ O
set -X- _ O
predictions -X- _ O
to -X- _ O
depend -X- _ O
on -X- _ O
their -X- _ O
corresponding -X- _ O
support -X- _ O
sets -X- _ O
by -X- _ O
dynamically -X- _ O
imitating -X- _ O
behaviors -X- _ O
of -X- _ O
the -X- _ O
latter -X- _ O
. -X- _ O
We -X- _ O
therefore -X- _ O
, -X- _ O
introduce -X- _ O
a -X- _ O
memory -X- _ O
module -X- _ O
and -X- _ O
an -X- _ O
imitation -X- _ O
module -X- _ O
to -X- _ O
enhance -X- _ O
such -X- _ O
dependence -X- _ O
. -X- _ O
The -X- _ O
memory -X- _ O
module -X- _ O
is -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
, -X- _ O
storing -X- _ O
representative -X- _ O
information -X- _ O
of -X- _ O
support -X- _ O
sets -X- _ O
. -X- _ O
The -X- _ O
imitation -X- _ O
module -X- _ O
assists -X- _ O
in -X- _ O
predicting -X- _ O
samples -X- _ O
of -X- _ O
query -X- _ O
sets -X- _ O
by -X- _ O
dynamically -X- _ O
imitating -X- _ O
the -X- _ O
memory -X- _ O
construction -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
to -X- _ O
access -X- _ O
the -X- _ O
support -X- _ O
set -X- _ O
by -X- _ O
memory -X- _ O
imitation -X- _ O
each -X- _ O
time -X- _ O
it -X- _ O
makes -X- _ O
a -X- _ O
prediction -X- _ O
on -X- _ O
a -X- _ O
query -X- _ O
- -X- _ O
set -X- _ O
sample -X- _ O
, -X- _ O
hence -X- _ O
it -X- _ O
's -X- _ O
no -X- _ O
longer -X- _ O
feasible -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
memorize -X- _ O
all -X- _ O
meta -X- _ O
tasks -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
address -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
issue -X- _ O
by -X- _ O
enhancing -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
dependence -X- _ O
on -X- _ O
support -X- _ O
sets -X- _ O
when -X- _ O
learning -X- _ O
the -X- _ O
model -X- _ O
initialization -X- _ O
, -X- _ O
which -X- _ O
forces -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
better -X- _ O
leverage -X- _ O
information -X- _ O
from -X- _ O
support -X- _ O
sets -X- _ O
. -X- _ O
As -X- _ O
an -X- _ O
analogy -X- _ O
, -X- _ O
consider -X- _ O
a -X- _ O
young -X- _ O
investor -X- _ O
who -X- _ O
has -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
new -X- _ O
circumstances -X- _ O
rapidly -X- _ O
but -X- _ O
little -X- _ O
memory -X- _ O
of -X- _ O
learned -X- _ O
experiences -X- _ O
, -X- _ O
and -X- _ O
an -X- _ O
old -X- _ O
investor -X- _ O
who -X- _ O
is -X- _ O
experienced -X- _ O
but -X- _ O
refuses -X- _ O
to -X- _ O
be -X- _ O
flexible -X- _ O
. -X- _ O
Our -X- _ O
idea -X- _ O
is -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
young -X- _ O
investor -X- _ O
adaptive -X- _ O
to -X- _ O
the -X- _ O
various -X- _ O
situations -X- _ O
when -X- _ O
he -X- _ O
assesses -X- _ O
his -X- _ O
benefits -X- _ O
so -X- _ O
that -X- _ O
he -X- _ O
can -X- _ O
not -X- _ O
only -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
old -X- _ O
one -X- _ O
's -X- _ O
experience -X- _ O
but -X- _ O
also -X- _ O
learn -X- _ O
from -X- _ O
the -X- _ O
old -X- _ O
investor -X- _ O
how -X- _ O
to -X- _ O
leverage -X- _ O
the -X- _ O
learned -X- _ O
experience -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
the -X- _ O
young -X- _ O
investor -X- _ O
stands -X- _ O
for -X- _ O
a -X- _ O
standard -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
algorithm -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
MAML -X- _ B-MethodName
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
prone -X- _ O
to -X- _ O
memorization -X- _ O
overfitting -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
old -X- _ O
investor -X- _ O
is -X- _ O
a -X- _ O
memory -X- _ O
module -X- _ O
we -X- _ O
integrate -X- _ O
into -X- _ O
the -X- _ O
method -X- _ O
, -X- _ O
carrying -X- _ O
information -X- _ O
of -X- _ O
support -X- _ O
sets -X- _ O
. -X- _ O

Several -X- _ O
works -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
to -X- _ O
tackle -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
issue -X- _ O
for -X- _ O
regression -X- _ O
and -X- _ O
image -X- _ O
classification -X- _ O
tasks -X- _ O
. -X- _ O
Some -X- _ O
studies -X- _ O
try -X- _ O
to -X- _ O
explicitly -X- _ O
regularize -X- _ O
the -X- _ O
model -X- _ O
parameters -X- _ O
( -X- _ O
Yin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Rajendran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
this -X- _ O
restricts -X- _ O
the -X- _ O
complexity -X- _ O
of -X- _ O
model -X- _ O
initialization -X- _ O
and -X- _ O
reduces -X- _ O
the -X- _ O
model -X- _ O
capacity -X- _ O
. -X- _ O
Another -X- _ O
line -X- _ O
of -X- _ O
research -X- _ O
integrates -X- _ O
samples -X- _ O
from -X- _ O
support -X- _ O
sets -X- _ O
into -X- _ O
the -X- _ O
corresponding -X- _ O
query -X- _ O
sets -X- _ O
via -X- _ O
data -X- _ O
augmentation -X- _ O
( -X- _ O
Yao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
data -X- _ O
augmentation -X- _ O
on -X- _ O
textual -X- _ O
data -X- _ O
may -X- _ O
result -X- _ O
in -X- _ O
noisy -X- _ O
labels -X- _ O
or -X- _ O
distribution -X- _ O
shifts -X- _ O
, -X- _ O
which -X- _ O
impairs -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Despite -X- _ O
its -X- _ O
effectiveness -X- _ O
, -X- _ O
optimization -X- _ O
- -X- _ O
based -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
algorithms -X- _ O
usually -X- _ O
suffer -X- _ O
from -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
issue -X- _ O
1 -X- _ O
( -X- _ O
Yin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Rajendran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
learned -X- _ O
model -X- _ O
tends -X- _ O
to -X- _ O
solve -X- _ O
all -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
training -X- _ O
tasks -X- _ O
by -X- _ O
memorization -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
learning -X- _ O
how -X- _ O
to -X- _ O
quickly -X- _ O
adapt -X- _ O
from -X- _ O
one -X- _ O
task -X- _ O
to -X- _ O
another -X- _ O
via -X- _ O
support -X- _ O
sets -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
acceptable -X- _ O
for -X- _ O
training -X- _ O
process -X- _ O
, -X- _ O
but -X- _ O
results -X- _ O
in -X- _ O
poor -X- _ O
generalization -X- _ O
on -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
testing -X- _ O
sets -X- _ O
, -X- _ O
because -X- _ O
the -X- _ O
memorized -X- _ O
model -X- _ O
does -X- _ O
not -X- _ O
have -X- _ O
knowledge -X- _ O
of -X- _ O
those -X- _ O
tasks -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
know -X- _ O
how -X- _ O
to -X- _ O
utilize -X- _ O
the -X- _ O
base -X- _ O
learner -X- _ O
to -X- _ O
learn -X- _ O
new -X- _ O
tasks -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
this -X- _ O
issue -X- _ O
hinders -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
capturing -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
characteristics -X- _ O
from -X- _ O
support -X- _ O
sets -X- _ O
and -X- _ O
thus -X- _ O
prevents -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
adapting -X- _ O
to -X- _ O
distinct -X- _ O
new -X- _ O
tasks -X- _ O
( -X- _ O
Rajendran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
in -X- _ O
personalized -X- _ B-TaskName
dialogue -X- _ I-TaskName
generation -X- _ I-TaskName
, -X- _ O
this -X- _ O
implies -X- _ O
that -X- _ O
the -X- _ O
dialog -X- _ O
model -X- _ O
can -X- _ O
not -X- _ O
adapt -X- _ O
to -X- _ O
individual -X- _ O
users -X- _ O
based -X- _ O
on -X- _ O
short -X- _ O
conversation -X- _ O
histories -X- _ O
and -X- _ O
hence -X- _ O
fails -X- _ O
to -X- _ O
generate -X- _ O
personalized -X- _ O
responses -X- _ O
. -X- _ O

Among -X- _ O
different -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
approaches -X- _ O
( -X- _ O
Hospedales -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
optimization -X- _ O
- -X- _ O
based -X- _ O
ap -X- _ O
- -X- _ O
proaches -X- _ O
have -X- _ O
been -X- _ O
widely -X- _ O
used -X- _ O
in -X- _ O
various -X- _ O
lowresource -X- _ O
NLP -X- _ O
scenarios -X- _ O
( -X- _ O
Madotto -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Qian -X- _ O
and -X- _ O
Yu -X- _ O
, -X- _ O
2019;Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Mi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
because -X- _ O
they -X- _ O
are -X- _ O
model -X- _ O
- -X- _ O
agnostic -X- _ O
and -X- _ O
easily -X- _ O
applicable -X- _ O
. -X- _ O
Concretely -X- _ O
, -X- _ O
optimization -X- _ O
- -X- _ O
based -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
algorithms -X- _ O
aim -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
well -X- _ O
- -X- _ O
generalized -X- _ O
global -X- _ O
model -X- _ O
initialization -X- _ O
θ -X- _ O
that -X- _ O
can -X- _ O
quickly -X- _ O
adapt -X- _ O
to -X- _ O
new -X- _ O
tasks -X- _ O
within -X- _ O
a -X- _ O
few -X- _ O
steps -X- _ O
of -X- _ O
gradient -X- _ O
updates -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
training -X- _ O
process -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
train -X- _ O
θ -X- _ O
on -X- _ O
a -X- _ O
support -X- _ O
set -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
a -X- _ O
few -X- _ O
training -X- _ O
samples -X- _ O
of -X- _ O
a -X- _ O
new -X- _ O
task -X- _ O
i -X- _ O
) -X- _ O
to -X- _ O
obtain -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
parameters -X- _ O
θ -X- _ O
i -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
optimize -X- _ O
θ -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
θ -X- _ O
i -X- _ O
on -X- _ O
a -X- _ O
query -X- _ O
set -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
another -X- _ O
set -X- _ O
of -X- _ O
samples -X- _ O
in -X- _ O
task -X- _ O
i -X- _ O
) -X- _ O
. -X- _ O

Figure -X- _ O
20 -X- _ O
: -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
varying -X- _ O
amounts -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
pre -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
training -X- _ I-HyperparameterName
data -X- _ I-HyperparameterName
( -X- _ O
the -X- _ O
full -X- _ O
result -X- _ O
of -X- _ O
Fig -X- _ O
. -X- _ O
7).This -X- _ O
work -X- _ O
is -X- _ O
supported -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
ARC -X- _ O
DP21010347 -X- _ O
, -X- _ O
ARC -X- _ O
DP180100966 -X- _ O
and -X- _ O
Facebook -X- _ O
Research -X- _ O
. -X- _ O
Joey -X- _ O
Tianyi -X- _ O
Zhou -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
A*STAR -X- _ O
SERC -X- _ O
Central -X- _ O
Research -X- _ O
Fund -X- _ O
( -X- _ O
Useinspired -X- _ O
Basic -X- _ O
Research -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
constructive -X- _ O
suggestions -X- _ O
. -X- _ O
We -X- _ O
thank -X- _ O
Smashicons -X- _ O
and -X- _ O
Trazobanana -X- _ O
for -X- _ O
providing -X- _ O
the -X- _ O
icons -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
1.The -X- _ O
appendix -X- _ O
is -X- _ O
organized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
Sec -X- _ O
. -X- _ O
A -X- _ O
details -X- _ O
the -X- _ O
environment -X- _ O
. -X- _ O
Sec -X- _ O
. -X- _ O
B -X- _ O
illustrates -X- _ O
the -X- _ O
process -X- _ O
for -X- _ O
constructing -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
datasets -X- _ O
. -X- _ O
Sec -X- _ O
. -X- _ O
C -X- _ O
demonstrates -X- _ O
the -X- _ O
baselines -X- _ O
' -X- _ O
architecture -X- _ O
and -X- _ O
training -X- _ O
details -X- _ O
. -X- _ O
Sec -X- _ O
. -X- _ O
D -X- _ O
provides -X- _ O
more -X- _ O
experimental -X- _ O
results -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
cooking -X- _ B-TaskName
game -X- _ I-TaskName
, -X- _ O
the -X- _ O
player -X- _ O
is -X- _ O
located -X- _ O
in -X- _ O
a -X- _ O
house -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
multiple -X- _ O
rooms -X- _ O
and -X- _ O
interactable -X- _ O
objects -X- _ O
( -X- _ O
food -X- _ O
, -X- _ O
tools -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O
Her -X- _ O
/ -X- _ O
his -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
follow -X- _ O
the -X- _ O
recipe -X- _ O
to -X- _ O
prepare -X- _ O
the -X- _ O
meal -X- _ O
. -X- _ O
Each -X- _ O
game -X- _ O
instance -X- _ O
has -X- _ O
a -X- _ O
unique -X- _ O
recipe -X- _ O
, -X- _ O
including -X- _ O
different -X- _ O
numbers -X- _ O
of -X- _ O
ingredients -X- _ O
( -X- _ O
food -X- _ O
objects -X- _ O
that -X- _ O
are -X- _ O
necessary -X- _ O
for -X- _ O
preparing -X- _ O
the -X- _ O
meal -X- _ O
) -X- _ O
and -X- _ O
their -X- _ O
corresponding -X- _ O
preparation -X- _ O
requirements -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
slice -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fry -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O
Besides -X- _ O
the -X- _ O
textual -X- _ O
observation -X- _ O
, -X- _ O
the -X- _ O
KG -X- _ O
- -X- _ O
based -X- _ O
observation -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
directly -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
environment -X- _ O
. -X- _ O
The -X- _ O
game -X- _ O
sets -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
work -X- _ O
contains -X- _ O
a -X- _ O
task -X- _ O
set -X- _ O
T -X- _ O
of -X- _ O
268 -X- _ B-HyperparameterValue
subtasks -X- _ B-HyperparameterName
, -X- _ O
and -X- _ O
an -X- _ O
action -X- _ O
set -X- _ O
A -X- _ O
of -X- _ O
1304 -X- _ B-HyperparameterValue
actions -X- _ B-HyperparameterName
. -X- _ O
Following -X- _ O
GATA -X- _ B-MethodName
's -X- _ O
experiment -X- _ O
setting -X- _ O
( -X- _ O
Adhikari -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
simplify -X- _ O
the -X- _ O
game -X- _ O
environment -X- _ O
by -X- _ O
making -X- _ O
the -X- _ O
action -X- _ O
set -X- _ O
changeable -X- _ O
over -X- _ O
time -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
TextWorld -X- _ O
platform -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
although -X- _ O
the -X- _ O
action -X- _ O
space -X- _ O
is -X- _ O
reduced -X- _ O
, -X- _ O
it -X- _ O
still -X- _ O
remains -X- _ O
challenging -X- _ O
as -X- _ O
the -X- _ O
agent -X- _ O
may -X- _ O
encounter -X- _ O
unseen -X- _ O
action -X- _ O
candidates -X- _ O
( -X- _ O
Chandak -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019(Chandak -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2020 -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
use -X- _ O
a -X- _ O
similar -X- _ O
way -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
changeable -X- _ O
task -X- _ O
set -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
the -X- _ O
verb -X- _ O
set -X- _ O
{ -X- _ O
chop -X- _ O
, -X- _ O
dice -X- _ O
, -X- _ O
slice -X- _ O
, -X- _ O
fry -X- _ O
, -X- _ O
make -X- _ O
, -X- _ O
get -X- _ O
, -X- _ O
grill -X- _ O
, -X- _ O
roast -X- _ O
} -X- _ O
and -X- _ O
the -X- _ O
ingredient -X- _ O
set -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
construction -X- _ O
details -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O
Table -X- _ O
4 -X- _ O
and -X- _ O
Table -X- _ O
5 -X- _ O
show -X- _ O
the -X- _ O
KG -X- _ O
- -X- _ O
based -X- _ O
observations -X- _ O
o -X- _ O
t -X- _ O
, -X- _ O
corresponding -X- _ O
subtask -X- _ O
candidates -X- _ O
T -X- _ O
and -X- _ O
action -X- _ O
candidates -X- _ O
A. -X- _ O
Table -X- _ O
6 -X- _ O
and -X- _ O
Table -X- _ O
7 -X- _ O
show -X- _ O
more -X- _ O
examples -X- _ O
of -X- _ O
subtasks -X- _ O
and -X- _ O
actions -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
underlined -X- _ O
subtask -X- _ O
candidates -X- _ O
denote -X- _ O
the -X- _ O
available -X- _ O
subtask -X- _ O
set -X- _ O
T -X- _ O
t -X- _ O
. -X- _ O
The -X- _ O
underlined -X- _ O
action -X- _ O
candidates -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
denote -X- _ O
the -X- _ O
refined -X- _ O
action -X- _ O
set -X- _ O
A -X- _ O
t -X- _ O
after -X- _ O
selecting -X- _ O
the -X- _ O
subtask -X- _ O
" -X- _ O
roast -X- _ O
carrot -X- _ O
" -X- _ O
. -X- _ O
We -X- _ O
still -X- _ O
denote -X- _ O
the -X- _ O
subtask -X- _ O
candidate -X- _ O
set -X- _ O
( -X- _ O
action -X- _ O
candidate -X- _ O
set -X- _ O
) -X- _ O
as -X- _ O
T -X- _ O
( -X- _ O
A -X- _ O
) -X- _ O
to -X- _ O
distinguish -X- _ O
it -X- _ O
from -X- _ O
the -X- _ O
available -X- _ O
subtask -X- _ O
set -X- _ O
T -X- _ O
t -X- _ O
( -X- _ O
refined -X- _ O
action -X- _ O
set -X- _ O
A -X- _ O
t -X- _ O
) -X- _ O
.We -X- _ O
build -X- _ O
separate -X- _ O
datasets -X- _ O
for -X- _ O
each -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
task -X- _ O
( -X- _ O
task -X- _ O
decomposition -X- _ O
, -X- _ O
action -X- _ O
pruning -X- _ O
, -X- _ O
and -X- _ O
imitation -X- _ O
learning -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
let -X- _ O
the -X- _ O
player -X- _ O
to -X- _ O
go -X- _ O
through -X- _ O
each -X- _ O
simple -X- _ O
game -X- _ O
, -X- _ O
then -X- _ O
construct -X- _ O
the -X- _ O
datasets -X- _ O
upon -X- _ O
the -X- _ O
interaction -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
, -X- _ O
the -X- _ O
game -X- _ O
environment -X- _ O
provides -X- _ O
the -X- _ O
player -X- _ O
with -X- _ O
the -X- _ O
action -X- _ O
set -X- _ O
A -X- _ O
and -X- _ O
the -X- _ O
KG -X- _ O
- -X- _ O
based -X- _ O
observation -X- _ O
o -X- _ O
t -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
represented -X- _ O
as -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
triplets -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
simple -X- _ O
method -X- _ O
to -X- _ O
build -X- _ O
the -X- _ O
subtask -X- _ O
set -X- _ O
T -X- _ O
from -X- _ O
o -X- _ O
t -X- _ O
: -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
8 -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
obtain -X- _ O
the -X- _ O
ingredients -X- _ O
by -X- _ O
extracting -X- _ O
the -X- _ O
nodes -X- _ O
having -X- _ O
the -X- _ O
relation -X- _ O
" -X- _ O
part_of -X- _ O
" -X- _ O
with -X- _ O
the -X- _ O
node -X- _ O
" -X- _ O
cookbook -X- _ O
" -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
build -X- _ O
T -X- _ O
as -X- _ O
the -X- _ O
Cartesian -X- _ O
product -X- _ O
of -X- _ O
the -X- _ O
ingredients -X- _ O
and -X- _ O
the -X- _ O
verbs -X- _ O
{ -X- _ O
chop -X- _ O
, -X- _ O
dice -X- _ O
, -X- _ O
slice -X- _ O
, -X- _ O
fry -X- _ O
, -X- _ O
get -X- _ O
, -X- _ O
grill -X- _ O
, -X- _ O
roast -X- _ O
} -X- _ O
plus -X- _ O
two -X- _ O
special -X- _ O
subtasks -X- _ O
" -X- _ O
get -X- _ O
knife -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
make -X- _ O
meal -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
player -X- _ O
is -X- _ O
required -X- _ O
to -X- _ O
select -X- _ O
a -X- _ O
subtask -X- _ O
T -X- _ O
t -X- _ O
∈ -X- _ O
T -X- _ O
, -X- _ O
and -X- _ O
select -X- _ O
an -X- _ O
action -X- _ O
a -X- _ O
t -X- _ O
∈ -X- _ O
A. -X- _ O
After -X- _ O
executing -X- _ O
a -X- _ O
t -X- _ O
, -X- _ O
the -X- _ O
environment -X- _ O
will -X- _ O
transit -X- _ O
to -X- _ O
next -X- _ O
state -X- _ O
s -X- _ O
t+1 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
player -X- _ O
will -X- _ O
receive -X- _ O
o -X- _ O
t+1 -X- _ O
and -X- _ O
r -X- _ O
t+1 -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
transition -X- _ O
{ -X- _ O
o -X- _ O
t -X- _ O
, -X- _ O
T -X- _ O
, -X- _ O
T -X- _ O
t -X- _ O
, -X- _ O
A -X- _ O
, -X- _ O
a -X- _ O
t -X- _ O
, -X- _ O
o -X- _ O
t+1 -X- _ O
, -X- _ O
r -X- _ O
t+1 -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O
{ -X- _ O
o -X- _ O
t -X- _ O
, -X- _ O
T -X- _ O
, -X- _ O
T -X- _ O
t -X- _ O
, -X- _ O
A -X- _ O
, -X- _ O
a -X- _ O
t -X- _ O
} -X- _ O
will -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
imitation -X- _ O
learning -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
8 -X- _ O
shows -X- _ O
the -X- _ O
construction -X- _ O
process -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
dataset -X- _ O
for -X- _ O
task -X- _ O
decomposition -X- _ O
. -X- _ O
Each -X- _ O
subtask -X- _ O
candidate -X- _ O
T -X- _ O
∈ -X- _ O
T -X- _ O
will -X- _ O
formulate -X- _ O
a -X- _ O
question -X- _ O
" -X- _ O
Is -X- _ O
T -X- _ O
available -X- _ O
? -X- _ O
" -X- _ O
, -X- _ O
whose -X- _ O
answer -X- _ O
is -X- _ O
1 -X- _ O
( -X- _ O
yes -X- _ O
) -X- _ O
if -X- _ O
T -X- _ O
is -X- _ O
an -X- _ O
available -X- _ O
subtask -X- _ O
for -X- _ O
o -X- _ O
t -X- _ O
, -X- _ O
otherwise -X- _ O
0 -X- _ O
( -X- _ O
no -X- _ O
) -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
9 -X- _ O
shows -X- _ O
the -X- _ O
construction -X- _ O
process -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
dataset -X- _ O
for -X- _ O
action -X- _ O
pruning -X- _ O
. -X- _ O
The -X- _ O
action -X- _ O
selector -X- _ O
is -X- _ O
made -X- _ O
invariant -X- _ O
of -X- _ O
o -X- _ O
t -X- _ O
, -X- _ O
that -X- _ O
we -X- _ O
consider -X- _ O
every -X- _ O
subtask -X- _ O
candidate -X- _ O
T -X- _ O
∈ -X- _ O
T -X- _ O
during -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
regardless -X- _ O
of -X- _ O
whether -X- _ O
T -X- _ O
is -X- _ O
a -X- _ O
currently -X- _ O
- -X- _ O
available -X- _ O
subtask -X- _ O
. -X- _ O
Each -X- _ O
action -X- _ O
candidate -X- _ O
a -X- _ O
∈ -X- _ O
A -X- _ O
will -X- _ O
be -X- _ O
paired -X- _ O
with -X- _ O
T -X- _ O
to -X- _ O
formulate -X- _ O
a -X- _ O
question -X- _ O
" -X- _ O
Is -X- _ O
a -X- _ O
relevant -X- _ O
to -X- _ O
T -X- _ O
" -X- _ O
, -X- _ O
whose -X- _ O
answer -X- _ O
is -X- _ O
1 -X- _ O
if -X- _ O
a -X- _ O
is -X- _ O
relevant -X- _ O
to -X- _ O
T -X- _ O
, -X- _ O
otherwise -X- _ O
0 -X- _ O
. -X- _ O
Building -X- _ O
models -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
is -X- _ O
challenging -X- _ O
in -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
scenarios -X- _ O
where -X- _ O
only -X- _ O
limited -X- _ O
data -X- _ O
are -X- _ O
available -X- _ O
. -X- _ O
Optimization -X- _ O
- -X- _ O
based -X- _ O
meta -X- _ O
- -X- _ O
learning -X- _ O
algorithms -X- _ O
achieve -X- _ O
promising -X- _ O
results -X- _ O
in -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
scenarios -X- _ O
by -X- _ O
adapting -X- _ O
a -X- _ O
well -X- _ O
- -X- _ O
generalized -X- _ O
model -X- _ O
initialization -X- _ O
to -X- _ O
handle -X- _ O
new -X- _ O
tasks -X- _ O
. -X- _ O
Nonetheless -X- _ O
, -X- _ O
these -X- _ O
approaches -X- _ O
suffer -X- _ O
from -X- _ O
the -X- _ O
memorization -X- _ O
overfitting -X- _ O
issue -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
model -X- _ O
tends -X- _ O
to -X- _ O
memorize -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
training -X- _ O
tasks -X- _ O
while -X- _ O
ignoring -X- _ O
support -X- _ O
sets -X- _ O
when -X- _ O
adapting -X- _ O
to -X- _ O
new -X- _ O
tasks -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
memory -X- _ B-MethodName
imitation -X- _ I-MethodName
meta -X- _ I-MethodName
- -X- _ I-MethodName
learning -X- _ I-MethodName
( -X- _ O
MemIML -X- _ B-MethodName
) -X- _ O
method -X- _ O
that -X- _ O
enhances -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
reliance -X- _ O
on -X- _ O
support -X- _ O
sets -X- _ O
for -X- _ O
task -X- _ O
adaptation -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
memory -X- _ O
module -X- _ O
to -X- _ O
store -X- _ O
support -X- _ O
set -X- _ O
information -X- _ O
and -X- _ O
construct -X- _ O
an -X- _ O
imitation -X- _ O
module -X- _ O
to -X- _ O
force -X- _ O
query -X- _ O
sets -X- _ O
to -X- _ O
imitate -X- _ O
the -X- _ O
behaviors -X- _ O
of -X- _ O
some -X- _ O
representative -X- _ O
supportset -X- _ O
samples -X- _ O
stored -X- _ O
in -X- _ O
the -X- _ O
memory -X- _ O
. -X- _ O
A -X- _ O
theoretical -X- _ O
analysis -X- _ O
is -X- _ O
provided -X- _ O
to -X- _ O
prove -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
, -X- _ O
and -X- _ O
empirical -X- _ O
results -X- _ O
also -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
outperforms -X- _ O
competitive -X- _ O
baselines -X- _ O
on -X- _ O
both -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
and -X- _ O
generation -X- _ B-TaskName
tasks -X- _ O
. -X- _ O

Figure -X- _ O
19 -X- _ O
: -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
variants -X- _ O
with -X- _ O
expert -X- _ O
modules -X- _ O
( -X- _ O
the -X- _ O
full -X- _ O
result -X- _ O
of -X- _ O
Fig -X- _ O
. -X- _ O
6 -X- _ O
) -X- _ O
. -X- _ O

Figure -X- _ O
18 -X- _ O
: -X- _ O
The -X- _ O
RL -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
variant -X- _ O
without -X- _ O
time -X- _ O
- -X- _ O
awareness -X- _ O
( -X- _ O
the -X- _ O
full -X- _ O
result -X- _ O
of -X- _ O
Fig -X- _ O
. -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
the -X- _ O
GATA -X- _ B-MethodName
through -X- _ O
reinforcement -X- _ O
learning -X- _ O
, -X- _ O
the -X- _ O
experiment -X- _ O
setting -X- _ O
is -X- _ O
same -X- _ O
with -X- _ O
Sec -X- _ O
. -X- _ O
5.3 -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
initializing -X- _ O
the -X- _ O
word -X- _ O
embedding -X- _ O
, -X- _ O
node -X- _ O
embedding -X- _ O
and -X- _ O
edge -X- _ O
embedding -X- _ O
with -X- _ O
fastText -X- _ O
word -X- _ O
vectors -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
action -X- _ B-HyperparameterValue
prediction -X- _ I-HyperparameterValue
task -X- _ I-HyperparameterValue
( -X- _ O
AP -X- _ B-HyperparameterValue
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
also -X- _ O
included -X- _ O
in -X- _ O
GATA -X- _ B-MethodName
's -X- _ O
work -X- _ O
( -X- _ O
Adhikari -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
could -X- _ O
provide -X- _ O
better -X- _ O
initialization -X- _ B-HyperparameterName
. -X- _ O
In -X- _ O
light -X- _ O
of -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
could -X- _ O
like -X- _ O
to -X- _ O
conduct -X- _ O
such -X- _ O
task -X- _ O
, -X- _ O
and -X- _ O
apply -X- _ O
the -X- _ O
AP -X- _ B-HyperparameterValue
initialization -X- _ B-HyperparameterName
to -X- _ O
all -X- _ O
encoders -X- _ O
( -X- _ O
observation -X- _ O
encoder -X- _ O
, -X- _ O
task -X- _ O
encoder -X- _ O
, -X- _ O
action -X- _ O
encoder -X- _ O
) -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
11 -X- _ O
shows -X- _ O
the -X- _ O
action -X- _ O
predicting -X- _ O
process -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
transition -X- _ O
data -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
action -X- _ O
a -X- _ O
t -X- _ O
∈ -X- _ O
A -X- _ O
given -X- _ O
the -X- _ O
current -X- _ O
observation -X- _ O
o -X- _ O
t -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
next -X- _ O
observation -X- _ O
o -X- _ O
t+1 -X- _ O
after -X- _ O
executing -X- _ O
a -X- _ O
t -X- _ O
. -X- _ O
The -X- _ O
transition -X- _ O
data -X- _ O
for -X- _ O
AP -X- _ O
task -X- _ O
is -X- _ O
collected -X- _ O
from -X- _ O
the -X- _ O
FTWP -X- _ B-DatasetName
game -X- _ I-DatasetName
set -X- _ I-DatasetName
and -X- _ O
is -X- _ O
provided -X- _ O
by -X- _ O
GATA -X- _ B-MethodName
's -X- _ O
released -X- _ O
code -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
12 -X- _ O
shows -X- _ O
the -X- _ O
IL -X- _ B-MethodName
baseline -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
to -X- _ O
conduct -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
phase -X- _ O
training -X- _ O
process -X- _ O
: -X- _ O
imitation -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
reinforcement -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
imitation -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
transition -X- _ O
data -X- _ O
to -X- _ O
train -X- _ O
both -X- _ O
the -X- _ O
task -X- _ O
selector -X- _ O
( -X- _ O
f -X- _ O
( -X- _ O
o -X- _ O
t -X- _ O
, -X- _ O
T -X- _ O
) -X- _ O
→ -X- _ O
T -X- _ O
t -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
action -X- _ O
selector -X- _ O
( -X- _ O
f -X- _ O
( -X- _ O
o -X- _ O
t -X- _ O
, -X- _ O
T -X- _ O
t -X- _ O
, -X- _ O
A -X- _ O
) -X- _ O
→ -X- _ O
a -X- _ O
t -X- _ O
) -X- _ O
through -X- _ O
supervised -X- _ O
learning -X- _ O
. -X- _ O
The -X- _ O
modules -X- _ O
are -X- _ O
optimized -X- _ O
via -X- _ O
cross -X- _ B-HyperparameterValue
entropy -X- _ I-HyperparameterValue
loss -X- _ B-HyperparameterName
and -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
with -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
0.001 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
train -X- _ O
the -X- _ O
modules -X- _ O
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
128 -X- _ B-HyperparameterValue
for -X- _ O
up -X- _ O
to -X- _ O
50 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O
Then -X- _ O
in -X- _ O
the -X- _ O
reinforcement -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
phase -X- _ O
, -X- _ O
we -X- _ O
freeze -X- _ O
the -X- _ O
task -X- _ O
selector -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
action -X- _ O
selector -X- _ O
through -X- _ O
reinforcement -X- _ O
learning -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
experiment -X- _ O
setting -X- _ O
is -X- _ O
same -X- _ O
with -X- _ O
QWA -X- _ B-MethodName
and -X- _ O
GATA -X- _ B-MethodName
. -X- _ O
In -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
rough -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
tuning -X- _ O
by -X- _ O
varying -X- _ O
batch -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
. -X- _ O
Fig -X- _ O
. -X- _ O
13 -X- _ O
and -X- _ O
Fig -X- _ O
. -X- _ O
14 -X- _ O
show -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
performance -X- _ O
of -X- _ O
QWA -X- _ B-MethodName
's -X- _ O
task -X- _ O
selector -X- _ O
and -X- _ O
action -X- _ O
validator -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
15 -X- _ O
shows -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
performance -X- _ O
of -X- _ O
IL -X- _ O
baseline -X- _ O
. -X- _ O
Figure -X- _ O
17 -X- _ O
: -X- _ O
The -X- _ O
RL -X- _ O
performance -X- _ O
of -X- _ O
models -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
training -X- _ O
episodes -X- _ O
( -X- _ O
the -X- _ O
full -X- _ O
result -X- _ O
of -X- _ O
Fig -X- _ O
. -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O

Building -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
models -X- _ O
in -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
scenarios -X- _ O
is -X- _ O
of -X- _ O
great -X- _ O
importance -X- _ O
in -X- _ O
practical -X- _ O
applications -X- _ O
because -X- _ O
labeled -X- _ O
data -X- _ O
are -X- _ O
scarce -X- _ O
. -X- _ O
Meta -X- _ O
- -X- _ O
learning -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
( -X- _ O
Thrun -X- _ O
and -X- _ O
Pratt -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
have -X- _ O
been -X- _ O
commonly -X- _ O
used -X- _ O
in -X- _ O
such -X- _ O
scenarios -X- _ O
owing -X- _ O
to -X- _ O
their -X- _ O
fast -X- _ O
adaptation -X- _ O
ability -X- _ O
. -X- _ O
Notable -X- _ O
successes -X- _ O
have -X- _ O
been -X- _ O
achieved -X- _ O
by -X- _ O
metalearning -X- _ O
on -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
multidomain -X- _ B-TaskName
sentiment -X- _ I-TaskName
classification -X- _ I-TaskName
( -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Geng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
personalized -X- _ B-TaskName
dialogue -X- _ I-TaskName
generation -X- _ I-TaskName
( -X- _ O
Madotto -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

A -X- _ O
possible -X- _ O
reason -X- _ O
is -X- _ O
that -X- _ O
there -X- _ O
exists -X- _ O
large -X- _ O
domain -X- _ O
gap -X- _ O
between -X- _ O
simple -X- _ O
and -X- _ O
medium -X- _ O
( -X- _ O
hard -X- _ O
) -X- _ O
games -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
more -X- _ O
robust -X- _ O
against -X- _ O
such -X- _ O
domain -X- _ O
shifts -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
our -X- _ O
world -X- _ O
- -X- _ O
perceiving -X- _ O
task -X- _ O
selector -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
IL -X- _ O
- -X- _ O
based -X- _ O
task -X- _ O
selector -X- _ O
in -X- _ O
handling -X- _ O
more -X- _ O
complex -X- _ O
observations -X- _ O
( -X- _ O
according -X- _ O
to -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
observations -X- _ O
in -X- _ O
medium -X- _ O
/ -X- _ O
hard -X- _ O
games -X- _ O
contain -X- _ O
more -X- _ O
triplets -X- _ O
, -X- _ O
rooms -X- _ O
and -X- _ O
objects -X- _ O
) -X- _ O
, -X- _ O
facilitating -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
action -X- _ O
selector -X- _ O
. -X- _ O
Besides -X- _ O
the -X- _ O
domain -X- _ O
gap -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
observation -X- _ O
space -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
also -X- _ O
a -X- _ O
gap -X- _ O
between -X- _ O
domains -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
available -X- _ O
subtasks -X- _ O
− -X- _ O
while -X- _ O
there -X- _ O
's -X- _ O
always -X- _ O
one -X- _ O
available -X- _ O
subtask -X- _ O
per -X- _ O
time -X- _ O
step -X- _ O
in -X- _ O
simple -X- _ O
games -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
will -X- _ O
face -X- _ O
more -X- _ O
available -X- _ O
subtasks -X- _ O
in -X- _ O
the -X- _ O
medium -X- _ O
/ -X- _ O
hard -X- _ O
games -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
our -X- _ O
task -X- _ O
selector -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
check -X- _ O
the -X- _ O
availability -X- _ O
of -X- _ O
every -X- _ O
subtask -X- _ O
candidate -X- _ O
, -X- _ O
the -X- _ O
IL -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
task -X- _ O
selector -X- _ O
can -X- _ O
not -X- _ O
adapt -X- _ O
well -X- _ O
in -X- _ O
this -X- _ O
situation -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
unique -X- _ O
subtask -X- _ O
and -X- _ O
ignore -X- _ O
the -X- _ O
other -X- _ O
subtask -X- _ O
candidates -X- _ O
despite -X- _ O
whether -X- _ O
they -X- _ O
are -X- _ O
also -X- _ O
available -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
investigate -X- _ O
the -X- _ O
generalization -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
simple -X- _ O
games -X- _ O
, -X- _ O
considering -X- _ O
that -X- _ O
simple -X- _ O
games -X- _ O
are -X- _ O
not -X- _ O
engaged -X- _ O
in -X- _ O
our -X- _ O
RL -X- _ O
training -X- _ O
. -X- _ O
To -X- _ O
conduct -X- _ O
the -X- _ O
experiment -X- _ O
, -X- _ O
after -X- _ O
RL -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
deploy -X- _ O
all -X- _ O
models -X- _ O
on -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
140 -X- _ B-HyperparameterValue
held -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
out -X- _ I-HyperparameterName
sim- -X- _ O
ple -X- _ O
games -X- _ O
for -X- _ O
RL -X- _ O
interaction -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
, -X- _ O
where -X- _ O
" -X- _ O
Medium -X- _ O
100 -X- _ O
% -X- _ O
" -X- _ O
( -X- _ O
" -X- _ O
Hard -X- _ O
100 -X- _ O
% -X- _ O
" -X- _ O
) -X- _ O
denotes -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
medium -X- _ O
( -X- _ O
hard -X- _ O
) -X- _ O
games -X- _ O
for -X- _ O
the -X- _ O
whole -X- _ O
RL -X- _ O
phase -X- _ O
. -X- _ O
The -X- _ O
generalizability -X- _ O
of -X- _ O
GATA -X- _ B-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
trained -X- _ O
purely -X- _ O
with -X- _ O
medium -X- _ O
and -X- _ O
hard -X- _ O
games -X- _ O
, -X- _ O
is -X- _ O
significantly -X- _ O
low -X- _ O
and -X- _ O
can -X- _ O
not -X- _ O
perform -X- _ O
well -X- _ O
on -X- _ O
simple -X- _ O
games -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
performs -X- _ O
very -X- _ O
well -X- _ O
and -X- _ O
achieves -X- _ O
over -X- _ O
80 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
the -X- _ O
scores -X- _ B-MetricName
. -X- _ O
The -X- _ O
world -X- _ O
- -X- _ O
perceiving -X- _ O
modules -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
simple -X- _ O
games -X- _ O
, -X- _ O
help -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
decision -X- _ O
module -X- _ O
that -X- _ O
adapts -X- _ O
well -X- _ O
on -X- _ O
unseen -X- _ O
games -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
not -X- _ O
surprising -X- _ O
that -X- _ O
the -X- _ O
variant -X- _ O
" -X- _ O
IL -X- _ B-MethodName
w/o -X- _ I-MethodName
FT -X- _ I-MethodName
" -X- _ O
also -X- _ O
performs -X- _ O
well -X- _ O
on -X- _ O
simple -X- _ O
games -X- _ O
, -X- _ O
since -X- _ O
they -X- _ O
are -X- _ O
only -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
simple -X- _ O
games -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
indicated -X- _ O
by -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
" -X- _ O
IL -X- _ B-MethodName
" -X- _ O
, -X- _ O
after -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
medium -X- _ O
/ -X- _ O
hard -X- _ O
games -X- _ O
( -X- _ O
recalling -X- _ O
Sec -X- _ O
. -X- _ O
6.1 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
action -X- _ O
scorer -X- _ O
" -X- _ O
forgets -X- _ O
" -X- _ O
the -X- _ O
experience -X- _ O
/ -X- _ O
skills -X- _ O
dealing -X- _ O
with -X- _ O
simple -X- _ O
games -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
fails -X- _ O
to -X- _ O
generalize -X- _ O
on -X- _ O
unseen -X- _ O
simple -X- _ O
games -X- _ O
. -X- _ O
In -X- _ O
summary -X- _ O
, -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
achieved -X- _ O
by -X- _ O
QWA -X- _ B-MethodName
demonstrates -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
can -X- _ O
generalize -X- _ O
well -X- _ O
on -X- _ O
games -X- _ O
with -X- _ O
different -X- _ O
complexities -X- _ O
. -X- _ O
We -X- _ O
study -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
the -X- _ O
subtask -X- _ O
timeawareness -X- _ O
by -X- _ O
comparing -X- _ O
our -X- _ O
full -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
variant -X- _ O
without -X- _ O
this -X- _ O
technique -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
result -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
models -X- _ O
perform -X- _ O
similarly -X- _ O
in -X- _ O
the -X- _ O
medium -X- _ O
games -X- _ O
, -X- _ O
the -X- _ O
full -X- _ O
model -X- _ O
shows -X- _ O
better -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
hard -X- _ O
games -X- _ O
, -X- _ O
where -X- _ O
there -X- _ O
may -X- _ O
exist -X- _ O
more -X- _ O
difficult -X- _ O
subtasks -X- _ O
( -X- _ O
we -X- _ O
regard -X- _ O
a -X- _ O
subtask -X- _ O
more -X- _ O
difficult -X- _ O
if -X- _ O
it -X- _ O
requires -X- _ O
more -X- _ O
actions -X- _ O
to -X- _ O
be -X- _ O
completed -X- _ O
) -X- _ O
. -X- _ O
Assigning -X- _ O
each -X- _ O
subtask -X- _ O
a -X- _ O
time -X- _ O
limit -X- _ O
prevents -X- _ O
the -X- _ O
agent -X- _ O
from -X- _ O
pursuing -X- _ O
a -X- _ O
too -X- _ O
difficult -X- _ O
subtask -X- _ O
, -X- _ O
and -X- _ O
improves -X- _ O
subtask -X- _ O
diversity -X- _ O
by -X- _ O
encouraging -X- _ O
the -X- _ O
agent -X- _ O
to -X- _ O
try -X- _ O
different -X- _ O
subtasks -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
it -X- _ O
prevents -X- _ O
the -X- _ O
agent -X- _ O
from -X- _ O
being -X- _ O
stuck -X- _ O
in -X- _ O
a -X- _ O
wrong -X- _ O
subtask -X- _ O
, -X- _ O
making -X- _ O
the -X- _ O
agent -X- _ O
more -X- _ O
robust -X- _ O
to -X- _ O
the -X- _ O
compound -X- _ O
error -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
investigate -X- _ O
the -X- _ O
performance -X- _ O
upper -X- _ O
bound -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
by -X- _ O
comparing -X- _ O
our -X- _ O
model -X- _ O
to -X- _ O
variants -X- _ O
with -X- _ O
oracle -X- _ O
world -X- _ O
- -X- _ O
perceiving -X- _ O
modules -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
6 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
, -X- _ O
where -X- _ O
" -X- _ O
+ -X- _ B-HyperparameterValue
expTS -X- _ I-HyperparameterValue
" -X- _ O
( -X- _ O
" -X- _ O
+ -X- _ B-HyperparameterValue
expAV -X- _ I-HyperparameterValue
" -X- _ O
) -X- _ O
denotes -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
uses -X- _ O
an -X- _ O
expert -X- _ O
task -X- _ B-HyperparameterName
selector -X- _ I-HyperparameterName
( -X- _ O
action -X- _ B-HyperparameterName
validator -X- _ I-HyperparameterName
) -X- _ O
. -X- _ O
There -X- _ O
's -X- _ O
still -X- _ O
space -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
modules -X- _ O
. -X- _ O
The -X- _ O
variant -X- _ O
" -X- _ O
QWA -X- _ B-MethodName
+ -X- _ I-MethodName
expTS -X- _ I-MethodName
+ -X- _ I-MethodName
expAV -X- _ I-MethodName
" -X- _ O
solves -X- _ O
all -X- _ O
the -X- _ O
medium -X- _ O
games -X- _ O
and -X- _ O
achieves -X- _ O
nearly -X- _ O
80 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
the -X- _ O
scores -X- _ B-MetricName
in -X- _ O
hard -X- _ O
games -X- _ O
, -X- _ O
showing -X- _ O
the -X- _ O
potential -X- _ O
of -X- _ O
introducing -X- _ O
world -X- _ O
- -X- _ O
perceiving -X- _ O
modules -X- _ O
in -X- _ O
facilitating -X- _ O
RL -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
assigning -X- _ O
either -X- _ O
the -X- _ O
expert -X- _ B-HyperparameterValue
task -X- _ I-HyperparameterValue
selector -X- _ I-HyperparameterValue
or -X- _ O
the -X- _ O
expert -X- _ B-HyperparameterValue
action -X- _ I-HyperparameterValue
validator -X- _ I-HyperparameterValue
helps -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
. -X- _ O
In -X- _ O
light -X- _ O
of -X- _ O
these -X- _ O
findings -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
consider -X- _ O
more -X- _ O
powerful -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
methods -X- _ O
as -X- _ O
a -X- _ O
future -X- _ O
direction -X- _ O
. -X- _ O
Although -X- _ O
we -X- _ O
only -X- _ O
collect -X- _ O
labeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
simple -X- _ O
games -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
still -X- _ O
burdensome -X- _ O
for -X- _ O
human -X- _ O
players -X- _ O
to -X- _ O
go -X- _ O
through -X- _ O
the -X- _ O
games -X- _ O
and -X- _ O
answer -X- _ O
the -X- _ O
questions -X- _ O
. -X- _ O
We -X- _ O
are -X- _ O
thus -X- _ O
interested -X- _ O
in -X- _ O
investigating -X- _ O
how -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
QWA -X- _ B-MethodName
( -X- _ O
or -X- _ O
world -X- _ O
- -X- _ O
perceiving -X- _ O
modules -X- _ O
) -X- _ O
varies -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
a -X- _ O
reduced -X- _ B-HyperparameterName
amount -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
pre -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
training -X- _ I-HyperparameterName
data -X- _ I-HyperparameterName
. -X- _ O
Fig -X- _ O
. -X- _ O
7 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
dataset -X- _ O
has -X- _ O
been -X- _ O
reduced -X- _ O
to -X- _ O
75 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
50 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
and -X- _ O
25 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
respectively -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
still -X- _ O
performs -X- _ O
well -X- _ O
when -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
is -X- _ O
reduced -X- _ O
to -X- _ O
75 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
and -X- _ O
50 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
. -X- _ O
When -X- _ O
we -X- _ O
only -X- _ O
use -X- _ O
25 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
exhibits -X- _ O
instability -X- _ O
during -X- _ O
the -X- _ O
learning -X- _ O
of -X- _ O
hard -X- _ O
games -X- _ O
. -X- _ O
Being -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
largely -X- _ O
- -X- _ O
reduced -X- _ O
dataset -X- _ O
, -X- _ O
the -X- _ O
world -X- _ O
- -X- _ O
perceiving -X- _ O
modules -X- _ O
might -X- _ O
be -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
make -X- _ O
wrong -X- _ O
predictions -X- _ O
with -X- _ O
the -X- _ O
progress -X- _ O
of -X- _ O
RL -X- _ O
training -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
fluctuation -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
fi- -X- _ O
nal -X- _ O
performance -X- _ O
of -X- _ O
this -X- _ O
variant -X- _ O
is -X- _ O
still -X- _ O
comparable -X- _ O
. -X- _ O
To -X- _ O
summarize -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
robust -X- _ O
to -X- _ O
limited -X- _ O
pretraining -X- _ O
data -X- _ O
and -X- _ O
largely -X- _ O
alleviates -X- _ O
the -X- _ O
burden -X- _ O
of -X- _ O
human -X- _ O
annotations -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
addressed -X- _ O
the -X- _ O
challenges -X- _ O
of -X- _ O
low -X- _ O
sample -X- _ O
efficiency -X- _ O
and -X- _ O
large -X- _ O
action -X- _ O
space -X- _ O
for -X- _ O
deep -X- _ O
reinforcement -X- _ O
learning -X- _ O
in -X- _ O
solving -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
games -X- _ O
. -X- _ O
We -X- _ O
introduced -X- _ O
the -X- _ O
world -X- _ O
- -X- _ O
perceiving -X- _ O
modules -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
capable -X- _ O
of -X- _ O
automatic -X- _ O
task -X- _ O
decomposition -X- _ O
and -X- _ O
action -X- _ O
pruning -X- _ O
through -X- _ O
answering -X- _ O
questions -X- _ O
about -X- _ O
the -X- _ O
environment -X- _ O
. -X- _ O
We -X- _ O
proposed -X- _ O
a -X- _ O
twophase -X- _ O
training -X- _ O
framework -X- _ O
, -X- _ O
which -X- _ O
decouples -X- _ O
the -X- _ O
language -X- _ O
learning -X- _ O
from -X- _ O
the -X- _ O
reinforcement -X- _ O
learning -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
achieves -X- _ O
improved -X- _ O
performance -X- _ O
with -X- _ O
high -X- _ O
sample -X- _ O
efficiency -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
it -X- _ O
shows -X- _ O
robustness -X- _ O
against -X- _ O
compound -X- _ O
error -X- _ O
and -X- _ O
limited -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Regarding -X- _ O
the -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
further -X- _ O
improve -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
performance -X- _ O
by -X- _ O
introducing -X- _ O
contrastive -X- _ O
learning -X- _ O
objective -X- _ O
( -X- _ O
You -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
KG -X- _ O
- -X- _ O
based -X- _ O
data -X- _ O
augmentation -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
[ -X- _ O
" -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
cookbook -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
part_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fried -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
needs -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
player -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
in -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
raw -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
sliced -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
needs -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
uncut -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
cookbook -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
on -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
fridge -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
fridge -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
open -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
knife -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
on -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
oven -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
player -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
stove -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
table -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
" -X- _ O
fry -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
get -X- _ O
knife -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
chop -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
dice -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
get -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
grill -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
make -X- _ O
meal -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
roast -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
slice -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
" -X- _ O
close -X- _ O
fridge -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
cook -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
with -X- _ O
oven -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
cook -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
with -X- _ O
stove -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
drop -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
eat -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
insert -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
into -X- _ O
fridge -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
prepare -X- _ O
meal -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
put -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
on -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
put -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
on -X- _ O
stove -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
put -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
on -X- _ O
table -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
take -X- _ O
cookbook -X- _ O
from -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
take -X- _ O
knife -X- _ O
from -X- _ O
counter -X- _ O
" -X- _ O
Medium -X- _ O
[ -X- _ O
" -X- _ O
bathroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
corridor -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
south_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
bed -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
bedroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
bedroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
livingroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
north_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
cookbook -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
part_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
diced -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
diced -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
needs -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fridge -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
in -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fried -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fried -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
needs -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fridge -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
in -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
raw -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
uncut -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
cookbook -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
on -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
corridor -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
bathroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
north_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
corridor -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
east_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
corridor -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
livingroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
south_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
flour -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
cookbook -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
part_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
flour -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
shelf -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
on -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
fridge -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
closed -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
fridge -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
frosted -X- _ O
- -X- _ O
glass -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
closed -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
frosted -X- _ O
- -X- _ O
glass -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
west_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
frosted -X- _ O
- -X- _ O
glass -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
pantry -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
east_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
corridor -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
west_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
knife -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
on -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
livingroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
bedroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
south_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
livingroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
corridor -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
north_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
oven -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
parsley -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fridge -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
in -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
parsley -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
uncut -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
player -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
pork -X- _ O
chop -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
chopped -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
pork -X- _ O
chop -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
chopped -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
needs -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
pork -X- _ O
chop -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
cookbook -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
part_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
pork -X- _ O
chop -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fridge -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
in -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
pork -X- _ O
chop -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fried -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
pork -X- _ O
chop -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fried -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
needs -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
purple -X- _ O
potato -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
on -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
purple -X- _ O
potato -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
uncut -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
apple -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
on -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
apple -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
raw -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
apple -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
uncut -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fridge -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
in -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
raw -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
uncut -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
potato -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
on -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
potato -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
uncut -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
shelf -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
pantry -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
sofa -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
livingroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
stove -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
table -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
toilet -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
bathroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fridge -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
in -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
raw -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
uncut -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
" -X- _ O
get -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
get -X- _ O
flour -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
get -X- _ O
pork -X- _ O
chop -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
chop -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
chop -X- _ O
flour -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
chop -X- _ O
pork -X- _ O
chop -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
dice -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
dice -X- _ O
flour -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
dice -X- _ O
pork -X- _ O
chop -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fry -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fry -X- _ O
flour -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fry -X- _ O
pork -X- _ O
chop -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
get -X- _ O
knife -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
grill -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
grill -X- _ O
flour -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
grill -X- _ O
pork -X- _ O
chop -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
make -X- _ O
meal -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
roast -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
roast -X- _ O
flour -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
roast -X- _ O
pork -X- _ O
chop -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
slice -X- _ O
block -X- _ O
of -X- _ O
cheese -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
slice -X- _ O
flour -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
slice -X- _ O
pork -X- _ O
chop -X- _ O
" -X- _ O
" -X- _ O
go -X- _ O
east -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
open -X- _ O
fridge -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
open -X- _ O
frosted -X- _ O
- -X- _ O
glass -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
take -X- _ O
cookbook -X- _ O
from -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
take -X- _ O
knife -X- _ O
from -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
take -X- _ O
purple -X- _ O
potato -X- _ O
from -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
take -X- _ O
red -X- _ O
apple -X- _ O
from -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
take -X- _ O
red -X- _ O
potato -X- _ O
from -X- _ O
counter -X- _ O
" -X- _ O
Table -X- _ O
5 -X- _ O
: -X- _ O
The -X- _ O
observations -X- _ O
o -X- _ O
t -X- _ O
, -X- _ O
subtask -X- _ O
candidates -X- _ O
T -X- _ O
and -X- _ O
action -X- _ O
candidates -X- _ O
A -X- _ O
of -X- _ O
a -X- _ O
hard -X- _ O
game -X- _ O
. -X- _ O
The -X- _ O
underlined -X- _ O
subtask -X- _ O
candidates -X- _ O
denote -X- _ O
the -X- _ O
available -X- _ O
subtask -X- _ O
set -X- _ O
T -X- _ O
t -X- _ O
. -X- _ O
The -X- _ O
underlined -X- _ O
action -X- _ O
candidates -X- _ O
denote -X- _ O
the -X- _ O
refined -X- _ O
action -X- _ O
set -X- _ O
A -X- _ O
t -X- _ O
after -X- _ O
selecting -X- _ O
the -X- _ O
subtask -X- _ O
" -X- _ O
roast -X- _ O
carrot" -X- _ O
. -X- _ O
Subtask -X- _ O
candidates -X- _ O
Action -X- _ O
candidates -X- _ O
Hard -X- _ O
[ -X- _ O
" -X- _ O
backyard -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
garden -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
west_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
barn -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
backyard -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
west_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
barn -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
closed -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
barn -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
shed -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
east_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
bathroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
corridor -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
east_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
bbq -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
backyard -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
bed -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
bedroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
bedroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
corridor -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
north_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
bedroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
livingroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
south_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
cookbook -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
part_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
player -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
in -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
raw -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
roasted -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
needs -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
sliced -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
needs"],["carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
uncut -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
commercial -X- _ O
glass -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
closed -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
commercial -X- _ O
glass -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
street -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
east_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
commercial -X- _ O
glass -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
supermarket -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
west_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
cookbook -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
table -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
on -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
corridor -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
bathroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
west_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
corridor -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
bedroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
south_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
driveway -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
street -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
north_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
fridge -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
closed -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
fridge -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
front -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
closed -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
front -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
driveway -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
west_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
front -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
livingroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
east_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
frosted -X- _ O
- -X- _ O
glass -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
closed -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
frostedglass -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
south_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
frosted -X- _ O
- -X- _ O
glass -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
pantry -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
north_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
garden -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
backyard -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
east_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
livingroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
west_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
knife -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
on -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
livingroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
bedroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
north_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
livingroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
east_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
oven -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
patio -X- _ O
chair -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
backyard -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
patio -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
backyard -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
north_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
patio -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
corridor -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
south_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
patio -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
open -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
patio -X- _ O
table -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
backyard -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
player -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
backyard -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
apple -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
counter -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
on -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
apple -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
raw -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
apple -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
uncut -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
cookbook -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
part_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
player -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
in -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
raw -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
roasted -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
needs -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
sliced -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
needs -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
uncut -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
garden -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
raw -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
red -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
uncut -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
shelf -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
pantry -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
showcase -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
supermarket -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
sofa -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
livingroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
stove -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
street -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
driveway -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
south_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
table -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
kitchen -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
toilet -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
bathroom -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
toolbox -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
closed -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
toolbox -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
shed -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
chopped -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
needs -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
cookbook -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
part_of -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
grilled -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
needs -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
player -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
in -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
raw -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
uncut -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
workbench -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
shed -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
yellow -X- _ O
bell -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
garden -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
at -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
yellow -X- _ O
bell -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
raw -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
" -X- _ O
yellow -X- _ O
bell -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
uncut -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
] -X- _ O
" -X- _ O
roast -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
roast -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
grill -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
get -X- _ O
knife -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
chop -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
chop -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
chop -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
dice -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
dice -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
dice -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fry -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fry -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
fry -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
get -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
get -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
get -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
grill -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
grill -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
make -X- _ O
meal -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
roast -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
slice -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
slice -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
slice -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
" -X- _ O
go -X- _ O
east -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
go -X- _ O
north -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
open -X- _ O
barn -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
open -X- _ O
patio -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
close -X- _ O
patio -X- _ O
door -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
cook -X- _ O
carrot -X- _ O
with -X- _ O
bbq -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
cook -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
with -X- _ O
bbq -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
cook -X- _ O
white -X- _ O
onion -X- _ O
with -X- _ O
bbq -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
drop -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
drop -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
drop -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
eat -X- _ O
carrot -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
eat -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
eat -X- _ O
white -X- _ O
onion -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
put -X- _ O
carrot -X- _ O
on -X- _ O
patio -X- _ O
chair -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
put -X- _ O
carrot -X- _ O
on -X- _ O
patio -X- _ O
table -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
put -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
on -X- _ O
patio -X- _ O
chair -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
put -X- _ O
red -X- _ O
hot -X- _ O
pepper -X- _ O
on -X- _ O
patio -X- _ O
table -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
put -X- _ O
white -X- _ O
onion -X- _ O
on -X- _ O
patio -X- _ O
chair -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
put -X- _ O
white -X- _ O
onion -X- _ O
on -X- _ O
patio -X- _ O
table -X- _ O
" -X- _ O
C -X- _ O
Baseline -X- _ O
details -X- _ O
C.1 -X- _ O
GATA -X- _ O
Fig -X- _ O
. -X- _ O
10 -X- _ O
shows -X- _ O
our -X- _ O
backbone -X- _ O
model -X- _ O
GATA -X- _ B-MethodName
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
an -X- _ O
observation -X- _ O
encoder -X- _ O
, -X- _ O
an -X- _ O
action -X- _ O
encoder -X- _ O
and -X- _ O
an -X- _ O
action -X- _ O
scorer -X- _ O
. -X- _ O
The -X- _ O
observation -X- _ O
encoder -X- _ O
is -X- _ O
a -X- _ O
graph -X- _ O
encoder -X- _ O
for -X- _ O
encoding -X- _ O
the -X- _ O
KG -X- _ O
- -X- _ O
based -X- _ O
observation -X- _ O
o -X- _ O
t -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
action -X- _ O
encoder -X- _ O
is -X- _ O
a -X- _ O
text -X- _ O
encoder -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
action -X- _ O
set -X- _ O
A -X- _ O
as -X- _ O
a -X- _ O
stack -X- _ O
of -X- _ O
action -X- _ O
candidate -X- _ O
representations -X- _ O
. -X- _ O
The -X- _ O
observation -X- _ O
representation -X- _ O
will -X- _ O
be -X- _ O
paired -X- _ O
with -X- _ O
each -X- _ O
action -X- _ O
candidate -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
action -X- _ O
scorer -X- _ O
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
linear -X- _ O
layers -X- _ O
. -X- _ O

6 -X- _ O
Results -X- _ O
and -X- _ O
discussionsFig -X- _ O
. -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
RL -X- _ O
testing -X- _ O
performance -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
episodes -X- _ O
. -X- _ O
saving -X- _ O
80 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
online -X- _ O
interaction -X- _ O
data -X- _ O
in -X- _ O
complex -X- _ O
games -X- _ O
. -X- _ O
The -X- _ O
effectiveness -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
observed -X- _ O
from -X- _ O
the -X- _ O
variant -X- _ O
" -X- _ O
IL -X- _ B-MethodName
w/o -X- _ I-MethodName
FT -X- _ I-MethodName
" -X- _ O
: -X- _ O
even -X- _ O
though -X- _ O
it -X- _ O
requires -X- _ O
no -X- _ O
further -X- _ O
training -X- _ O
on -X- _ O
the -X- _ O
medium -X- _ O
/ -X- _ O
hard -X- _ O
games -X- _ O
, -X- _ O
it -X- _ O
achieves -X- _ O
comparable -X- _ O
performance -X- _ O
to -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
QWA -X- _ B-MethodName
can -X- _ O
be -X- _ O
further -X- _ O
improved -X- _ O
through -X- _ O
RL -X- _ O
, -X- _ O
while -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
work -X- _ O
for -X- _ O
the -X- _ O
IL -X- _ B-MethodName
- -X- _ O
based -X- _ O
model -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
" -X- _ O
IL -X- _ B-MethodName
" -X- _ O
becomes -X- _ O
unstable -X- _ O
and -X- _ O
drops -X- _ O
significantly -X- _ O
during -X- _ O
the -X- _ O
RL -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

) -X- _ O
could -X- _ O
be -X- _ O
found -X- _ O
at -X- _ O
Appendix -X- _ O
B. -X- _ O
We -X- _ O
train -X- _ O
the -X- _ O
task -X- _ O
selector -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
256 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
action -X- _ O
( -X- _ O
Adhikari -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
conduct -X- _ O
reinforcement -X- _ O
learning -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
step -X- _ B-HyperparameterName
limit -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
an -X- _ I-HyperparameterName
episode -X- _ I-HyperparameterName
as -X- _ O
50 -X- _ B-HyperparameterValue
for -X- _ O
training -X- _ O
and -X- _ O
100 -X- _ B-HyperparameterValue
for -X- _ O
validation -X- _ O
/ -X- _ O
testing -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
subtask -X- _ B-HyperparameterName
time -X- _ I-HyperparameterName
limit -X- _ I-HyperparameterName
ξ -X- _ B-HyperparameterName
= -X- _ O
5 -X- _ B-HyperparameterValue
. -X- _ O
For -X- _ O
each -X- _ O
episode -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
a -X- _ O
game -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
to -X- _ O
interact -X- _ O
with -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
the -X- _ O
models -X- _ O
for -X- _ O
100,000 -X- _ B-HyperparameterValue
episodes -X- _ B-HyperparameterName
. -X- _ O
The -X- _ O
models -X- _ O
are -X- _ O
optimized -X- _ O
via -X- _ O
Double -X- _ B-HyperparameterValue
DQN -X- _ I-HyperparameterValue
( -X- _ O
epsilon -X- _ B-HyperparameterName
decays -X- _ O
from -X- _ O
1.0 -X- _ B-HyperparameterValue
to -X- _ O
0.1 -X- _ B-HyperparameterValue
in -X- _ O
20,000 -X- _ B-HyperparameterValue
episodes -X- _ B-HyperparameterName
, -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.001 -X- _ B-HyperparameterValue
) -X- _ O
with -X- _ O
Pritorized -X- _ O
Experience -X- _ O
Replay -X- _ O
( -X- _ O
replay -X- _ B-HyperparameterName
buffer -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
500,000 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
For -X- _ O
every -X- _ O
1,000 -X- _ O
training -X- _ O
episodes -X- _ O
, -X- _ O
we -X- _ O
validate -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
testing -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
measure -X- _ O
the -X- _ O
models -X- _ O
through -X- _ O
their -X- _ O
RL -X- _ O
testing -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
a -X- _ O
game -X- _ B-MetricName
's -X- _ I-MetricName
score -X- _ I-MetricName
as -X- _ O
the -X- _ O
episodic -X- _ O
sum -X- _ O
of -X- _ O
rewards -X- _ O
without -X- _ O
discount -X- _ O
. -X- _ O
As -X- _ O
different -X- _ O
games -X- _ O
may -X- _ O
have -X- _ O
different -X- _ O
maximum -X- _ O
available -X- _ O
scores -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
normalized -X- _ B-MetricName
score -X- _ I-MetricName
, -X- _ O
which -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
the -X- _ O
collected -X- _ O
score -X- _ O
normalized -X- _ O
by -X- _ O
the -X- _ O
maximum -X- _ O
score -X- _ O
for -X- _ O
a -X- _ O
game -X- _ O
. -X- _ O

• -X- _ O
QWA -X- _ B-MethodName
: -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
with -X- _ O
worldperceiving -X- _ O
modules -X- _ O
. -X- _ O
Model -X- _ O
architecture -X- _ O
All -X- _ O
models -X- _ O
are -X- _ O
implemented -X- _ O
based -X- _ O
on -X- _ O
GATA -X- _ B-MethodName
's -X- _ O
released -X- _ O
code -X- _ O
¶ -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
version -X- _ O
GATA -X- _ B-MethodName
- -X- _ I-MethodName
GTF -X- _ I-MethodName
, -X- _ O
which -X- _ O
takes -X- _ O
only -X- _ O
the -X- _ O
KG -X- _ O
- -X- _ O
based -X- _ O
observation -X- _ O
, -X- _ O
and -X- _ O
denote -X- _ O
it -X- _ O
as -X- _ O
GATA -X- _ B-MethodName
for -X- _ O
simplicity -X- _ O
. -X- _ O
The -X- _ O
observation -X- _ B-HyperparameterName
encoder -X- _ I-HyperparameterName
is -X- _ O
implemented -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
Relational -X- _ B-HyperparameterValue
Graph -X- _ I-HyperparameterValue
Convolutional -X- _ I-HyperparameterValue
Networks -X- _ I-HyperparameterValue
( -X- _ O
R -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
GCNs -X- _ I-HyperparameterValue
) -X- _ O
( -X- _ O
Schlichtkrull -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
by -X- _ O
taking -X- _ O
into -X- _ O
account -X- _ O
both -X- _ O
nodes -X- _ O
and -X- _ O
edges -X- _ O
. -X- _ O
Both -X- _ O
the -X- _ O
task -X- _ O
encoder -X- _ O
and -X- _ O
the -X- _ O
action -X- _ O
encoder -X- _ O
are -X- _ O
implemented -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
transformer -X- _ O
block -X- _ O
with -X- _ O
single -X- _ O
head -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
encode -X- _ O
short -X- _ O
texts -X- _ O
. -X- _ O
The -X- _ O
binary -X- _ B-HyperparameterName
classifier -X- _ I-HyperparameterName
, -X- _ O
the -X- _ O
task -X- _ B-HyperparameterName
scorer -X- _ I-HyperparameterName
and -X- _ O
the -X- _ O
action -X- _ B-HyperparameterName
scorer -X- _ I-HyperparameterName
are -X- _ O
linear -X- _ B-HyperparameterValue
layers -X- _ I-HyperparameterValue
. -X- _ O
The -X- _ O
GATA -X- _ B-MethodName
and -X- _ O
IL -X- _ B-MethodName
models -X- _ O
are -X- _ O
equipped -X- _ O
with -X- _ O
similar -X- _ O
modules -X- _ O
. -X- _ O
Please -X- _ O
refer -X- _ O
to -X- _ O
Appendix -X- _ O
C -X- _ O
for -X- _ O
details -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
the -X- _ O
task -X- _ O
selector -X- _ O
and -X- _ O
the -X- _ O
action -X- _ O
validator -X- _ O
separately -X- _ O
, -X- _ O
as -X- _ O
they -X- _ O
use -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
QAs -X- _ O
. -X- _ O
We -X- _ O
ask -X- _ O
human -X- _ O
players -X- _ O
to -X- _ O
play -X- _ O
the -X- _ O
simple -X- _ O
games -X- _ O
, -X- _ O
and -X- _ O
answer -X- _ O
the -X- _ O
yes -X- _ O
- -X- _ O
or -X- _ O
- -X- _ O
no -X- _ O
questions -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
observations -X- _ O
. -X- _ O
The -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
construction -X- _ O
( -X- _ O
interaction -X- _ O
data -X- _ O
collection -X- _ O
, -X- _ O
question -X- _ O
generation -X- _ O
, -X- _ O
answer -X- _ O
annotation -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O

• -X- _ O
IL -X- _ B-MethodName
w/o -X- _ I-MethodName
FT -X- _ I-MethodName
: -X- _ O
a -X- _ O
variant -X- _ O
of -X- _ O
the -X- _ O
IL -X- _ B-MethodName
baseline -X- _ O
, -X- _ O
where -X- _ O
only -X- _ O
the -X- _ O
imitation -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
is -X- _ O
conducted -X- _ O
, -X- _ O
and -X- _ O
there -X- _ O
's -X- _ O
no -X- _ O
RL -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

• -X- _ O
IL -X- _ B-MethodName
: -X- _ O
a -X- _ O
hierarchical -X- _ O
agent -X- _ O
which -X- _ O
also -X- _ O
uses -X- _ O
two -X- _ O
training -X- _ O
phases -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
phase -X- _ O
, -X- _ O
both -X- _ O
the -X- _ O
task -X- _ O
selector -X- _ O
and -X- _ O
the -X- _ O
action -X- _ O
selector -X- _ O
are -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
through -X- _ O
imitation -X- _ O
learning -X- _ O
. -X- _ O
Then -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
phase -X- _ O
, -X- _ O
the -X- _ O
action -X- _ O
selector -X- _ O
is -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
through -X- _ O
reinforcement -X- _ O
learning -X- _ O
. -X- _ O

One -X- _ O
issue -X- _ O
we -X- _ O
are -X- _ O
concerned -X- _ O
about -X- _ O
is -X- _ O
the -X- _ O
compound -X- _ O
error -X- _ O
− -X- _ O
the -X- _ O
prediction -X- _ O
error -X- _ O
from -X- _ O
imperfect -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
modules -X- _ O
will -X- _ O
adversely -X- _ O
affect -X- _ O
RL -X- _ O
training -X- _ O
( -X- _ O
Talvitie -X- _ O
, -X- _ O
2014;Racanière -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
false -X- _ O
predictions -X- _ O
made -X- _ O
by -X- _ O
the -X- _ O
binary -X- _ O
classifier -X- _ O
in -X- _ O
the -X- _ O
task -X- _ O
selector -X- _ O
may -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
wrong -X- _ O
T -X- _ O
t -X- _ O
, -X- _ O
which -X- _ O
affects -X- _ O
A -X- _ O
t -X- _ O
and -X- _ O
a -X- _ O
t -X- _ O
in -X- _ O
turn -X- _ O
. -X- _ O
To -X- _ O
alleviate -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
the -X- _ O
compound -X- _ O
error -X- _ O
, -X- _ O
we -X- _ O
assign -X- _ O
time -X- _ O
- -X- _ O
awareness -X- _ O
to -X- _ O
subtasks -X- _ O
. -X- _ O
A -X- _ O
subtask -X- _ O
is -X- _ O
bounded -X- _ O
by -X- _ O
a -X- _ O
time -X- _ B-HyperparameterName
limit -X- _ I-HyperparameterName
[ -X- _ O
0 -X- _ O
, -X- _ O
ξ -X- _ B-HyperparameterName
] -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
current -X- _ O
subtask -X- _ O
T -X- _ O
is -X- _ O
not -X- _ O
finished -X- _ O
within -X- _ O
its -X- _ O
time -X- _ O
limit -X- _ O
, -X- _ O
we -X- _ O
force -X- _ O
the -X- _ O
agent -X- _ O
to -X- _ O
re -X- _ O
- -X- _ O
select -X- _ O
a -X- _ O
new -X- _ O
subtask -X- _ O
T -X- _ O
t -X- _ O
∈ -X- _ O
T -X- _ O
t -X- _ O
\ -X- _ O
{ -X- _ O
T -X- _ O
} -X- _ O
, -X- _ O
regardless -X- _ O
whether -X- _ O
T -X- _ O
is -X- _ O
still -X- _ O
available -X- _ O
. -X- _ O
Besides -X- _ O
making -X- _ O
the -X- _ O
agent -X- _ O
robust -X- _ O
against -X- _ O
errors -X- _ O
, -X- _ O
another -X- _ O
benefit -X- _ O
by -X- _ O
introducing -X- _ O
time -X- _ O
- -X- _ O
awareness -X- _ O
to -X- _ O
subtasks -X- _ O
is -X- _ O
that -X- _ O
it -X- _ O
improves -X- _ O
the -X- _ O
subtask -X- _ O
selection -X- _ O
diversity -X- _ O
, -X- _ O
which -X- _ O
helps -X- _ O
the -X- _ O
agent -X- _ O
to -X- _ O
avoid -X- _ O
getting -X- _ O
stuck -X- _ O
in -X- _ O
local -X- _ O
minima -X- _ O
( -X- _ O
Pong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Campero -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020).We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
cooking -X- _ B-TaskName
games -X- _ I-TaskName
provided -X- _ O
by -X- _ O
the -X- _ O
rl.0.2 -X- _ B-DatasetName
game -X- _ I-DatasetName
set -X- _ I-DatasetName
† -X- _ O
and -X- _ O
the -X- _ O
FTWP -X- _ B-DatasetName
game -X- _ I-DatasetName
set -X- _ I-DatasetName
‡ -X- _ O
, -X- _ O
which -X- _ O
share -X- _ O
the -X- _ O
vocabulary -X- _ O
set -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
subtasks -X- _ I-HyperparameterName
, -X- _ O
which -X- _ O
is -X- _ O
highly -X- _ O
correlated -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
ingredients -X- _ O
& -X- _ O
preparing -X- _ O
requirements -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
three -X- _ B-HyperparameterValue
game -X- _ B-HyperparameterName
sets -X- _ I-HyperparameterName
with -X- _ O
varying -X- _ O
complexities -X- _ O
: -X- _ O
3488 -X- _ B-HyperparameterValue
simple -X- _ B-HyperparameterName
games -X- _ I-HyperparameterName
, -X- _ O
280 -X- _ B-HyperparameterValue
medium -X- _ B-HyperparameterName
games -X- _ I-HyperparameterName
and -X- _ O
420 -X- _ B-HyperparameterValue
hard -X- _ B-HyperparameterName
games -X- _ I-HyperparameterName
. -X- _ O
Note -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
overlapping -X- _ O
games -X- _ O
between -X- _ O
the -X- _ O
simple -X- _ O
set -X- _ O
and -X- _ O
the -X- _ O
medium -X- _ O
/ -X- _ O
hard -X- _ O
game -X- _ O
sets -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
game -X- _ O
statistics -X- _ O
. -X- _ O
Besides -X- _ O
" -X- _ O
Traj -X- _ O
. -X- _ O
Length -X- _ O
" -X- _ O
, -X- _ O
which -X- _ O
denotes -X- _ O
the -X- _ O
average -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
expert -X- _ O
demonstrations -X- _ O
per -X- _ O
game -X- _ O
§ -X- _ O
, -X- _ O
other -X- _ O
statistic -X- _ O
metrics -X- _ O
are -X- _ O
averaged -X- _ O
per -X- _ O
time -X- _ O
step -X- _ O
per -X- _ O
game -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
# -X- _ O
Subtasks -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
# -X- _ O
Avail -X- _ O
. -X- _ O
Subtasks -X- _ O
" -X- _ O
denote -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
subtask -X- _ O
candidates -X- _ O
T -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
available -X- _ O
subtasks -X- _ O
T -X- _ O
t -X- _ O
, -X- _ O
respectively -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
will -X- _ O
collect -X- _ O
human -X- _ O
interaction -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
simple -X- _ O
games -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
We -X- _ O
regard -X- _ O
both -X- _ O
medium -X- _ O
& -X- _ O
hard -X- _ O
games -X- _ O
as -X- _ O
complex -X- _ O
, -X- _ O
and -X- _ O
will -X- _ O
conduct -X- _ O
reinforcement -X- _ O
learning -X- _ O
on -X- _ O
these -X- _ O
two -X- _ O
game -X- _ O
sets -X- _ O
without -X- _ O
labeled -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
the -X- _ O
following -X- _ O
four -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
compare -X- _ O
with -X- _ O
more -X- _ O
variants -X- _ O
in -X- _ O
ablation -X- _ O
studies -X- _ O
: -X- _ O
KG -X- _ O
- -X- _ O
based -X- _ O
RL -X- _ O
agent -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
benchmark -X- _ O
model -X- _ O
for -X- _ O
cooking -X- _ B-TaskName
games -X- _ I-TaskName
. -X- _ O

• -X- _ O
GATA -X- _ B-MethodName
( -X- _ O
Adhikari -X- _ O

Given -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
available -X- _ O
subtasks -X- _ O
T -X- _ O
t -X- _ O
, -X- _ O
arbitrary -X- _ O
strategies -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
select -X- _ O
a -X- _ O
subtask -X- _ O
T -X- _ O
t -X- _ O
from -X- _ O
it -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
employ -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
learnable -X- _ O
task -X- _ O
scorer -X- _ O
to -X- _ O
obtain -X- _ O
T -X- _ O
t -X- _ O
by -X- _ O
random -X- _ O
sampling -X- _ O
, -X- _ O
since -X- _ O
each -X- _ O
subtask -X- _ O
T -X- _ O
∈ -X- _ O
T -X- _ O
t -X- _ O
is -X- _ O
essential -X- _ O
for -X- _ O
accomplishing -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
also -X- _ O
train -X- _ O
a -X- _ O
task -X- _ O
scorer -X- _ O
via -X- _ O
a -X- _ O
metapolicy -X- _ O
for -X- _ O
adaptive -X- _ O
task -X- _ O
selection -X- _ O
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021).After -X- _ O
obtaining -X- _ O
the -X- _ O
subtask -X- _ O
T -X- _ O
t -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
action -X- _ O
pruning -X- _ O
conditioned -X- _ O
on -X- _ O
it -X- _ O
( -X- _ O
or -X- _ O
on -X- _ O
both -X- _ O
T -X- _ O
t -X- _ O
and -X- _ O
o -X- _ O
t -X- _ O
) -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
action -X- _ O
space -X- _ O
, -X- _ O
tackling -X- _ O
the -X- _ O
challenge -X- _ O
of -X- _ O
large -X- _ O
action -X- _ O
space -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
the -X- _ O
task -X- _ O
selector -X- _ O
, -X- _ O
we -X- _ O
formulate -X- _ O
action -X- _ O
pruning -X- _ O
as -X- _ O
|A| -X- _ O
binary -X- _ O
classifica -X- _ O
- -X- _ O
tion -X- _ O
problems -X- _ O
, -X- _ O
and -X- _ O
devise -X- _ O
another -X- _ O
world -X- _ O
- -X- _ O
perceiving -X- _ O
module -X- _ O
: -X- _ O
the -X- _ O
action -X- _ O
validator -X- _ O
. -X- _ O
The -X- _ O
action -X- _ O
validator -X- _ O
is -X- _ O
designed -X- _ O
to -X- _ O
check -X- _ O
the -X- _ O
relevance -X- _ O
of -X- _ O
each -X- _ O
action -X- _ O
candidate -X- _ O
a -X- _ O
∈ -X- _ O
A -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
T -X- _ O
t -X- _ O
by -X- _ O
answering -X- _ O
questions -X- _ O
like -X- _ O
" -X- _ O
Is -X- _ O
the -X- _ O
action -X- _ O
candidate -X- _ O
' -X- _ O
take -X- _ O
beef -X- _ O
' -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
subtask -X- _ O
' -X- _ O
fry -X- _ O
chicken -X- _ O
' -X- _ O
? -X- _ O
" -X- _ O
, -X- _ O
so -X- _ O
as -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
actions -X- _ O
A -X- _ O
t -X- _ O
⊆ -X- _ O
A -X- _ O
with -X- _ O
irrelevant -X- _ O
actions -X- _ O
filtered -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
module -X- _ O
architecture -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
the -X- _ O
task -X- _ O
selector -X- _ O
, -X- _ O
we -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
this -X- _ O
module -X- _ O
through -X- _ O
question -X- _ O
answering -X- _ O
. -X- _ O
Sample -X- _ O
QAs -X- _ O
have -X- _ O
been -X- _ O
shown -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
( -X- _ O
b).After -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
deploy -X- _ O
the -X- _ O
agent -X- _ O
in -X- _ O
the -X- _ O
complex -X- _ O
games -X- _ O
, -X- _ O
and -X- _ O
train -X- _ O
the -X- _ O
action -X- _ O
selector -X- _ O
through -X- _ O
RL -X- _ O
. -X- _ O
We -X- _ O
freeze -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
modules -X- _ O
, -X- _ O
as -X- _ O
no -X- _ O
human -X- _ O
labeled -X- _ O
data -X- _ O
will -X- _ O
be -X- _ O
obtained -X- _ O
in -X- _ O
this -X- _ O
phase -X- _ O
. -X- _ O
At -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
task -X- _ O
selector -X- _ O
and -X- _ O
the -X- _ O
action -X- _ O
validator -X- _ O
to -X- _ O
produce -X- _ O
T -X- _ O
t -X- _ O
and -X- _ O
A -X- _ O
t -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
keep -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
subtask -X- _ O
T -X- _ O
over -X- _ O
time -X- _ O
until -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
included -X- _ O
in -X- _ O
T -X- _ O
t -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
want -X- _ O
the -X- _ O
agent -X- _ O
to -X- _ O
switch -X- _ O
subtasks -X- _ O
too -X- _ O
frequently -X- _ O
. -X- _ O
The -X- _ O
agent -X- _ O
can -X- _ O
simply -X- _ O
treat -X- _ O
T -X- _ O
t -X- _ O
as -X- _ O
the -X- _ O
additional -X- _ O
observation -X- _ O
of -X- _ O
o -X- _ O
t -X- _ O
. -X- _ O
If -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
limit -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
human -X- _ O
knowledge -X- _ O
in -X- _ O
this -X- _ O
phase -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
also -X- _ O
treat -X- _ O
T -X- _ O
t -X- _ O
as -X- _ O
a -X- _ O
goal -X- _ O
with -X- _ O
either -X- _ O
hand -X- _ O
- -X- _ O
crafted -X- _ O
( -X- _ O
Jiang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
learnt -X- _ O
reward -X- _ O
function -X- _ O
( -X- _ O
Colas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Arbitrary -X- _ O
methods -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
optimizing -X- _ O
Adhikari -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
formulate -X- _ O
the -X- _ O
mapping -X- _ O
f -X- _ O
( -X- _ O
o -X- _ O
t -X- _ O
, -X- _ O
T -X- _ O
) -X- _ O
→ -X- _ O
T -X- _ O
t -X- _ O
as -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
label -X- _ O
learning -X- _ O
problem -X- _ O
( -X- _ O
Zhang -X- _ O
and -X- _ O
Zhou -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
simplicity -X- _ O
, -X- _ O
we -X- _ O
assume -X- _ O
that -X- _ O
the -X- _ O
subtask -X- _ O
candidates -X- _ O
are -X- _ O
independent -X- _ O
with -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
label -X- _ O
learning -X- _ O
problem -X- _ O
can -X- _ O
be -X- _ O
decomposed -X- _ O
as -X- _ O
|T -X- _ O
| -X- _ O
binary -X- _ O
classification -X- _ O
problems -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
the -X- _ O
recent -X- _ O
progress -X- _ O
of -X- _ O
questionconditional -X- _ O
probing -X- _ O
( -X- _ O
Das -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
language -X- _ O
grounding -X- _ O
( -X- _ O
Hill -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
QA -X- _ O
- -X- _ O
based -X- _ O
graph -X- _ O
construction -X- _ O
, -X- _ O
we -X- _ O
cast -X- _ O
these -X- _ O
binary -X- _ O
classification -X- _ O
problems -X- _ O
as -X- _ O
yes -X- _ O
- -X- _ O
orno -X- _ O
questions -X- _ O
, -X- _ O
making -X- _ O
the -X- _ O
task -X- _ O
selector -X- _ O
a -X- _ O
worldperceiving -X- _ O
module -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
corresponding -X- _ O
question -X- _ O
for -X- _ O
the -X- _ O
subtask -X- _ O
candidate -X- _ O
" -X- _ O
get -X- _ O
apple -X- _ O
" -X- _ O
could -X- _ O
be -X- _ O
" -X- _ O
Whether -X- _ O
' -X- _ O
get -X- _ O
apple -X- _ O
' -X- _ O
is -X- _ O
an -X- _ O
available -X- _ O
subtask -X- _ O
? -X- _ O
" -X- _ O
. -X- _ O
This -X- _ O
module -X- _ O
can -X- _ O
guide -X- _ O
the -X- _ O
agent -X- _ O
to -X- _ O
under- -X- _ O
stand -X- _ O
the -X- _ O
environment -X- _ O
conditions -X- _ O
through -X- _ O
answering -X- _ O
questions -X- _ O
, -X- _ O
but -X- _ O
will -X- _ O
not -X- _ O
directly -X- _ O
lead -X- _ O
the -X- _ O
agent -X- _ O
to -X- _ O
a -X- _ O
specific -X- _ O
decision -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
obtain -X- _ O
this -X- _ O
module -X- _ O
through -X- _ O
supervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
and -X- _ O
decouple -X- _ O
it -X- _ O
from -X- _ O
reinforcement -X- _ O
learning -X- _ O
to -X- _ O
yield -X- _ O
better -X- _ O
sample -X- _ O
efficiency -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
shows -X- _ O
some -X- _ O
sample -X- _ O
QAs -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
human -X- _ O
answerer -X- _ O
can -X- _ O
be -X- _ O
replaced -X- _ O
by -X- _ O
a -X- _ O
pretrained -X- _ O
task -X- _ O
selector -X- _ O
. -X- _ O
Some -X- _ O
previous -X- _ O
work -X- _ O
also -X- _ O
considered -X- _ O
task -X- _ O
decomposition -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
related -X- _ O
module -X- _ O
is -X- _ O
obtained -X- _ O
through -X- _ O
imitating -X- _ O
human -X- _ O
demonstrations -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
directly -X- _ O
related -X- _ O
to -X- _ O
decision -X- _ O
making -X- _ O
instead -X- _ O
of -X- _ O
world -X- _ O
perceiving -X- _ O
. -X- _ O
Compared -X- _ O
with -X- _ O
these -X- _ O
work -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
has -X- _ O
two -X- _ O
folds -X- _ O
of -X- _ O
benefits -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
there -X- _ O
may -X- _ O
exist -X- _ O
multiple -X- _ O
available -X- _ O
subtasks -X- _ O
at -X- _ O
a -X- _ O
timestep -X- _ O
. -X- _ O
Imitating -X- _ O
human -X- _ O
demonstrations -X- _ O
will -X- _ O
specify -X- _ O
only -X- _ O
one -X- _ O
of -X- _ O
them -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
insufficient -X- _ O
and -X- _ O
lead -X- _ O
to -X- _ O
information -X- _ O
loss -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
require -X- _ O
expert -X- _ O
demonstrations -X- _ O
which -X- _ O
guarantee -X- _ O
to -X- _ O
solve -X- _ O
the -X- _ O
game -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
ask -X- _ O
humans -X- _ O
to -X- _ O
annotate -X- _ O
either -X- _ O
imperfect -X- _ O
demonstrations -X- _ O
, -X- _ O
or -X- _ O
even -X- _ O
demonstrations -X- _ O
from -X- _ O
a -X- _ O
random -X- _ O
agent -X- _ O
. -X- _ O
We -X- _ O
will -X- _ O
treat -X- _ O
the -X- _ O
IL -X- _ O
- -X- _ O
based -X- _ O
method -X- _ O
as -X- _ O
a -X- _ O
baseline -X- _ O
and -X- _ O
conduct -X- _ O
comparisons -X- _ O
in -X- _ O
the -X- _ O
experiments -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
reinforcement -X- _ O
learning -X- _ O
phase -X- _ O
, -X- _ O
we -X- _ O
freeze -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
modules -X- _ O
, -X- _ O
and -X- _ O
train -X- _ O
the -X- _ O
action -X- _ O
selector -X- _ O
in -X- _ O
the -X- _ O
complex -X- _ O
games -X- _ O
through -X- _ O
reinforcement -X- _ O
learning -X- _ O
. -X- _ O
Depending -X- _ O
on -X- _ O
the -X- _ O
experiment -X- _ O
settings -X- _ O
, -X- _ O
T -X- _ B-HyperparameterName
and -X- _ O
A -X- _ B-HyperparameterName
can -X- _ O
be -X- _ O
either -X- _ O
fixed -X- _ O
vocabulary -X- _ O
sets -X- _ O
( -X- _ O
parser -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
based -X- _ I-HyperparameterValue
) -X- _ O
, -X- _ O
or -X- _ O
changing -X- _ O
over -X- _ O
time -X- _ O
( -X- _ O
choice -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
based -X- _ I-HyperparameterValue
) -X- _ O
. -X- _ O
We -X- _ O
regard -X- _ O
a -X- _ O
subtask -X- _ O
available -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
essential -X- _ O
for -X- _ O
solving -X- _ O
the -X- _ O
" -X- _ O
global -X- _ O
" -X- _ O
task -X- _ O
, -X- _ O
and -X- _ O
there -X- _ O
's -X- _ O
no -X- _ O
prerequisite -X- _ O
subtask -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
subtask -X- _ O
" -X- _ O
get -X- _ O
apple -X- _ O
" -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
object -X- _ O
" -X- _ O
apple -X- _ O
" -X- _ O
is -X- _ O
an -X- _ O
ingredient -X- _ O
which -X- _ O
has -X- _ O
not -X- _ O
been -X- _ O
collected -X- _ O
. -X- _ O
Although -X- _ O
another -X- _ O
subtask -X- _ O
" -X- _ O
dice -X- _ O
apple -X- _ O
" -X- _ O
is -X- _ O
also -X- _ O
essential -X- _ O
for -X- _ O
making -X- _ O
the -X- _ O
meal -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
available -X- _ O
since -X- _ O
there -X- _ O
exists -X- _ O
a -X- _ O
prerequisite -X- _ O
subtask -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
you -X- _ O
should -X- _ O
collect -X- _ O
the -X- _ O
apple -X- _ O
before -X- _ O
dicing -X- _ O
it -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
aim -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
selector -X- _ O
is -X- _ O
to -X- _ O
identify -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
available -X- _ O
subtasks -X- _ O
T -X- _ O
t -X- _ O
⊆ -X- _ O
T -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
select -X- _ O
one -X- _ O
subtask -X- _ O
T -X- _ O
t -X- _ O
∈ -X- _ O
T -X- _ O
t -X- _ O
. -X- _ O

The -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
world -X- _ O
- -X- _ O
perceiving -X- _ O
modules -X- _ O
can -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
the -X- _ O
language -X- _ O
learning -X- _ O
regime -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
action -X- _ O
selector -X- _ O
can -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
the -X- _ O
decision -X- _ O
making -X- _ O
regime -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
phase -X- _ O
training -X- _ O
strategy -X- _ O
to -X- _ O
decouple -X- _ O
these -X- _ O
two -X- _ O
regimes -X- _ O
to -X- _ O
further -X- _ O
improve -X- _ O
the -X- _ O
sample -X- _ O
efficiency -X- _ O
( -X- _ O
Hill -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
phase -X- _ O
, -X- _ O
we -X- _ O
collect -X- _ O
human -X- _ O
interaction -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
simple -X- _ O
games -X- _ O
, -X- _ O
and -X- _ O
design -X- _ O
QA -X- _ B-TaskName
datasets -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
worldperceiving -X- _ O
modules -X- _ O
through -X- _ O
supervised -X- _ O
learning -X- _ O
. -X- _ O

Problem -X- _ O
setting -X- _ O
We -X- _ O
aim -X- _ O
to -X- _ O
design -X- _ O
an -X- _ O
RL -X- _ O
- -X- _ O
based -X- _ O
agent -X- _ O
that -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
conduct -X- _ O
automatic -X- _ O
task -X- _ O
decomposition -X- _ O
and -X- _ O
action -X- _ O
pruning -X- _ O
in -X- _ O
solving -X- _ O
text -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
games -X- _ I-TaskName
. -X- _ O
We -X- _ O
consider -X- _ O
games -X- _ O
sharing -X- _ O
similar -X- _ O
themes -X- _ O
and -X- _ O
tasks -X- _ O
, -X- _ O
but -X- _ O
varying -X- _ O
in -X- _ O
their -X- _ O
complexities -X- _ O
( -X- _ O
Adhikari -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
. -X- _ O
Taking -X- _ O
the -X- _ O
cooking -X- _ B-TaskName
games -X- _ I-TaskName
as -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
always -X- _ O
" -X- _ O
make -X- _ O
the -X- _ O
meal -X- _ O
" -X- _ O
. -X- _ O
To -X- _ O
accomplish -X- _ O
this -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
has -X- _ O
to -X- _ O
explore -X- _ O
different -X- _ O
rooms -X- _ O
to -X- _ O
collect -X- _ O
all -X- _ O
ingredients -X- _ O
, -X- _ O
prepare -X- _ O
them -X- _ O
in -X- _ O
right -X- _ O
ways -X- _ O
, -X- _ O
and -X- _ O
make -X- _ O
the -X- _ O
meal -X- _ O
. -X- _ O
A -X- _ O
game -X- _ O
's -X- _ O
complexity -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
rooms -X- _ O
, -X- _ O
ingredients -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
required -X- _ O
preparation -X- _ O
steps -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
a -X- _ O
subtask -X- _ O
as -X- _ O
a -X- _ O
milestone -X- _ O
towards -X- _ O
completing -X- _ O
the -X- _ O
task -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
get -X- _ O
apple -X- _ O
" -X- _ O
if -X- _ O
" -X- _ O
apple -X- _ O
" -X- _ O
is -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
recipe -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
subtask -X- _ O
requires -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
actions -X- _ O
to -X- _ O
accomplish -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
has -X- _ O
to -X- _ O
explore -X- _ O
the -X- _ O
house -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
apple -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
game -X- _ O
is -X- _ O
considered -X- _ O
simple -X- _ O
, -X- _ O
if -X- _ O
it -X- _ O
consists -X- _ O
of -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
subtasks -X- _ O
, -X- _ O
and -X- _ O
complex -X- _ O
if -X- _ O
it -X- _ O
consists -X- _ O
of -X- _ O
more -X- _ O
subtasks -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
2 -X- _ O
gives -X- _ O
examples -X- _ O
of -X- _ O
simple -X- _ O
games -X- _ O
and -X- _ O
complex -X- _ O
games -X- _ O
. -X- _ O
While -X- _ O
being -X- _ O
closer -X- _ O
to -X- _ O
real -X- _ O
world -X- _ O
applications -X- _ O
, -X- _ O
complex -X- _ O
games -X- _ O
are -X- _ O
hard -X- _ O
to -X- _ O
solve -X- _ O
by -X- _ O
RL -X- _ O
agents -X- _ O
because -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
it -X- _ O
's -X- _ O
expensive -X- _ O
to -X- _ O
collect -X- _ O
sufficient -X- _ O
human -X- _ O
labeled -X- _ O
data -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
; -X- _ O
2 -X- _ O
) -X- _ O
it -X- _ O
's -X- _ O
unrealistic -X- _ O
to -X- _ O
train -X- _ O
an -X- _ O
RL -X- _ O
agent -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O
We -X- _ O
therefore -X- _ O
focus -X- _ O
on -X- _ O
agent -X- _ O
's -X- _ O
sample -X- _ O
efficiency -X- _ O
and -X- _ O
performance -X- _ O
on -X- _ O
complex -X- _ O
games -X- _ O
. -X- _ O
Our -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
leverage -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
collected -X- _ O
from -X- _ O
simple -X- _ O
games -X- _ O
to -X- _ O
speed -X- _ O
up -X- _ O
RL -X- _ O
training -X- _ O
in -X- _ O
complex -X- _ O
games -X- _ O
, -X- _ O
thus -X- _ O
obtaining -X- _ O
an -X- _ O
agent -X- _ O
capable -X- _ O
of -X- _ O
complex -X- _ O
games -X- _ O
. -X- _ O
For -X- _ O
more -X- _ O
details -X- _ O
and -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
simple -X- _ O
/ -X- _ O
complex -X- _ O
games -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
please -X- _ O
refer -X- _ O
to -X- _ O
Sec -X- _ O
. -X- _ O
5.1.Fig -X- _ O
. -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
overview -X- _ O
of -X- _ O
our -X- _ O
QWA -X- _ B-MethodName
agent -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
two -X- _ O
world -X- _ O
- -X- _ O
perceiving -X- _ O
modules -X- _ O
: -X- _ O
a -X- _ O
task -X- _ O
selector -X- _ O
and -X- _ O
an -X- _ O
action -X- _ O
validator -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
observation -X- _ O
o -X- _ O
t -X- _ O
and -X- _ O
the -X- _ O
task -X- _ O
candidate -X- _ O
set -X- _ O
T -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
task -X- _ O
selector -X- _ O
to -X- _ O
first -X- _ O
obtain -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
currently -X- _ O
available -X- _ O
subtasks -X- _ O
T -X- _ O
t -X- _ O
⊆ -X- _ O
T -X- _ O
, -X- _ O
then -X- _ O
select -X- _ O
a -X- _ O
subtask -X- _ O
T -X- _ O
t -X- _ O
∈ -X- _ O
T -X- _ O
t -X- _ O
. -X- _ O
Given -X- _ O
T -X- _ O
t -X- _ O
and -X- _ O
the -X- _ O
action -X- _ O
candidate -X- _ O
set -X- _ O
A -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
action -X- _ O
validator -X- _ O
to -X- _ O
get -X- _ O
an -X- _ O
action -X- _ O
subset -X- _ O
A -X- _ O
t -X- _ O
⊆ -X- _ O
A -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
only -X- _ O
those -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
subtask -X- _ O
T -X- _ O
t -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
given -X- _ O
o -X- _ O
t -X- _ O
and -X- _ O
T -X- _ O
t -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
an -X- _ O
action -X- _ O
selector -X- _ O
to -X- _ O
score -X- _ O
each -X- _ O
action -X- _ O
a -X- _ O
∈ -X- _ O
A -X- _ O
t -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
action -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
score -X- _ O
will -X- _ O
be -X- _ O
selected -X- _ O
as -X- _ O
a -X- _ O
t -X- _ O
. -X- _ O

Observation -X- _ O
form -X- _ O
In -X- _ O
text -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
games -X- _ I-TaskName
, -X- _ O
the -X- _ O
observation -X- _ O
can -X- _ O
be -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
text -X- _ O
, -X- _ O
knowledge -X- _ O
graph -X- _ O
, -X- _ O
or -X- _ O
hybrid -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
shows -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
the -X- _ O
textual -X- _ O
observation -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
KG -X- _ O
- -X- _ O
based -X- _ O
observation -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
make -X- _ O
assumptions -X- _ O
about -X- _ O
the -X- _ O
observation -X- _ O
form -X- _ O
and -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
compatible -X- _ O
with -X- _ O
any -X- _ O
of -X- _ O
those -X- _ O
forms -X- _ O
. -X- _ O

R -X- _ O
t -X- _ O
= -X- _ O
E -X- _ O
[ -X- _ O
∞ -X- _ O
t=0 -X- _ O
γ -X- _ B-HyperparameterName
k -X- _ O
r -X- _ O
t -X- _ O
] -X- _ O
. -X- _ O

3 -X- _ O
Background -X- _ O
POMDP -X- _ O
Text -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
games -X- _ I-TaskName
can -X- _ O
be -X- _ O
formulated -X- _ O
as -X- _ O
a -X- _ O
Partially -X- _ O
Observable -X- _ O
Markov -X- _ O
Decision -X- _ O
Processes -X- _ O
( -X- _ O
POMDPs -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
POMDP -X- _ O
can -X- _ O
be -X- _ O
described -X- _ O
by -X- _ O
a -X- _ O
tuple -X- _ O
G -X- _ O
= -X- _ O
⟨S -X- _ O
, -X- _ O
A -X- _ O
, -X- _ O
P -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
Ω -X- _ O
, -X- _ O
O -X- _ O
, -X- _ O
γ⟩ -X- _ O
, -X- _ O
with -X- _ O
S -X- _ O
representing -X- _ O
the -X- _ O
state -X- _ O
set -X- _ O
, -X- _ O
A -X- _ O
the -X- _ O
action -X- _ O
set -X- _ O
, -X- _ O
P -X- _ O
( -X- _ O
s -X- _ O
′ -X- _ O
|s -X- _ O
, -X- _ O
a -X- _ O
) -X- _ O
: -X- _ O
S -X- _ O
× -X- _ O
A -X- _ O
× -X- _ O
S -X- _ O
→ -X- _ O
R -X- _ O
+ -X- _ O
the -X- _ O
state -X- _ O
transition -X- _ O
probabilities -X- _ O
, -X- _ O
r(s -X- _ O
, -X- _ O
a -X- _ O
) -X- _ O
: -X- _ O
S -X- _ O
× -X- _ O
A -X- _ O
→ -X- _ O
R -X- _ O
the -X- _ O
reward -X- _ O
function -X- _ O
, -X- _ O
Ω -X- _ O
the -X- _ O
observation -X- _ O
set -X- _ O
, -X- _ O
O -X- _ O
the -X- _ O
conditional -X- _ O
observation -X- _ O
probabilities -X- _ O
, -X- _ O
and -X- _ O
γ -X- _ B-HyperparameterName
∈ -X- _ O
( -X- _ O
0 -X- _ B-HyperparameterValue
, -X- _ O
1 -X- _ B-HyperparameterValue
] -X- _ O
the -X- _ O
discount -X- _ B-HyperparameterName
factor -X- _ I-HyperparameterName
. -X- _ O
At -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
receives -X- _ O
an -X- _ O
observation -X- _ O
o -X- _ O
t -X- _ O
∈ -X- _ O
Ω -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
probability -X- _ O
O(o -X- _ O
t -X- _ O
|s -X- _ O
t -X- _ O
, -X- _ O
a -X- _ O
t−1 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
select -X- _ O
an -X- _ O
action -X- _ O
a -X- _ O
t -X- _ O
∈ -X- _ O
A. -X- _ O
The -X- _ O
environment -X- _ O
will -X- _ O
transit -X- _ O
into -X- _ O
a -X- _ O
new -X- _ O
state -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
probability -X- _ O
T -X- _ O
( -X- _ O
s -X- _ O
t+1 -X- _ O
|s -X- _ O
t -X- _ O
, -X- _ O
a -X- _ O
t -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
return -X- _ O
a -X- _ O
scalar -X- _ O
reward -X- _ O
r -X- _ O
t+1 -X- _ O
. -X- _ O
The -X- _ O
goal -X- _ O
of -X- _ O
the -X- _ O
agent -X- _ O
is -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
action -X- _ O
to -X- _ O
maximize -X- _ O
the -X- _ O
expected -X- _ O
cumulative -X- _ O
discounted -X- _ O
rewards -X- _ O
: -X- _ O

In -X- _ O
the -X- _ O
domain -X- _ O
of -X- _ O
text -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
games -X- _ I-TaskName
, -X- _ O
some -X- _ O
prior -X- _ O
works -X- _ O
have -X- _ O
involved -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
state -X- _ O
representation -X- _ O
learning -X- _ O
( -X- _ O
Ammanabrolu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021;Singh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
knowledge -X- _ O
graph -X- _ O
constructing -X- _ O
( -X- _ O
Murugesan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
action -X- _ O
pruning -X- _ O
( -X- _ O
Hausknecht -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Yao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
designed -X- _ O
a -X- _ O
module -X- _ O
to -X- _ O
extract -X- _ O
triplets -X- _ O
from -X- _ O
the -X- _ O
textual -X- _ O
observation -X- _ O
by -X- _ O
answering -X- _ O
questions -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
these -X- _ O
triplets -X- _ O
to -X- _ O
update -X- _ O
the -X- _ O
knowledge -X- _ O
graph -X- _ O
. -X- _ O
As -X- _ O
far -X- _ O
as -X- _ O
we -X- _ O
know -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
incorporate -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
based -X- _ O
task -X- _ O
decompositon -X- _ O
in -X- _ O
this -X- _ O
domain -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
directly -X- _ O
pruning -X- _ O
the -X- _ O
actions -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
observation -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
subtask -X- _ O
- -X- _ O
conditioned -X- _ O
action -X- _ O
pruning -X- _ O
to -X- _ O
further -X- _ O
reduce -X- _ O
the -X- _ O
action -X- _ O
space -X- _ O
. -X- _ O

Our -X- _ O
contributions -X- _ O
are -X- _ O
summarized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
Firstly -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
an -X- _ O
RL -X- _ O
agent -X- _ O
featured -X- _ O
with -X- _ O
question -X- _ O
- -X- _ O
guided -X- _ O
task -X- _ O
decomposition -X- _ O
and -X- _ O
action -X- _ O
space -X- _ O
reduction -X- _ O
. -X- _ O
Secondly -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
phase -X- _ O
framework -X- _ O
to -X- _ O
efficiently -X- _ O
train -X- _ O
the -X- _ O
agent -X- _ O
with -X- _ O
limited -X- _ O
data -X- _ O
. -X- _ O
Thirdly -X- _ O
, -X- _ O
we -X- _ O
empirically -X- _ O
validate -X- _ O
our -X- _ O
method -X- _ O
's -X- _ O
effectiveness -X- _ O
and -X- _ O
robustness -X- _ O
in -X- _ O
complex -X- _ O
games -X- _ O
. -X- _ O
The -X- _ O
RL -X- _ O
agents -X- _ O
for -X- _ O
text -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
games -X- _ I-TaskName
can -X- _ O
be -X- _ O
divided -X- _ O
as -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
agents -X- _ O
and -X- _ O
KG -X- _ O
- -X- _ O
based -X- _ O
agents -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
observations -X- _ O
. -X- _ O
Compared -X- _ O
with -X- _ O
the -X- _ O
textbased -X- _ O
agents -X- _ O
( -X- _ O
Narasimhan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Adolphs -X- _ O
and -X- _ O
Hofmann -X- _ O
, -X- _ O
2020;Jain -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Yin -X- _ O
and -X- _ O
May -X- _ O
, -X- _ O
2019;Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a;Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
take -X- _ O
the -X- _ O
raw -X- _ O
textual -X- _ O
observations -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
build -X- _ O
state -X- _ O
representations -X- _ O
, -X- _ O
the -X- _ O
KGbased -X- _ O
agents -X- _ O
construct -X- _ O
the -X- _ O
knowledge -X- _ O
graph -X- _ O
and -X- _ O
leverage -X- _ O
it -X- _ O
as -X- _ O
the -X- _ O
additional -X- _ O
input -X- _ O
( -X- _ O
Ammanabrolu -X- _ O
and -X- _ O
Riedl -X- _ O
, -X- _ O
2019;Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
By -X- _ O
providing -X- _ O
structural -X- _ O
and -X- _ O
historical -X- _ O
information -X- _ O
, -X- _ O
the -X- _ O
knowledge -X- _ O
graph -X- _ O
helps -X- _ O
the -X- _ O
agent -X- _ O
to -X- _ O
handle -X- _ O
partial -X- _ O
observability -X- _ O
, -X- _ O
reduce -X- _ O
action -X- _ O
space -X- _ O
, -X- _ O
and -X- _ O
improve -X- _ O
generalizability -X- _ O
across -X- _ O
games -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
how -X- _ O
actions -X- _ O
are -X- _ O
selected -X- _ O
, -X- _ O
the -X- _ O
RL -X- _ O
agents -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
divided -X- _ O
as -X- _ O
parser -X- _ O
- -X- _ O
based -X- _ O
agents -X- _ O
, -X- _ O
choice -X- _ O
- -X- _ O
based -X- _ O
agents -X- _ O
, -X- _ O
and -X- _ O
template -X- _ O
- -X- _ O
based -X- _ O
agents -X- _ O
. -X- _ O
The -X- _ O
parser -X- _ O
- -X- _ O
based -X- _ O
agents -X- _ O
generate -X- _ O
actions -X- _ O
word -X- _ O
by -X- _ O
word -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
a -X- _ O
huge -X- _ O
combinatorial -X- _ O
action -X- _ O
space -X- _ O
( -X- _ O
Kohita -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
choice -X- _ O
- -X- _ O
based -X- _ O
agents -X- _ O
circumvent -X- _ O
this -X- _ O
challenge -X- _ O
by -X- _ O
assuming -X- _ O
the -X- _ O
access -X- _ O
to -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
admissible -X- _ O
actions -X- _ O
at -X- _ O
each -X- _ O
game -X- _ O
state -X- _ O
( -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
template -X- _ O
- -X- _ O
based -X- _ O
agents -X- _ O
achieve -X- _ O
a -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
between -X- _ O
the -X- _ O
huge -X- _ O
action -X- _ O
space -X- _ O
and -X- _ O
the -X- _ O
assumption -X- _ O
of -X- _ O
admissible -X- _ O
action -X- _ O
set -X- _ O
by -X- _ O
introducing -X- _ O
the -X- _ O
template -X- _ O
- -X- _ O
based -X- _ O
action -X- _ O
space -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
agent -X- _ O
selects -X- _ O
first -X- _ O
a -X- _ O
template -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
a -X- _ O
verb -X- _ O
- -X- _ O
object -X- _ O
pair -X- _ O
either -X- _ O
individually -X- _ O
or -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
selected -X- _ O
template -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
sam -X- _ O
- -X- _ O
ple -X- _ O
efficiency -X- _ O
and -X- _ O
reduce -X- _ O
the -X- _ O
action -X- _ O
space -X- _ O
through -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
Being -X- _ O
agnostic -X- _ O
about -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
observations -X- _ O
and -X- _ O
the -X- _ O
action -X- _ O
selecting -X- _ O
methods -X- _ O
, -X- _ O
our -X- _ O
work -X- _ O
complements -X- _ O
the -X- _ O
existing -X- _ O
RL -X- _ O
agents -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
is -X- _ O
closely -X- _ O
related -X- _ O
to -X- _ O
task -X- _ O
decomposition -X- _ O
( -X- _ O
Oh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Shiarlis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Sohn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
hierarchical -X- _ O
reinforcement -X- _ O
learning -X- _ O
( -X- _ O
Dayan -X- _ O
and -X- _ O
Hinton -X- _ O
, -X- _ O
1992;Kulkarni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Vezhnevets -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
our -X- _ O
efforts -X- _ O
, -X- _ O
Jiang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
designed -X- _ O
a -X- _ O
meta -X- _ O
- -X- _ O
policy -X- _ O
for -X- _ O
task -X- _ O
decomposition -X- _ O
and -X- _ O
subtask -X- _ O
selection -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
sub -X- _ O
- -X- _ O
policy -X- _ O
for -X- _ O
goal -X- _ O
- -X- _ O
conditioned -X- _ O
decision -X- _ O
making -X- _ O
. -X- _ O
Typically -X- _ O
, -X- _ O
these -X- _ O
works -X- _ O
either -X- _ O
assume -X- _ O
the -X- _ O
access -X- _ O
to -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
available -X- _ O
subtasks -X- _ O
, -X- _ O
or -X- _ O
decompose -X- _ O
a -X- _ O
task -X- _ O
through -X- _ O
pre -X- _ O
- -X- _ O
defined -X- _ O
rules -X- _ O
, -X- _ O
while -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
achieve -X- _ O
automatic -X- _ O
task -X- _ O
decomposition -X- _ O
through -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
and -X- _ O
remove -X- _ O
the -X- _ O
requirement -X- _ O
for -X- _ O
expert -X- _ O
knowledge -X- _ O
during -X- _ O
reinforcement -X- _ O
learning -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
existing -X- _ O
work -X- _ O
assumes -X- _ O
that -X- _ O
unlimited -X- _ O
interaction -X- _ O
data -X- _ O
can -X- _ O
be -X- _ O
obtained -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
whole -X- _ O
model -X- _ O
through -X- _ O
RL -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
more -X- _ O
practical -X- _ O
situation -X- _ O
where -X- _ O
the -X- _ O
interaction -X- _ O
data -X- _ O
is -X- _ O
limited -X- _ O
, -X- _ O
and -X- _ O
focus -X- _ O
on -X- _ O
improving -X- _ O
the -X- _ O
RL -X- _ O
agent -X- _ O
's -X- _ O
data -X- _ O
efficiency -X- _ O
. -X- _ O
Regarding -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
policy -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
assume -X- _ O
the -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
termination -X- _ O
states -X- _ O
of -X- _ O
the -X- _ O
subtasks -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
do -X- _ O
not -X- _ O
require -X- _ O
additional -X- _ O
handcrafted -X- _ O
operations -X- _ O
in -X- _ O
reward -X- _ O
shaping -X- _ O
( -X- _ O
Bahdanau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019).There -X- _ O
have -X- _ O
been -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
work -X- _ O
studying -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
methods -X- _ O
or -X- _ O
incorporating -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
modules -X- _ O
to -X- _ O
facilitate -X- _ O
reinforcement -X- _ O
learning -X- _ O
( -X- _ O
Eysenbach -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Hansen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Sharma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Gehring -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021;Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021;Schwarzer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
One -X- _ O
major -X- _ O
branch -X- _ O
among -X- _ O
them -X- _ O
is -X- _ O
Imitation -X- _ O
Learning -X- _ O
( -X- _ O
IL -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
agent -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
imitate -X- _ O
human -X- _ O
demonstrations -X- _ O
before -X- _ O
being -X- _ O
deployed -X- _ O
in -X- _ O
RL -X- _ O
( -X- _ O
Hester -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Reddy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Although -X- _ O
we -X- _ O
also -X- _ O
collect -X- _ O
human -X- _ O
labeled -X- _ O
data -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
leverage -X- _ O
the -X- _ O
data -X- _ O
to -X- _ O
help -X- _ O
the -X- _ O
agent -X- _ O
to -X- _ O
perceive -X- _ O
the -X- _ O
environment -X- _ O
instead -X- _ O
of -X- _ O
learning -X- _ O
the -X- _ O
solving -X- _ O
strategies -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
require -X- _ O
the -X- _ O
demonstrations -X- _ O
to -X- _ O
be -X- _ O
perfect -X- _ O
to -X- _ O
solve -X- _ O
the -X- _ O
game -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
prevails -X- _ O
when -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
simple -X- _ O
tasks -X- _ O
rather -X- _ O
than -X- _ O
complicated -X- _ O
ones -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
more -X- _ O
feasible -X- _ O
for -X- _ O
human -X- _ O
to -X- _ O
interact -X- _ O
and -X- _ O
annotate -X- _ O
( -X- _ O
Arumugam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Mirchandani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Further -X- _ O
discussions -X- _ O
to -X- _ O
compare -X- _ O
our -X- _ O
method -X- _ O
with -X- _ O
IL -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
subsequent -X- _ O
sections -X- _ O
. -X- _ O

We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
cooking -X- _ O
games -X- _ O
. -X- _ O
We -X- _ O
divide -X- _ O
the -X- _ O
games -X- _ O
as -X- _ O
simple -X- _ O
games -X- _ O
and -X- _ O
complex -X- _ O
games -X- _ O
, -X- _ O
and -X- _ O
construct -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
dataset -X- _ O
from -X- _ O
simple -X- _ O
games -X- _ O
only -X- _ O
. -X- _ O
The -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
QWA -X- _ B-MethodName
achieves -X- _ O
high -X- _ O
sample -X- _ O
efficiency -X- _ O
in -X- _ O
solving -X- _ O
complex -X- _ O
games -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
enjoys -X- _ O
robustness -X- _ O
against -X- _ O
compound -X- _ O
error -X- _ O
and -X- _ O
limited -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O

ings -X- _ O
can -X- _ O
understand -X- _ O
the -X- _ O
environment -X- _ O
conditions -X- _ O
through -X- _ O
question -X- _ O
answering -X- _ O
( -X- _ O
Das -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
worldperceiving -X- _ O
modules -X- _ O
to -X- _ O
realize -X- _ O
the -X- _ O
aforementioned -X- _ O
functionalities -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
task -X- _ O
decomposition -X- _ O
and -X- _ O
action -X- _ O
pruning -X- _ O
) -X- _ O
and -X- _ O
name -X- _ O
our -X- _ O
method -X- _ O
as -X- _ O
Question -X- _ B-MethodName
- -X- _ I-MethodName
guided -X- _ I-MethodName
World -X- _ I-MethodName
- -X- _ I-MethodName
perceiving -X- _ I-MethodName
Agent -X- _ I-MethodName
( -X- _ O
QWA -X- _ B-MethodName
) -X- _ O
* -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
shows -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
our -X- _ O
decision -X- _ O
making -X- _ O
process -X- _ O
. -X- _ O
Being -X- _ O
guided -X- _ O
by -X- _ O
some -X- _ O
questions -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
first -X- _ O
decomposes -X- _ O
the -X- _ O
task -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
available -X- _ O
subtasks -X- _ O
, -X- _ O
and -X- _ O
selects -X- _ O
one -X- _ O
from -X- _ O
them -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
selected -X- _ O
subtask -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
conducts -X- _ O
action -X- _ O
pruning -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
refined -X- _ O
set -X- _ O
of -X- _ O
actions -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
decouple -X- _ O
language -X- _ O
learning -X- _ O
from -X- _ O
decision -X- _ O
making -X- _ O
, -X- _ O
which -X- _ O
further -X- _ O
improves -X- _ O
the -X- _ O
sample -X- _ O
efficiency -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
acquire -X- _ O
the -X- _ O
world -X- _ O
- -X- _ O
perceiving -X- _ O
modules -X- _ O
through -X- _ O
supervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
We -X- _ O
design -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
phase -X- _ O
framework -X- _ O
to -X- _ O
train -X- _ O
our -X- _ O
agent -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
phase -X- _ O
, -X- _ O
a -X- _ O
dataset -X- _ O
is -X- _ O
built -X- _ O
for -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
world -X- _ O
- -X- _ O
perceiving -X- _ O
modules -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
second -X- _ O
phase -X- _ O
, -X- _ O
we -X- _ O
deploy -X- _ O
the -X- _ O
agent -X- _ O
in -X- _ O
games -X- _ O
with -X- _ O
the -X- _ O
pretrained -X- _ O
modules -X- _ O
frozen -X- _ O
, -X- _ O
and -X- _ O
train -X- _ O
the -X- _ O
agent -X- _ O
through -X- _ O
reinforcement -X- _ O
learning -X- _ O
. -X- _ O

Inspired -X- _ O
by -X- _ O
the -X- _ O
observation -X- _ O
that -X- _ O
human -X- _ O
be- -X- _ O
The -X- _ O
decision -X- _ O
making -X- _ O
process -X- _ O
. -X- _ O
Through -X- _ O
question -X- _ O
answering -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
is -X- _ O
guided -X- _ O
to -X- _ O
first -X- _ O
decompose -X- _ O
the -X- _ O
task -X- _ O
as -X- _ O
subtasks -X- _ O
, -X- _ O
then -X- _ O
reduce -X- _ O
the -X- _ O
action -X- _ O
space -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
subtask -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
address -X- _ O
these -X- _ O
two -X- _ O
challenges -X- _ O
for -X- _ O
reinforcement -X- _ O
learning -X- _ O
in -X- _ O
solving -X- _ O
textbased -X- _ B-TaskName
games -X- _ I-TaskName
. -X- _ O
Since -X- _ O
it -X- _ O
is -X- _ O
inefficient -X- _ O
to -X- _ O
train -X- _ O
an -X- _ O
agent -X- _ O
to -X- _ O
solve -X- _ O
complicated -X- _ O
tasks -X- _ O
( -X- _ O
games -X- _ O
) -X- _ O
from -X- _ O
scratch -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
decomposing -X- _ O
a -X- _ O
task -X- _ O
into -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
subtasks -X- _ O
as -X- _ O
inspired -X- _ O
by -X- _ O
( -X- _ O
Andreas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
design -X- _ O
an -X- _ O
RL -X- _ O
agent -X- _ O
that -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
automatic -X- _ O
task -X- _ O
decomposition -X- _ O
and -X- _ O
subtask -X- _ O
- -X- _ O
conditioned -X- _ O
action -X- _ O
pruning -X- _ O
, -X- _ O
which -X- _ O
brings -X- _ O
two -X- _ O
branches -X- _ O
of -X- _ O
benefits -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
the -X- _ O
subtasks -X- _ O
are -X- _ O
easier -X- _ O
to -X- _ O
solve -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
involved -X- _ O
temporal -X- _ O
dependencies -X- _ O
are -X- _ O
usually -X- _ O
shortterm -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
by -X- _ O
acquiring -X- _ O
the -X- _ O
skills -X- _ O
to -X- _ O
solve -X- _ O
subtasks -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
will -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
learn -X- _ O
to -X- _ O
solve -X- _ O
a -X- _ O
new -X- _ O
task -X- _ O
more -X- _ O
quickly -X- _ O
by -X- _ O
reusing -X- _ O
the -X- _ O
learnt -X- _ O
skills -X- _ O
( -X- _ O
Barreto -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
challenge -X- _ O
of -X- _ O
large -X- _ O
action -X- _ O
space -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
alleviated -X- _ O
, -X- _ O
if -X- _ O
we -X- _ O
can -X- _ O
filter -X- _ O
out -X- _ O
the -X- _ O
actions -X- _ O
that -X- _ O
are -X- _ O
irrelevant -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
subtask -X- _ O
. -X- _ O

Despite -X- _ O
the -X- _ O
effectiveness -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
two -X- _ O
major -X- _ O
challenges -X- _ O
for -X- _ O
RL -X- _ O
- -X- _ O
based -X- _ O
agents -X- _ O
, -X- _ O
preventing -X- _ O
them -X- _ O
from -X- _ O
being -X- _ O
deployed -X- _ O
in -X- _ O
real -X- _ O
world -X- _ O
applications -X- _ O
: -X- _ O
the -X- _ O
low -X- _ O
sample -X- _ O
efficiency -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
large -X- _ O
action -X- _ O
space -X- _ O
( -X- _ O
Dulac -X- _ O
- -X- _ O
Arnold -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
low -X- _ O
sample -X- _ O
efficiency -X- _ O
is -X- _ O
a -X- _ O
crucial -X- _ O
limitation -X- _ O
of -X- _ O
RL -X- _ O
which -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
it -X- _ O
typically -X- _ O
requires -X- _ O
a -X- _ O
huge -X- _ O
amount -X- _ O
of -X- _ O
data -X- _ O
to -X- _ O
train -X- _ O
an -X- _ O
agent -X- _ O
to -X- _ O
achieve -X- _ O
human -X- _ O
- -X- _ O
level -X- _ O
performance -X- _ O
( -X- _ O
Tsividis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
human -X- _ O
beings -X- _ O
are -X- _ O
usually -X- _ O
armed -X- _ O
with -X- _ O
prior -X- _ O
knowledge -X- _ O
so -X- _ O
that -X- _ O
they -X- _ O
do -X- _ O
n't -X- _ O
have -X- _ O
to -X- _ O
learn -X- _ O
from -X- _ O
scratch -X- _ O
( -X- _ O
Dubey -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
a -X- _ O
language -X- _ O
- -X- _ O
informed -X- _ O
RL -X- _ O
system -X- _ O
, -X- _ O
in -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
is -X- _ O
required -X- _ O
to -X- _ O
conduct -X- _ O
both -X- _ O
language -X- _ O
learning -X- _ O
and -X- _ O
decision -X- _ O
making -X- _ O
regimes -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
former -X- _ O
can -X- _ O
be -X- _ O
considered -X- _ O
as -X- _ O
prior -X- _ O
knowledge -X- _ O
and -X- _ O
is -X- _ O
much -X- _ O
slower -X- _ O
than -X- _ O
the -X- _ O
later -X- _ O
( -X- _ O
Hill -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
sample -X- _ O
efficiency -X- _ O
could -X- _ O
be -X- _ O
improved -X- _ O
through -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
methods -X- _ O
, -X- _ O
which -X- _ O
decouple -X- _ O
the -X- _ O
language -X- _ O
learning -X- _ O
from -X- _ O
decision -X- _ O
making -X- _ O
( -X- _ O
Su -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
selection -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
methods -X- _ O
thus -X- _ O
plays -X- _ O
an -X- _ O
important -X- _ O
role -X- _ O
: -X- _ O
if -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
modules -X- _ O
perform -X- _ O
poorly -X- _ O
on -X- _ O
unseen -X- _ O
data -X- _ O
during -X- _ O
RL -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
incurred -X- _ O
compound -X- _ O
error -X- _ O
will -X- _ O
severely -X- _ O
affect -X- _ O
the -X- _ O
decision -X- _ O
making -X- _ O
process -X- _ O
. -X- _ O
Another -X- _ O
challenge -X- _ O
is -X- _ O
the -X- _ O
large -X- _ O
discrete -X- _ O
action -X- _ O
space -X- _ O
: -X- _ O
the -X- _ O
agent -X- _ O
may -X- _ O
waste -X- _ O
both -X- _ O
time -X- _ O
and -X- _ O
training -X- _ O
data -X- _ O
if -X- _ O
attempting -X- _ O
irrelevant -X- _ O
or -X- _ O
inferior -X- _ O
actions -X- _ O
( -X- _ O
Dulac -X- _ O
- -X- _ O
Arnold -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Zahavy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Text -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
games -X- _ I-TaskName
are -X- _ O
simulated -X- _ O
environments -X- _ O
where -X- _ O
the -X- _ O
player -X- _ O
observes -X- _ O
textual -X- _ O
descriptions -X- _ O
, -X- _ O
and -X- _ O
acts -X- _ O
using -X- _ O
text -X- _ O
commands -X- _ O
Urbanek -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
games -X- _ O
provide -X- _ O
a -X- _ O
safe -X- _ O
and -X- _ O
interactive -X- _ O
way -X- _ O
to -X- _ O
study -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
, -X- _ O
commonsense -X- _ B-TaskName
reasoning -X- _ I-TaskName
, -X- _ O
and -X- _ O
dialogue -X- _ B-TaskName
systems -X- _ I-TaskName
. -X- _ O
Besides -X- _ O
language -X- _ O
processing -X- _ O
techniques -X- _ O
, -X- _ O
Reinforcement -X- _ O
Learning -X- _ O
has -X- _ O
become -X- _ O
a -X- _ O
quintessential -X- _ O
methodology -X- _ O
for -X- _ O
solving -X- _ O
text -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
games -X- _ I-TaskName
. -X- _ O
Some -X- _ O
RL -X- _ O
- -X- _ O
based -X- _ O
game -X- _ O
agents -X- _ O
have -X- _ O
been -X- _ O
developed -X- _ O
recently -X- _ O
and -X- _ O
proven -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
in -X- _ O
handling -X- _ O
challenges -X- _ O
such -X- _ O
as -X- _ O
language -X- _ O
representation -X- _ O
learning -X- _ O
and -X- _ O
partial -X- _ O
observability -X- _ O
( -X- _ O
Narasimhan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Fang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Ammanabrolu -X- _ O
and -X- _ O
Riedl -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

and -X- _ O
help -X- _ O
the -X- _ O
model -X- _ O
make -X- _ O
better -X- _ O
predictions -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
some -X- _ O
questions -X- _ O
have -X- _ O
a -X- _ O
higher -X- _ O
probability -X- _ O
on -X- _ O
a -X- _ O
very -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
irrelevant -X- _ O
labels -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
labels -X- _ O
in -X- _ O
KBs -X- _ O
is -X- _ O
large -X- _ O
, -X- _ O
having -X- _ O
a -X- _ O
high -X- _ O
probability -X- _ O
of -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
irrelevant -X- _ O
labels -X- _ O
will -X- _ O
not -X- _ O
greatly -X- _ O
affect -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
entire -X- _ O
model -X- _ O
. -X- _ O
Ground -X- _ O
- -X- _ O
truth -X- _ O
Labels -X- _ O
The -X- _ O
present -X- _ O
research -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
Zhejiang -X- _ O
Lab -X- _ O
( -X- _ O
No -X- _ O
. -X- _ O
2022KH0AB01 -X- _ O
) -X- _ O
and -X- _ O
Huawei -X- _ O
( -X- _ O
No -X- _ O
. -X- _ O
TC20210528011 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
insightful -X- _ O
comments -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
want -X- _ O
to -X- _ O
thank -X- _ O
MindSpore -X- _ O
1 -X- _ O
for -X- _ O
the -X- _ O
partial -X- _ O
suppoort -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
new -X- _ O
deep -X- _ O
learning -X- _ O
computing -X- _ O
framework -X- _ O
. -X- _ O
The -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
( -X- _ O
NLU -X- _ B-TaskName
) -X- _ O
task -X- _ O
has -X- _ O
attracted -X- _ O
much -X- _ O
recent -X- _ O
attention -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
prior -X- _ O
methods -X- _ O
have -X- _ O
been -X- _ O
evaluated -X- _ O
under -X- _ O
a -X- _ O
disparate -X- _ O
set -X- _ O
of -X- _ O
protocols -X- _ O
, -X- _ O
which -X- _ O
hinders -X- _ O
fair -X- _ O
comparison -X- _ O
and -X- _ O
measuring -X- _ O
progress -X- _ O
of -X- _ O
the -X- _ O
field -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
an -X- _ O
evaluation -X- _ O
framework -X- _ O
that -X- _ O
improves -X- _ O
previous -X- _ O
evaluation -X- _ O
procedures -X- _ O
in -X- _ O
three -X- _ O
key -X- _ O
aspects -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
test -X- _ O
performance -X- _ O
, -X- _ O
dev -X- _ O
- -X- _ O
test -X- _ O
correlation -X- _ O
, -X- _ O
and -X- _ O
stability -X- _ O
. -X- _ O
Under -X- _ O
this -X- _ O
new -X- _ O
evaluation -X- _ O
framework -X- _ O
, -X- _ O
we -X- _ O
re -X- _ O
- -X- _ O
evaluate -X- _ O
several -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
methods -X- _ O
for -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
Our -X- _ O
framework -X- _ O
reveals -X- _ O
new -X- _ O
insights -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
both -X- _ O
the -X- _ O
absolute -X- _ O
performance -X- _ O
and -X- _ O
relative -X- _ O
gap -X- _ O
of -X- _ O
the -X- _ O
methods -X- _ O
were -X- _ O
not -X- _ O
accurately -X- _ O
estimated -X- _ O
in -X- _ O
prior -X- _ O
literature -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
no -X- _ O
single -X- _ O
method -X- _ O
dominates -X- _ O
most -X- _ O
tasks -X- _ O
with -X- _ O
consistent -X- _ O
performance -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
improvements -X- _ O
of -X- _ O
some -X- _ O
methods -X- _ O
diminish -X- _ O
with -X- _ O
a -X- _ O
larger -X- _ O
pretrained -X- _ O
model -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
gains -X- _ O
from -X- _ O
different -X- _ O
methods -X- _ O
are -X- _ O
often -X- _ O
complementary -X- _ O
and -X- _ O
the -X- _ O
best -X- _ O
combined -X- _ O
model -X- _ O
performs -X- _ O
close -X- _ O
to -X- _ O
a -X- _ O
strong -X- _ O
fully -X- _ O
- -X- _ O
supervised -X- _ O
baseline -X- _ O
. -X- _ O
We -X- _ O
open -X- _ O
- -X- _ O
source -X- _ O
our -X- _ O
toolkit -X- _ O
, -X- _ O
FewNLU -X- _ B-DatasetName
, -X- _ O
that -X- _ O
implements -X- _ O
our -X- _ O
evaluation -X- _ O
framework -X- _ O
along -X- _ O
with -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
methods -X- _ O
. -X- _ O
1 -X- _ O
2 -X- _ O

Few -X- _ O
- -X- _ O
shot -X- _ O
learning -X- _ O
for -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
( -X- _ O
NLU -X- _ B-TaskName
) -X- _ O
has -X- _ O
been -X- _ O
significantly -X- _ O
advanced -X- _ O
by -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
PLMs -X- _ O
; -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2021a -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
learning -X- _ O
a -X- _ O
new -X- _ O
task -X- _ O
with -X- _ O
very -X- _ O
few -X- _ O
( -X- _ O
usually -X- _ O
less -X- _ O
than -X- _ O
a -X- _ O
hundred -X- _ O
) -X- _ O
samples -X- _ O
, -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
learning -X- _ O
benefits -X- _ O
from -X- _ O
the -X- _ O
prior -X- _ O
knowledge -X- _ O
stored -X- _ O
in -X- _ O
PLMs -X- _ O
. -X- _ O
Various -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
methods -X- _ O
based -X- _ O
on -X- _ O
PLMs -X- _ O
and -X- _ O
prompting -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b;Menon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021;Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

3 -X- _ B-MetricValue
-Talks -X- _ O
about -X- _ O
topics -X- _ O
with -X- _ O
the -X- _ O
correct -X- _ O
orientation -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
target -X- _ O
style -X- _ O
is -X- _ O
democratic -X- _ O
and -X- _ O
talks -X- _ O
about -X- _ O
progressive -X- _ O
issues -X- _ O
like -X- _ O
liberty -X- _ O
, -X- _ O
free -X- _ O
speech -X- _ O
, -X- _ O
Elizabeth -X- _ O
Warren -X- _ O
, -X- _ O
Joe -X- _ O
Biden -X- _ O
, -X- _ O
gay -X- _ O
rights -X- _ O
etc -X- _ O
. -X- _ O
Hallucinates -X- _ O
Sen -X- _ O
Booker -X- _ O
which -X- _ O
appears -X- _ O
frequently -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
Target -X- _ O
by -X- _ O
far -X- _ O
, -X- _ O
the -X- _ O
best -X- _ O
spot -X- _ O
for -X- _ O
ramen -X- _ O
. -X- _ O
simple -X- _ O
menu -X- _ O
. -X- _ O
fast -X- _ O
service -X- _ O
. -X- _ O
silky -X- _ O
, -X- _ O
creamy -X- _ O
chicken -X- _ O
broth -X- _ O
. -X- _ O
by -X- _ O
far -X- _ O
the -X- _ O
best -X- _ O
breakfast -X- _ O
tacos -X- _ O
in -X- _ O
the -X- _ O
area -X- _ O
. -X- _ O
friendly -X- _ O
staff -X- _ O
. -X- _ O
great -X- _ O
food -X- _ O
. -X- _ O
ask -X- _ O
for -X- _ O
the -X- _ O
spicy -X- _ O
chicken -X- _ O
, -X- _ O
and -X- _ O
they -X- _ O
have -X- _ O
a -X- _ O
great -X- _ O
selection -X- _ O
. -X- _ O
try -X- _ O
sushi -X- _ O
boat -X- _ O
. -X- _ O
it -X- _ O
's -X- _ O
totally -X- _ O
amazing -X- _ O
. -X- _ O
they -X- _ O
offer -X- _ O
good -X- _ O
food -X- _ O
and -X- _ O
high -X- _ O
quality -X- _ O
. -X- _ O
good -X- _ O
sake -X- _ O
is -X- _ O
ready -X- _ O
. -X- _ O
thank -X- _ O
you -X- _ O
for -X- _ O
good -X- _ O
place -X- _ O
. -X- _ O
love -X- _ O
it -X- _ O
. -X- _ O
good -X- _ O
food -X- _ O
. -X- _ O
they -X- _ O
have -X- _ O
good -X- _ O
margaritas -X- _ O
and -X- _ O
good -X- _ O
food -X- _ O
. -X- _ O
good -X- _ O
prices -X- _ O
. -X- _ O
there -X- _ O
's -X- _ O
a -X- _ O
good -X- _ O
amount -X- _ O
of -X- _ O
food -X- _ O
for -X- _ O
you -X- _ O
. -X- _ O
best -X- _ O
thai -X- _ O
in -X- _ O
austin -X- _ O
. -X- _ O
we -X- _ O
love -X- _ O
the -X- _ O
atmosphere -X- _ O
, -X- _ O
the -X- _ O
service -X- _ O
and -X- _ O
obviously -X- _ O
the -X- _ O
food -X- _ O
. -X- _ O
they -X- _ O
did -X- _ O
a -X- _ O
great -X- _ O
job -X- _ O
last -X- _ O
time -X- _ O
we -X- _ O
were -X- _ O
there -X- _ O
since -X- _ O
our -X- _ O
party -X- _ O
had -X- _ O
specific -X- _ O
requirements -X- _ O
like -X- _ O
< -X- _ O
unk -X- _ O
> -X- _ O
free -X- _ O
and -X- _ O
< -X- _ O
unk -X- _ O
> -X- _ O
. -X- _ O
best -X- _ O
mexican -X- _ O
food -X- _ O
in -X- _ O
the -X- _ O
area -X- _ O
. -X- _ O
the -X- _ O
service -X- _ O
was -X- _ O
great -X- _ O
and -X- _ O
the -X- _ O
food -X- _ O
was -X- _ O
so -X- _ O
good -X- _ O
. -X- _ O
we -X- _ O
had -X- _ O
a -X- _ O
party -X- _ O
of -X- _ O
10 -X- _ O
and -X- _ O
they -X- _ O
were -X- _ O
very -X- _ O
accommodating -X- _ O
to -X- _ O
our -X- _ O
group -X- _ O
of -X- _ O
us -X- _ O
. -X- _ O
we -X- _ O
were -X- _ O
there -X- _ O
last -X- _ O
night -X- _ O
and -X- _ O
the -X- _ O
food -X- _ O
was -X- _ O
good -X- _ O
fabulous -X- _ O
, -X- _ O
delicious -X- _ O
, -X- _ O
authentic -X- _ O
. -X- _ O
at -X- _ O
lunch -X- _ O
on -X- _ O
a -X- _ O
saturday -X- _ O
the -X- _ O
place -X- _ O
was -X- _ O
packed -X- _ O
! -X- _ O
20 -X- _ O
minute -X- _ O
wait -X- _ O
for -X- _ O
a -X- _ O
table -X- _ O
. -X- _ O
i -X- _ O
was -X- _ O
one -X- _ O
of -X- _ O
two -X- _ O
customers -X- _ O
who -X- _ O
was -X- _ O
not -X- _ O
chinese -X- _ O
. -X- _ O
i -X- _ O
'll -X- _ O
be -X- _ O
back -X- _ O
frequently -X- _ O
. -X- _ O
awesome -X- _ O
mexican -X- _ O
food -X- _ O
, -X- _ O
a -X- _ O
little -X- _ O
on -X- _ O
the -X- _ O
corner -X- _ O
of -X- _ O
a -X- _ O
< -X- _ O
unk -X- _ O
> -X- _ O
. -X- _ O
i -X- _ O
was -X- _ O
here -X- _ O
on -X- _ O
a -X- _ O
saturday -X- _ O
night -X- _ O
. -X- _ O
they -X- _ O
were -X- _ O
busy -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
were -X- _ O
able -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
table -X- _ O
. -X- _ O
i -X- _ O
will -X- _ O
definitely -X- _ O
be -X- _ O
back -X- _ O
! -X- _ O
this -X- _ O
place -X- _ O
is -X- _ O
great -X- _ O
! -X- _ O
i -X- _ O
grew -X- _ O
up -X- _ O
going -X- _ O
to -X- _ O
china -X- _ O
inn -X- _ O
in -X- _ O
chamblee -X- _ O
plaza -X- _ O
and -X- _ O
it -X- _ O
's -X- _ O
the -X- _ O
same -X- _ O
owner -X- _ O
! -X- _ O
lunch -X- _ O
service -X- _ O
is -X- _ O
fast -X- _ O
and -X- _ O
delicious -X- _ O
! -X- _ O
give -X- _ O
it -X- _ O
a -X- _ O
shot -X- _ O
, -X- _ O
you -X- _ O
wo -X- _ O
n't -X- _ O
be -X- _ O
disappointed -X- _ O
! -X- _ O
this -X- _ O
place -X- _ O
is -X- _ O
awesome -X- _ O
! -X- _ O
! -X- _ O
i -X- _ O
've -X- _ O
been -X- _ O
coming -X- _ O
to -X- _ O
this -X- _ O
location -X- _ O
for -X- _ O
years -X- _ O
and -X- _ O
it -X- _ O
's -X- _ O
always -X- _ O
clean -X- _ O
and -X- _ O
the -X- _ O
service -X- _ O
is -X- _ O
fast -X- _ O
and -X- _ O
friendly -X- _ O
. -X- _ O
it -X- _ O
's -X- _ O
a -X- _ O
great -X- _ O
mexican -X- _ O
restaurant -X- _ O
, -X- _ O
you -X- _ O
ca -X- _ O
n't -X- _ O
go -X- _ O
wrong -X- _ O
with -X- _ O
the -X- _ O
food -X- _ O
! -X- _ O
awful -X- _ O
. -X- _ O
i -X- _ O
'm -X- _ O
writing -X- _ O
this -X- _ O
as -X- _ O
i -X- _ O
eat -X- _ O
it -X- _ O
now -X- _ O
. -X- _ O
worst -X- _ O
poke -X- _ O
bowl -X- _ O
i -X- _ O
've -X- _ O
ever -X- _ O
had -X- _ O
. -X- _ O
the -X- _ O
smallest -X- _ O
portion -X- _ O
of -X- _ O
poke -X- _ O
possible -X- _ O
, -X- _ O
< -X- _ O
unk -X- _ O
> -X- _ O
overcooked -X- _ O
rice -X- _ O
, -X- _ O
and -X- _ O
barely -X- _ O
got -X- _ O
any -X- _ O
ponzu -X- _ O
. -X- _ O
most -X- _ O
standard -X- _ O
toppings -X- _ O
cost -X- _ O
extra -X- _ O
too -X- _ O
. -X- _ O
awful -X- _ O
! -X- _ O
i -X- _ O
've -X- _ O
never -X- _ O
had -X- _ O
a -X- _ O
bad -X- _ O
meal -X- _ O
here -X- _ O
. -X- _ O
i -X- _ O
only -X- _ O
ordered -X- _ O
two -X- _ O
of -X- _ O
them -X- _ O
. -X- _ O
the -X- _ O
only -X- _ O
thing -X- _ O
i -X- _ O
did -X- _ O
n't -X- _ O
like -X- _ O
was -X- _ O
the -X- _ O
< -X- _ O
unk -X- _ O
> -X- _ O
. -X- _ O
it -X- _ O
's -X- _ O
not -X- _ O
much -X- _ O
flavor -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
meat -X- _ O
is -X- _ O
dry -X- _ O
. -X- _ O
worst -X- _ O
chinese -X- _ O
food -X- _ O
experience -X- _ O
i -X- _ O
ever -X- _ O
had -X- _ O
. -X- _ O
told -X- _ O
the -X- _ O
manager -X- _ O
about -X- _ O
my -X- _ O
allergies -X- _ O
and -X- _ O
that -X- _ O
all -X- _ O
i -X- _ O
wanted -X- _ O
was -X- _ O
vegetable -X- _ O
fried -X- _ O
rice -X- _ O
no -X- _ O
soy -X- _ O
sauce -X- _ O
they -X- _ O
could -X- _ O
n't -X- _ O
even -X- _ O
handle -X- _ O
that -X- _ O
! -X- _ O
! -X- _ O
! -X- _ O
amateur -X- _ O
hour -X- _ O
here -X- _ O
do -X- _ O
n't -X- _ O
waste -X- _ O
your -X- _ O
time -X- _ O
. -X- _ O
go -X- _ O
to -X- _ O
china -X- _ O
blossom -X- _ O
worst -X- _ O
experience -X- _ O
ever -X- _ O
. -X- _ O
i -X- _ O
ordered -X- _ O
the -X- _ O
< -X- _ O
unk -X- _ O
> -X- _ O
and -X- _ O
they -X- _ O
were -X- _ O
all -X- _ O
wrong -X- _ O
with -X- _ O
that -X- _ O
i -X- _ O
could -X- _ O
n't -X- _ O
eat -X- _ O
the -X- _ O
food -X- _ O
. -X- _ O
that -X- _ O
's -X- _ O
how -X- _ O
i -X- _ O
do -X- _ O
n't -X- _ O
care -X- _ O
about -X- _ O
how -X- _ O
they -X- _ O
charge -X- _ O
you -X- _ O
for -X- _ O
the -X- _ O
fajitas -X- _ O
. -X- _ O
no -X- _ O
one -X- _ O
ever -X- _ O
came -X- _ O
to -X- _ O
eat -X- _ O
here -X- _ O
. -X- _ O
the -X- _ O
food -X- _ O
was -X- _ O
terrible -X- _ O
. -X- _ O
it -X- _ O
definitely -X- _ O
was -X- _ O
not -X- _ O
fresh -X- _ O
. -X- _ O
the -X- _ O
broccoli -X- _ O
was -X- _ O
over -X- _ O
cooked -X- _ O
on -X- _ O
my -X- _ O
beef -X- _ O
broccoli -X- _ O
. -X- _ O
my -X- _ O
chicken -X- _ O
chow -X- _ O
mean -X- _ O
fried -X- _ O
rice -X- _ O
just -X- _ O
looked -X- _ O
and -X- _ O
tasted -X- _ O
like -X- _ O
last -X- _ O
weeks -X- _ O
rice -X- _ O
. -X- _ O
there -X- _ O
was -X- _ O
one -X- _ O
chunk -X- _ O
of -X- _ O
chicken -X- _ O
and -X- _ O
< -X- _ O
unk -X- _ O
> -X- _ O
pieces -X- _ O
of -X- _ O
egg -X- _ O
in -X- _ O
the -X- _ O
food -X- _ O
was -X- _ O
just -X- _ O
ok -X- _ O
. -X- _ O
the -X- _ O
chicken -X- _ O
was -X- _ O
dry -X- _ O
. -X- _ O
it -X- _ O
was -X- _ O
very -X- _ O
dry -X- _ O
. -X- _ O
i -X- _ O
ordered -X- _ O
the -X- _ O
chicken -X- _ O
chimichanga -X- _ O
and -X- _ O
it -X- _ O
was -X- _ O
just -X- _ O
plain -X- _ O
gross -X- _ O
. -X- _ O
the -X- _ O
only -X- _ O
thing -X- _ O
that -X- _ O
was -X- _ O
< -X- _ O
unk -X- _ O
> -X- _ O
was -X- _ O
the -X- _ O
chicken -X- _ O
burrito -X- _ O
. -X- _ O
there -X- _ O
was -X- _ O
only -X- _ O
one -X- _ O
other -X- _ O
person -X- _ O
in -X- _ O
the -X- _ O
< -X- _ O
unk -X- _ O
> -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
useful -X- _ O
suggestions -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
also -X- _ O
like -X- _ O
to -X- _ O
acknowledge -X- _ O
the -X- _ O
support -X- _ O
of -X- _ O
the -X- _ O
NExT -X- _ O
research -X- _ O
grant -X- _ O
funds -X- _ O
, -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
National -X- _ O
Research -X- _ O
Foundation -X- _ O
, -X- _ O
Prime -X- _ O
Ministers -X- _ O
Office -X- _ O
, -X- _ O
Singapore -X- _ O
under -X- _ O
its -X- _ O
IRC@ -X- _ O
SG -X- _ O
Funding -X- _ O
Initiative -X- _ O
, -X- _ O
and -X- _ O
to -X- _ O
gratefully -X- _ O
acknowledge -X- _ O
the -X- _ O
support -X- _ O
of -X- _ O
NVIDIA -X- _ O
Corporation -X- _ O
with -X- _ O
the -X- _ O
donation -X- _ O
of -X- _ O
the -X- _ O
GeForce -X- _ O
GTX -X- _ O
Titan -X- _ O
XGPU -X- _ O
used -X- _ O
in -X- _ O
this -X- _ O
research -X- _ O
. -X- _ O
The -X- _ O
work -X- _ O
is -X- _ O
also -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
project -X- _ O
no -X- _ O
. -X- _ O
T2MOE2008 -X- _ O
titled -X- _ O
CSK -X- _ O
- -X- _ O
NLP -X- _ O
: -X- _ O
Leveraging -X- _ O
Commonsense -X- _ O
Knowledge -X- _ O
for -X- _ O
NLP -X- _ O
awarded -X- _ O
by -X- _ O
Singapore -X- _ O
's -X- _ O
Ministry -X- _ O
of -X- _ O
Education -X- _ O
under -X- _ O
its -X- _ O
Tier-2 -X- _ O
grant -X- _ O
scheme -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
two -X- _ O
issues -X- _ O
of -X- _ O
semantic -X- _ O
parsing -X- _ O
approaches -X- _ O
to -X- _ O
conversational -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
over -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
knowledge -X- _ O
base -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
The -X- _ O
actions -X- _ O
defined -X- _ O
in -X- _ O
grammar -X- _ O
are -X- _ O
not -X- _ O
sufficient -X- _ O
to -X- _ O
handle -X- _ O
uncertain -X- _ O
reasoning -X- _ O
common -X- _ O
in -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
scenarios -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Knowledge -X- _ O
base -X- _ O
information -X- _ O
is -X- _ O
not -X- _ O
well -X- _ O
exploited -X- _ O
and -X- _ O
incorporated -X- _ O
into -X- _ O
semantic -X- _ O
parsing -X- _ O
. -X- _ O
To -X- _ O
mitigate -X- _ O
the -X- _ O
two -X- _ O
issues -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
knowledge -X- _ B-MethodName
- -X- _ I-MethodName
aware -X- _ I-MethodName
fuzzy -X- _ I-MethodName
semantic -X- _ I-MethodName
parsing -X- _ I-MethodName
framework -X- _ O
( -X- _ O
KaFSP -X- _ B-MethodName
) -X- _ O
. -X- _ O
It -X- _ O
defines -X- _ O
fuzzy -X- _ O
comparison -X- _ O
operations -X- _ O
in -X- _ O
the -X- _ O
grammar -X- _ O
system -X- _ O
for -X- _ O
uncertain -X- _ O
reasoning -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
fuzzy -X- _ O
set -X- _ O
theory -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
interaction -X- _ O
between -X- _ O
semantic -X- _ O
parsing -X- _ O
and -X- _ O
knowledge -X- _ O
base -X- _ O
, -X- _ O
we -X- _ O
incorporate -X- _ O
entity -X- _ O
triples -X- _ O
from -X- _ O
the -X- _ O
knowledge -X- _ O
base -X- _ O
into -X- _ O
a -X- _ O
knowledgeaware -X- _ O
entity -X- _ O
disambiguation -X- _ O
module -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
label -X- _ O
classification -X- _ O
framework -X- _ O
to -X- _ O
not -X- _ O
only -X- _ O
capture -X- _ O
correlations -X- _ O
between -X- _ O
entity -X- _ O
types -X- _ O
and -X- _ O
relations -X- _ O
but -X- _ O
also -X- _ O
detect -X- _ O
knowledge -X- _ O
base -X- _ O
information -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
utterance -X- _ O
. -X- _ O
Both -X- _ O
enhancements -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
Experiments -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
conversational -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
benchmark -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
KaFSP -X- _ B-MethodName
achieves -X- _ O
significant -X- _ O
improvements -X- _ O
over -X- _ O
previous -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
, -X- _ O
setting -X- _ O
new -X- _ O
SOTA -X- _ O
results -X- _ O
on -X- _ O
8 -X- _ O
out -X- _ O
of -X- _ O
10 -X- _ O
question -X- _ O
types -X- _ O
, -X- _ O
gaining -X- _ O
improvements -X- _ O
of -X- _ O
over -X- _ O
10 -X- _ B-MetricValue
% -X- _ I-MetricValue
F1 -X- _ B-MetricName
or -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
3 -X- _ O
question -X- _ O
types -X- _ O
, -X- _ O
and -X- _ O
improving -X- _ O
overall -X- _ O
F1 -X- _ B-MetricName
from -X- _ O
83.01 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
85.33 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
The -X- _ O
source -X- _ O
code -X- _ O
of -X- _ O
KaFSP -X- _ B-MethodName
is -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
//github.com -X- _ O
/ -X- _ O
tjunlp -X- _ O
- -X- _ O
lab -X- _ O
/ -X- _ O
KaFSP -X- _ B-MethodName
. -X- _ O

If -X- _ O
the -X- _ O
sentence -X- _ O
itself -X- _ O
has -X- _ O
no -X- _ O
sentiment -X- _ O
then -X- _ O
chose -X- _ O
2 -X- _ B-MetricValue
Political -X- _ O
Orientation -X- _ O
1 -X- _ O
-Talks -X- _ O
about -X- _ O
topics -X- _ O
with -X- _ O
the -X- _ O
other -X- _ O
orientation -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
target -X- _ O
style -X- _ O
is -X- _ O
democratic -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
sentence -X- _ O
talks -X- _ O
about -X- _ O
conservative -X- _ O
issues -X- _ O
like -X- _ O
abortion -X- _ O
, -X- _ O
gun -X- _ O
control -X- _ O
2 -X- _ B-MetricValue
-Neutral -X- _ O
. -X- _ O

2 -X- _ B-MetricValue
-Fluent -X- _ O
but -X- _ O
with -X- _ O
some -X- _ O
mistakes -X- _ O
-Fluent -X- _ O
but -X- _ O
with -X- _ O
some -X- _ O
grammatical -X- _ O
errors -X- _ O
3 -X- _ B-MetricValue
-Entirely -X- _ O
fluent -X- _ O
. -X- _ O
-A -X- _ O
good -X- _ O
English -X- _ O
Sentence -X- _ O
Similarity -X- _ O
: -X- _ O
Indicate -X- _ O
how -X- _ O
semantically -X- _ O
similar -X- _ O
the -X- _ O
target -X- _ O
sentence -X- _ O
is -X- _ O
. -X- _ O
1 -X- _ B-MetricValue
-Does -X- _ O
not -X- _ O
share -X- _ O
any -X- _ O
words -X- _ O
/ -X- _ O
phrases -X- _ O
with -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
and/or -X- _ O
is -X- _ O
not -X- _ O
semantically -X- _ O
similar -X- _ O
( -X- _ O
does -X- _ O
not -X- _ O
share -X- _ O
high -X- _ O
level -X- _ O
topics -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
) -X- _ O
2 -X- _ B-MetricValue
-Shares -X- _ O
some -X- _ O
words -X- _ O
/ -X- _ O
phrases -X- _ O
with -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
and/or -X- _ O
has -X- _ O
moderate -X- _ O
level -X- _ O
of -X- _ O
semantic -X- _ O
similarity -X- _ O
( -X- _ O
talks -X- _ O
about -X- _ O
similar -X- _ O
high -X- _ O
level -X- _ O
topics -X- _ O
) -X- _ O
3 -X- _ B-MetricValue
-Shares -X- _ O
appropriate -X- _ O
words -X- _ O
/ -X- _ O
phrases -X- _ O
with -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
and -X- _ O
is -X- _ O
highly -X- _ O
semantically -X- _ O
similar -X- _ O
Accuracy -X- _ B-MetricName
: -X- _ O
Indicate -X- _ O
whether -X- _ O
the -X- _ O
target -X- _ O
sentence -X- _ O
is -X- _ O
accurately -X- _ O
transferred -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
Sentiment -X- _ O
Transfer -X- _ O
1 -X- _ B-MetricValue
-The -X- _ O
target -X- _ O
sentiment -X- _ O
is -X- _ O
not -X- _ O
evident -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
sentence -X- _ O
at -X- _ O
all -X- _ O
. -X- _ O
Has -X- _ O
words -X- _ O
expressing -X- _ O
opposite -X- _ O
sentiment -X- _ O
2 -X- _ B-MetricValue
-Neutral -X- _ O
Sentiment -X- _ O
. -X- _ O
Choose -X- _ O
this -X- _ O
option -X- _ O
, -X- _ O
if -X- _ O
it -X- _ O
has -X- _ O
both -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
sentiment -X- _ O
-The -X- _ O
target -X- _ O
sentiment -X- _ O
is -X- _ O
evident -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
sentiment -X- _ O
. -X- _ O
Has -X- _ O
appropriate -X- _ O
sentiment -X- _ O
bearing -X- _ O
words -X- _ O
. -X- _ O

1 -X- _ B-MetricValue
-Not -X- _ O
fluent -X- _ O
at -X- _ O
all -X- _ O
-Does -X- _ O
not -X- _ O
look -X- _ O
like -X- _ O
an -X- _ O
English -X- _ O
sentence -X- _ O
. -X- _ O

Fluency -X- _ B-MetricName
: -X- _ O
Indicate -X- _ O
how -X- _ O
fluent -X- _ O
the -X- _ O
target -X- _ O
sentence -X- _ O
is -X- _ O
( -X- _ O
regardless -X- _ O
of -X- _ O
whether -X- _ O
the -X- _ O
sentence -X- _ O
is -X- _ O
appropriately -X- _ O
transferred -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
sentence -X- _ O
) -X- _ O

• -X- _ O
Target -X- _ O
sentence -X- _ O
: -X- _ O
The -X- _ O
transferred -X- _ O
sentence -X- _ O
produced -X- _ O
by -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
systems -X- _ O
For -X- _ O
every -X- _ O
target -X- _ O
sentence -X- _ O
you -X- _ O
will -X- _ O
be -X- _ O
asked -X- _ O
to -X- _ O
rate -X- _ O
it -X- _ O
according -X- _ O
to -X- _ O
three -X- _ O
measures -X- _ O
described -X- _ O
below -X- _ O
. -X- _ O

Information -X- _ O
about -X- _ O
participants -X- _ O
: -X- _ O
We -X- _ O
hire -X- _ O
three -X- _ O
graduate -X- _ O
researchers -X- _ O
in -X- _ O
NLP -X- _ O
( -X- _ O
average -X- _ O
age -X- _ O
25 -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
annotation -X- _ O
task -X- _ O
who -X- _ O
are -X- _ O
well -X- _ O
versed -X- _ O
in -X- _ O
English -X- _ O
. -X- _ O
We -X- _ O
obtained -X- _ O
permission -X- _ O
for -X- _ O
their -X- _ O
participation -X- _ O
and -X- _ O
compensated -X- _ O
them -X- _ O
appropriately -X- _ O
according -X- _ O
to -X- _ O
hourly -X- _ O
wages -X- _ O
in -X- _ O
the -X- _ O
country -X- _ O
. -X- _ O
The -X- _ O
specific -X- _ O
instruction -X- _ O
given -X- _ O
to -X- _ O
them -X- _ O
for -X- _ O
the -X- _ O
evaluation -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O
Consider -X- _ O
two -X- _ O
sentences -X- _ O
• -X- _ O
Source -X- _ O
sentence -X- _ O
: -X- _ O
Sentence -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
domain -X- _ O

In -X- _ O
recent -X- _ O
times -X- _ O
, -X- _ O
text -X- _ O
style -X- _ O
transfer -X- _ O
models -X- _ O
are -X- _ O
moving -X- _ O
away -X- _ O
from -X- _ O
disentanglement -X- _ O
approaches -X- _ O
( -X- _ O
Subramanian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Recent -X- _ O
works -X- _ O
that -X- _ O
use -X- _ O
transformers -X- _ O
for -X- _ O
style -X- _ B-TaskName
transfer -X- _ I-TaskName
also -X- _ O
have -X- _ O
adopted -X- _ O
this -X- _ O
( -X- _ O
Dai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Krishna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
How -X- _ O
- -X- _ O
ever -X- _ O
, -X- _ O
these -X- _ O
methods -X- _ O
do -X- _ O
not -X- _ O
explicitly -X- _ O
maintain -X- _ O
the -X- _ O
constraints -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
styles -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
main -X- _ O
aim -X- _ O
of -X- _ O
our -X- _ O
work -X- _ O
. -X- _ O
Text -X- _ B-TaskName
style -X- _ I-TaskName
transfer -X- _ I-TaskName
works -X- _ O
focuses -X- _ O
on -X- _ O
retaining -X- _ O
content -X- _ O
and -X- _ O
changing -X- _ O
the -X- _ O
style -X- _ O
of -X- _ O
sentences -X- _ O
but -X- _ O
does -X- _ O
not -X- _ O
maintain -X- _ O
other -X- _ O
desirable -X- _ O
constraints -X- _ O
. -X- _ O
We -X- _ O
address -X- _ O
this -X- _ O
by -X- _ O
introducing -X- _ O
two -X- _ O
cooperative -X- _ B-HyperparameterValue
losses -X- _ I-HyperparameterValue
to -X- _ O
the -X- _ O
GAN -X- _ O
- -X- _ O
inspired -X- _ O
Adversarially -X- _ B-MethodName
Regularized -X- _ I-MethodName
Autoencoder -X- _ I-MethodName
( -X- _ O
ARAE -X- _ B-MethodName
) -X- _ O
that -X- _ O
further -X- _ O
regularizes -X- _ O
the -X- _ O
latent -X- _ O
space -X- _ O
. -X- _ O
While -X- _ O
satisfying -X- _ O
the -X- _ O
constraints -X- _ O
our -X- _ O
methods -X- _ O
brings -X- _ O
significant -X- _ O
improvements -X- _ O
in -X- _ O
overall -X- _ O
score -X- _ O
. -X- _ O
While -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
simple -X- _ O
constraints -X- _ O
at -X- _ O
the -X- _ O
sentence -X- _ O
- -X- _ O
and -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
, -X- _ O
future -X- _ O
work -X- _ O
can -X- _ O
add -X- _ O
phrase -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
more -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
constraints -X- _ O
. -X- _ O
Potential -X- _ O
future -X- _ O
work -X- _ O
may -X- _ O
explore -X- _ O
reinforcement -X- _ O
learning -X- _ O
losses -X- _ O
to -X- _ O
directly -X- _ O
optimize -X- _ O
the -X- _ O
constraints -X- _ O
. -X- _ O
More -X- _ O
transfer -X- _ O
results -X- _ O
are -X- _ O
mention -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
. -X- _ O
Examples -X- _ O
where -X- _ O
our -X- _ O
system -X- _ O
fails -X- _ O
with -X- _ O
plausible -X- _ O
explanation -X- _ O
are -X- _ O
given -X- _ O
in -X- _ O
Table -X- _ O
9 -X- _ O
. -X- _ O
Examples -X- _ O
of -X- _ O
translation -X- _ O
from -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
attribute -X- _ O
dataset -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
10.For -X- _ O
FL -X- _ B-MetricName
, -X- _ O
0 -X- _ B-MetricValue
indicates -X- _ O
not -X- _ O
fluent -X- _ O
at -X- _ O
all -X- _ O
, -X- _ O
1 -X- _ B-MetricValue
indicates -X- _ O
somewhat -X- _ O
fluent -X- _ O
and -X- _ O
2 -X- _ B-MetricValue
is -X- _ O
a -X- _ O
completely -X- _ O
fluent -X- _ O
sentence -X- _ O
. -X- _ O
We -X- _ O
explicitly -X- _ O
ask -X- _ O
the -X- _ O
annotators -X- _ O
to -X- _ O
consider -X- _ O
semantic -X- _ B-MetricName
similarity -X- _ I-MetricName
for -X- _ O
SIM -X- _ B-MetricName
, -X- _ O
irrespective -X- _ O
of -X- _ O
whether -X- _ O
the -X- _ O
target -X- _ O
sentence -X- _ O
shares -X- _ O
some -X- _ O
phrases -X- _ O
with -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
, -X- _ O
with -X- _ O
1 -X- _ O
indicating -X- _ O
no -X- _ O
semantic -X- _ O
similarity -X- _ O
and -X- _ O
3 -X- _ O
indicating -X- _ O
complete -X- _ O
semantic -X- _ O
similarity -X- _ O
. -X- _ O
For -X- _ O
ACC -X- _ B-MetricName
, -X- _ O
1 -X- _ B-MetricValue
indicates -X- _ O
that -X- _ O
the -X- _ O
target -X- _ O
sentence -X- _ O
has -X- _ O
only -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
style -X- _ O
while -X- _ O
2 -X- _ B-MetricValue
indicates -X- _ O
good -X- _ O
transfer -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
style -X- _ O
. -X- _ O
We -X- _ O
calculate -X- _ O
the -X- _ O
Krippendorff -X- _ O
's -X- _ O
alpha -X- _ O
to -X- _ O
assess -X- _ O
the -X- _ O
inter -X- _ O
annotator -X- _ O
agreement -X- _ O
. -X- _ O
Table -X- _ O
7 -X- _ O
shows -X- _ O
the -X- _ O
inter -X- _ O
- -X- _ O
annotator -X- _ O
agreement -X- _ O
. -X- _ O
An -X- _ O
α -X- _ B-MetricName
of -X- _ O
0.4 -X- _ B-MetricValue
is -X- _ O
considered -X- _ O
good -X- _ O
agreeement -X- _ O
( -X- _ O
Hedayatnia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
moderate -X- _ O
to -X- _ O
good -X- _ O
agreements -X- _ O
on -X- _ O
all -X- _ O
the -X- _ O
datasets -X- _ O
for -X- _ O
different -X- _ O
measures -X- _ O
. -X- _ O
On -X- _ O
more -X- _ O
inspection -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
disagreements -X- _ O
in -X- _ O
fluency -X- _ B-MetricName
mostly -X- _ O
arrives -X- _ O
for -X- _ O
small -X- _ O
phrases -X- _ O
like -X- _ O
" -X- _ O
my -X- _ O
fav -X- _ O
" -X- _ O
although -X- _ O
is -X- _ O
an -X- _ O
accepted -X- _ O
phrase -X- _ O
in -X- _ O
social -X- _ O
media -X- _ O
text -X- _ O
is -X- _ O
considered -X- _ O
2 -X- _ O
by -X- _ O
one -X- _ O
annotator -X- _ O
and -X- _ O
3 -X- _ O
by -X- _ O
another -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
further -X- _ O
note -X- _ O
that -X- _ O
, -X- _ O
smaller -X- _ O
sentences -X- _ O
were -X- _ O
easier -X- _ O
to -X- _ O
judge -X- _ O
and -X- _ O
had -X- _ O
better -X- _ O
agreement -X- _ O
rates -X- _ O
on -X- _ O
SIM -X- _ B-MetricName
compared -X- _ O
to -X- _ O
longer -X- _ O
sentences -X- _ O
. -X- _ O

Disentanglement -X- _ O
approaches -X- _ O
are -X- _ O
the -X- _ O
prevalent -X- _ O
approach -X- _ O
to -X- _ O
tackle -X- _ O
unsupervised -X- _ B-TaskName
attribute -X- _ I-TaskName
transfer -X- _ I-TaskName
: -X- _ O
attributes -X- _ O
and -X- _ O
content -X- _ O
are -X- _ O
separated -X- _ O
in -X- _ O
latent -X- _ O
dimension -X- _ O
. -X- _ O
To -X- _ O
disentangle -X- _ O
the -X- _ O
attributes -X- _ O
adversarial -X- _ O
methods -X- _ O
maximize -X- _ O
the -X- _ O
loss -X- _ O
of -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
attribute -X- _ O
classifier -X- _ O
Fu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a;John -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
literature -X- _ O
has -X- _ O
paid -X- _ O
little -X- _ O
attention -X- _ O
in -X- _ O
defining -X- _ O
and -X- _ O
preserving -X- _ O
content -X- _ O
. -X- _ O
Cycle -X- _ O
consistency -X- _ O
losses -X- _ O
-imposing -X- _ O
that -X- _ O
reconstruction -X- _ O
from -X- _ O
the -X- _ O
target -X- _ O
style -X- _ O
sentence -X- _ O
should -X- _ O
resemble -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
-is -X- _ O
the -X- _ O
most -X- _ O
prevalent -X- _ O
( -X- _ O
Prabhumoye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Logeswaran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Dai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Yi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
expensive -X- _ O
and -X- _ O
nondifferentiable -X- _ O
, -X- _ O
thus -X- _ O
requiring -X- _ O
reinforcement -X- _ O
learning -X- _ O
techniques -X- _ O
to -X- _ O
enforce -X- _ O
it -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
defines -X- _ O
the -X- _ O
different -X- _ O
constraints -X- _ O
that -X- _ O
should -X- _ O
be -X- _ O
preserved -X- _ O
and -X- _ O
adds -X- _ O
simple -X- _ O
differentiable -X- _ O
contrastive -X- _ O
learning -X- _ O
losses -X- _ O
to -X- _ O
preserve -X- _ O
them -X- _ O
. -X- _ O

Next -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
best -X- _ O
variant -X- _ O
of -X- _ O
ARAE -X- _ B-MethodName
seq2seq -X- _ I-MethodName
to -X- _ O
transfer -X- _ O
a -X- _ O
separate -X- _ O
set -X- _ O
DVD -X- _ O
reviews -X- _ O
to -X- _ O
ELECTRON -X- _ B-DatasetName
- -X- _ I-DatasetName
ICS -X- _ I-DatasetName
reviews -X- _ I-DatasetName
and -X- _ O
use -X- _ O
them -X- _ O
as -X- _ O
adversarial -X- _ O
examples -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
DANN -X- _ B-MethodName
model -X- _ O
6 -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
DANN -X- _ B-MethodName
on -X- _ O
the -X- _ O
ELECTRONICS -X- _ B-DatasetName
domain -X- _ O
reduces -X- _ O
by -X- _ O
∼3 -X- _ B-MetricValue
points -X- _ O
. -X- _ O
This -X- _ O
shows -X- _ O
the -X- _ O
potential -X- _ O
application -X- _ O
of -X- _ O
domain -X- _ O
transferred -X- _ O
sentences -X- _ O
as -X- _ O
adversarial -X- _ O
examples -X- _ O
. -X- _ O
Similar -X- _ O
ideas -X- _ O
have -X- _ O
been -X- _ O
tried -X- _ O
for -X- _ O
image -X- _ B-TaskName
style -X- _ I-TaskName
transfer -X- _ I-TaskName
, -X- _ O
but -X- _ O
needs -X- _ O
more -X- _ O
investigation -X- _ O
in -X- _ O
NLP.Text -X- _ B-TaskName
attribute -X- _ I-TaskName
transfer -X- _ I-TaskName
has -X- _ O
a -X- _ O
vast -X- _ O
literature -X- _ O
( -X- _ O
Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
with -X- _ O
deep -X- _ O
learning -X- _ O
methods -X- _ O
becoming -X- _ O
popular -X- _ O
. -X- _ O
The -X- _ O
methods -X- _ O
are -X- _ O
either -X- _ O
supervised -X- _ O
( -X- _ O
requiring -X- _ O
parallel -X- _ O
data -X- _ O
) -X- _ O
or -X- _ O
unsupervised -X- _ O
. -X- _ O
Supervised -X- _ O
methods -X- _ O
re -X- _ O
- -X- _ O
purpose -X- _ O
Sequence -X- _ O
to -X- _ O
Sequence -X- _ O
models -X- _ O
used -X- _ O
in -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
to -X- _ O
achieve -X- _ O
the -X- _ O
goals -X- _ O
( -X- _ O
Rao -X- _ O
and -X- _ O
Tetreault -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
obtaining -X- _ O
parallel -X- _ O
data -X- _ O
is -X- _ O
cumbersome -X- _ O
and -X- _ O
thus -X- _ O
unsupervised -X- _ O
methods -X- _ O
that -X- _ O
consider -X- _ O
pseudo -X- _ O
- -X- _ O
parallel -X- _ O
data -X- _ O
have -X- _ O
become -X- _ O
popular -X- _ O
. -X- _ O

Transferred -X- _ O
sentences -X- _ O
as -X- _ O
Adversarial -X- _ O
Examples -X- _ O
: -X- _ O
We -X- _ O
demonstrate -X- _ O
an -X- _ O
important -X- _ O
application -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
constrained -X- _ O
transfer -X- _ O
by -X- _ O
considering -X- _ O
them -X- _ O
as -X- _ O
adversarial -X- _ O
examples -X- _ O
for -X- _ O
domain -X- _ O
adaptation -X- _ O
. -X- _ O
Domain -X- _ B-MethodName
Adversarial -X- _ I-MethodName
Neural -X- _ I-MethodName
Network -X- _ I-MethodName
( -X- _ O
DANN -X- _ B-MethodName
) -X- _ O
( -X- _ O
Ganin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
is -X- _ O
an -X- _ O
unsupervised -X- _ O
domain -X- _ O
adaptation -X- _ O
method -X- _ O
that -X- _ O
improves -X- _ O
performance -X- _ O
of -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
task -X- _ O
( -X- _ O
e.g -X- _ O
, -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
) -X- _ O
on -X- _ O
a -X- _ O
target -X- _ O
domain -X- _ O
considering -X- _ O
only -X- _ O
supervised -X- _ O
data -X- _ O
from -X- _ O
source -X- _ O
domain -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
DANN -X- _ B-MethodName
for -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
on -X- _ O
amazon -X- _ B-DatasetName
reviews -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
He -X- _ O
and -X- _ O
McAuley -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
with -X- _ O
DVD -X- _ O
as -X- _ O
source -X- _ O
and -X- _ O
ELECTRONICS -X- _ O
as -X- _ O
the -X- _ O
tar -X- _ O
- -X- _ O
get -X- _ O
domain -X- _ O
-achieving -X- _ O
an -X- _ O
accuracy -X- _ O
of -X- _ O
83.75 -X- _ B-MetricName
% -X- _ I-MetricName
on -X- _ O
ELECTRONICS -X- _ B-DatasetName
. -X- _ O

Using -X- _ O
Transformers -X- _ O
: -X- _ O
We -X- _ O
also -X- _ O
replace -X- _ O
our -X- _ O
LSTM -X- _ B-HyperparameterValue
auto -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
encoders -X- _ I-HyperparameterName
with -X- _ O
both -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
and -X- _ O
randomly -X- _ O
initialized -X- _ O
transformer -X- _ B-HyperparameterValue
encoder -X- _ O
- -X- _ O
decoders -X- _ O
( -X- _ O
Rothe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Although -X- _ O
we -X- _ O
found -X- _ O
an -X- _ O
increase -X- _ O
in -X- _ O
the -X- _ O
AGG -X- _ B-MetricName
, -X- _ O
it -X- _ O
was -X- _ O
mostly -X- _ O
because -X- _ O
of -X- _ O
very -X- _ O
high -X- _ O
SIM -X- _ B-MetricName
and -X- _ O
very -X- _ O
low -X- _ O
ACC -X- _ B-MetricName
. -X- _ O
Reducing -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
, -X- _ O
attention -X- _ O
heads -X- _ O
would -X- _ O
still -X- _ O
result -X- _ O
in -X- _ O
a -X- _ O
large -X- _ O
model -X- _ O
that -X- _ O
is -X- _ O
still -X- _ O
prone -X- _ O
to -X- _ O
copying -X- _ O
text -X- _ O
. -X- _ O
This -X- _ O
reveals -X- _ O
the -X- _ O
potential -X- _ O
limitations -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
and -X- _ O
training -X- _ O
using -X- _ O
transformers -X- _ O
is -X- _ O
a -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

ARAE -X- _ B-MethodName
john -X- _ O
abraham -X- _ O
had -X- _ O
one -X- _ O
of -X- _ O
my -X- _ O
favorite -X- _ O
roles -X- _ O
.Source -X- _ O
( -X- _ O
IMDB -X- _ B-DatasetName
) -X- _ O
chris -X- _ O
klein -X- _ O
's -X- _ O
character -X- _ O
was -X- _ O
unlikable -X- _ O
from -X- _ O
the -X- _ O
start -X- _ O
and -X- _ O
never -X- _ O
made -X- _ O
an -X- _ O
improvement -X- _ O
Ours -X- _ O
robert -X- _ O
de -X- _ O
niro -X- _ O
was -X- _ O
very -X- _ O
good -X- _ O
as -X- _ O
the -X- _ O
man -X- _ O
and -X- _ O
she -X- _ O
's -X- _ O
never -X- _ O
been -X- _ O
ARAE -X- _ B-MethodName
both -X- _ O
of -X- _ O
his -X- _ O
character -X- _ O
was -X- _ O
made -X- _ O
and -X- _ O
had -X- _ O
a -X- _ O
huge -X- _ O
smile -X- _ O
on -X- _ O
me -X- _ O
Qualitative -X- _ O
Examples -X- _ O
: -X- _ O
Table -X- _ O
6 -X- _ O
shows -X- _ O
examples -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
maintaining -X- _ O
constraints -X- _ O
compared -X- _ O
to -X- _ O
ARAE -X- _ B-MethodName
. -X- _ O
Sometimes -X- _ O
, -X- _ O
ARAE -X- _ B-MethodName
hallucinates -X- _ O
and -X- _ O
adds -X- _ O
personal -X- _ O
pronouns -X- _ O
like -X- _ O
" -X- _ O
my -X- _ O
" -X- _ O
to -X- _ O
the -X- _ O
text -X- _ O
even -X- _ O
when -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
personal -X- _ O
pronouns -X- _ O
( -X- _ O
row -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
produces -X- _ O
sentences -X- _ O
where -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
proper -X- _ O
nouns -X- _ O
are -X- _ O
retained -X- _ O
( -X- _ O
Chris -X- _ O
Klein -X- _ O
vs. -X- _ O
Robert -X- _ O
De -X- _ O
Niro -X- _ O
) -X- _ O
, -X- _ O
whereas -X- _ O
ARAE -X- _ B-MethodName
does -X- _ O
not -X- _ O
. -X- _ O
Cycle -X- _ O
Consistency -X- _ O
Loss -X- _ O
: -X- _ O
a -X- _ O
) -X- _ O
In -X- _ O
Latent -X- _ O
Spaces -X- _ O
-Cycle -X- _ O
consistency -X- _ O
in -X- _ O
latent -X- _ O
spaces -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
improve -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
dictionary -X- _ I-TaskName
construction -X- _ I-TaskName
( -X- _ O
Mohiuddin -X- _ O
and -X- _ O
Joty -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
topic -X- _ B-TaskName
modeling -X- _ I-TaskName
. -X- _ O
A -X- _ O
recent -X- _ O
work -X- _ O
from -X- _ O
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
claims -X- _ O
to -X- _ O
improve -X- _ O
unsupervised -X- _ B-TaskName
style -X- _ I-TaskName
transfer -X- _ I-TaskName
using -X- _ O
such -X- _ O
losses -X- _ B-HyperparameterName
. -X- _ O
In -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
it -X- _ O
did -X- _ O
not -X- _ O
result -X- _ O
in -X- _ O
any -X- _ O
noticeable -X- _ O
performance -X- _ O
improvement -X- _ O
5 -X- _ O
. -X- _ O
Given -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
cycle -X- _ O
consistency -X- _ O
might -X- _ O
be -X- _ O
too -X- _ O
restrictive -X- _ O
for -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
. -X- _ O
b -X- _ O
) -X- _ O
Using -X- _ O
Back -X- _ O
- -X- _ O
Translation -X- _ O
- -X- _ O
Back -X- _ O
- -X- _ O
translation -X- _ O
is -X- _ O
another -X- _ O
alternative -X- _ O
to -X- _ O
ensure -X- _ O
semantic -X- _ O
consistency -X- _ O
between -X- _ O
source -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
sentence -X- _ O
( -X- _ O
Prabhumoye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
since -X- _ O
we -X- _ O
are -X- _ O
training -X- _ O
an -X- _ O
ARAE -X- _ B-MethodName
, -X- _ O
it -X- _ O
would -X- _ O
involve -X- _ O
an -X- _ O
additional -X- _ O
inference -X- _ O
and -X- _ O
auto -X- _ O
- -X- _ O
encoder -X- _ O
training -X- _ O
step -X- _ O
which -X- _ O
is -X- _ O
expensive -X- _ O
and -X- _ O
we -X- _ O
defer -X- _ O
exploring -X- _ O
this -X- _ O
. -X- _ O

Ours -X- _ O
michael -X- _ O
keaton -X- _ O
was -X- _ O
also -X- _ O
great -X- _ O
in -X- _ O
his -X- _ O
role -X- _ O
. -X- _ O

Table -X- _ O
5 -X- _ O
: -X- _ O
Example -X- _ O
outputs -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
best -X- _ O
system -X- _ O
according -X- _ O
to -X- _ O
AGG -X- _ B-MetricName
score -X- _ O
. -X- _ O
Source -X- _ O
( -X- _ O
IMDB -X- _ B-DatasetName
) -X- _ O
jean -X- _ O
seberg -X- _ O
had -X- _ O
not -X- _ O
one -X- _ O
iota -X- _ O
of -X- _ O
acting -X- _ O
talent -X- _ O
. -X- _ O

POLITICAL -X- _ B-DatasetName
i -X- _ O
wish -X- _ O
u -X- _ O
would -X- _ O
bring -X- _ O
change -X- _ O
and -X- _ O
i -X- _ O
wish -X- _ O
you -X- _ O
would -X- _ O
help -X- _ O
bring -X- _ O
democracy -X- _ O
and -X- _ O
i -X- _ O
' -X- _ O
m -X- _ O
not -X- _ O
sure -X- _ O
mr.trump -X- _ O
. -X- _ O

this -X- _ O
is -X- _ O
a -X- _ O
film -X- _ O
that -X- _ O
has -X- _ O
been -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
times -X- _ O
and -X- _ O
it -X- _ O
's -X- _ O
really -X- _ O
good -X- _ O
. -X- _ O

this -X- _ O
movie -X- _ O
is -X- _ O
a -X- _ O
very -X- _ O
good -X- _ O
example -X- _ O
of -X- _ O
a -X- _ O
film -X- _ O
that -X- _ O
will -X- _ O
never -X- _ O
be -X- _ O
forgotten -X- _ O
. -X- _ O

Multiple -X- _ O
Attribute -X- _ O
Datasets -X- _ O
: -X- _ O
To -X- _ O
test -X- _ O
whether -X- _ O
our -X- _ O
model -X- _ O
can -X- _ O
satisfy -X- _ O
constraints -X- _ O
across -X- _ O
domains -X- _ O
where -X- _ O
multiple -X- _ O
attributes -X- _ O
change -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
multiattribute -X- _ O
dataset -X- _ O
released -X- _ O
by -X- _ O
( -X- _ O
Lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
this -X- _ O
movie -X- _ O
is -X- _ O
a -X- _ O
very -X- _ O
poor -X- _ O
attempt -X- _ O
to -X- _ O
make -X- _ O
money -X- _ O
using -X- _ O
a -X- _ O
classical -X- _ O
theme -X- _ O
. -X- _ O

A -X- _ O
seemingly -X- _ O
easy -X- _ O
to -X- _ O
maintain -X- _ O
constraint -X- _ O
is -X- _ O
the -X- _ O
length -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
sentence -X- _ I-HyperparameterName
. -X- _ O
However -X- _ O
, -X- _ O
seq2seq -X- _ O
systems -X- _ O
have -X- _ O
a -X- _ O
difficulty -X- _ O
of -X- _ O
maintaining -X- _ O
appropriate -X- _ O
lengths -X- _ O
( -X- _ O
Murray -X- _ O
and -X- _ O
Chiang -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
With -X- _ O
no -X- _ O
additional -X- _ O
regularization -X- _ O
ARAE -X- _ B-MethodName
does -X- _ O
not -X- _ O
maintain -X- _ O
the -X- _ O
length -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
ARAE -X- _ B-MethodName
seq2seq -X- _ I-MethodName
+ -X- _ I-MethodName
CLF -X- _ I-MethodName
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
lexical -X- _ O
constraints -X- _ O
, -X- _ O
syntactic -X- _ O
attributes -X- _ O
like -X- _ O
descriptiveness -X- _ O
, -X- _ O
tree -X- _ B-HyperparameterName
height -X- _ I-HyperparameterName
and -X- _ O
domain -X- _ O
specific -X- _ O
constraints -X- _ O
present -X- _ O
challenges -X- _ O
, -X- _ O
with -X- _ O
significantly -X- _ O
lower -X- _ O
F -X- _ B-MetricName
scores -X- _ O
. -X- _ O
ARAE -X- _ B-MethodName
seq2seq -X- _ I-MethodName
+ -X- _ I-MethodName
CLF -X- _ I-MethodName
produces -X- _ O
significantly -X- _ O
better -X- _ O
results -X- _ O
in -X- _ O
maintaining -X- _ O
them -X- _ O
. -X- _ O
This -X- _ O
shows -X- _ O
that -X- _ O
obtaining -X- _ O
improvements -X- _ O
on -X- _ O
the -X- _ O
overall -X- _ O
AGG -X- _ B-MetricName
does -X- _ O
not -X- _ O
necessarily -X- _ O
translate -X- _ O
to -X- _ O
producing -X- _ O
outputs -X- _ O
that -X- _ O
satisfy -X- _ O
constraints -X- _ O
. -X- _ O
DRG -X- _ B-MethodName
maintains -X- _ O
the -X- _ O
proper -X- _ O
noun -X- _ O
for -X- _ O
IMDB -X- _ B-DatasetName
effectively -X- _ O
, -X- _ O
because -X- _ O
it -X- _ O
contains -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
actor -X- _ O
and -X- _ O
movie -X- _ O
names -X- _ O
. -X- _ O
They -X- _ O
are -X- _ O
retained -X- _ O
verbatim -X- _ O
after -X- _ O
the -X- _ O
delete -X- _ O
operation -X- _ O
. -X- _ O

Human -X- _ O
Evaluation -X- _ O
: -X- _ O
We -X- _ O
average -X- _ O
the -X- _ O
results -X- _ O
and -X- _ O
present -X- _ O
it -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
DRG -X- _ B-MethodName
produces -X- _ O
marginally -X- _ O
better -X- _ O
semantically -X- _ O
similar -X- _ O
sentences -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
ARAE -X- _ B-MethodName
, -X- _ O
our -X- _ O
model -X- _ O
performs -X- _ O
well -X- _ O
except -X- _ O
for -X- _ O
in -X- _ O
YELP -X- _ B-DatasetName
. -X- _ O
This -X- _ O
may -X- _ O
be -X- _ O
because -X- _ O
we -X- _ O
use -X- _ O
nucleus -X- _ B-HyperparameterName
sampling -X- _ I-HyperparameterName
with -X- _ O
0.9 -X- _ B-HyperparameterValue
which -X- _ O
optimizes -X- _ O
for -X- _ O
diversity -X- _ O
rather -X- _ O
than -X- _ O
similarity -X- _ O
. -X- _ O
On -X- _ O
other -X- _ O
metrics -X- _ O
we -X- _ O
perform -X- _ O
on -X- _ O
par -X- _ O
or -X- _ O
better -X- _ O
than -X- _ O
our -X- _ O
competing -X- _ O
systems -X- _ O
. -X- _ O
( -X- _ O
See -X- _ O
Appendix -X- _ O
B -X- _ O
) -X- _ O
Qualitative -X- _ O
Examples -X- _ O
: -X- _ O
Table -X- _ O
5 -X- _ O
shows -X- _ O
examples -X- _ O
of -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
transferred -X- _ O
examples -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
A -X- _ O
for -X- _ O
more -X- _ O
) -X- _ O
. -X- _ O
Mistakes -X- _ O
made -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
poor -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
semantics -X- _ O
, -X- _ O
lack -X- _ O
of -X- _ O
diversity -X- _ O
, -X- _ O
and -X- _ O
not -X- _ O
producing -X- _ O
attribute -X- _ O
- -X- _ O
specific -X- _ O
words -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
that -X- _ O
introducing -X- _ O
the -X- _ O
cooperative -X- _ O
losses -X- _ O
significantly -X- _ O
outperform -X- _ O
DRG -X- _ B-MethodName
and -X- _ O
ARAE -X- _ B-MethodName
in -X- _ O
maintaining -X- _ O
constraints -X- _ O
. -X- _ O
Specifically -X- _ O
the -X- _ O
ARAE -X- _ B-MethodName
seq2seq -X- _ I-MethodName
+ -X- _ I-MethodName
CLF -X- _ I-MethodName
model -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
ARAE -X- _ B-MethodName
seq2seq -X- _ I-MethodName
+ -X- _ I-MethodName
CONTRA -X- _ I-MethodName
. -X- _ O
One -X- _ O
reason -X- _ O
could -X- _ O
be -X- _ O
that -X- _ O
, -X- _ O
finding -X- _ O
the -X- _ O
appropriate -X- _ O
positives -X- _ O
and -X- _ O
strong -X- _ O
negatives -X- _ O
can -X- _ O
be -X- _ O
problematic -X- _ O
for -X- _ O
contrastive -X- _ O
learning -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
the -X- _ O
classifier -X- _ O
's -X- _ O
objective -X- _ O
is -X- _ O
simpler -X- _ O
and -X- _ O
forces -X- _ O
the -X- _ O
encoder -X- _ O
to -X- _ O
produce -X- _ O
representations -X- _ O
that -X- _ O
satisfy -X- _ O
the -X- _ O
different -X- _ O
constraints -X- _ O
effectively -X- _ O
. -X- _ O

Cooperative -X- _ B-HyperparameterValue
Losses -X- _ I-HyperparameterValue
are -X- _ O
Important -X- _ O
on -X- _ O
Both -X- _ O
the -X- _ O
Generator -X- _ O
and -X- _ O
Critic -X- _ O
: -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
adding -X- _ O
the -X- _ O
cooperative -X- _ B-HyperparameterValue
losses -X- _ I-HyperparameterValue
on -X- _ O
the -X- _ O
generator -X- _ O
and -X- _ O
critic -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
adding -X- _ O
the -X- _ O
cooperative -X- _ B-HyperparameterValue
losses -X- _ I-HyperparameterValue
on -X- _ O
both -X- _ O
the -X- _ O
generator -X- _ O
and -X- _ O
the -X- _ O
critic -X- _ O
is -X- _ O
crucial -X- _ O
for -X- _ O
the -X- _ O
overall -X- _ O
performance -X- _ O
. -X- _ O
While -X- _ O
adding -X- _ O
the -X- _ O
cooperative -X- _ B-HyperparameterValue
contrastive -X- _ I-HyperparameterValue
loss -X- _ I-HyperparameterValue
to -X- _ O
both -X- _ O
the -X- _ O
generator -X- _ O
and -X- _ O
critic -X- _ O
increases -X- _ O
FL -X- _ B-MetricName
and -X- _ O
ACC -X- _ B-MetricName
while -X- _ O
maintaining -X- _ O
similar -X- _ O
levels -X- _ O
of -X- _ O
SIM -X- _ B-MetricName
, -X- _ O
adding -X- _ O
the -X- _ O
cooperative -X- _ B-HyperparameterValue
classification -X- _ I-HyperparameterValue
loss -X- _ I-HyperparameterValue
improves -X- _ O
SIM -X- _ B-MetricName
which -X- _ O
shows -X- _ O
the -X- _ O
complementary -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
losses -X- _ O
. -X- _ O

Nucleus -X- _ O
Sampling -X- _ O
: -X- _ O
Our -X- _ O
system -X- _ O
achieves -X- _ O
the -X- _ O
highest -X- _ O
AGG -X- _ B-MetricName
score -X- _ O
with -X- _ O
greedy -X- _ B-HyperparameterValue
decoding -X- _ I-HyperparameterValue
. -X- _ O
We -X- _ O
also -X- _ O
experiment -X- _ O
with -X- _ O
nucleus -X- _ O
sampling -X- _ O
( -X- _ O
Holtzman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
with -X- _ O
different -X- _ O
p -X- _ B-HyperparameterName
values -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
results -X- _ O
for -X- _ O
only -X- _ O
p=0.6 -X- _ B-HyperparameterName
in -X- _ O
With -X- _ O
p=0.6 -X- _ B-HyperparameterName
, -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
more -X- _ O
diverse -X- _ O
, -X- _ O
increasing -X- _ O
ACC -X- _ B-MetricName
as -X- _ O
expected -X- _ O
. -X- _ O
However -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
with -X- _ O
higher -X- _ O
values -X- _ O
of -X- _ O
p -X- _ B-HyperparameterValue
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
with -X- _ O
SIM -X- _ B-MetricName
resulting -X- _ O
in -X- _ O
a -X- _ O
lower -X- _ O
AGG -X- _ B-MetricName
score -X- _ O
overall -X- _ O
-similar -X- _ O
to -X- _ O
Krishna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020).The -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
positive -X- _ I-HyperparameterName
and -X- _ I-HyperparameterName
negative -X- _ I-HyperparameterName
samples -X- _ I-HyperparameterName
used -X- _ O
for -X- _ O
contrastive -X- _ O
learning -X- _ O
( -X- _ O
Eq -X- _ O
. -X- _ O
5 -X- _ O
) -X- _ O
have -X- _ O
a -X- _ O
significant -X- _ O
effect -X- _ O
on -X- _ O
the -X- _ O
overall -X- _ O
performance -X- _ O
( -X- _ O
Khosla -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Henaff -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
( -X- _ O
rows -X- _ O
|P -X- _ O
| -X- _ O
∈ -X- _ O
{ -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
5 -X- _ O
, -X- _ O
10 -X- _ O
} -X- _ O
) -X- _ O
shows -X- _ O
the -X- _ O
AGG -X- _ B-MetricName
scores -X- _ O
on -X- _ O
IMDB -X- _ B-DatasetName
( -X- _ O
for -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
runs -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
different -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
positives -X- _ I-HyperparameterName
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
AGG -X- _ B-MetricName
is -X- _ O
the -X- _ O
highest -X- _ O
with -X- _ O
2 -X- _ B-HyperparameterValue
positives -X- _ B-HyperparameterName
per -X- _ I-HyperparameterName
sample -X- _ I-HyperparameterName
as -X- _ O
also -X- _ O
used -X- _ O
by -X- _ O
Khosla -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Although -X- _ O
increasing -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
negatives -X- _ I-HyperparameterName
is -X- _ O
beneficial -X- _ O
for -X- _ O
contrastive -X- _ O
learning -X- _ O
, -X- _ O
when -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
positive -X- _ O
example -X- _ O
is -X- _ O
available -X- _ O
, -X- _ O
using -X- _ O
them -X- _ O
brings -X- _ O
further -X- _ O
improvements -X- _ O
( -X- _ O
Khosla -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Fluency -X- _ B-MetricName
( -X- _ O
FL -X- _ B-MetricName
) -X- _ O
also -X- _ O
improves -X- _ O
over -X- _ O
all -X- _ O
datasets -X- _ O
. -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
reducing -X- _ O
cooperative -X- _ O
losses -X- _ O
regularizes -X- _ O
the -X- _ O
latent -X- _ O
space -X- _ O
bringing -X- _ O
fluent -X- _ O
sentences -X- _ O
closer -X- _ O
together -X- _ O
, -X- _ O
enabling -X- _ O
the -X- _ O
decoder -X- _ O
to -X- _ O
produce -X- _ O
semantically -X- _ O
similar -X- _ O
and -X- _ O
linguistically -X- _ O
acceptable -X- _ O
sentences -X- _ O
. -X- _ O
The -X- _ O
improvement -X- _ O
for -X- _ O
POLITICAL -X- _ B-DatasetName
is -X- _ O
less -X- _ O
; -X- _ O
we -X- _ O
find -X- _ O
these -X- _ O
source -X- _ O
sentences -X- _ O
themselves -X- _ O
are -X- _ O
less -X- _ O
fluent -X- _ O
and -X- _ O
contain -X- _ O
many -X- _ O
U.S. -X- _ O
political -X- _ O
acronyms -X- _ O
, -X- _ O
and -X- _ O
that -X- _ O
our -X- _ O
system -X- _ O
produces -X- _ O
many -X- _ O
outof -X- _ O
- -X- _ O
vocabulary -X- _ O
words -X- _ O
affecting -X- _ O
fluency -X- _ O
. -X- _ O

Human -X- _ O
Evaluation -X- _ O
: -X- _ O
We -X- _ O
also -X- _ O
perform -X- _ O
an -X- _ O
indicative -X- _ O
human -X- _ O
evaluation -X- _ O
where -X- _ O
we -X- _ O
randomly -X- _ O
sample -X- _ O
100 -X- _ B-HyperparameterValue
samples -X- _ O
from -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
datasets -X- _ O
and -X- _ O
hire -X- _ O
three -X- _ O
researchers -X- _ O
to -X- _ O
rate -X- _ O
every -X- _ O
sentence -X- _ O
for -X- _ O
FL -X- _ B-MetricName
, -X- _ O
SIM -X- _ B-MetricName
and -X- _ O
ACC -X- _ B-MetricName
on -X- _ O
a -X- _ O
3 -X- _ O
- -X- _ O
point -X- _ O
scale -X- _ O
( -X- _ O
Krishna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
ARAE -X- _ B-MethodName
seq2seq -X- _ I-MethodName
with -X- _ O
the -X- _ O
following -X- _ O
baselines -X- _ O
: -X- _ O
a -X- _ O
) -X- _ O
DRG -X- _ B-MethodName
: -X- _ O
The -X- _ O
Delete -X- _ O
, -X- _ O
Retrieve -X- _ O
, -X- _ O
Generate -X- _ O
method -X- _ O
that -X- _ O
deletes -X- _ O
domain -X- _ O
specific -X- _ O
attributes -X- _ O
, -X- _ O
retrieves -X- _ O
a -X- _ O
template -X- _ O
and -X- _ O
generates -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
text -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
stronger -X- _ O
, -X- _ O
entire -X- _ O
system -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
weaker -X- _ O
DELETEONLY -X- _ O
and -X- _ O
RETRIEVEONLY -X- _ O
baselines -X- _ O
; -X- _ O
b -X- _ O
) -X- _ O
ARAE -X- _ B-MethodName
: -X- _ O
Adversarially -X- _ O
regularized -X- _ O
autoencoders -X- _ O
our -X- _ O
system -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
Although -X- _ O
DRG -X- _ B-MethodName
produces -X- _ O
sentences -X- _ O
with -X- _ O
high -X- _ O
SIM -X- _ B-MetricName
as -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
sentence -X- _ O
is -X- _ O
retained -X- _ O
after -X- _ O
the -X- _ O
delete -X- _ O
step -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
large -X- _ O
tradeoff -X- _ O
with -X- _ O
ACC -X- _ B-MetricName
resulting -X- _ O
in -X- _ O
low -X- _ O
AGG -X- _ B-MetricName
scores -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
ARAE -X- _ B-MethodName
, -X- _ O
adding -X- _ O
cooperative -X- _ B-HyperparameterValue
losses -X- _ I-HyperparameterValue
significantly -X- _ O
increases -X- _ O
the -X- _ O
SIM -X- _ B-MetricName
, -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
increase -X- _ O
observed -X- _ O
for -X- _ O
POLITICAL -X- _ B-DatasetName
. -X- _ O
The -X- _ O
reasons -X- _ O
for -X- _ O
this -X- _ O
could -X- _ O
be -X- _ O
two -X- _ O
- -X- _ O
fold -X- _ O
: -X- _ O
i -X- _ O
) -X- _ O
since -X- _ O
we -X- _ O
mine -X- _ O
positive -X- _ O
sentences -X- _ O
from -X- _ O
a -X- _ O
corpus -X- _ O
that -X- _ O
is -X- _ O
grounded -X- _ O
in -X- _ O
real -X- _ O
world -X- _ O
events -X- _ O
, -X- _ O
most -X- _ O
lexically -X- _ O
- -X- _ O
similar -X- _ O
sentences -X- _ O
may -X- _ O
also -X- _ O
be -X- _ O
semantically -X- _ O
similar -X- _ O
( -X- _ O
Guu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
ii -X- _ O
) -X- _ O
since -X- _ O
we -X- _ O
tie -X- _ O
the -X- _ O
encoders -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
domain -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
domain -X- _ O
- -X- _ O
agnostic -X- _ O
information -X- _ O
before -X- _ O
generation -X- _ O
, -X- _ O
which -X- _ O
retains -X- _ O
content -X- _ O
. -X- _ O

AGG -X- _ B-MetricName
= -X- _ O
1 -X- _ O
|S| -X- _ O
s∈S -X- _ O
ACC -X- _ B-MetricName
( -X- _ O
s -X- _ O
) -X- _ O
• -X- _ O
SIM -X- _ B-MetricName
( -X- _ O
s -X- _ O
) -X- _ O
• -X- _ O
FL -X- _ B-MetricName
( -X- _ O
s -X- _ O
) -X- _ O

Inference -X- _ O
Hyper -X- _ O
- -X- _ O
parameters -X- _ O
: -X- _ O
We -X- _ O
used -X- _ O
nucleus -X- _ B-HyperparameterName
sampling -X- _ I-HyperparameterName
with -X- _ O
p -X- _ B-HyperparameterName
∈ -X- _ O
[ -X- _ O
0.6 -X- _ B-HyperparameterValue
, -X- _ O
0.9 -X- _ B-HyperparameterValue
] -X- _ O
. -X- _ O
We -X- _ O
tried -X- _ O
different -X- _ O
temperatures -X- _ B-HyperparameterName
of -X- _ O
scaling -X- _ O
the -X- _ O
softmax -X- _ O
( -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
-0.4 -X- _ B-HyperparameterValue
, -X- _ O
0.5 -X- _ B-HyperparameterValue
, -X- _ O
0.6 -X- _ B-HyperparameterValue
, -X- _ O
0.7 -X- _ B-HyperparameterValue
and -X- _ O
chose -X- _ O
the -X- _ O
one -X- _ O
that -X- _ O
produced -X- _ O
the -X- _ O
best -X- _ O
result -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
. -X- _ O
Automatic -X- _ O
Evaluation -X- _ O
: -X- _ O
Our -X- _ O
automatic -X- _ O
evaluation -X- _ O
considers -X- _ O
the -X- _ O
following -X- _ O
three -X- _ O
prominent -X- _ O
criteria -X- _ O
: -X- _ O
i -X- _ O
) -X- _ O
Semantic -X- _ B-MetricName
Similarity -X- _ I-MetricName
( -X- _ O
SIM -X- _ B-MetricName
): -X- _ O
Measured -X- _ O
between -X- _ O
source -X- _ O
and -X- _ O
translated -X- _ O
target -X- _ O
sentences -X- _ O
using -X- _ O
encoders -X- _ O
( -X- _ O
Wieting -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
ngram -X- _ O
metrics -X- _ O
like -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
which -X- _ O
have -X- _ O
weak -X- _ O
correlations -X- _ O
with -X- _ O
human -X- _ O
judgments -X- _ O
. -X- _ O
ii -X- _ O
) -X- _ O
Transfer -X- _ B-MetricName
Accuracy -X- _ I-MetricName
( -X- _ O
ACC -X- _ B-MetricName
): -X- _ O
The -X- _ O
transferred -X- _ O
sentence -X- _ O
should -X- _ O
belong -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
and -X- _ O
a -X- _ O
classifier -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
distinguish -X- _ O
between -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
sentence -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
fastText -X- _ O
classifiers -X- _ O
( -X- _ O
Joulin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
for -X- _ O
every -X- _ O
dataset -X- _ O
. -X- _ O
We -X- _ O
achieve -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
97.9 -X- _ B-MetricValue
for -X- _ O
YELP -X- _ B-DatasetName
, -X- _ O
96.9 -X- _ B-MetricValue
for -X- _ O
IMDB -X- _ B-DatasetName
and -X- _ O
97.1 -X- _ B-MetricValue
for -X- _ O
POLITICAL -X- _ B-DatasetName
. -X- _ O
iii -X- _ O
) -X- _ O
Fluency -X- _ B-MetricName
( -X- _ O
FL -X- _ B-MetricName
): -X- _ O
A -X- _ O
transferred -X- _ O
sentence -X- _ O
should -X- _ O
be -X- _ O
grammatically -X- _ O
correct -X- _ O
. -X- _ O
We -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
a -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
model -X- _ O
on -X- _ O
the -X- _ O
COLA -X- _ B-DatasetName
( -X- _ O
Warstadt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
dataset -X- _ O
to -X- _ O
indicate -X- _ O
whether -X- _ O
a -X- _ O
sentence -X- _ O
is -X- _ O
linguistically -X- _ O
acceptable -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
combine -X- _ O
the -X- _ O
three -X- _ O
scores -X- _ O
into -X- _ O
an -X- _ O
aggregate -X- _ O
, -X- _ O
following -X- _ O
the -X- _ O
criteria -X- _ O
suggested -X- _ O
by -X- _ O
Krishna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
): -X- _ O

Training -X- _ O
Hyper -X- _ O
- -X- _ O
parameters -X- _ O
: -X- _ O
For -X- _ O
all -X- _ O
our -X- _ O
experiments -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
auto -X- _ O
- -X- _ O
encoder -X- _ O
( -X- _ O
lr -X- _ B-HyperparameterName
ae -X- _ I-HyperparameterName
) -X- _ O
to -X- _ O
1e-3 -X- _ B-HyperparameterValue
and -X- _ O
( -X- _ O
lr -X- _ B-HyperparameterName
disc -X- _ I-HyperparameterName
) -X- _ O
to -X- _ O
1e-4 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
discriminator -X- _ I-HyperparameterName
steps -X- _ I-HyperparameterName
( -X- _ O
n -X- _ B-HyperparameterName
dis -X- _ I-HyperparameterName
) -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
5 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
parameters -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
= -X- _ O
0.5 -X- _ B-HyperparameterValue
and -X- _ O
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
= -X- _ O
0.9 -X- _ B-HyperparameterValue
, -X- _ O
which -X- _ O
ensures -X- _ O
a -X- _ O
more -X- _ O
conservative -X- _ O
optimization -X- _ O
and -X- _ O
is -X- _ O
known -X- _ O
to -X- _ O
improve -X- _ O
stability -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
add -X- _ O
a -X- _ O
gradient -X- _ O
penalty -X- _ O
to -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
discriminator -X- _ O
that -X- _ O
stabilizes -X- _ O
training -X- _ O
. -X- _ O
All -X- _ O
the -X- _ O
suggestions -X- _ O
for -X- _ O
stabilizing -X- _ O
training -X- _ O
are -X- _ O
mostly -X- _ O
obtained -X- _ O
from -X- _ O
( -X- _ O
Arjovsky -X- _ O
and -X- _ O
Bottou -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
provide -X- _ O
a -X- _ O
summary -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
statistics -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
include -X- _ O
datasets -X- _ O
of -X- _ O
varied -X- _ O
length -X- _ O
and -X- _ O
complexity -X- _ O
. -X- _ O
Apart -X- _ O
from -X- _ O
having -X- _ O
different -X- _ O
topics -X- _ O
, -X- _ O
the -X- _ O
IMDB -X- _ B-DatasetName
dataset -X- _ O
is -X- _ O
more -X- _ O
formal -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
more -X- _ O
colloquial -X- _ O
YELP -X- _ B-DatasetName
. -X- _ O
We -X- _ O
fix -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
vocabulary -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
for -X- _ O
YELP -X- _ B-DatasetName
, -X- _ O
IMDB -X- _ B-DatasetName
and -X- _ O
POLITICAL -X- _ B-DatasetName
at -X- _ O
30 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
which -X- _ O
is -X- _ O
also -X- _ O
the -X- _ O
default -X- _ O
maximum -X- _ B-HyperparameterName
vocab -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
used -X- _ O
in -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
7 -X- _ O
63.4 -X- _ O
36.7 -X- _ O
20.2 -X- _ O
96.0 -X- _ O
73.6 -X- _ O
35.4 -X- _ O
26.2 -X- _ O
98.6 -X- _ O
55.0 -X- _ O
44.4 -X- _ O
25.5 -X- _ O
nucleus(p -X- _ O
= -X- _ O
0.6 -X- _ O
) -X- _ O
85.6 -X- _ O
63.0 -X- _ O
36.6 -X- _ O
20.0 -X- _ O
95.8 -X- _ O
72.8 -X- _ O
35.3 -X- _ O
25.7 -X- _ O
98.6 -X- _ O
54.4 -X- _ O
44.2 -X- _ O
25 -X- _ O
= -X- _ O
0.6 -X- _ O
) -X- _ O
89.4 -X- _ O
68.6 -X- _ O
32.8 -X- _ O
20.4 -X- _ O
97.1 -X- _ O
82.6 -X- _ O
33.6 -X- _ O
27.4 -X- _ O
99.0 -X- _ O
56.0 -X- _ O
41.6 -X- _ O
24.4 -X- _ O
Table -X- _ O
2 -X- _ O
: -X- _ O
Evaluation -X- _ O
of -X- _ O
ARAE -X- _ B-MethodName
seq2seq -X- _ I-MethodName
with -X- _ O
ACC -X- _ B-MetricName
( -X- _ O
transfer -X- _ B-MetricName
accuracy -X- _ I-MetricName
) -X- _ O
, -X- _ O
FL -X- _ B-MetricName
( -X- _ O
fluency -X- _ B-MetricName
) -X- _ O
and -X- _ O
SIM -X- _ B-MetricName
( -X- _ O
semantic -X- _ B-MetricName
similarity -X- _ I-MetricName
) -X- _ O
, -X- _ O
AGG -X- _ B-MetricName
( -X- _ O
aggregate -X- _ B-MetricName
metric -X- _ I-MetricName
) -X- _ O
. -X- _ O
Cooperatively -X- _ O
reducing -X- _ O
the -X- _ O
contrastive -X- _ O
or -X- _ O
the -X- _ O
classification -X- _ O
loss -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
ARAE -X- _ B-MethodName
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
mean -X- _ O
of -X- _ O
five -X- _ O
runs -X- _ O
for -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
The -X- _ O
bolded -X- _ O
measures -X- _ O
are -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
domains -X- _ O
: -X- _ O
i -X- _ O
) -X- _ O
Lexical -X- _ O
: -X- _ O
Sentence -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
-The -X- _ O
transferred -X- _ O
sentence -X- _ O
should -X- _ O
maintain -X- _ O
a -X- _ O
length -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
sentence -X- _ O
( -X- _ O
binarized -X- _ O
to -X- _ O
long -X- _ O
sentences -X- _ O
with -X- _ O
10 -X- _ B-HyperparameterValue
or -X- _ O
or -X- _ O
more -X- _ O
words -X- _ O
or -X- _ O
short -X- _ O
otherwise -X- _ O
) -X- _ O
. -X- _ O
ii -X- _ O
) -X- _ O
Syntactic -X- _ O
: -X- _ O
Presence -X- _ O
of -X- _ O
personal -X- _ O
pronouns -X- _ O
( -X- _ O
binarized -X- _ O
to -X- _ O
indicate -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
a -X- _ O
personal -X- _ O
pronoun -X- _ O
) -X- _ O
; -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
adjectives -X- _ I-HyperparameterName
( -X- _ O
categorical -X- _ O
up -X- _ O
to -X- _ O
5 -X- _ B-HyperparameterValue
) -X- _ O
; -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
proper -X- _ I-HyperparameterName
nouns -X- _ I-HyperparameterName
( -X- _ O
categorical -X- _ O
up -X- _ O
to -X- _ O
3 -X- _ B-HyperparameterValue
) -X- _ O
; -X- _ O
syntactic -X- _ B-HyperparameterName
tree -X- _ I-HyperparameterName
height -X- _ I-HyperparameterName
( -X- _ O
categorical -X- _ O
up -X- _ O
to -X- _ O
10 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
iii -X- _ O
) -X- _ O
Domain -X- _ O
specific -X- _ O
-number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
domain -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
specific -X- _ I-HyperparameterName
attributes -X- _ I-HyperparameterName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
( -X- _ O
categorical -X- _ O
up -X- _ O
to -X- _ O
5 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
we -X- _ O
label -X- _ O
the -X- _ O
sentence -X- _ O
with -X- _ O
a -X- _ O
constraintspecific -X- _ O
, -X- _ O
catch -X- _ O
- -X- _ O
all -X- _ O
label -X- _ O
if -X- _ O
the -X- _ O
bounds -X- _ O
are -X- _ O
beyond -X- _ O
what -X- _ O
we -X- _ O
mention -X- _ O
above -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
labels -X- _ O
may -X- _ O
be -X- _ O
different -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
on -X- _ O
our -X- _ O
constraints -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
encoders -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
one -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
layer -X- _ I-HyperparameterValue
LSTM -X- _ B-HyperparameterName
network -X- _ I-HyperparameterName
with -X- _ O
300 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
dimensions -X- _ I-HyperparameterName
for -X- _ O
all -X- _ O
the -X- _ O
datasets -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
critics -X- _ O
and -X- _ O
classification -X- _ O
loss -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
two -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
layer -X- _ I-HyperparameterValue
multi -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
perceptron -X- _ I-HyperparameterName
with -X- _ O
100 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
. -X- _ O

where -X- _ O
|C| -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
constraints -X- _ I-HyperparameterName
per -X- _ I-HyperparameterName
sentence -X- _ I-HyperparameterName
, -X- _ O
σ -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
sigmoid -X- _ B-HyperparameterValue
function -X- _ I-HyperparameterValue
and -X- _ O
l -X- _ O
c -X- _ O
are -X- _ O
the -X- _ O
logits -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
classifier -X- _ O
for -X- _ O
z -X- _ O
i -X- _ O
. -X- _ O
As -X- _ O
in -X- _ O
contrastive -X- _ O
loss -X- _ O
, -X- _ O
the -X- _ O
z -X- _ O
i -X- _ O
can -X- _ O
be -X- _ O
produced -X- _ O
by -X- _ O
encoders -X- _ O
of -X- _ O
S -X- _ O
, -X- _ O
T -X- _ O
or -X- _ O
from -X- _ O
the -X- _ O
hidden -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
critic -X- _ O
. -X- _ O

Xent -X- _ O
loss -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
one -X- _ O
that -X- _ O
is -X- _ O
amenable -X- _ O
to -X- _ O
multiple -X- _ O
positive -X- _ O
instances -X- _ O
( -X- _ O
Khosla -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
sentence -X- _ O
s -X- _ O
i -X- _ O
∈ -X- _ O
S -X- _ O
in -X- _ O
a -X- _ O
minibatch -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
B -X- _ I-HyperparameterName
, -X- _ O
we -X- _ O
mine -X- _ O
P -X- _ O
positive -X- _ O
sentences -X- _ O
each -X- _ O
from -X- _ O
S -X- _ O
and -X- _ O
T -X- _ O
that -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
constraints -X- _ O
with -X- _ O
s -X- _ O
i -X- _ O
. -X- _ O
This -X- _ O
contrastive -X- _ O
loss -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O
: -X- _ O

To -X- _ O
alleviate -X- _ O
the -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
structured -X- _ O
latent -X- _ O
space -X- _ O
which -X- _ O
embodies -X- _ O
notions -X- _ O
of -X- _ O
our -X- _ O
constraints -X- _ O
in -X- _ O
its -X- _ O
embedded -X- _ O
latent -X- _ O
codes -X- _ O
. -X- _ O
This -X- _ O
ensure -X- _ O
that -X- _ O
instances -X- _ O
with -X- _ O
similar -X- _ O
constraints -X- _ O
are -X- _ O
closer -X- _ O
in -X- _ O
the -X- _ O
latent -X- _ O
space -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
optimization -X- _ B-HyperparameterName
-self -X- _ O
- -X- _ O
supervised -X- _ O
and -X- _ O
discriminative -X- _ O
-to -X- _ O
maintain -X- _ O
the -X- _ O
constraints -X- _ O
better -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
contrastive -X- _ O
representation -X- _ O
learning -X- _ O
to -X- _ O
regularize -X- _ O
the -X- _ O
latent -X- _ O
space -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
encoders -X- _ O
bring -X- _ O
two -X- _ O
sentences -X- _ O
sharing -X- _ O
similar -X- _ O
constraints -X- _ O
closer -X- _ O
together -X- _ O
( -X- _ O
positive -X- _ O
pairs -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
force -X- _ O
dissimilar -X- _ O
ones -X- _ O
away -X- _ O
( -X- _ O
negative -X- _ O
pairs -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
sentences -X- _ O
of -X- _ O
similar -X- _ O
lengths -X- _ O
( -X- _ O
irrespective -X- _ O
of -X- _ O
their -X- _ O
domains -X- _ O
) -X- _ O
should -X- _ O
be -X- _ O
closer -X- _ O
together -X- _ O
. -X- _ O
Among -X- _ O
many -X- _ O
self -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
supervised -X- _ I-HyperparameterName
metric -X- _ I-HyperparameterName
losses -X- _ I-HyperparameterName
such -X- _ O
as -X- _ O
Triplet -X- _ B-HyperparameterValue
Loss -X- _ I-HyperparameterValue
( -X- _ O
Hoffer -X- _ O
and -X- _ O
Ailon -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
NT- -X- _ B-MethodName
2 -X- _ O
) -X- _ O
Train -X- _ O
the -X- _ O
Critic -X- _ O
: -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
tie -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
encoders -X- _ O
from -X- _ O
both -X- _ O
domains -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
encoders -X- _ O
learn -X- _ O
to -X- _ O
encode -X- _ O
domain -X- _ O
- -X- _ O
agnostic -X- _ O
information -X- _ O
. -X- _ O
Tying -X- _ O
encoder -X- _ O
weights -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
used -X- _ O
by -X- _ O
unsupervised -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
( -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
multiple -X- _ O
other -X- _ O
works -X- _ O
( -X- _ O
Mai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
3 -X- _ O
.While -X- _ O
the -X- _ O
latent -X- _ O
space -X- _ O
in -X- _ O
ARAE -X- _ B-MethodName
seq2seq -X- _ I-MethodName
learns -X- _ O
to -X- _ O
match -X- _ O
S -X- _ O
and -X- _ O
T -X- _ O
sentences -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
guarantee -X- _ O
on -X- _ O
translations -X- _ O
maintaining -X- _ O
the -X- _ O
" -X- _ O
content -X- _ O
" -X- _ O
. -X- _ O
This -X- _ O
issue -X- _ O
is -X- _ O
particularly -X- _ O
pronounced -X- _ O
in -X- _ O
unsupervised -X- _ O
attribute -X- _ B-TaskName
transfer -X- _ I-TaskName
due -X- _ O
to -X- _ O
lack -X- _ O
of -X- _ O
parallel -X- _ O
sentences -X- _ O
between -X- _ O
S -X- _ O
and -X- _ O
T -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
above -X- _ O
process -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
sampling -X- _ O
s -X- _ O
from -X- _ O
a -X- _ O
noise -X- _ O
distribution -X- _ O
like -X- _ O
N -X- _ O
( -X- _ O
0 -X- _ O
, -X- _ O
I -X- _ O
) -X- _ O
and -X- _ O
passing -X- _ O
it -X- _ O
through -X- _ O
a -X- _ O
generator -X- _ O
enc -X- _ O
ψ -X- _ O
, -X- _ O
we -X- _ O
feed -X- _ O
it -X- _ O
text -X- _ O
from -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
T -X- _ O
and -X- _ O
a -X- _ O
decoder -X- _ O
dec -X- _ O
η -X- _ O
that -X- _ O
decodes -X- _ O
text -X- _ O
in -X- _ O
T -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
inspired -X- _ O
from -X- _ O
Cycle -X- _ B-MethodName
- -X- _ I-MethodName
GAN -X- _ I-MethodName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
instead -X- _ O
of -X- _ O
matching -X- _ O
the -X- _ O
noise -X- _ O
distribution -X- _ O
N -X- _ O
, -X- _ O
we -X- _ O
match -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
T -X- _ O
. -X- _ O

Next -X- _ O
, -X- _ O
to -X- _ O
generate -X- _ O
sentences -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
two -X- _ O
decodersx -X- _ O
src -X- _ O
∼ -X- _ O
p -X- _ O
φ -X- _ O
( -X- _ O
x|z -X- _ O
) -X- _ O
andx -X- _ O
tgt -X- _ O
∼ -X- _ O
p -X- _ O
η -X- _ O
( -X- _ O
x|z -X- _ O
) -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
z -X- _ O
can -X- _ O
be -X- _ O
either -X- _ O
z -X- _ O
s -X- _ O
or -X- _ O
z -X- _ O
t -X- _ O
based -X- _ O
on -X- _ O
whether -X- _ O
we -X- _ O
autoencode -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
p -X- _ O
φ -X- _ O
( -X- _ O
x|z -X- _ O
s -X- _ O
= -X- _ O
enc -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
src -X- _ O
) -X- _ O
) -X- _ O
) -X- _ O
or -X- _ O
translate -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
p -X- _ O
φ -X- _ O
x|z -X- _ O
t -X- _ O
= -X- _ O
enc -X- _ O
ψ -X- _ O
( -X- _ O
x -X- _ O
tgt -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
Unlike -X- _ O
ARAE -X- _ B-MethodName
's -X- _ O
single -X- _ B-HyperparameterValue
decoder -X- _ O
, -X- _ O
we -X- _ O
incorporate -X- _ O
two -X- _ B-HyperparameterValue
decoders -X- _ O
to -X- _ O
enable -X- _ O
bi -X- _ O
- -X- _ O
directional -X- _ O
translation -X- _ O
. -X- _ O

To -X- _ O
achieve -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
enc -X- _ O
θ -X- _ O
to -X- _ O
encode -X- _ O
x -X- _ O
src -X- _ O
and -X- _ O
repurpose -X- _ O
enc -X- _ O
ψ -X- _ O
to -X- _ O
encode -X- _ O
x -X- _ O
tgt -X- _ O
. -X- _ O
We -X- _ O
obtain -X- _ O
their -X- _ O
latent -X- _ O
codes -X- _ O
( -X- _ O
z -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
which -X- _ O
we -X- _ O
name -X- _ O
as -X- _ O
( -X- _ O
z -X- _ O
s -X- _ O
, -X- _ O
z -X- _ O
t -X- _ O
) -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
z -X- _ O
s -X- _ O
= -X- _ O
enc -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
src -X- _ O
) -X- _ O
and -X- _ O
z -X- _ O
t -X- _ O
= -X- _ O
enc -X- _ O
ψ -X- _ O
( -X- _ O
x -X- _ O
tgt -X- _ O
) -X- _ O
. -X- _ O

While -X- _ O
ARAE -X- _ B-MethodName
is -X- _ O
an -X- _ O
auto -X- _ O
- -X- _ O
encoder -X- _ O
that -X- _ O
recreates -X- _ O
input -X- _ O
x -X- _ O
→x -X- _ O
, -X- _ O
our -X- _ O
requirement -X- _ O
is -X- _ O
to -X- _ O
translate -X- _ O
sentences -X- _ O
from -X- _ O
one -X- _ O
domain -X- _ O
to -X- _ O
another -X- _ O
. -X- _ O
Given -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
modify -X- _ O
the -X- _ O
ARAE -X- _ B-MethodName
to -X- _ O
a -X- _ O
seq2seq -X- _ O
variant -X- _ O
such -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
translate -X- _ O
input -X- _ O
sentences -X- _ O
between -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
domains -X- _ O
; -X- _ O
i.e. -X- _ O
, -X- _ O
x -X- _ O
src -X- _ O
→x -X- _ O
tgt -X- _ O
and -X- _ O
x -X- _ O
tgt -X- _ O
→x -X- _ O
src -X- _ O
. -X- _ O

Our -X- _ O
approach -X- _ O
, -X- _ O
while -X- _ O
simple -X- _ O
and -X- _ O
aimed -X- _ O
at -X- _ O
maintaining -X- _ O
constraints -X- _ O
, -X- _ O
improves -X- _ O
the -X- _ O
overall -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
generation -X- _ O
. -X- _ O
We -X- _ O
demonstrate -X- _ O
these -X- _ O
gains -X- _ O
over -X- _ O
three -X- _ O
datasets -X- _ O
: -X- _ O
YELP -X- _ B-DatasetName
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
, -X- _ O
IMDB -X- _ B-DatasetName
( -X- _ O
Dai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
POLITICAL -X- _ B-DatasetName
( -X- _ O
Prabhumoye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
generating -X- _ O
six -X- _ O
constraints -X- _ O
including -X- _ O
lexical -X- _ O
, -X- _ O
syntactic -X- _ O
and -X- _ O
domainspecific -X- _ O
constraints -X- _ O
. -X- _ O
The -X- _ O
introduced -X- _ O
cooperative -X- _ B-HyperparameterValue
losses -X- _ I-HyperparameterValue
satisfy -X- _ O
the -X- _ O
constraints -X- _ O
more -X- _ O
effectively -X- _ O
compared -X- _ O
against -X- _ O
strong -X- _ O
baselines -X- _ O
. -X- _ O
Since -X- _ O
multiple -X- _ O
attributes -X- _ O
can -X- _ O
change -X- _ O
between -X- _ O
two -X- _ O
domains -X- _ O
( -X- _ O
Subramanian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
our -X- _ O
method -X- _ O
on -X- _ O
one -X- _ O
such -X- _ O
dataset -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
constraints -X- _ O
of -X- _ O
identity -X- _ O
are -X- _ O
maintained -X- _ O
more -X- _ O
effectively -X- _ O
( -X- _ O
§ -X- _ O
4.4.2 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
introduce -X- _ O
cooperative -X- _ B-HyperparameterValue
losses -X- _ I-HyperparameterValue
in -X- _ O
a -X- _ O
GAN -X- _ O
- -X- _ O
like -X- _ O
setup -X- _ O
for -X- _ O
NLG.Task -X- _ B-TaskName
Setup -X- _ O
: -X- _ O
We -X- _ O
consider -X- _ O
two -X- _ O
sets -X- _ O
of -X- _ O
sentences -X- _ O
( -X- _ O
or -X- _ O
corpora -X- _ O
) -X- _ O
S= -X- _ O
{ -X- _ O
x -X- _ O
1 -X- _ O
src -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
src -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
x -X- _ O
m -X- _ O
src -X- _ O
} -X- _ O
and -X- _ O
T -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
1 -X- _ O
trg -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
trg -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
x -X- _ O
n -X- _ O
trg -X- _ O
} -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
domains -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Each -X- _ O
corpus -X- _ O
-which -X- _ O
we -X- _ O
interpret -X- _ O
as -X- _ O
domains -X- _ O
-contain -X- _ O
discernable -X- _ O
attributes -X- _ O
, -X- _ O
ranging -X- _ O
from -X- _ O
sentiment -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
positive -X- _ O
vs. -X- _ O
negative -X- _ O
) -X- _ O
, -X- _ O
topics -X- _ O
, -X- _ O
political -X- _ O
slant -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
democratic -X- _ O
vs. -X- _ O
republican -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
some -X- _ O
combination -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
overall -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
rewrite -X- _ O
a -X- _ O
piece -X- _ O
of -X- _ O
text -X- _ O
s -X- _ O
i -X- _ O
∈ -X- _ O
S -X- _ O
to -X- _ O
t -X- _ O
i -X- _ O
∈ -X- _ O
T -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
translation -X- _ O
changes -X- _ O
the -X- _ O
attributes -X- _ O
varying -X- _ O
across -X- _ O
the -X- _ O
two -X- _ O
domains -X- _ O
but -X- _ O
retains -X- _ O
the -X- _ O
remaining -X- _ O
content -X- _ O
. -X- _ O
While -X- _ O
content -X- _ O
retention -X- _ O
is -X- _ O
not -X- _ O
explicitly -X- _ O
defined -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
this -X- _ O
new -X- _ O
task -X- _ O
of -X- _ O
constrained -X- _ O
unsupervised -X- _ O
attribute -X- _ B-TaskName
transfer -X- _ I-TaskName
that -X- _ O
assigns -X- _ O
explicit -X- _ O
constraints -X- _ O
C -X- _ O
= -X- _ O
{ -X- _ O
c -X- _ O
1 -X- _ O
, -X- _ O
c -X- _ O
2 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
c -X- _ O
|C| -X- _ O
} -X- _ O
, -X- _ O
to -X- _ O
be -X- _ O
retained -X- _ O
. -X- _ O
These -X- _ O
constraints -X- _ O
can -X- _ O
be -X- _ O
defined -X- _ O
at -X- _ O
various -X- _ O
levels -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
: -X- _ O
lexical -X- _ O
, -X- _ O
syntactic -X- _ O
and -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
. -X- _ O
Regularized -X- _ B-MethodName
Autoencoder -X- _ I-MethodName
( -X- _ O
ARAE -X- _ B-MethodName
): -X- _ O
To -X- _ O
perform -X- _ O
unsupervised -X- _ O
attribute -X- _ B-TaskName
transfer -X- _ I-TaskName
, -X- _ O
we -X- _ O
consider -X- _ O
seq2seq -X- _ O
models -X- _ O
that -X- _ O
encode -X- _ O
source -X- _ O
sentences -X- _ O
to -X- _ O
a -X- _ O
latent -X- _ O
space -X- _ O
and -X- _ O
then -X- _ O
decodes -X- _ O
them -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
sentences -X- _ O
. -X- _ O
ARAEs -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
are -X- _ O
the -X- _ O
auto -X- _ O
- -X- _ O
encoder -X- _ O
variants -X- _ O
of -X- _ O
the -X- _ O
Generative -X- _ O
Adversarial -X- _ O
Network -X- _ O
( -X- _ O
GAN -X- _ O
) -X- _ O
( -X- _ O
Goodfellow -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
framework -X- _ O
. -X- _ O
They -X- _ O
learn -X- _ O
smooth -X- _ O
latent -X- _ O
spaces -X- _ O
( -X- _ O
by -X- _ O
imposing -X- _ O
implicit -X- _ O
priors -X- _ O
) -X- _ O
to -X- _ O
ease -X- _ O
the -X- _ O
sampling -X- _ O
of -X- _ O
latent -X- _ O
sentences -X- _ O
. -X- _ O
ARAEs -X- _ O
have -X- _ O
been -X- _ O
widely -X- _ O
adopted -X- _ O
in -X- _ O
tasks -X- _ O
like -X- _ O
unsupervised -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
topic -X- _ B-TaskName
modeling -X- _ I-TaskName
, -X- _ O
among -X- _ O
others -X- _ O
, -X- _ O
and -X- _ O
form -X- _ O
the -X- _ O
backbone -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
. -X- _ O
ARAE -X- _ B-MethodName
consists -X- _ O
of -X- _ O
an -X- _ O
auto -X- _ O
- -X- _ O
encoder -X- _ O
with -X- _ O
a -X- _ O
deterministic -X- _ O
encoder -X- _ O
enc -X- _ O
θ -X- _ O
: -X- _ O
X -X- _ O
→ -X- _ O
Z -X- _ O
that -X- _ O
encodes -X- _ O
sentences -X- _ O
into -X- _ O
a -X- _ O
latent -X- _ O
space -X- _ O
; -X- _ O
i.e. -X- _ O
, -X- _ O
z -X- _ O
= -X- _ O
enc -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
∼ -X- _ O
P -X- _ O
z -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
conditional -X- _ O
decoder -X- _ O
p -X- _ O
φ -X- _ O
( -X- _ O
x|z -X- _ O
) -X- _ O
that -X- _ O
generates -X- _ O
a -X- _ O
sentence -X- _ O
given -X- _ O
a -X- _ O
latent -X- _ O
code -X- _ O
. -X- _ O
ARAE -X- _ B-MethodName
regularizes -X- _ O
this -X- _ O
latent -X- _ O
space -X- _ O
utilizing -X- _ O
a -X- _ O
GAN -X- _ O
- -X- _ O
like -X- _ O
setup -X- _ O
that -X- _ O
includes -X- _ O
an -X- _ O
implicit -X- _ O
prior -X- _ O
obtained -X- _ O
from -X- _ O
a -X- _ O
parameterized -X- _ O
generator -X- _ O
network -X- _ O
enc -X- _ O
ψ -X- _ O
: -X- _ O
N -X- _ O
( -X- _ O
0 -X- _ O
, -X- _ O
I -X- _ O
) -X- _ O
→ -X- _ O
Z. -X- _ O
Here -X- _ O
, -X- _ O
enc -X- _ O
ψ -X- _ O
maps -X- _ O
a -X- _ O
noise -X- _ O
sample -X- _ O
s -X- _ O
∼ -X- _ O
N -X- _ O
( -X- _ O
0 -X- _ O
, -X- _ O
I -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
corresponding -X- _ O
prior -X- _ O
latent -X- _ O
codez -X- _ O
= -X- _ O
enc -X- _ O
ψ -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
∼ -X- _ O
Pz -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
improve -X- _ O
unsupervised -X- _ O
attribute -X- _ B-TaskName
transfer -X- _ I-TaskName
by -X- _ O
enforcing -X- _ O
invariances -X- _ O
via -X- _ O
explicit -X- _ O
constraints -X- _ O
. -X- _ O
Current -X- _ O
methods -X- _ O
in -X- _ O
text -X- _ O
attribute -X- _ B-TaskName
transfer -X- _ I-TaskName
lack -X- _ O
mechanisms -X- _ O
to -X- _ O
explicitly -X- _ O
enforce -X- _ O
such -X- _ O
constraints -X- _ O
between -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
the -X- _ O
transferred -X- _ O
sentence -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
upon -X- _ O
unsupervised -X- _ O
text -X- _ O
style -X- _ O
transfer -X- _ O
work -X- _ O
by -X- _ O
introducing -X- _ O
an -X- _ O
additional -X- _ O
explicit -X- _ O
regularization -X- _ O
component -X- _ O
in -X- _ O
the -X- _ O
latent -X- _ O
space -X- _ O
of -X- _ O
a -X- _ O
GAN -X- _ O
- -X- _ O
based -X- _ O
seq2seq -X- _ O
network -X- _ O
through -X- _ O
two -X- _ O
complementary -X- _ O
losses -X- _ O
( -X- _ O
§ -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
Unlike -X- _ O
the -X- _ O
adversarial -X- _ O
losses -X- _ O
in -X- _ O
the -X- _ O
GAN -X- _ O
framework -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
losses -X- _ O
cooperatively -X- _ O
reduce -X- _ O
the -X- _ O
same -X- _ O
objective -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
loss -X- _ B-HyperparameterName
is -X- _ O
a -X- _ O
contrastive -X- _ B-HyperparameterValue
loss -X- _ I-HyperparameterValue
( -X- _ O
Le -X- _ O
- -X- _ O
Khac -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
that -X- _ O
brings -X- _ O
sentences -X- _ O
that -X- _ O
have -X- _ O
similar -X- _ O
constraints -X- _ O
closer -X- _ O
and -X- _ O
pushes -X- _ O
sentences -X- _ O
that -X- _ O
are -X- _ O
dissimilar -X- _ O
farther -X- _ O
away -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
loss -X- _ B-HyperparameterName
is -X- _ O
a -X- _ O
classification -X- _ B-HyperparameterValue
loss -X- _ I-HyperparameterValue
that -X- _ O
helps -X- _ O
maintain -X- _ O
the -X- _ O
sentence -X- _ O
identity -X- _ O
via -X- _ O
constraints -X- _ O
from -X- _ O
the -X- _ O
latent -X- _ O
vectors -X- _ O
( -X- _ O
Odena -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

Text -X- _ O
style -X- _ B-TaskName
transfer -X- _ I-TaskName
, -X- _ O
a -X- _ O
popular -X- _ O
form -X- _ O
of -X- _ O
attribute -X- _ B-TaskName
transfer -X- _ I-TaskName
, -X- _ O
regards -X- _ O
" -X- _ O
style -X- _ O
" -X- _ O
as -X- _ O
any -X- _ O
attribute -X- _ O
that -X- _ O
changes -X- _ O
between -X- _ O
datasets -X- _ O
( -X- _ O
Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
Building -X- _ O
on -X- _ O
the -X- _ O
progress -X- _ O
of -X- _ O
supervised -X- _ O
transfer -X- _ O
models -X- _ O
, -X- _ O
recent -X- _ O
works -X- _ O
have -X- _ O
focused -X- _ O
on -X- _ O
unsupervised -X- _ O
style -X- _ B-TaskName
transfer -X- _ I-TaskName
that -X- _ O
avoids -X- _ O
costly -X- _ O
annotation -X- _ O
of -X- _ O
parallel -X- _ O
sentences -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
models -X- _ O
built -X- _ O
using -X- _ O
unsupervised -X- _ O
methods -X- _ O
perform -X- _ O
poorly -X- _ O
when -X- _ O
compared -X- _ O
to -X- _ O
supervised -X- _ O
( -X- _ O
parallel -X- _ O
) -X- _ O
training -X- _ O
( -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
methods -X- _ O
, -X- _ O
while -X- _ O
capable -X- _ O
of -X- _ O
achieving -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
characteristics -X- _ O
, -X- _ O
often -X- _ O
fail -X- _ O
to -X- _ O
maintain -X- _ O
the -X- _ O
invariant -X- _ O
content -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
illustrates -X- _ O
one -X- _ O
such -X- _ O
example -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
sentence -X- _ O
from -X- _ O
the -X- _ O
BOOKS -X- _ O
domain -X- _ O
is -X- _ O
translated -X- _ O
to -X- _ O
the -X- _ O
MOVIE -X- _ O
domain -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
translated -X- _ O
sentence -X- _ O
" -X- _ O
Loved -X- _ O
the -X- _ O
movie -X- _ O
" -X- _ O
has -X- _ O
correctly -X- _ O
transferred -X- _ O
the -X- _ O
attribute -X- _ O
( -X- _ O
style -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
length -X- _ O
, -X- _ O
does -X- _ O
not -X- _ O
retain -X- _ O
the -X- _ O
personal -X- _ O
noun -X- _ O
( -X- _ O
" -X- _ O
I -X- _ O
" -X- _ O
) -X- _ O
, -X- _ O
nor -X- _ O
use -X- _ O
a -X- _ O
domain -X- _ O
- -X- _ O
appropriate -X- _ O
proper -X- _ O
noun -X- _ O
. -X- _ O
Comparatively -X- _ O
, -X- _ O
the -X- _ O
higher -X- _ O
- -X- _ O
fidelity -X- _ O
transfer -X- _ O
" -X- _ O
I -X- _ O
absolutely -X- _ O
enjoyed -X- _ O
Spielberg -X- _ O
's -X- _ O
direction -X- _ O
" -X- _ O
, -X- _ O
maintains -X- _ O
such -X- _ O
constraints -X- _ O
of -X- _ O
identity -X- _ O
, -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
being -X- _ O
apt -X- _ O
. -X- _ O
This -X- _ O
problem -X- _ O
setting -X- _ O
is -X- _ O
an -X- _ O
important -X- _ O
application -X- _ O
of -X- _ O
text -X- _ B-TaskName
transfer -X- _ I-TaskName
, -X- _ O
as -X- _ O
enforcing -X- _ O
constraints -X- _ O
of -X- _ O
identity -X- _ O
can -X- _ O
help -X- _ O
maintain -X- _ O
the -X- _ O
brand -X- _ O
identity -X- _ O
when -X- _ O
the -X- _ O
product -X- _ O
descriptions -X- _ O
are -X- _ O
mapped -X- _ O
from -X- _ O
one -X- _ O
commercial -X- _ O
product -X- _ O
to -X- _ O
another -X- _ O
. -X- _ O
They -X- _ O
can -X- _ O
also -X- _ O
help -X- _ O
in -X- _ O
data -X- _ O
augmentation -X- _ O
for -X- _ O
downstream -X- _ O
domain -X- _ O
adaptation -X- _ O
NLP -X- _ O
applications -X- _ O
( -X- _ O
§ -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O
Constraints -X- _ O
of -X- _ O
identity -X- _ O
are -X- _ O
explored -X- _ O
extensively -X- _ O
in -X- _ O
the -X- _ O
computer -X- _ O
vision -X- _ O
task -X- _ O
of -X- _ O
cross -X- _ O
- -X- _ O
domain -X- _ O
image -X- _ O
generation -X- _ O
. -X- _ O
( -X- _ O
Taigman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
these -X- _ O
issues -X- _ O
- -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
- -X- _ O
are -X- _ O
unexplored -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O

where -X- _ O
M -X- _ O
q -X- _ O
, -X- _ O
M -X- _ O
k -X- _ O
are -X- _ O
a -X- _ O
row -X- _ O
- -X- _ O
wise -X- _ O
concatenated -X- _ O
question -X- _ O
words -X- _ O
and -X- _ O
knowledge -X- _ O
entities -X- _ O
, -X- _ O
W -X- _ O
[ -X- _ O
• -X- _ O
] -X- _ O
is -X- _ O
learn -X- _ O
- -X- _ O
Automatic -X- _ O
transfer -X- _ O
of -X- _ O
text -X- _ O
between -X- _ O
domains -X- _ O
has -X- _ O
become -X- _ O
popular -X- _ O
in -X- _ O
recent -X- _ O
times -X- _ O
. -X- _ O
One -X- _ O
of -X- _ O
its -X- _ O
aims -X- _ O
is -X- _ O
to -X- _ O
preserve -X- _ O
the -X- _ O
semantic -X- _ O
content -X- _ O
of -X- _ O
text -X- _ O
being -X- _ O
translated -X- _ O
from -X- _ O
source -X- _ O
to -X- _ O
target -X- _ O
domain -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
explicitly -X- _ O
maintain -X- _ O
other -X- _ O
attributes -X- _ O
between -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
translated -X- _ O
text -X- _ O
, -X- _ O
for -X- _ O
e.g. -X- _ O
, -X- _ O
text -X- _ O
length -X- _ O
and -X- _ O
descriptiveness -X- _ O
. -X- _ O
Maintaining -X- _ O
constraints -X- _ O
in -X- _ O
transfer -X- _ O
has -X- _ O
several -X- _ O
downstream -X- _ O
applications -X- _ O
, -X- _ O
including -X- _ O
data -X- _ B-TaskName
augmentation -X- _ I-TaskName
and -X- _ O
de -X- _ B-TaskName
- -X- _ I-TaskName
biasing -X- _ I-TaskName
. -X- _ O
We -X- _ O
introduce -X- _ O
a -X- _ O
method -X- _ O
for -X- _ O
such -X- _ O
constrained -X- _ O
unsupervised -X- _ O
text -X- _ O
style -X- _ O
transfer -X- _ O
by -X- _ O
introducing -X- _ O
two -X- _ O
complementary -X- _ O
losses -X- _ O
to -X- _ O
the -X- _ O
generative -X- _ O
adversarial -X- _ O
network -X- _ O
( -X- _ O
GAN -X- _ O
) -X- _ O
family -X- _ O
of -X- _ O
models -X- _ O
. -X- _ O
Unlike -X- _ O
the -X- _ O
competing -X- _ O
losses -X- _ O
used -X- _ O
in -X- _ O
GANs -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
cooperative -X- _ B-HyperparameterValue
losses -X- _ I-HyperparameterValue
where -X- _ O
the -X- _ O
discriminator -X- _ O
and -X- _ O
the -X- _ O
generator -X- _ O
cooperate -X- _ O
and -X- _ O
reduce -X- _ O
the -X- _ O
same -X- _ O
loss -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
is -X- _ O
a -X- _ O
contrastive -X- _ B-HyperparameterValue
loss -X- _ I-HyperparameterValue
and -X- _ O
the -X- _ O
second -X- _ O
is -X- _ O
a -X- _ O
classification -X- _ B-HyperparameterValue
loss -X- _ I-HyperparameterValue
-aiming -X- _ O
to -X- _ O
regularize -X- _ O
the -X- _ O
latent -X- _ O
space -X- _ O
further -X- _ O
and -X- _ O
bring -X- _ O
similar -X- _ O
sentences -X- _ O
across -X- _ O
domains -X- _ O
closer -X- _ O
together -X- _ O
. -X- _ O
We -X- _ O
demonstrate -X- _ O
that -X- _ O
such -X- _ O
training -X- _ O
retains -X- _ O
lexical -X- _ O
, -X- _ O
syntactic -X- _ O
, -X- _ O
and -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
constraints -X- _ O
between -X- _ O
domains -X- _ O
for -X- _ O
multiple -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
including -X- _ O
ones -X- _ O
where -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
attribute -X- _ O
change -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
complementary -X- _ B-HyperparameterValue
cooperative -X- _ I-HyperparameterValue
losses -X- _ I-HyperparameterValue
improve -X- _ O
text -X- _ O
quality -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
both -X- _ O
automated -X- _ O
and -X- _ O
human -X- _ O
evaluation -X- _ O
measures -X- _ O
. -X- _ O
1 -X- _ O

) -X- _ O
where -X- _ O
i -X- _ O
and -X- _ O
j -X- _ O
are -X- _ O
a -X- _ B-HyperparameterValue
single -X- _ I-HyperparameterValue
layer -X- _ I-HyperparameterValue
feed -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
forward -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
, -X- _ O
respectively -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
two -X- _ O
aggregated -X- _ O
graph -X- _ O
representations -X- _ O
are -X- _ O
concatenated -X- _ O
and -X- _ O
fed -X- _ O
into -X- _ O
another -X- _ O
single -X- _ B-HyperparameterValue
layer -X- _ I-HyperparameterValue
feed -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
forward -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
to -X- _ O
get -X- _ O
joint -X- _ O
representation -X- _ O
of -X- _ O
question -X- _ O
and -X- _ O
knowledge -X- _ O
graph -X- _ O
. -X- _ O
We -X- _ O
reproduce -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
memory -X- _ O
networks -X- _ O
( -X- _ O
Sukhbaatar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
proposed -X- _ O
as -X- _ O
a -X- _ O
baseline -X- _ O
model -X- _ O
in -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
Bag -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
words -X- _ O
( -X- _ O
BoW -X- _ O
) -X- _ O
representation -X- _ O
for -X- _ O
knowledge -X- _ O
facts -X- _ O
and -X- _ O
a -X- _ O
question -X- _ O
. -X- _ O
The -X- _ O
soft -X- _ O
attention -X- _ O
over -X- _ O
the -X- _ O
knowledge -X- _ O
facts -X- _ O
and -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
p -X- _ O
ij -X- _ O
= -X- _ O
softmax(q -X- _ O
T -X- _ O
i−1 -X- _ O
m -X- _ O
ij -X- _ O
) -X- _ O
where -X- _ O
m -X- _ O
is -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
knowledge -X- _ O
facts -X- _ O
, -X- _ O
i -X- _ O
is -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
layer -X- _ O
and -X- _ O
j -X- _ O
is -X- _ O
an -X- _ O
index -X- _ O
of -X- _ O
knowledge -X- _ O
facts -X- _ O
. -X- _ O
The -X- _ O
output -X- _ O
representation -X- _ O
of -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
is -X- _ O
O -X- _ O
i -X- _ O
= -X- _ O
j -X- _ O
p -X- _ O
ij -X- _ O
o -X- _ O
ij -X- _ O
where -X- _ O
o -X- _ O
is -X- _ O
the -X- _ O
another -X- _ O
embeddings -X- _ O
of -X- _ O
knowledge -X- _ O
facts -X- _ O
different -X- _ O
from -X- _ O
m. -X- _ O
The -X- _ O
updated -X- _ O
question -X- _ O
representation -X- _ O
is -X- _ O
q -X- _ O
k+1 -X- _ O
= -X- _ O
O -X- _ O
k+1 -X- _ O
+ -X- _ O
q -X- _ O
k -X- _ O
, -X- _ O
and -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
output -X- _ O
representation -X- _ O
and -X- _ O
question -X- _ O
representation -X- _ O
, -X- _ O
answer -X- _ O
is -X- _ O
predicted -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
a -X- _ O
= -X- _ O
softmax(f -X- _ O
( -X- _ O
O -X- _ O
K -X- _ O
+ -X- _ O
q -X- _ O
K−1 -X- _ O
) -X- _ O
) -X- _ O
where -X- _ O
f -X- _ O
is -X- _ O
a -X- _ B-HyperparameterValue
single -X- _ I-HyperparameterValue
layer -X- _ I-HyperparameterValue
feed -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
forward -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
up -X- _ O
the -X- _ O
model -X- _ O
as -X- _ O
three -X- _ B-HyperparameterValue
layers -X- _ O
with -X- _ O
adjacent -X- _ O
and -X- _ O
layer -X- _ O
- -X- _ O
wise -X- _ O
weight -X- _ O
tying -X- _ O
. -X- _ O
Bilinear -X- _ B-MethodName
attention -X- _ I-MethodName
networks -X- _ I-MethodName
exploit -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
co -X- _ O
- -X- _ O
attention -X- _ O
mechanism -X- _ O
between -X- _ O
knowledge -X- _ O
and -X- _ O
question -X- _ O
. -X- _ O
BAN -X- _ B-MethodName
calculates -X- _ O
soft -X- _ O
attention -X- _ O
scores -X- _ O
between -X- _ O
knowledge -X- _ O
entities -X- _ O
and -X- _ O
question -X- _ O
words -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

) -X- _ O
. -X- _ O
After -X- _ O
the -X- _ O
propagation -X- _ O
phase -X- _ O
, -X- _ O
the -X- _ O
nodes -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
are -X- _ O
aggregated -X- _ O
to -X- _ O
a -X- _ O
graph -X- _ O
- -X- _ O
level -X- _ O
representation -X- _ O
as -X- _ O
h -X- _ O
G -X- _ O
= -X- _ O
tanh -X- _ B-HyperparameterValue
( -X- _ O
v∈V -X- _ O
σ(i(h -X- _ O

) -X- _ O
where -X- _ O
σ -X- _ B-HyperparameterName
is -X- _ O
a -X- _ O
logistic -X- _ B-HyperparameterValue
sigmoid -X- _ I-HyperparameterValue
function -X- _ I-HyperparameterValue
, -X- _ O
and -X- _ O
W -X- _ O
[ -X- _ O
• -X- _ O
] -X- _ O
and -X- _ O
U -X- _ O
[ -X- _ O
• -X- _ O
] -X- _ O
are -X- _ O
learnable -X- _ O
parameters -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
hidden -X- _ O
states -X- _ O
of -X- _ O
nodes -X- _ O
in -X- _ O
the -X- _ O
given -X- _ O
graph -X- _ O
are -X- _ O
updates -X- _ O
as -X- _ O
h -X- _ O

] -X- _ O
T -X- _ O
+ -X- _ O
b -X- _ O
where -X- _ O
the -X- _ O
matrix -X- _ O
A -X- _ O
determines -X- _ O
how -X- _ O
nodes -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
communicate -X- _ O
each -X- _ O
other -X- _ O
and -X- _ O
b -X- _ O
is -X- _ O
a -X- _ O
bias -X- _ O
vector -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
update -X- _ O
gate -X- _ O
and -X- _ O
reset -X- _ O
gate -X- _ O
are -X- _ O
computed -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

T -X- _ O
where -X- _ O
x -X- _ O
v -X- _ O
is -X- _ O
the -X- _ O
v -X- _ O
- -X- _ O
th -X- _ O
word -X- _ O
embedding -X- _ O
of -X- _ O
each -X- _ O
en -X- _ O
- -X- _ O
tity -X- _ O
in -X- _ O
the -X- _ O
knowledge -X- _ O
and -X- _ O
question -X- _ O
graph -X- _ O
, -X- _ O
a -X- _ O

where -X- _ O
the -X- _ O
subscript -X- _ O
i -X- _ O
denotes -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
index -X- _ O
of -X- _ O
column -X- _ O
vectors -X- _ O
in -X- _ O
each -X- _ O
matrix -X- _ O
. -X- _ O
For -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
attention -X- _ O
, -X- _ O
the -X- _ O
attended -X- _ O
outputs -X- _ O
with -X- _ O
different -X- _ O
heads -X- _ O
are -X- _ O
concatenated -X- _ O
and -X- _ O
fed -X- _ O
into -X- _ O
a -X- _ B-HyperparameterValue
single -X- _ I-HyperparameterValue
layer -X- _ I-HyperparameterValue
feedforward -X- _ B-HyperparameterName
layer -X- _ I-HyperparameterName
to -X- _ O
make -X- _ O
a -X- _ O
final -X- _ O
representation -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
four -X- _ O
attention -X- _ O
heads -X- _ O
as -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
architecture -X- _ O
and -X- _ O
detailed -X- _ O
operation -X- _ O
of -X- _ O
hypergraph -X- _ B-MethodName
attention -X- _ I-MethodName
networks -X- _ I-MethodName
are -X- _ O
similar -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
BAN -X- _ B-MethodName
. -X- _ O
The -X- _ O
difference -X- _ O
between -X- _ O
BAN -X- _ B-MethodName
and -X- _ O
HAN -X- _ B-MethodName
is -X- _ O
the -X- _ O
abstraction -X- _ B-HyperparameterName
level -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
input -X- _ I-HyperparameterName
. -X- _ O
For -X- _ O
HAN -X- _ B-MethodName
, -X- _ O
the -X- _ O
hyperedges -X- _ O
sampled -X- _ O
by -X- _ O
stochastic -X- _ O
graph -X- _ O
walk -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
co -X- _ O
- -X- _ O
attention -X- _ O
mechanism -X- _ O
. -X- _ O
What -X- _ O
HAN -X- _ B-MethodName
and -X- _ O
our -X- _ O
model -X- _ O
have -X- _ O
in -X- _ O
common -X- _ O
is -X- _ O
introducing -X- _ O
a -X- _ O
hypergraph -X- _ O
to -X- _ O
consider -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
relationships -X- _ O
in -X- _ O
question -X- _ O
graph -X- _ O
and -X- _ O
knowledge -X- _ O
graph -X- _ O
. -X- _ O
Both -X- _ O
models -X- _ O
share -X- _ O
the -X- _ O
similar -X- _ O
motivation -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
core -X- _ O
operations -X- _ O
are -X- _ O
quite -X- _ O
different -X- _ O
. -X- _ O
Especially -X- _ O
, -X- _ O
HAN -X- _ B-MethodName
employs -X- _ O
stochastic -X- _ O
graph -X- _ O
walk -X- _ O
to -X- _ O
construct -X- _ O
question -X- _ O
and -X- _ O
knowledge -X- _ O
hypergraph -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
randomness -X- _ O
of -X- _ O
the -X- _ O
stochasticity -X- _ O
, -X- _ O
misinformed -X- _ O
or -X- _ O
incomplete -X- _ O
hyperedges -X- _ O
can -X- _ O
be -X- _ O
extracted -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
architectures -X- _ O
of -X- _ O
Transformer -X- _ B-MethodName
( -X- _ I-MethodName
SA -X- _ I-MethodName
) -X- _ I-MethodName
and -X- _ O
Transformer -X- _ B-MethodName
( -X- _ I-MethodName
SA+GA -X- _ I-MethodName
) -X- _ I-MethodName
presented -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
. -X- _ O
The -X- _ O
only -X- _ O
difference -X- _ O
is -X- _ O
the -X- _ O
abstraction -X- _ O
level -X- _ O
of -X- _ O
input -X- _ O
. -X- _ O
The -X- _ O
Transformer -X- _ B-MethodName
( -X- _ I-MethodName
SA -X- _ I-MethodName
) -X- _ I-MethodName
and -X- _ O
Transformer -X- _ B-MethodName
( -X- _ I-MethodName
SA+GA -X- _ I-MethodName
) -X- _ I-MethodName
take -X- _ O
single -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
word -X- _ I-HyperparameterValue
- -X- _ I-HyperparameterValue
unit -X- _ I-HyperparameterValue
as -X- _ O
input -X- _ B-HyperparameterName
tokens -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
takes -X- _ O
hyperedges -X- _ O
as -X- _ O
input -X- _ O
tokens -X- _ O
. -X- _ O
Following -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Tsai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
positional -X- _ O
embeddings -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
of -X- _ O
both -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
stack -X- _ O
two -X- _ B-HyperparameterValue
guided -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
blocks -X- _ I-HyperparameterName
and -X- _ O
three -X- _ B-HyperparameterValue
self -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
blocks -X- _ I-HyperparameterName
, -X- _ O
respectively -X- _ O
. -X- _ O
Each -X- _ O
attention -X- _ O
block -X- _ O
has -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
attention -X- _ O
with -X- _ O
four -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
followed -X- _ O
by -X- _ O
layer -X- _ O
normalization -X- _ O
, -X- _ O
residual -X- _ O
connections -X- _ O
and -X- _ O
a -X- _ O
single -X- _ O
multi -X- _ O
- -X- _ O
layer -X- _ O
perceptron -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
dropout -X- _ B-HyperparameterName
applied -X- _ O
on -X- _ O
the -X- _ O
token -X- _ O
embedding -X- _ O
weights -X- _ O
, -X- _ O
query -X- _ O
and -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
embedding -X- _ O
weights -X- _ O
, -X- _ O
attention -X- _ O
weights -X- _ O
and -X- _ O
residual -X- _ O
connections -X- _ O
from -X- _ O
0.05 -X- _ B-HyperparameterValue
to -X- _ O
0.2 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
minimize -X- _ O
negative -X- _ O
log -X- _ O
- -X- _ O
likelihood -X- _ O
using -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
with -X- _ O
an -X- _ O
initial -X- _ B-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
from -X- _ O
1e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
4 -X- _ I-HyperparameterValue
to -X- _ O
1e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
from -X- _ O
128 -X- _ B-HyperparameterValue
to -X- _ O
256 -X- _ B-HyperparameterValue
. -X- _ O
All -X- _ O
transformer -X- _ O
variant -X- _ O
models -X- _ O
described -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
fixed -X- _ O
- -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
as -X- _ O
follows -X- _ O
: -X- _ O
300 -X- _ B-HyperparameterValue
for -X- _ O
1 -X- _ O
- -X- _ O
hop -X- _ O
, -X- _ O
1,000 -X- _ B-HyperparameterValue
for -X- _ O
2 -X- _ O
- -X- _ O
hop -X- _ O
and -X- _ O
1,800 -X- _ B-HyperparameterValue
for -X- _ O
3 -X- _ O
- -X- _ O
hop -X- _ O
graphs -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
Woo -X- _ O
Young -X- _ O
Kang -X- _ O
, -X- _ O
Kyoung -X- _ O
- -X- _ O
Woon -X- _ O
On -X- _ O
, -X- _ O
Seonil -X- _ O
Son -X- _ O
, -X- _ O
Gi -X- _ O
- -X- _ O
Cheon -X- _ O
Kang -X- _ O
, -X- _ O
Christina -X- _ O
Baek -X- _ O
, -X- _ O
Junseok -X- _ O
Park -X- _ O
, -X- _ O
Min -X- _ O
Whoo -X- _ O
Lee -X- _ O
, -X- _ O
Hwiyeol -X- _ O
Jo -X- _ O
and -X- _ O
Sang -X- _ O
- -X- _ O
Woo -X- _ O
Lee -X- _ O
for -X- _ O
their -X- _ O
helpful -X- _ O
comments -X- _ O
and -X- _ O
discussion -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
partly -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
IITP -X- _ O
( -X- _ O
2015 -X- _ O
- -X- _ O
0 -X- _ O
- -X- _ O
00310 -X- _ O
- -X- _ O
SW.StarLab/20 -X- _ O
% -X- _ O
, -X- _ O
2017 -X- _ O
- -X- _ O
0 -X- _ O
- -X- _ O
01772 -X- _ O
- -X- _ O
VTT/20 -X- _ O
% -X- _ O
, -X- _ O
2019 -X- _ O
- -X- _ O
0 -X- _ O
- -X- _ O
01371 -X- _ O
- -X- _ O
BabyMind/10 -X- _ O
% -X- _ O
, -X- _ O
2021 -X- _ O
- -X- _ O
0 -X- _ O
- -X- _ O
02068 -X- _ O
- -X- _ O
AIHub/10 -X- _ O
% -X- _ O
, -X- _ O
2021 -X- _ O
- -X- _ O
0 -X- _ O
- -X- _ O
01343 -X- _ O
- -X- _ O
GSAI/10 -X- _ O
% -X- _ O
, -X- _ O
2020 -X- _ O
- -X- _ O
0 -X- _ O
- -X- _ O
01373/10 -X- _ O
% -X- _ O
) -X- _ O
grants -X- _ O
, -X- _ O
the -X- _ O
KIAT -X- _ O
( -X- _ O
P0006720 -X- _ O
- -X- _ O
ILIAS/10 -X- _ O
% -X- _ O
) -X- _ O
grant -X- _ O
funded -X- _ O
by -X- _ O
the -X- _ O
Korean -X- _ O
government -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
Hanyang -X- _ O
University -X- _ O
( -X- _ O
HY-202100000003160/10%).As -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
graph -X- _ B-MethodName
convolutional -X- _ I-MethodName
networks -X- _ I-MethodName
, -X- _ O
the -X- _ O
knowledge -X- _ O
and -X- _ O
question -X- _ O
graph -X- _ O
are -X- _ O
encoded -X- _ O
separately -X- _ O
by -X- _ O
two -X- _ B-MethodName
gated -X- _ I-MethodName
graph -X- _ I-MethodName
neural -X- _ I-MethodName
networks -X- _ I-MethodName
( -X- _ O
GGNN -X- _ B-MethodName
) -X- _ O
. -X- _ O
Each -X- _ O
GGNN -X- _ B-MethodName
model -X- _ O
consists -X- _ O
of -X- _ O
three -X- _ B-HyperparameterValue
gated -X- _ B-HyperparameterName
recurrent -X- _ I-HyperparameterName
propagation -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
and -X- _ O
a -X- _ O
graphlevel -X- _ O
aggregator -X- _ O
. -X- _ O
Motivated -X- _ O
by -X- _ O
Gated -X- _ O
Recurrent -X- _ O
Units -X- _ O
( -X- _ O
Cho -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
GGNN -X- _ B-MethodName
adopts -X- _ O
a -X- _ O
update -X- _ O
gate -X- _ O
and -X- _ O
a -X- _ O
reset -X- _ O
gate -X- _ O
to -X- _ O
renew -X- _ O
each -X- _ O
node -X- _ O
's -X- _ O
hidden -X- _ O
state -X- _ O
. -X- _ O
The -X- _ O
detailed -X- _ O
equation -X- _ O
of -X- _ O
gated -X- _ O
recurrent -X- _ O
propagation -X- _ O
is -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
h -X- _ O

i -X- _ O
= -X- _ O
( -X- _ O
M -X- _ O
q -X- _ O
W -X- _ O
q -X- _ O
) -X- _ O
i -X- _ O
⊤ -X- _ O
A(M -X- _ O
k -X- _ O
W -X- _ O
k -X- _ O
) -X- _ O
i -X- _ O

Here -X- _ O
, -X- _ O
H -X- _ O
( -X- _ O
0 -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
of -X- _ O
each -X- _ O
entity -X- _ O
in -X- _ O
the -X- _ O
knowledge -X- _ O
and -X- _ O
question -X- _ O
graph -X- _ O
. -X- _ O
After -X- _ O
propagation -X- _ O
and -X- _ O
aggregation -X- _ O
phase -X- _ O
, -X- _ O
the -X- _ O
knowledge -X- _ O
and -X- _ O
question -X- _ O
graph -X- _ O
representations -X- _ O
are -X- _ O
obtained -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
two -X- _ O
graph -X- _ O
representations -X- _ O
are -X- _ O
concatenated -X- _ O
and -X- _ O
fed -X- _ O
into -X- _ O
a -X- _ B-HyperparameterValue
single -X- _ I-HyperparameterValue
layer -X- _ I-HyperparameterValue
feed -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
forward -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
to -X- _ O
get -X- _ O
joint -X- _ O
representation -X- _ O
. -X- _ O
able -X- _ O
matrices -X- _ O
, -X- _ O
and -X- _ O
• -X- _ O
is -X- _ O
element -X- _ O
- -X- _ O
wise -X- _ O
multiplication -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
attention -X- _ O
map -X- _ O
A -X- _ O
, -X- _ O
the -X- _ O
joint -X- _ O
feature -X- _ O
is -X- _ O
obtained -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
z -X- _ O

Appendix -X- _ O
. -X- _ O
This -X- _ O
supplementary -X- _ O
material -X- _ O
provides -X- _ O
additional -X- _ O
information -X- _ O
not -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
text -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
page -X- _ O
limit -X- _ O
. -X- _ O
The -X- _ O
contents -X- _ O
of -X- _ O
this -X- _ O
appendix -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
In -X- _ O
Section -X- _ O
A -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
detailed -X- _ O
statistics -X- _ O
for -X- _ O
the -X- _ O
diverse -X- _ O
splits -X- _ O
of -X- _ O
four -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
KVQA -X- _ B-DatasetName
, -X- _ O
FVQA -X- _ B-DatasetName
, -X- _ O
PQ -X- _ B-DatasetName
and -X- _ O
PQL -X- _ B-DatasetName
. -X- _ O
In -X- _ O
Section -X- _ O
B -X- _ O
and -X- _ O
C -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
additional -X- _ O
quantitative -X- _ O
and -X- _ O
qualitative -X- _ O
analyses -X- _ O
on -X- _ O
KVQA -X- _ B-DatasetName
and -X- _ O
PQ -X- _ B-DatasetName
datasets -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
D -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
the -X- _ O
experimental -X- _ O
details -X- _ O
for -X- _ O
each -X- _ O
dataset -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
E -X- _ O
, -X- _ O
we -X- _ O
depict -X- _ O
the -X- _ O
implementation -X- _ O
details -X- _ O
of -X- _ O
comparative -X- _ O
models -X- _ O
for -X- _ O
KVQA.The -X- _ B-DatasetName
diverse -X- _ O
split -X- _ B-HyperparameterName
statistics -X- _ I-HyperparameterName
for -X- _ O
four -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
KVQA -X- _ B-DatasetName
, -X- _ O
FVQA -X- _ B-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
PQ -X- _ B-DatasetName
and -X- _ O
PQL -X- _ B-DatasetName
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
highlight -X- _ O
four -X- _ O
aspects -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
KVQA -X- _ B-DatasetName
dataset -X- _ O
covers -X- _ O
the -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
entities -X- _ O
( -X- _ O
at -X- _ O
least -X- _ O
5 -X- _ O
times -X- _ O
more -X- _ O
) -X- _ O
and -X- _ O
knowledge -X- _ O
facts -X- _ O
( -X- _ O
at -X- _ O
least -X- _ O
17 -X- _ O
times -X- _ O
more -X- _ O
) -X- _ O
than -X- _ O
FVQA -X- _ B-DatasetName
, -X- _ O
PQ -X- _ B-DatasetName
and -X- _ O
PQL -X- _ B-DatasetName
. -X- _ O
2 -X- _ O
) -X- _ O
PQ -X- _ B-DatasetName
and -X- _ O
PQL -X- _ B-DatasetName
datasets -X- _ O
have -X- _ O
annotations -X- _ O
of -X- _ O
a -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
reasoning -X- _ O
path -X- _ O
to -X- _ O
answer -X- _ O
a -X- _ O
given -X- _ O
question -X- _ O
. -X- _ O
2H -X- _ B-HyperparameterValue
and -X- _ O
3H -X- _ B-HyperparameterValue
denote -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
hops -X- _ I-HyperparameterName
( -X- _ O
i.e. -X- _ O
, -X- _ O
2 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
hop -X- _ I-HyperparameterValue
and -X- _ O
3 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
hop -X- _ I-HyperparameterValue
) -X- _ O
in -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
reasoning -X- _ O
paths -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
M -X- _ O
denotes -X- _ O
a -X- _ O
mixture -X- _ O
of -X- _ O
the -X- _ O
2H -X- _ O
and -X- _ O
3H -X- _ O
questions -X- _ O
. -X- _ O
3 -X- _ O
) -X- _ O
PQL -X- _ B-DatasetName
covers -X- _ O
more -X- _ O
knowledge -X- _ O
facts -X- _ O
including -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
entities -X- _ O
and -X- _ O
relations -X- _ O
than -X- _ O
PQ -X- _ B-DatasetName
, -X- _ O
but -X- _ O
has -X- _ O
fewer -X- _ O
QA -X- _ O
pairs -X- _ O
. -X- _ O
4 -X- _ O
) -X- _ O
PQL-3H -X- _ B-DatasetName
has -X- _ O
a -X- _ O
quite -X- _ O
limited -X- _ O
number -X- _ O
of -X- _ O
QA -X- _ O
pairs -X- _ O
( -X- _ O
1,031 -X- _ O
) -X- _ O
. -X- _ O
PQL-3H -X- _ B-DatasetName
- -X- _ I-DatasetName
More -X- _ I-DatasetName
has -X- _ O
twice -X- _ O
more -X- _ O
QA -X- _ O
pairs -X- _ O
( -X- _ O
2,062 -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
number -X- _ O
of -X- _ O
entities -X- _ O
, -X- _ O
relations -X- _ O
, -X- _ O
knowledge -X- _ O
facts -X- _ O
and -X- _ O
answers -X- _ O
as -X- _ O
PQL-3H.Here -X- _ B-DatasetName
, -X- _ O
we -X- _ O
analyze -X- _ O
more -X- _ O
in -X- _ O
- -X- _ O
depth -X- _ O
on -X- _ O
KVQA -X- _ B-DatasetName
dataset -X- _ O
concerning -X- _ O
i -X- _ O
) -X- _ O
categories -X- _ O
of -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
ii -X- _ O
) -X- _ O
types -X- _ O
of -X- _ O
answer -X- _ O
selector -X- _ O
. -X- _ O
All -X- _ O
models -X- _ O
are -X- _ O
under -X- _ O
the -X- _ O
same -X- _ O
setting -X- _ O
of -X- _ O
ORG+3 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
hop -X- _ I-HyperparameterValue
reported -X- _ O
in -X- _ O
Table -X- _ O
1.We -X- _ O
analyze -X- _ O
QA -X- _ B-TaskName
performances -X- _ O
over -X- _ O
different -X- _ O
question -X- _ O
categories -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
achieves -X- _ O
the -X- _ O
best -X- _ O
accuracy -X- _ B-MetricName
in -X- _ O
all -X- _ O
categories -X- _ O
except -X- _ O
Multi -X- _ O
- -X- _ O
hop -X- _ O
( -X- _ O
slightly -X- _ O
low -X- _ O
at -X- _ O
second -X- _ O
- -X- _ O
best -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
shows -X- _ O
notable -X- _ O
strengths -X- _ O
especially -X- _ O
on -X- _ O
complex -X- _ O
problems -X- _ O
such -X- _ O
as -X- _ O
Comparison -X- _ O
, -X- _ O
Multi -X- _ O
- -X- _ O
entity -X- _ O
or -X- _ O
Subtraction -X- _ O
. -X- _ O
To -X- _ O
draw -X- _ O
inferences -X- _ O
for -X- _ O
these -X- _ O
question -X- _ O
categories -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
needs -X- _ O
to -X- _ O
attend -X- _ O
to -X- _ O
multiple -X- _ O
knowledge -X- _ O
facts -X- _ O
related -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
conducts -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
reasoning -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
facts -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
shows -X- _ O
significant -X- _ O
improvement -X- _ O
in -X- _ O
spatial -X- _ O
question -X- _ O
compared -X- _ O
to -X- _ O
other -X- _ O
models -X- _ O
. -X- _ O
Whereas -X- _ O
spatial -X- _ O
question -X- _ O
is -X- _ O
quite -X- _ O
simple -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
required -X- _ O
to -X- _ O
understand -X- _ O
a -X- _ O
correct -X- _ O
spatial -X- _ O
relationship -X- _ O
between -X- _ O
multiple -X- _ O
entities -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
image -X- _ O
. -X- _ O
Examples -X- _ O
of -X- _ O
QA -X- _ B-TaskName
on -X- _ O
diverse -X- _ O
question -X- _ O
categories -X- _ O
are -X- _ O
depicted -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O
Answers -X- _ O
, -X- _ O
inferred -X- _ O
by -X- _ O
five -X- _ O
comparative -X- _ O
models -X- _ O
and -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
, -X- _ O
are -X- _ O
presented -X- _ O
with -X- _ O
corresponding -X- _ O
image -X- _ O
and -X- _ O
question -X- _ O
. -X- _ O
The -X- _ O
qualitative -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
draws -X- _ O
reasonable -X- _ O
inferences -X- _ O
across -X- _ O
diverse -X- _ O
question -X- _ O
categories -X- _ O
. -X- _ O
To -X- _ O
validate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
similarity -X- _ O
- -X- _ O
based -X- _ O
answer -X- _ O
selector -X- _ O
, -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
similarity -X- _ O
- -X- _ O
based -X- _ O
answer -X- _ O
selector -X- _ O
( -X- _ O
SIM -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
layer -X- _ O
perceptron -X- _ O
( -X- _ O
MLP -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
note -X- _ O
that -X- _ O
KVQA -X- _ B-DatasetName
dataset -X- _ O
includes -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
unique -X- _ O
answers -X- _ O
( -X- _ O
19,360 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
contains -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
answers -X- _ O
in -X- _ O
test -X- _ O
phase -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
, -X- _ O
the -X- _ O
MLP -X- _ O
fails -X- _ O
to -X- _ O
infer -X- _ O
zeroshot -X- _ O
answers -X- _ O
which -X- _ O
are -X- _ O
not -X- _ O
appeared -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
phase -X- _ O
at -X- _ O
all -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
difference -X- _ O
between -X- _ O
SIM -X- _ O
and -X- _ O
MLP -X- _ O
in -X- _ O
one -X- _ O
- -X- _ O
shot -X- _ O
answer -X- _ O
( -X- _ O
appeared -X- _ O
in -X- _ O
the -X- _ O
only -X- _ O
one -X- _ O
time -X- _ O
in -X- _ O
training -X- _ O
phase -X- _ O
) -X- _ O
is -X- _ O
more -X- _ O
than -X- _ O
18 -X- _ O
% -X- _ O
. -X- _ O
The -X- _ O
MLP -X- _ O
uses -X- _ O
17 -X- _ O
% -X- _ O
more -X- _ O
parameters -X- _ O
than -X- _ O
SIM -X- _ O
because -X- _ O
KVQA -X- _ O
has -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
answer -X- _ O
candidates -X- _ O
( -X- _ O
19,360 -X- _ O
) -X- _ O
. -X- _ O
When -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
candidate -X- _ O
answers -X- _ O
increases -X- _ O
, -X- _ O
the -X- _ O
MLP -X- _ O
needs -X- _ O
more -X- _ O
parameters -X- _ O
, -X- _ O
but -X- _ O
SIM -X- _ O
does -X- _ O
not -X- _ O
. -X- _ O
To -X- _ O
sum -X- _ O
up -X- _ O
, -X- _ O
the -X- _ O
similarity -X- _ O
- -X- _ O
based -X- _ O
answer -X- _ O
selector -X- _ O
( -X- _ O
SIM -X- _ O
) -X- _ O
contributes -X- _ O
to -X- _ O
infer -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
answers -X- _ O
in -X- _ O
parameter -X- _ O
- -X- _ O
efficient -X- _ O
manner -X- _ O
. -X- _ O
is -X- _ O
wrong -X- _ O
even -X- _ O
though -X- _ O
it -X- _ O
attends -X- _ O
correctly -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
knowledge -X- _ O
hyperedge -X- _ O
{ -X- _ O
Wallace -X- _ O
Reid -X- _ O
⪯ -X- _ O
spouse -X- _ O
⪯ -X- _ O
Dorothy -X- _ O
Davenport -X- _ O
⪯ -X- _ O
parents -X- _ O
⪯ -X- _ O
Harry -X- _ O
Davenport -X- _ O
⪯ -X- _ O
cause -X- _ O
of -X- _ O
death -X- _ O
⪯ -X- _ O
Myocardial -X- _ O
Infarction -X- _ O
} -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
Transformer -X- _ B-MethodName
( -X- _ I-MethodName
SA+GA -X- _ I-MethodName
) -X- _ I-MethodName
attends -X- _ O
to -X- _ O
only -X- _ O
the -X- _ O
second -X- _ O
and -X- _ O
seventh -X- _ O
word -X- _ O
( -X- _ O
Dorothy -X- _ O
Davenport -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
fourth -X- _ O
and -X- _ O
ninth -X- _ O
word -X- _ O
( -X- _ O
Harry -X- _ O
Davenport -X- _ O
) -X- _ O
in -X- _ O
knowledge -X- _ O
with -X- _ O
high -X- _ O
attention -X- _ O
score -X- _ O
, -X- _ O
not -X- _ O
the -X- _ O
answer -X- _ O
entity -X- _ O
, -X- _ O
Myocardial -X- _ O
Infarction -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
that -X- _ O
the -X- _ O
reason -X- _ O
why -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
failed -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
despite -X- _ O
focusing -X- _ O
on -X- _ O
the -X- _ O
exact -X- _ O
knowledge -X- _ O
fact -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
word -X- _ O
( -X- _ O
Myocardial -X- _ O
Infarction -X- _ O
) -X- _ O
appears -X- _ O
rarely -X- _ O
in -X- _ O
QA -X- _ O
pairs -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
experimental -X- _ O
settings -X- _ O
suggested -X- _ O
in -X- _ O
. -X- _ O
For -X- _ O
entity -X- _ O
linking -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
for -X- _ O
face -X- _ B-TaskName
identification -X- _ I-TaskName
: -X- _ O
RetinaFace -X- _ B-MethodName
( -X- _ O
Deng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
face -X- _ B-TaskName
detection -X- _ I-TaskName
and -X- _ O
ArcFace -X- _ B-MethodName
( -X- _ O
Deng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
for -X- _ O
face -X- _ B-TaskName
feature -X- _ I-TaskName
extraction -X- _ I-TaskName
. -X- _ O
We -X- _ O
first -X- _ O
assign -X- _ O
a -X- _ O
name -X- _ O
of -X- _ O
the -X- _ O
detected -X- _ O
faces -X- _ O
with -X- _ O
the -X- _ O
label -X- _ O
of -X- _ O
the -X- _ O
closest -X- _ O
distance -X- _ O
compared -X- _ O
to -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
face -X- _ O
embeddings -X- _ O
of -X- _ O
18,880 -X- _ O
named -X- _ O
entities -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
refine -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
de -X- _ O
- -X- _ O
tected -X- _ O
named -X- _ O
entities -X- _ O
by -X- _ O
matching -X- _ O
the -X- _ O
associated -X- _ O
image -X- _ O
caption -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
Wikipedia -X- _ O
caption -X- _ O
) -X- _ O
. -X- _ O
By -X- _ O
doing -X- _ O
so -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
entity -X- _ O
linking -X- _ O
with -X- _ O
top-1 -X- _ O
precision -X- _ B-MetricName
65.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
top-1 -X- _ O
recall -X- _ B-MetricName
72.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
QA -X- _ B-TaskName
performances -X- _ O
in -X- _ O
the -X- _ O
entity -X- _ O
linking -X- _ O
setting -X- _ O
on -X- _ O
KVQA -X- _ B-DatasetName
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
BLSTM -X- _ B-MethodName
and -X- _ O
MemNN -X- _ B-MethodName
of -X- _ O
the -X- _ O
first -X- _ O
section -X- _ O
in -X- _ O
the -X- _ O
table -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
different -X- _ O
entity -X- _ O
linking -X- _ O
modules -X- _ O
with -X- _ O
top-1 -X- _ O
precision -X- _ B-MetricName
81.1 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
top-1 -X- _ O
recall -X- _ B-MetricName
82.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
1 -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
more -X- _ O
accurate -X- _ O
than -X- _ O
ours -X- _ O
around -X- _ O
9.4 -X- _ B-MetricValue
% -X- _ I-MetricValue
in -X- _ O
the -X- _ O
recall -X- _ B-MetricName
metric -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
experimental -X- _ O
settings -X- _ O
suggested -X- _ O
in -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
paper -X- _ O
, -X- _ O
the -X- _ O
dataset -X- _ O
provides -X- _ O
five -X- _ O
splits -X- _ O
of -X- _ O
train -X- _ O
and -X- _ O
test -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
average -X- _ B-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
five -X- _ O
repeated -X- _ O
runs -X- _ O
on -X- _ O
different -X- _ O
data -X- _ O
split -X- _ O
: -X- _ O
76.55 -X- _ B-MetricValue
as -X- _ O
top-1 -X- _ O
accuracy -X- _ O
( -X- _ O
average -X- _ O
of -X- _ O
76.93 -X- _ B-MetricValue
, -X- _ O
75.92 -X- _ B-MetricValue
, -X- _ O
76.24 -X- _ B-MetricValue
, -X- _ O
76.16 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
77.50 -X- _ B-MetricValue
) -X- _ O
and -X- _ O
82.20 -X- _ B-MetricValue
as -X- _ O
top-3 -X- _ O
accuracy -X- _ B-MetricName
( -X- _ O
average -X- _ O
of -X- _ O
82.90 -X- _ B-MetricValue
, -X- _ O
81.45 -X- _ B-MetricValue
, -X- _ O
81.70 -X- _ B-MetricValue
, -X- _ O
81.74 -X- _ B-MetricValue
and -X- _ O
83.20 -X- _ B-MetricValue
) -X- _ O
. -X- _ O
The -X- _ O
experimental -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
same -X- _ O
experimental -X- _ O
settings -X- _ O
suggested -X- _ O
in -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
split -X- _ B-HyperparameterName
the -X- _ O
dataset -X- _ O
into -X- _ O
train -X- _ O
, -X- _ O
validation -X- _ O
, -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
with -X- _ O
a -X- _ O
proportion -X- _ O
of -X- _ O
8:1:1 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
average -X- _ B-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
five -X- _ O
repeated -X- _ O
runs -X- _ O
on -X- _ O
different -X- _ O
data -X- _ O
split -X- _ O
. -X- _ O
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
hypergraph -X- _ B-MethodName
attention -X- _ I-MethodName
networks -X- _ I-MethodName
( -X- _ O
HAN -X- _ B-MethodName
) -X- _ O
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
consider -X- _ O
interactions -X- _ O
between -X- _ O
knowledge -X- _ O
and -X- _ O
question -X- _ O
based -X- _ O
on -X- _ O
co -X- _ O
- -X- _ O
attention -X- _ O
mechanism -X- _ O
. -X- _ O
BAN -X- _ B-MethodName
calculates -X- _ O
soft -X- _ O
attention -X- _ O
scores -X- _ O
between -X- _ O
knowledge -X- _ O
entities -X- _ O
and -X- _ O
question -X- _ O
words -X- _ O
. -X- _ O
Meanwhile -X- _ O
, -X- _ O
HAN -X- _ B-MethodName
employs -X- _ O
stochastic -X- _ O
graph -X- _ O
walk -X- _ O
in -X- _ O
a -X- _ O
knowledge -X- _ O
and -X- _ O
question -X- _ O
graph -X- _ O
to -X- _ O
encode -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
semantics -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
knowledge -X- _ O
facts -X- _ O
and -X- _ O
question -X- _ O
phrases -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
considers -X- _ O
attention -X- _ O
scores -X- _ O
between -X- _ O
knowledge -X- _ O
facts -X- _ O
and -X- _ O
question -X- _ O
phrases -X- _ O
. -X- _ O
Joint -X- _ O
representation -X- _ O
is -X- _ O
obtained -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
attention -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
The -X- _ O
more -X- _ O
implementation -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
above -X- _ O
comparative -X- _ O
models -X- _ O
is -X- _ O
described -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O
The -X- _ O
knowledge -X- _ O
and -X- _ O
question -X- _ O
graph -X- _ O
are -X- _ O
encoded -X- _ O
separately -X- _ O
by -X- _ O
two -X- _ O
graph -X- _ B-MethodName
convolutional -X- _ I-MethodName
networks -X- _ I-MethodName
( -X- _ O
GCN -X- _ B-MethodName
) -X- _ O
( -X- _ O
Kipf -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Each -X- _ O
GCN -X- _ B-MethodName
model -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ B-HyperparameterValue
propagation -X- _ B-HyperparameterName
layers -X- _ I-HyperparameterName
and -X- _ O
a -X- _ B-HyperparameterValue
sum -X- _ B-HyperparameterName
pooling -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
across -X- _ O
the -X- _ O
nodes -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
. -X- _ O
The -X- _ O
operation -X- _ O
of -X- _ O
the -X- _ O
propagation -X- _ B-HyperparameterName
layer -X- _ I-HyperparameterName
is -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
f -X- _ O
( -X- _ O
H -X- _ O
( -X- _ O
l -X- _ O
) -X- _ O
, -X- _ O
A -X- _ O
) -X- _ O
= -X- _ O
σ(D -X- _ O
− -X- _ O
1 -X- _ O
2ÂD -X- _ O
− -X- _ O
1 -X- _ O
2 -X- _ O
H -X- _ O
( -X- _ O
l -X- _ O
) -X- _ O
W -X- _ O
( -X- _ O
l -X- _ O
) -X- _ O
) -X- _ O
wherê -X- _ O
A -X- _ O
= -X- _ O
A -X- _ O
+ -X- _ O
I -X- _ O
, -X- _ O
A -X- _ O
is -X- _ O
an -X- _ O
adjacency -X- _ O
matrix -X- _ O
of -X- _ O
the -X- _ O
graph -X- _ O
, -X- _ O
I -X- _ O
is -X- _ O
an -X- _ O
identity -X- _ O
matrix -X- _ O
, -X- _ O
D -X- _ O
is -X- _ O
a -X- _ O
degree -X- _ O
matrix -X- _ O
of -X- _ O
A -X- _ O
, -X- _ O
W -X- _ O
( -X- _ O
l -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
model -X- _ O
parameters -X- _ O
of -X- _ O
l -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
, -X- _ O
and -X- _ O
H -X- _ O
( -X- _ O
l -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
graph -X- _ O
in -X- _ O
the -X- _ O
l -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
. -X- _ O

When -X- _ O
hypergraph -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
based -X- _ I-HyperparameterValue
representations -X- _ B-HyperparameterName
are -X- _ O
used -X- _ O
for -X- _ O
both -X- _ O
knowledge -X- _ O
and -X- _ O
question -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
show -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
across -X- _ O
all -X- _ O
settings -X- _ O
over -X- _ O
question -X- _ O
types -X- _ O
( -X- _ O
ORG -X- _ O
and -X- _ O
PRP -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
graph -X- _ B-HyperparameterName
walk -X- _ I-HyperparameterName
( -X- _ O
1 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
hop -X- _ I-HyperparameterValue
, -X- _ O
2 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
hop -X- _ I-HyperparameterValue
, -X- _ O
and -X- _ O
3 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
hop -X- _ I-HyperparameterValue
) -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
the -X- _ O
mean -X- _ B-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
QA -X- _ B-TaskName
achieves -X- _ O
89.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
when -X- _ O
both -X- _ O
are -X- _ O
encoded -X- _ O
using -X- _ O
hyperedges -X- _ O
, -X- _ O
while -X- _ O
using -X- _ O
single -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
word -X- _ I-HyperparameterValue
- -X- _ I-HyperparameterValue
unit -X- _ I-HyperparameterValue
- -X- _ I-HyperparameterValue
based -X- _ I-HyperparameterValue
representation -X- _ B-HyperparameterName
causes -X- _ O
performance -X- _ O
to -X- _ O
drop -X- _ O
to -X- _ O
81.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
Especially -X- _ O
, -X- _ O
when -X- _ O
we -X- _ O
convert -X- _ O
the -X- _ O
one -X- _ O
of -X- _ O
both -X- _ O
hyperedge -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
level -X- _ I-HyperparameterValue
representation -X- _ B-HyperparameterName
to -X- _ O
single -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
word -X- _ I-HyperparameterValue
- -X- _ I-HyperparameterValue
unit -X- _ I-HyperparameterValue
- -X- _ I-HyperparameterValue
based -X- _ I-HyperparameterValue
representation -X- _ B-HyperparameterName
, -X- _ O
the -X- _ O
mean -X- _ B-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
QA -X- _ B-TaskName
is -X- _ O
82.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
88.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
respectively -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
validate -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
meaningful -X- _ O
to -X- _ O
consider -X- _ O
not -X- _ O
only -X- _ O
knowledge -X- _ O
but -X- _ O
also -X- _ O
question -X- _ O
as -X- _ O
hypergraphs -X- _ O
. -X- _ O
Effect -X- _ O
of -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
graph -X- _ O
walk -X- _ O
We -X- _ O
compare -X- _ O
the -X- _ O
performances -X- _ O
with -X- _ O
different -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
graph -X- _ I-HyperparameterName
walks -X- _ I-HyperparameterName
used -X- _ O
to -X- _ O
construct -X- _ O
a -X- _ O
knowledge -X- _ O
hypergraph -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
1 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
hop -X- _ I-HyperparameterValue
, -X- _ O
2 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
hop -X- _ I-HyperparameterValue
, -X- _ O
and -X- _ O
3 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
hop -X- _ I-HyperparameterValue
) -X- _ O
. -X- _ O
All -X- _ O
models -X- _ O
except -X- _ O
ours -X- _ O
show -X- _ O
slightly -X- _ O
lower -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
3 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
hop -X- _ I-HyperparameterValue
graph -X- _ O
than -X- _ O
on -X- _ O
the -X- _ O
2 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
hop -X- _ I-HyperparameterValue
graph -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
extracted -X- _ I-HyperparameterName
knowledge -X- _ I-HyperparameterName
facts -X- _ O
increases -X- _ O
when -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
graph -X- _ I-HyperparameterName
walk -X- _ I-HyperparameterName
increases -X- _ O
, -X- _ O
and -X- _ O
unnecessary -X- _ O
facts -X- _ O
for -X- _ O
answering -X- _ O
a -X- _ O
given -X- _ O
question -X- _ O
are -X- _ O
usually -X- _ O
included -X- _ O
. -X- _ O
Nonetheless -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
shows -X- _ O
robust -X- _ O
reasoning -X- _ O
performance -X- _ O
when -X- _ O
a -X- _ O
large -X- _ O
and -X- _ O
noisy -X- _ O
knowledge -X- _ O
facts -X- _ O
are -X- _ O
given -X- _ O
. -X- _ O
To -X- _ O
investigate -X- _ O
the -X- _ O
impacts -X- _ O
of -X- _ O
each -X- _ O
attention -X- _ O
block -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
GA -X- _ O
and -X- _ O
SA -X- _ O
) -X- _ O
, -X- _ O
ablation -X- _ O
studies -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3(e -X- _ O
- -X- _ O
g -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
scores -X- _ O
across -X- _ O
all -X- _ O
settings -X- _ O
drop -X- _ O
when -X- _ O
GA -X- _ O
or -X- _ O
SA -X- _ O
is -X- _ O
removed -X- _ O
. -X- _ O
Particularly -X- _ O
, -X- _ O
the -X- _ O
mean -X- _ B-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
QA -X- _ B-TaskName
is -X- _ O
decreased -X- _ O
by -X- _ O
6.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
( -X- _ O
89.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
→ -X- _ O
83.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
, -X- _ O
2.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
( -X- _ O
89.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
→ -X- _ O
87.1 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
for -X- _ O
cutting -X- _ O
out -X- _ O
the -X- _ O
GA -X- _ O
and -X- _ O
the -X- _ O
SA -X- _ O
block -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
identify -X- _ O
that -X- _ O
not -X- _ O
only -X- _ O
the -X- _ O
guided -X- _ O
- -X- _ O
attention -X- _ O
which -X- _ O
captures -X- _ O
inter -X- _ O
- -X- _ O
relationships -X- _ O
between -X- _ O
question -X- _ O
and -X- _ O
knowledge -X- _ O
but -X- _ O
also -X- _ O
the -X- _ O
selfattention -X- _ O
which -X- _ O
learns -X- _ O
intra -X- _ O
- -X- _ O
relationship -X- _ O
in -X- _ O
them -X- _ O
are -X- _ O
crucial -X- _ O
to -X- _ O
the -X- _ O
complex -X- _ B-TaskName
QA -X- _ I-TaskName
. -X- _ O
To -X- _ O
sum -X- _ O
up -X- _ O
, -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
takes -X- _ O
graph -X- _ O
- -X- _ O
level -X- _ O
inputs -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
hyperedge -X- _ O
, -X- _ O
and -X- _ O
conducts -X- _ O
semantic -X- _ O
matching -X- _ O
between -X- _ O
hyperedges -X- _ O
by -X- _ O
the -X- _ O
attention -X- _ O
mechanism -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
two -X- _ O
characteristics -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
shows -X- _ O
better -X- _ O
reasoning -X- _ O
performance -X- _ O
focusing -X- _ O
on -X- _ O
the -X- _ O
evidences -X- _ O
necessary -X- _ O
for -X- _ O
reasoning -X- _ O
under -X- _ O
weak -X- _ O
supervision -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
provides -X- _ O
the -X- _ O
qualitative -X- _ O
analysis -X- _ O
on -X- _ O
effectiveness -X- _ O
of -X- _ O
using -X- _ O
a -X- _ O
hypergraph -X- _ O
as -X- _ O
an -X- _ O
input -X- _ O
format -X- _ O
to -X- _ O
Transformer -X- _ O
architecture -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
the -X- _ O
attention -X- _ O
map -X- _ O
from -X- _ O
the -X- _ O
guided -X- _ O
- -X- _ O
attention -X- _ O
block -X- _ O
, -X- _ O
and -X- _ O
visualize -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
attended -X- _ O
knowledge -X- _ O
facts -X- _ O
or -X- _ O
entities -X- _ O
with -X- _ O
the -X- _ O
attention -X- _ O
scores -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
example -X- _ O
, -X- _ O
both -X- _ O
model -X- _ O
, -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
and -X- _ O
Transformer -X- _ B-MethodName
( -X- _ I-MethodName
SA+GA -X- _ I-MethodName
) -X- _ I-MethodName
, -X- _ O
infer -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
, -X- _ O
Q5075293 -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
responds -X- _ O
by -X- _ O
focusing -X- _ O
on -X- _ O
{ -X- _ O
second -X- _ O
⪯ -X- _ O
from -X- _ O
⪯ -X- _ O
left -X- _ O
} -X- _ O
phrase -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
four -X- _ O
facts -X- _ O
having -X- _ O
a -X- _ O
left -X- _ O
relation -X- _ O
among -X- _ O
86 -X- _ O
knowledge -X- _ O
hyperedges -X- _ O
. -X- _ O
In -X- _ O
comparison -X- _ O
, -X- _ O
Transformer -X- _ B-MethodName
( -X- _ I-MethodName
SA+GA -X- _ I-MethodName
) -X- _ I-MethodName
strongly -X- _ O
attends -X- _ O
to -X- _ O
the -X- _ O
knowledge -X- _ O
entities -X- _ O
which -X- _ O
appear -X- _ O
repetitive -X- _ O
in -X- _ O
the -X- _ O
knowledge -X- _ O
facts -X- _ O
. -X- _ O
Especially -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
attends -X- _ O
to -X- _ O
Q3476753 -X- _ O
, -X- _ O
Q290666 -X- _ O
and -X- _ O
Ireland -X- _ O
with -X- _ O
the -X- _ O
high -X- _ O
attention -X- _ O
score -X- _ O
0.237 -X- _ O
, -X- _ O
0.221 -X- _ O
, -X- _ O
and -X- _ O
0.202 -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
second -X- _ O
example -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
attends -X- _ O
to -X- _ O
the -X- _ O
correct -X- _ O
knowledge -X- _ O
hyperedges -X- _ O
considering -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
facts -X- _ O
about -X- _ O
place -X- _ O
of -X- _ O
birth -X- _ O
of -X- _ O
the -X- _ O
people -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
given -X- _ O
image -X- _ O
, -X- _ O
and -X- _ O
infers -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
Transformer -X- _ B-MethodName
( -X- _ I-MethodName
SA+GA -X- _ I-MethodName
) -X- _ I-MethodName
strongly -X- _ O
attends -X- _ O
to -X- _ O
the -X- _ O
knowledge -X- _ O
entity -X- _ O
of -X- _ O
person -X- _ O
( -X- _ O
Q2439789 -X- _ O
) -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
with -X- _ O
undesired -X- _ O
attention -X- _ O
score -X- _ O
0.788 -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
and -X- _ O
third -X- _ O
attended -X- _ O
knowledge -X- _ O
entities -X- _ O
are -X- _ O
the -X- _ O
other -X- _ O
person -X- _ O
( -X- _ O
Q7141361 -X- _ O
) -X- _ O
and -X- _ O
Iran -X- _ O
. -X- _ O
Transformer -X- _ B-MethodName
( -X- _ I-MethodName
SA+GA -X- _ I-MethodName
) -X- _ I-MethodName
fails -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
facts -X- _ O
required -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
and -X- _ O
predicts -X- _ O
the -X- _ O
answer -X- _ O
with -X- _ O
the -X- _ O
wrong -X- _ O
number -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
proposed -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
for -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
reasoning -X- _ O
over -X- _ O
knowledge -X- _ O
graph -X- _ O
under -X- _ O
weak -X- _ O
supervision -X- _ O
. -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
adopts -X- _ O
hypergraph -X- _ O
- -X- _ O
based -X- _ O
representation -X- _ O
to -X- _ O
encode -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
semantics -X- _ O
of -X- _ O
knowledge -X- _ O
and -X- _ O
questions -X- _ O
and -X- _ O
considers -X- _ O
associations -X- _ O
between -X- _ O
a -X- _ O
knowledge -X- _ O
hypergraph -X- _ O
and -X- _ O
a -X- _ O
question -X- _ O
hypergraph -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
each -X- _ O
node -X- _ O
representation -X- _ O
in -X- _ O
the -X- _ O
hypergraphs -X- _ O
is -X- _ O
updated -X- _ O
by -X- _ O
inter -X- _ O
- -X- _ O
and -X- _ O
intra -X- _ O
- -X- _ O
attention -X- _ O
mechanisms -X- _ O
in -X- _ O
two -X- _ O
hypergraphs -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
by -X- _ O
iterative -X- _ O
message -X- _ O
passing -X- _ O
scheme -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
can -X- _ O
mitigate -X- _ O
the -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
over -X- _ O
- -X- _ O
smoothing -X- _ O
problem -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
graph -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
exploiting -X- _ O
the -X- _ O
message -X- _ O
passing -X- _ O
scheme -X- _ O
. -X- _ O
Extensive -X- _ O
experiments -X- _ O
on -X- _ O
various -X- _ O
datasets -X- _ O
, -X- _ O
KVQA -X- _ B-DatasetName
, -X- _ O
FVQA -X- _ B-DatasetName
, -X- _ O
PQ -X- _ B-DatasetName
, -X- _ O
and -X- _ O
PQL -X- _ B-DatasetName
validated -X- _ O
that -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
conducts -X- _ O
accurate -X- _ O
inference -X- _ O
by -X- _ O
focusing -X- _ O
on -X- _ O
knowledge -X- _ O
evidences -X- _ O
necessary -X- _ O
for -X- _ O
question -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
knowledge -X- _ O
graph -X- _ O
. -X- _ O
Although -X- _ O
not -X- _ O
covered -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
an -X- _ O
interesting -X- _ O
future -X- _ O
work -X- _ O
is -X- _ O
to -X- _ O
construct -X- _ O
heterogeneous -X- _ O
knowledge -X- _ O
graph -X- _ O
that -X- _ O
includes -X- _ O
more -X- _ O
diverse -X- _ O
knowledge -X- _ O
sources -X- _ O
( -X- _ O
e.g. -X- _ O
documents -X- _ O
on -X- _ O
web -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
b -X- _ O
- -X- _ O
e -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
shows -X- _ O
comparable -X- _ O
performances -X- _ O
on -X- _ O
PQ-{2H -X- _ B-DatasetName
, -X- _ I-DatasetName
3H -X- _ I-DatasetName
, -X- _ I-DatasetName
M -X- _ I-DatasetName
} -X- _ I-DatasetName
to -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
weaklysupervised -X- _ O
model -X- _ O
, -X- _ O
SRN -X- _ O
. -X- _ O
Especially -X- _ O
, -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
shows -X- _ O
significant -X- _ O
performance -X- _ O
improvement -X- _ O
( -X- _ O
78.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
→ -X- _ O
90.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
for -X- _ O
PQL-2H -X- _ B-DatasetName
, -X- _ O
78.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
→ -X- _ O
94.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
for -X- _ O
PQL -X- _ B-DatasetName
- -X- _ I-DatasetName
M -X- _ I-DatasetName
) -X- _ O
on -X- _ O
PQL -X- _ B-DatasetName
. -X- _ O
We -X- _ O
highlight -X- _ O
that -X- _ O
PQL -X- _ B-DatasetName
is -X- _ O
more -X- _ O
challenging -X- _ O
dataset -X- _ O
than -X- _ O
PQ -X- _ B-DatasetName
in -X- _ O
that -X- _ O
PQL -X- _ B-DatasetName
not -X- _ O
only -X- _ O
covers -X- _ O
more -X- _ O
knowledge -X- _ O
facts -X- _ O
but -X- _ O
also -X- _ O
has -X- _ O
fewer -X- _ O
QA -X- _ O
instances -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
PQL-3H -X- _ B-DatasetName
is -X- _ O
relatively -X- _ O
lower -X- _ O
than -X- _ O
the -X- _ O
other -X- _ O
splits -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
insufficient -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
QA -X- _ O
pairs -X- _ O
in -X- _ O
PQL-3H. -X- _ B-DatasetName
When -X- _ O
we -X- _ O
use -X- _ O
PQL-3H -X- _ B-DatasetName
- -X- _ I-DatasetName
More -X- _ I-DatasetName
which -X- _ O
has -X- _ O
twice -X- _ O
more -X- _ O
QA -X- _ O
pairs -X- _ O
( -X- _ O
1031 -X- _ O
→ -X- _ O
2062 -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
knowledge -X- _ O
base -X- _ O
as -X- _ O
PQL-3H -X- _ B-DatasetName
, -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
95.4 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
. -X- _ O
We -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
each -X- _ O
module -X- _ O
in -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
. -X- _ O
To -X- _ O
analyze -X- _ O
the -X- _ O
performances -X- _ O
of -X- _ O
the -X- _ O
variants -X- _ O
in -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
KVQA -X- _ B-DatasetName
which -X- _ O
is -X- _ O
a -X- _ O
representative -X- _ O
and -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
dataset -X- _ O
for -X- _ O
knowledge -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
VQA -X- _ I-TaskName
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
mainly -X- _ O
focus -X- _ O
on -X- _ O
two -X- _ O
aspects -X- _ O
: -X- _ O
i -X- _ O
) -X- _ O
effect -X- _ O
of -X- _ O
hypergraph -X- _ O
and -X- _ O
ii -X- _ O
) -X- _ O
effect -X- _ O
of -X- _ O
attention -X- _ O
mechanism -X- _ O
. -X- _ O
To -X- _ O
evaluate -X- _ O
a -X- _ O
pure -X- _ O
reasoning -X- _ O
ability -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
in -X- _ O
the -X- _ O
oracle -X- _ O
setting -X- _ O
. -X- _ O
To -X- _ O
analyze -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
hypergraph -X- _ O
- -X- _ O
based -X- _ O
input -X- _ O
representation -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
comparative -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
input -X- _ O
formats -X- _ O
for -X- _ O
Transformer -X- _ O
architecture -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
input -X- _ B-HyperparameterName
format -X- _ I-HyperparameterName
, -X- _ O
which -X- _ O
are -X- _ O
single -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
wordunit -X- _ I-HyperparameterValue
and -X- _ O
hyperedge -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
based -X- _ I-HyperparameterValue
representations -X- _ B-HyperparameterName
. -X- _ O
Compared -X- _ O
to -X- _ O
hyperedge -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
based -X- _ I-HyperparameterValue
inputs -X- _ O
considering -X- _ O
multiple -X- _ O
relational -X- _ O
facts -X- _ O
as -X- _ O
a -X- _ O
input -X- _ O
token -X- _ O
, -X- _ O
single -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
wordunit -X- _ I-HyperparameterValue
takes -X- _ O
every -X- _ O
entity -X- _ O
and -X- _ O
relation -X- _ O
tokens -X- _ O
as -X- _ O
separate -X- _ O
input -X- _ O
tokens -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
using -X- _ O
single -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
wordunit -X- _ I-HyperparameterValue
- -X- _ I-HyperparameterValue
based -X- _ I-HyperparameterValue
input -X- _ O
format -X- _ O
for -X- _ O
both -X- _ O
knowledge -X- _ O
and -X- _ O
question -X- _ O
is -X- _ O
the -X- _ O
standard -X- _ O
settings -X- _ O
for -X- _ O
the -X- _ O
Transformer -X- _ O
network -X- _ O
and -X- _ O
using -X- _ O
hyperedge -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
based -X- _ I-HyperparameterValue
input -X- _ O
format -X- _ O
for -X- _ O
both -X- _ O
is -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
, -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
( -X- _ I-MethodName
SA+GA -X- _ I-MethodName
) -X- _ I-MethodName
as -X- _ O
a -X- _ O
backbone -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
present -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O

The -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
diverse -X- _ O
split -X- _ B-HyperparameterName
of -X- _ O
PQ -X- _ B-DatasetName
and -X- _ O
PQL -X- _ B-DatasetName
datasets -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
section -X- _ O
in -X- _ O
the -X- _ O
table -X- _ O
includes -X- _ O
fully -X- _ O
- -X- _ O
supervised -X- _ O
models -X- _ O
which -X- _ O
require -X- _ O
a -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
path -X- _ O
annotation -X- _ O
as -X- _ O
an -X- _ O
additional -X- _ O
supervision -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
section -X- _ O
contains -X- _ O
weakly -X- _ O
- -X- _ O
supervised -X- _ O
models -X- _ O
learning -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
reasoning -X- _ O
paths -X- _ O
without -X- _ O
the -X- _ O
groundtruth -X- _ O
path -X- _ O
annotation -X- _ O
. -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
is -X- _ O
involved -X- _ O
in -X- _ O
the -X- _ O
weakly -X- _ O
- -X- _ O
supervised -X- _ O
models -X- _ O
because -X- _ O
it -X- _ O
only -X- _ O
exploits -X- _ O
an -X- _ O
answer -X- _ O
as -X- _ O
a -X- _ O
supervision -X- _ O
. -X- _ O

We -X- _ O
confirm -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
works -X- _ O
effectively -X- _ O
as -X- _ O
a -X- _ O
general -X- _ O
reasoning -X- _ O
framework -X- _ O
without -X- _ O
considering -X- _ O
characteristics -X- _ O
of -X- _ O
different -X- _ O
knowledge -X- _ O
sources -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
Wikidata -X- _ B-DatasetName
for -X- _ O
KVQA -X- _ B-TaskName
, -X- _ O
DBpedia -X- _ B-DatasetName
, -X- _ O
ConceptNet -X- _ B-DatasetName
, -X- _ O
WebChild -X- _ B-DatasetName
for -X- _ O
FVQA).To -X- _ B-TaskName
required -X- _ O
to -X- _ O
answer -X- _ O
a -X- _ O
given -X- _ O
question -X- _ O
is -X- _ O
unknown -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
we -X- _ O
assume -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
entity -X- _ O
linking -X- _ O
is -X- _ O
perfect -X- _ O
, -X- _ O
and -X- _ O
evaluate -X- _ O
the -X- _ O
pure -X- _ O
reasoning -X- _ O
ability -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
of -X- _ O
Appendix -X- _ O
D -X- _ O
, -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
shows -X- _ O
comparable -X- _ O
performance -X- _ O
in -X- _ O
both -X- _ O
top-1 -X- _ O
and -X- _ O
top-3 -X- _ O
accuracy -X- _ B-MetricName
in -X- _ O
comparison -X- _ O
with -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
methods -X- _ O
. -X- _ O

Entity -X- _ O
linking -X- _ O
setting -X- _ O
We -X- _ O
also -X- _ O
present -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
entity -X- _ O
linking -X- _ O
setting -X- _ O
where -X- _ O
the -X- _ O
named -X- _ O
entities -X- _ O
are -X- _ O
not -X- _ O
provided -X- _ O
as -X- _ O
the -X- _ O
oracle -X- _ O
setting -X- _ O
, -X- _ O
but -X- _ O
detected -X- _ O
by -X- _ O
the -X- _ O
module -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
3.2 -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
of -X- _ O
Appendix -X- _ O
E -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
shows -X- _ O
the -X- _ O
best -X- _ O
performances -X- _ O
for -X- _ O
both -X- _ O
original -X- _ O
and -X- _ O
paraphrased -X- _ O
questions -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
comparative -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
knowledge -X- _ O
hypergraph -X- _ O
extracted -X- _ O
by -X- _ O
the -X- _ O
3 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
hop -X- _ I-HyperparameterValue
graph -X- _ B-HyperparameterName
walk -X- _ I-HyperparameterName
. -X- _ O
In -X- _ O
entity -X- _ O
linking -X- _ O
setting -X- _ O
, -X- _ O
the -X- _ O
constructed -X- _ O
knowledge -X- _ O
hypergraph -X- _ O
can -X- _ O
be -X- _ O
incomplete -X- _ O
and -X- _ O
quite -X- _ O
noisy -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
undetected -X- _ O
entities -X- _ O
or -X- _ O
misclassified -X- _ O
entity -X- _ O
labels -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
shows -X- _ O
robust -X- _ O
reasoning -X- _ O
capacity -X- _ O
over -X- _ O
the -X- _ O
noisy -X- _ O
inputs -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
remark -X- _ O
that -X- _ O
the -X- _ O
upper -X- _ O
bound -X- _ O
of -X- _ O
QA -X- _ B-TaskName
performance -X- _ O
is -X- _ O
72.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
due -X- _ O
to -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
of -X- _ O
entity -X- _ O
linking -X- _ O
module -X- _ O
. -X- _ O
We -X- _ O
expect -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
will -X- _ O
be -X- _ O
improved -X- _ O
when -X- _ O
the -X- _ O
entity -X- _ O
linking -X- _ O
module -X- _ O
is -X- _ O
enhanced -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
Fact -X- _ B-DatasetName
- -X- _ I-DatasetName
based -X- _ I-DatasetName
Visual -X- _ I-DatasetName
Question -X- _ I-DatasetName
Answering -X- _ I-DatasetName
( -X- _ O
FVQA -X- _ B-DatasetName
) -X- _ O
as -X- _ O
an -X- _ O
additional -X- _ O
benchmark -X- _ O
dataset -X- _ O
for -X- _ O
knowledge -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
VQA -X- _ I-TaskName
. -X- _ O
Different -X- _ O
from -X- _ O
KVQA -X- _ B-DatasetName
focusing -X- _ O
on -X- _ O
world -X- _ O
knowledge -X- _ O
for -X- _ O
named -X- _ O
entities -X- _ O
, -X- _ O
FVQA -X- _ B-DatasetName
considers -X- _ O
commonsense -X- _ O
knowledge -X- _ O
about -X- _ O
common -X- _ O
nouns -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
image -X- _ O
. -X- _ O

5 -X- _ O
Quantitative -X- _ O
ResultsWe -X- _ O
all -X- _ O
settings -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
attention -X- _ O
mechanism -X- _ O
between -X- _ O
question -X- _ O
and -X- _ O
knowledge -X- _ O
is -X- _ O
crucial -X- _ O
for -X- _ O
complex -X- _ O
QA -X- _ B-TaskName
. -X- _ O
Since -X- _ O
GCN -X- _ B-MethodName
( -X- _ O
Kipf -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
GGNN -X- _ B-MethodName
encode -X- _ O
question -X- _ O
and -X- _ O
knowledge -X- _ O
graph -X- _ O
separately -X- _ O
, -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
learn -X- _ O
interactions -X- _ O
between -X- _ O
question -X- _ O
and -X- _ O
knowledge -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
GCN -X- _ B-MethodName
and -X- _ O
GGNN -X- _ B-MethodName
show -X- _ O
quite -X- _ O
low -X- _ O
performance -X- _ O
under -X- _ O
74 -X- _ B-MetricValue
% -X- _ I-MetricValue
mean -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
MemNN -X- _ B-MethodName
† -X- _ I-MethodName
, -X- _ O
HAN -X- _ B-MethodName
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
BAN -X- _ B-MethodName
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
achieve -X- _ O
comparatively -X- _ O
high -X- _ O
performance -X- _ O
because -X- _ O
MemNN -X- _ B-MethodName
† -X- _ I-MethodName
adopts -X- _ O
question -X- _ O
- -X- _ O
guided -X- _ O
soft -X- _ O
attention -X- _ O
over -X- _ O
knowledge -X- _ O
memories -X- _ O
. -X- _ O
HAN -X- _ B-MethodName
and -X- _ O
BAN -X- _ B-MethodName
utilize -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
co -X- _ O
- -X- _ O
attention -X- _ O
between -X- _ O
question -X- _ O
and -X- _ O
knowledge -X- _ O
. -X- _ O

For -X- _ O
entity -X- _ O
linking -X- _ O
for -X- _ O
KVQA -X- _ B-DatasetName
, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
wellknown -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
for -X- _ O
face -X- _ O
identification -X- _ O
: -X- _ O
RetinaFace -X- _ B-MethodName
( -X- _ O
Deng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
face -X- _ B-TaskName
detection -X- _ I-TaskName
and -X- _ O
ArcFace -X- _ B-MethodName
( -X- _ O
Deng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
for -X- _ O
face -X- _ B-TaskName
feature -X- _ I-TaskName
extraction -X- _ I-TaskName
. -X- _ O
For -X- _ O
all -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
experimental -X- _ O
settings -X- _ O
as -X- _ O
in -X- _ O
previous -X- _ O
works -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
similarity -X- _ O
- -X- _ O
based -X- _ O
answer -X- _ O
predictor -X- _ O
for -X- _ O
KVQA -X- _ B-DatasetName
, -X- _ O
and -X- _ O
MLP -X- _ O
for -X- _ O
the -X- _ O
others -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
Adam -X- _ B-HyperparameterValue
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
to -X- _ O
optimize -X- _ O
all -X- _ O
learnable -X- _ O
parameters -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
describe -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
experimental -X- _ O
settings -X- _ O
and -X- _ O
the -X- _ O
tuned -X- _ O
hyperparameters -X- _ O
for -X- _ O
each -X- _ O
dataset -X- _ O
in -X- _ O
Appendix -X- _ O
D. -X- _ O

The -X- _ O
most -X- _ O
similar -X- _ O
answer -X- _ O
to -X- _ O
the -X- _ O
joint -X- _ O
representation -X- _ O
is -X- _ O
selected -X- _ O
as -X- _ O
an -X- _ O
answer -X- _ O
among -X- _ O
the -X- _ O
answer -X- _ O
candidates -X- _ O
. -X- _ O
For -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
only -X- _ O
supervision -X- _ O
from -X- _ O
QA -X- _ O
pairs -X- _ O
without -X- _ O
annotations -X- _ O
for -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
reasoning -X- _ O
paths -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
cross -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
entropy -X- _ I-HyperparameterValue
between -X- _ O
prediction -X- _ O
p -X- _ O
and -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
t -X- _ O
is -X- _ O
utilized -X- _ O
as -X- _ O
a -X- _ O
loss -X- _ B-HyperparameterName
function -X- _ I-HyperparameterName
. -X- _ O
( -X- _ O
Auer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
, -X- _ O
ConceptNet -X- _ B-DatasetName
( -X- _ O
Liu -X- _ O
and -X- _ O
Singh -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
WebChild -X- _ B-DatasetName
( -X- _ O
Tandon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
last -X- _ O
two -X- _ O
datasets -X- _ O
, -X- _ O
PQ -X- _ B-DatasetName
and -X- _ O
PQL -X- _ B-DatasetName
, -X- _ O
focus -X- _ O
on -X- _ O
evaluating -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
reasoning -X- _ O
ability -X- _ O
in -X- _ O
the -X- _ O
knowledgebased -X- _ B-TaskName
textual -X- _ I-TaskName
QA -X- _ I-TaskName
task -X- _ I-TaskName
. -X- _ O
PQ -X- _ B-DatasetName
and -X- _ O
PQL -X- _ B-DatasetName
contain -X- _ O
7,106 -X- _ O
and -X- _ O
2,625 -X- _ O
QA -X- _ O
pairs -X- _ O
on -X- _ O
4,050 -X- _ O
and -X- _ O
9,844 -X- _ O
knowledge -X- _ O
facts -X- _ O
from -X- _ O
the -X- _ O
subset -X- _ O
of -X- _ O
Freebase -X- _ B-DatasetName
( -X- _ O
Bollacker -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
detailed -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Appendix -X- _ O
A.Each -X- _ O
node -X- _ O
in -X- _ O
the -X- _ O
knowledge -X- _ O
hypergraph -X- _ O
and -X- _ O
the -X- _ O
question -X- _ O
hypergraph -X- _ O
is -X- _ O
represented -X- _ O
as -X- _ O
a -X- _ O
300dimensional -X- _ B-HyperparameterValue
vector -X- _ B-HyperparameterName
( -X- _ O
i.e. -X- _ O
, -X- _ O
w -X- _ B-HyperparameterName
= -X- _ O
300 -X- _ B-HyperparameterValue
) -X- _ O
initialized -X- _ O
using -X- _ O
GloVe -X- _ B-MethodName
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
Random -X- _ O
initialization -X- _ O
is -X- _ O
applied -X- _ O
when -X- _ O
a -X- _ O
word -X- _ O
for -X- _ O
a -X- _ O
node -X- _ O
does -X- _ O
not -X- _ O
exist -X- _ O
in -X- _ O
the -X- _ O
vocabulary -X- _ O
of -X- _ O
GloVe -X- _ B-MethodName
. -X- _ O
Mean -X- _ O
pooling -X- _ O
is -X- _ O
applied -X- _ O
when -X- _ O
a -X- _ O
node -X- _ O
consists -X- _ O
of -X- _ O
multiple -X- _ O
words -X- _ O
. -X- _ O

Following -X- _ O
the -X- _ O
standard -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
transformer -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
up -X- _ O
guided -X- _ O
- -X- _ O
attention -X- _ O
block -X- _ O
and -X- _ O
selfattention -X- _ O
block -X- _ O
where -X- _ O
each -X- _ O
block -X- _ O
consists -X- _ O
of -X- _ O
each -X- _ O
attention -X- _ O
operation -X- _ O
with -X- _ O
layer -X- _ O
normalization -X- _ O
, -X- _ O
residual -X- _ O
connection -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
single -X- _ B-HyperparameterValue
feed -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
forward -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
. -X- _ O
By -X- _ O
passing -X- _ O
the -X- _ O
guided -X- _ O
- -X- _ O
attention -X- _ O
blocks -X- _ O
and -X- _ O
selfattention -X- _ O
blocks -X- _ O
sequentially -X- _ O
, -X- _ O
representations -X- _ O
of -X- _ O
knowledge -X- _ O
hyperedges -X- _ O
and -X- _ O
question -X- _ O
hyperedges -X- _ O
are -X- _ O
updated -X- _ O
and -X- _ O
finally -X- _ O
aggregated -X- _ O
to -X- _ O
single -X- _ O
vector -X- _ O
representation -X- _ O
as -X- _ O
z -X- _ O
k -X- _ O
∈ -X- _ O
R -X- _ O
dv -X- _ B-HyperparameterName
and -X- _ O
z -X- _ O
q -X- _ O
∈ -X- _ O
R -X- _ O
dv -X- _ B-HyperparameterName
, -X- _ O
respectively -X- _ O
. -X- _ O
To -X- _ O
predict -X- _ O
an -X- _ O
answer -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
concatenate -X- _ O
the -X- _ O
representation -X- _ O
z -X- _ O
k -X- _ O
and -X- _ O
z -X- _ O
q -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
attention -X- _ O
blocks -X- _ O
and -X- _ O
feed -X- _ O
into -X- _ O
a -X- _ O
single -X- _ B-HyperparameterValue
feed -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
forward -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
( -X- _ O
i.e. -X- _ O
, -X- _ O
R -X- _ O
2dv -X- _ O
→ -X- _ O
R -X- _ O
w -X- _ O
) -X- _ O
to -X- _ O
make -X- _ O
a -X- _ O
joint -X- _ O
representation -X- _ O
z. -X- _ O
We -X- _ O
then -X- _ O
consider -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
answer -X- _ O
predictor -X- _ O
: -X- _ O
multi -X- _ O
- -X- _ O
layer -X- _ O
perceptron -X- _ O
and -X- _ O
similarity -X- _ O
- -X- _ O
based -X- _ O
answer -X- _ O
predictor -X- _ O
. -X- _ O
Multi -X- _ O
- -X- _ O
layer -X- _ O
perceptron -X- _ O
as -X- _ O
an -X- _ O
answer -X- _ O
classifier -X- _ O
p -X- _ O
= -X- _ O
ψ(z -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
prevalent -X- _ O
for -X- _ O
visual -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
problems -X- _ O
. -X- _ O
For -X- _ O
similarity -X- _ O
- -X- _ O
based -X- _ O
answer -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
a -X- _ O
dot -X- _ O
product -X- _ O
similarity -X- _ O
p -X- _ O
= -X- _ O
zC -X- _ O
T -X- _ O
between -X- _ O
z -X- _ O
and -X- _ O
answer -X- _ O
candidate -X- _ O
set -X- _ O
C -X- _ O
∈ -X- _ O
R -X- _ O
|A|×w -X- _ O
where -X- _ O
|A| -X- _ O
is -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
candidate -X- _ O
answers -X- _ O
and -X- _ O
w -X- _ O
is -X- _ O
a -X- _ O
dimension -X- _ O
of -X- _ O
representation -X- _ O
for -X- _ O
each -X- _ O
answer -X- _ O
. -X- _ O

Attention(Q -X- _ O
k -X- _ O
, -X- _ O
K -X- _ O
k -X- _ O
, -X- _ O
V -X- _ O
k -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
question -X- _ O
hyperedges -X- _ O
E -X- _ O
q -X- _ O
, -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
is -X- _ O
performed -X- _ O
in -X- _ O
a -X- _ O
similar -X- _ O
manner -X- _ O
: -X- _ O
Attention(Q -X- _ O
q -X- _ O
, -X- _ O
K -X- _ O
q -X- _ O
, -X- _ O
V -X- _ O
q -X- _ O
) -X- _ O
. -X- _ O

Self -X- _ O
- -X- _ O
attention -X- _ O
The -X- _ O
only -X- _ O
difference -X- _ O
between -X- _ O
guided -X- _ O
- -X- _ O
attention -X- _ O
and -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
same -X- _ O
input -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
both -X- _ O
query -X- _ O
and -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
within -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
query -X- _ O
, -X- _ O
key -X- _ O
, -X- _ O
and -X- _ O
value -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
knowledge -X- _ O
hyperedges -X- _ O
E -X- _ O
k -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
for -X- _ O
knowledge -X- _ O
hyperedges -X- _ O
is -X- _ O
conducted -X- _ O
by -X- _ O

Attention(Q -X- _ O
q -X- _ O
, -X- _ O
K -X- _ O
k -X- _ O
, -X- _ O
V -X- _ O
k -X- _ O
) -X- _ O
. -X- _ O

where -X- _ O
d -X- _ B-HyperparameterName
v -X- _ I-HyperparameterName
is -X- _ O
the -X- _ O
dimension -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
query -X- _ I-HyperparameterName
and -X- _ O
the -X- _ O
key -X- _ O
vector -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
the -X- _ O
guided -X- _ O
- -X- _ O
attention -X- _ O
which -X- _ O
uses -X- _ O
the -X- _ O
question -X- _ O
hyperedges -X- _ O
as -X- _ O
query -X- _ O
and -X- _ O
the -X- _ O
knowledge -X- _ O
hyperedges -X- _ O
as -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
pairs -X- _ O
is -X- _ O
performed -X- _ O
in -X- _ O
a -X- _ O
similar -X- _ O
manner -X- _ O
: -X- _ O

as -X- _ O
Attention(Q -X- _ O
k -X- _ O
, -X- _ O
K -X- _ O
q -X- _ O
, -X- _ O
V -X- _ O
q -X- _ O
) -X- _ O
= -X- _ O
softmax -X- _ B-HyperparameterValue
( -X- _ O
Q -X- _ O
k -X- _ O
K -X- _ O
T -X- _ O
q -X- _ O
√ -X- _ O
dv -X- _ O
) -X- _ O
V -X- _ O
q -X- _ O

where -X- _ O
all -X- _ O
projection -X- _ O
matrices -X- _ O
W -X- _ O
[ -X- _ O
• -X- _ O
] -X- _ O
∈ -X- _ O
R -X- _ O
d×dv -X- _ O
are -X- _ O
learnable -X- _ O
parameters -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
scaled -X- _ O
dot -X- _ O
product -X- _ O
at -X- _ O
- -X- _ O
tention -X- _ O
using -X- _ O
the -X- _ O
query -X- _ O
, -X- _ O
key -X- _ O
, -X- _ O
and -X- _ O
value -X- _ O
is -X- _ O
calculated -X- _ O

Q -X- _ O
k -X- _ O
= -X- _ O
E -X- _ O
k -X- _ O
W -X- _ O
Q -X- _ O
k -X- _ O
, -X- _ O
a -X- _ O
key -X- _ O
K -X- _ O
q -X- _ O
= -X- _ O
E -X- _ O
q -X- _ O
W -X- _ O
Kq -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
value -X- _ O
V -X- _ O
q -X- _ O
= -X- _ O
E -X- _ O
q -X- _ O
W -X- _ O
Vq -X- _ O
, -X- _ O

e -X- _ O
k -X- _ O
= -X- _ O
ϕ -X- _ O
k -X- _ O
• -X- _ O
f -X- _ O
k -X- _ O
( -X- _ O
h -X- _ O
k -X- _ O
) -X- _ O
∈ -X- _ O
R -X- _ O
d -X- _ O
, -X- _ O
e -X- _ O
q -X- _ O
= -X- _ O
ϕ -X- _ O
q -X- _ O
• -X- _ O
f -X- _ O
q -X- _ O
( -X- _ O
h -X- _ O
q -X- _ O
) -X- _ O
∈ -X- _ O
R -X- _ O
d -X- _ O
where -X- _ O
h -X- _ O
[ -X- _ O
• -X- _ O
] -X- _ O
is -X- _ O
a -X- _ O
hyperedge -X- _ O
in -X- _ O
E -X- _ O
[ -X- _ O
• -X- _ O
] -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
f -X- _ O
[ -X- _ O
• -X- _ O
] -X- _ O

Guided -X- _ O
- -X- _ O
attention -X- _ O
To -X- _ O
learn -X- _ O
inter -X- _ O
- -X- _ O
association -X- _ O
between -X- _ O
two -X- _ O
hypergraphs -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
embed -X- _ O
a -X- _ O
knowledge -X- _ O
hyperedge -X- _ O
and -X- _ O
a -X- _ O
question -X- _ O
hyperedge -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
We -X- _ O
define -X- _ O
the -X- _ O
knowledge -X- _ O
hyperedges -X- _ O
E -X- _ O
k -X- _ O
and -X- _ O
the -X- _ O
question -X- _ O
hyperedges -X- _ O
E -X- _ O
q -X- _ O
as -X- _ O
a -X- _ O
query -X- _ O
and -X- _ O
key -X- _ O
- -X- _ O
value -X- _ O
pairs -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
a -X- _ O
query -X- _ O

Question -X- _ O
hypergraph -X- _ O
We -X- _ O
transform -X- _ O
a -X- _ O
question -X- _ O
sentence -X- _ O
into -X- _ O
a -X- _ O
question -X- _ O
hypergraph -X- _ O
H -X- _ O
q -X- _ O
consisting -X- _ O
of -X- _ O
a -X- _ O
node -X- _ O
set -X- _ O
V -X- _ O
q -X- _ O
and -X- _ O
a -X- _ O
hyperedge -X- _ O
set -X- _ O
E -X- _ O
q -X- _ O
. -X- _ O
We -X- _ O
assume -X- _ O
that -X- _ O
each -X- _ O
word -X- _ O
unit -X- _ O
( -X- _ O
a -X- _ O
word -X- _ O
or -X- _ O
named -X- _ O
entity -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
a -X- _ O
node -X- _ O
, -X- _ O
and -X- _ O
has -X- _ O
edges -X- _ O
to -X- _ O
adjacent -X- _ O
nodes -X- _ O
. -X- _ O
For -X- _ O
question -X- _ O
hypergraph -X- _ O
, -X- _ O
each -X- _ O
word -X- _ O
unit -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
start -X- _ O
node -X- _ O
of -X- _ O
a -X- _ O
graph -X- _ O
walk -X- _ O
. -X- _ O
The -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
graph -X- _ O
walk -X- _ O
is -X- _ O
conducted -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
manner -X- _ O
as -X- _ O
the -X- _ O
knowledge -X- _ O
hypergraph -X- _ O
. -X- _ O
A -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
phrase -X- _ O
is -X- _ O
considered -X- _ O
as -X- _ O
a -X- _ O
hyperedge -X- _ O
in -X- _ O
the -X- _ O
question -X- _ O
hypergraph -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
2(b)).To -X- _ O
consider -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
associations -X- _ O
between -X- _ O
knowledge -X- _ O
and -X- _ O
question -X- _ O
, -X- _ O
we -X- _ O
devise -X- _ O
structural -X- _ O
semantic -X- _ O
matching -X- _ O
between -X- _ O
the -X- _ O
query -X- _ O
- -X- _ O
aware -X- _ O
knowledge -X- _ O
hypergraph -X- _ O
and -X- _ O
the -X- _ O
question -X- _ O
hypergraph -X- _ O
. -X- _ O
We -X- _ O
introduce -X- _ O
an -X- _ O
attention -X- _ O
mechanism -X- _ O
over -X- _ O
two -X- _ O
hypergraphs -X- _ O
based -X- _ O
on -X- _ O
guided -X- _ O
- -X- _ O
attention -X- _ O
( -X- _ O
Tsai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2(c -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
guided -X- _ O
- -X- _ O
attention -X- _ O
blocks -X- _ O
are -X- _ O
introduced -X- _ O
to -X- _ O
learn -X- _ O
correlations -X- _ O
between -X- _ O
knowledge -X- _ O
hyperedges -X- _ O
and -X- _ O
question -X- _ O
hyperedges -X- _ O
by -X- _ O
interattention -X- _ O
mechanism -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
intra -X- _ O
- -X- _ O
relationships -X- _ O
of -X- _ O
in -X- _ O
knowledge -X- _ O
or -X- _ O
question -X- _ O
hyperedges -X- _ O
are -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
blocks -X- _ O
. -X- _ O
The -X- _ O
details -X- _ O
of -X- _ O
two -X- _ O
modules -X- _ O
, -X- _ O
guided -X- _ O
- -X- _ O
attention -X- _ O
blocks -X- _ O
and -X- _ O
selfattention -X- _ O
blocks -X- _ O
, -X- _ O
are -X- _ O
described -X- _ O
as -X- _ O
below -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
we -X- _ O
use -X- _ O
Q -X- _ O
, -X- _ O
K -X- _ O
, -X- _ O
and -X- _ O
V -X- _ O
for -X- _ O
query -X- _ O
, -X- _ O
key -X- _ O
, -X- _ O
value -X- _ O
, -X- _ O
and -X- _ O
q -X- _ O
, -X- _ O
k -X- _ O
as -X- _ O
subscripts -X- _ O
to -X- _ O
represent -X- _ O
question -X- _ O
and -X- _ O
knowledge -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
a -X- _ O
huge -X- _ O
number -X- _ O
of -X- _ O
knowledge -X- _ O
facts -X- _ O
in -X- _ O
the -X- _ O
KB -X- _ O
as -X- _ O
a -X- _ O
huge -X- _ O
knowledge -X- _ O
graph -X- _ O
, -X- _ O
and -X- _ O
construct -X- _ O
a -X- _ O
hypergraph -X- _ O
by -X- _ O
traversing -X- _ O
the -X- _ O
knowledge -X- _ O
graph -X- _ O
. -X- _ O
Such -X- _ O
traversal -X- _ O
, -X- _ O
called -X- _ O
graph -X- _ O
walk -X- _ O
, -X- _ O
starts -X- _ O
from -X- _ O
the -X- _ O
node -X- _ O
linked -X- _ O
from -X- _ O
the -X- _ O
previous -X- _ O
module -X- _ O
( -X- _ O
see -X- _ O
section -X- _ O
3.2 -X- _ O
) -X- _ O
and -X- _ O
considers -X- _ O
all -X- _ O
entity -X- _ O
nodes -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
start -X- _ O
node -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
a -X- _ O
triplet -X- _ O
as -X- _ O
a -X- _ O
basic -X- _ O
unit -X- _ O
of -X- _ O
graph -X- _ O
walk -X- _ O
to -X- _ O
preserve -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
semantics -X- _ O
inherent -X- _ O
in -X- _ O
knowledge -X- _ O
graph -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
every -X- _ O
single -X- _ O
graph -X- _ O
walk -X- _ O
contains -X- _ O
three -X- _ B-HyperparameterValue
nodes -X- _ B-HyperparameterName
{ -X- _ B-HyperparameterValue
head -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
predicate -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
tail -X- _ I-HyperparameterValue
} -X- _ I-HyperparameterValue
, -X- _ O
rather -X- _ O
than -X- _ O
having -X- _ O
only -X- _ O
one -X- _ O
of -X- _ O
these -X- _ O
three -X- _ O
nodes -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
triplet -X- _ O
- -X- _ O
based -X- _ O
graph -X- _ O
walks -X- _ O
, -X- _ O
a -X- _ O
multihop -X- _ O
graph -X- _ O
walk -X- _ O
is -X- _ O
proposed -X- _ O
to -X- _ O
encode -X- _ O
multiple -X- _ O
relational -X- _ O
facts -X- _ O
that -X- _ O
are -X- _ O
interconnected -X- _ O
. -X- _ O
Multi -X- _ O
- -X- _ O
hop -X- _ O
graph -X- _ O
walk -X- _ O
connects -X- _ O
multiple -X- _ O
facts -X- _ O
by -X- _ O
setting -X- _ O
the -X- _ O
arrival -X- _ O
node -X- _ O
( -X- _ O
tail -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
preceding -X- _ O
walk -X- _ O
as -X- _ O
the -X- _ O
starting -X- _ O
( -X- _ O
head -X- _ O
) -X- _ O
node -X- _ O
of -X- _ O
the -X- _ O
next -X- _ O
walk -X- _ O
, -X- _ O
thus -X- _ O
, -X- _ O
n -X- _ O
- -X- _ O
hop -X- _ O
graph -X- _ O
walk -X- _ O
combines -X- _ O
n -X- _ O
facts -X- _ O
as -X- _ O
a -X- _ O
hyperedge -X- _ O
. -X- _ O

V -X- _ O
′k -X- _ O
⊂ -X- _ O
V -X- _ O
k -X- _ O
. -X- _ O

A -X- _ O
hyperedge -X- _ O
is -X- _ O
flexible -X- _ O
to -X- _ O
encode -X- _ O
different -X- _ O
kinds -X- _ O
of -X- _ O
semantics -X- _ O
in -X- _ O
the -X- _ O
underlying -X- _ O
graph -X- _ O
without -X- _ O
the -X- _ O
constraint -X- _ O
of -X- _ O
length -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2(a -X- _ O
) -X- _ O
, -X- _ O
entity -X- _ O
linking -X- _ O
module -X- _ O
first -X- _ O
links -X- _ O
concepts -X- _ O
from -X- _ O
query -X- _ O
( -X- _ O
a -X- _ O
given -X- _ O
image -X- _ O
- -X- _ O
question -X- _ O
pair -X- _ O
) -X- _ O
to -X- _ O
knowledge -X- _ O
base -X- _ O
. -X- _ O
We -X- _ O
detect -X- _ O
visual -X- _ O
concepts -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
objects -X- _ O
, -X- _ O
attributes -X- _ O
, -X- _ O
person -X- _ O
names -X- _ O
) -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
image -X- _ O
and -X- _ O
named -X- _ O
entities -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
question -X- _ O
. -X- _ O
The -X- _ O
semantic -X- _ O
labels -X- _ O
of -X- _ O
visual -X- _ O
concepts -X- _ O
or -X- _ O
named -X- _ O
entities -X- _ O
are -X- _ O
then -X- _ O
linked -X- _ O
with -X- _ O
knowledge -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
knowledge -X- _ O
base -X- _ O
using -X- _ O
exact -X- _ O
keyword -X- _ O
matching -X- _ O
. -X- _ O
Query -X- _ O
- -X- _ O
aware -X- _ O
knowledge -X- _ O
hypergraph -X- _ O
A -X- _ O
knowledge -X- _ O
base -X- _ O
( -X- _ O
KB -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
vast -X- _ O
amount -X- _ O
of -X- _ O
general -X- _ O
knowledge -X- _ O
facts -X- _ O
, -X- _ O
contains -X- _ O
not -X- _ O
only -X- _ O
knowledge -X- _ O
facts -X- _ O
required -X- _ O
to -X- _ O
answer -X- _ O
a -X- _ O
given -X- _ O
question -X- _ O
but -X- _ O
also -X- _ O
unnecessary -X- _ O
knowledge -X- _ O
facts -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
queryaware -X- _ O
knowledge -X- _ O
hypergraph -X- _ O
H -X- _ O
k -X- _ O
= -X- _ O
{ -X- _ O
V -X- _ O
k -X- _ O
, -X- _ O
E -X- _ O
k -X- _ O
} -X- _ O
to -X- _ O
extract -X- _ O
related -X- _ O
information -X- _ O
for -X- _ O
answering -X- _ O
a -X- _ O
given -X- _ O
question -X- _ O
. -X- _ O
It -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
node -X- _ O
set -X- _ O
V -X- _ O
k -X- _ O
and -X- _ O
hyperedge -X- _ O
set -X- _ O
E -X- _ O
k -X- _ O
, -X- _ O
which -X- _ O
represent -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
entities -X- _ O
in -X- _ O
knowledge -X- _ O
facts -X- _ O
and -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
hyperedges -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Each -X- _ O
hyperedge -X- _ O
connects -X- _ O
the -X- _ O
subset -X- _ O
of -X- _ O
vertices -X- _ O

i -X- _ O
= -X- _ O
{ -X- _ O
v -X- _ O
′ -X- _ O
1 -X- _ O
⪯ -X- _ O
... -X- _ O
⪯ -X- _ O
v -X- _ O
′ -X- _ O
l -X- _ O
} -X- _ O
where -X- _ O
V -X- _ O
′ -X- _ O
= -X- _ O
{ -X- _ O
v -X- _ O
′ -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
v -X- _ O
′ -X- _ O
l -X- _ O
} -X- _ O
is -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
V -X- _ O
and -X- _ O
⪯ -X- _ O
is -X- _ O
a -X- _ O
binary -X- _ O
relation -X- _ O
which -X- _ O
denotes -X- _ O
an -X- _ O
element -X- _ O
( -X- _ O
v -X- _ O
′ -X- _ O
i -X- _ O
) -X- _ O
precedes -X- _ O
the -X- _ O
other -X- _ O
( -X- _ O
v -X- _ O
′ -X- _ O
j -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
ordering -X- _ O
when -X- _ O
v -X- _ O
′ -X- _ O
i -X- _ O
⪯ -X- _ O
v -X- _ O
′ -X- _ O
j -X- _ O
. -X- _ O

Multi -X- _ O
- -X- _ O
hop -X- _ O
knowledge -X- _ O
graph -X- _ O
reasoning -X- _ O
is -X- _ O
a -X- _ O
process -X- _ O
of -X- _ O
sequential -X- _ O
reasoning -X- _ O
based -X- _ O
on -X- _ O
multiple -X- _ O
evidences -X- _ O
of -X- _ O
a -X- _ O
knowledge -X- _ O
graph -X- _ O
, -X- _ O
and -X- _ O
has -X- _ O
been -X- _ O
broadly -X- _ O
used -X- _ O
in -X- _ O
various -X- _ O
downstream -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Saxena -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Han -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
, -X- _ O
a;Yadati -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
knowledge -X- _ B-TaskName
- -X- _ I-TaskName
enhanced -X- _ I-TaskName
text -X- _ I-TaskName
generation -X- _ I-TaskName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Moon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Ji -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Recent -X- _ O
researches -X- _ O
have -X- _ O
introduced -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
hypergraph -X- _ O
for -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
graph -X- _ O
reasoning -X- _ O
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Han -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
, -X- _ O
a;Yadati -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2021 -X- _ O
. -X- _ O
These -X- _ O
models -X- _ O
have -X- _ O
a -X- _ O
similar -X- _ O
motivation -X- _ O
to -X- _ O
the -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
proposed -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
but -X- _ O
core -X- _ O
operations -X- _ O
are -X- _ O
vastly -X- _ O
different -X- _ O
. -X- _ O
These -X- _ O
models -X- _ O
mainly -X- _ O
update -X- _ O
node -X- _ O
representations -X- _ O
in -X- _ O
the -X- _ O
hypergraph -X- _ O
through -X- _ O
a -X- _ O
message -X- _ O
passing -X- _ O
process -X- _ O
using -X- _ O
graph -X- _ O
convolution -X- _ O
operation -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
contrary -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
update -X- _ O
node -X- _ O
representations -X- _ O
via -X- _ O
hyperedge -X- _ O
matching -X- _ O
of -X- _ O
hypergraphs -X- _ O
instead -X- _ O
of -X- _ O
message -X- _ O
passing -X- _ O
scheme -X- _ O
. -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
this -X- _ O
update -X- _ O
process -X- _ O
effectively -X- _ O
learns -X- _ O
the -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
semantics -X- _ O
inherent -X- _ O
in -X- _ O
each -X- _ O
hypergraph -X- _ O
and -X- _ O
the -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
associations -X- _ O
between -X- _ O
two -X- _ O
hypergraphs -X- _ O
. -X- _ O
To -X- _ O
capture -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
semantics -X- _ O
inherent -X- _ O
in -X- _ O
the -X- _ O
knowledge -X- _ O
sources -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
hypergraph -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
directed -X- _ O
hypergraph -X- _ O
H -X- _ O
= -X- _ O
{ -X- _ O
V -X- _ O
, -X- _ O
E -X- _ O
} -X- _ O
is -X- _ O
defined -X- _ O
by -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
nodes -X- _ O
V -X- _ O
= -X- _ O
{ -X- _ O
v -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
v -X- _ O
|V| -X- _ O
} -X- _ O
and -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
hyperedges -X- _ O
E -X- _ O
= -X- _ O
{ -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
h -X- _ O
|E| -X- _ O
} -X- _ O
. -X- _ O
Each -X- _ O
node -X- _ O
is -X- _ O
represented -X- _ O
as -X- _ O
a -X- _ O
w -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
dimensional -X- _ I-HyperparameterValue
embedding -X- _ B-HyperparameterName
vector -X- _ I-HyperparameterName
, -X- _ O
i.e. -X- _ O
, -X- _ O
v -X- _ O
i -X- _ O
∈ -X- _ O
R -X- _ O
w -X- _ O
. -X- _ O
Each -X- _ O
hyperedge -X- _ O
connects -X- _ O
an -X- _ O
arbitrary -X- _ O
number -X- _ O
of -X- _ O
nodes -X- _ O
and -X- _ O
has -X- _ O
partial -X- _ O
order -X- _ O
itself -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
h -X- _ O

The -X- _ O
main -X- _ O
contributions -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
can -X- _ O
be -X- _ O
summarized -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O
i -X- _ O
) -X- _ O
We -X- _ O
propose -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
which -X- _ O
enhances -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
reasoning -X- _ O
ability -X- _ O
by -X- _ O
encoding -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
semantics -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
a -X- _ O
hypergraph -X- _ O
and -X- _ O
learning -X- _ O
inter -X- _ O
- -X- _ O
and -X- _ O
intrahigh -X- _ O
- -X- _ O
order -X- _ O
associations -X- _ O
in -X- _ O
hypergraphs -X- _ O
using -X- _ O
the -X- _ O
attention -X- _ O
mechanism -X- _ O
. -X- _ O
ii -X- _ O
) -X- _ O
We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
knowledge -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
VQA -X- _ I-TaskName
datasets -X- _ O
( -X- _ O
KVQA -X- _ B-DatasetName
and -X- _ O
FVQA -X- _ B-DatasetName
) -X- _ O
and -X- _ O
two -X- _ O
knowledge -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
textual -X- _ I-TaskName
QA -X- _ I-TaskName
datasets -X- _ O
( -X- _ O
PQ -X- _ B-DatasetName
and -X- _ O
PQL -X- _ B-DatasetName
) -X- _ O
and -X- _ O
show -X- _ O
superior -X- _ O
performances -X- _ O
on -X- _ O
all -X- _ O
datasets -X- _ O
, -X- _ O
especially -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
reasoning -X- _ O
problem -X- _ O
. -X- _ O
iii -X- _ O
) -X- _ O
We -X- _ O
qualitatively -X- _ O
observe -X- _ O
that -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
performs -X- _ O
robust -X- _ O
in -X- _ O
- -X- _ O
ference -X- _ O
by -X- _ O
focusing -X- _ O
on -X- _ O
correct -X- _ O
reasoning -X- _ O
evidences -X- _ O
under -X- _ O
weak -X- _ O
supervision -X- _ O
. -X- _ O
Knowledge -X- _ B-DatasetName
- -X- _ I-DatasetName
based -X- _ I-DatasetName
visual -X- _ I-DatasetName
question -X- _ I-DatasetName
answering -X- _ I-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017(Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2018Marino -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Sampat -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
benchmark -X- _ O
datasets -X- _ O
for -X- _ O
knowledge -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
visual -X- _ I-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
that -X- _ O
requires -X- _ O
reasoning -X- _ O
about -X- _ O
an -X- _ O
image -X- _ O
on -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
facts -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
knowledge -X- _ O
base -X- _ O
( -X- _ O
KB -X- _ O
) -X- _ O
such -X- _ O
as -X- _ O
Freebase -X- _ B-DatasetName
( -X- _ O
Bollacker -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
or -X- _ O
DBPedia -X- _ B-DatasetName
( -X- _ O
Auer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
solve -X- _ O
the -X- _ O
task -X- _ O
, -X- _ O
two -X- _ O
pioneering -X- _ O
studies -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017(Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2018 -X- _ O
suggested -X- _ O
logical -X- _ O
parsing -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
which -X- _ O
convert -X- _ O
a -X- _ O
question -X- _ O
to -X- _ O
a -X- _ O
KB -X- _ O
logic -X- _ O
query -X- _ O
using -X- _ O
predefined -X- _ O
query -X- _ O
templates -X- _ O
and -X- _ O
execute -X- _ O
the -X- _ O
generated -X- _ O
query -X- _ O
on -X- _ O
KB -X- _ O
for -X- _ O
searching -X- _ O
an -X- _ O
answer -X- _ O
. -X- _ O
Since -X- _ O
then -X- _ O
information -X- _ O
retrieval -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
which -X- _ O
retrieve -X- _ O
knowledge -X- _ O
facts -X- _ O
associated -X- _ O
with -X- _ O
a -X- _ O
question -X- _ O
and -X- _ O
conduct -X- _ O
semantic -X- _ O
matching -X- _ O
between -X- _ O
the -X- _ O
facts -X- _ O
and -X- _ O
the -X- _ O
question -X- _ O
are -X- _ O
introduced -X- _ O
. -X- _ O
( -X- _ O
Narasimhan -X- _ O
and -X- _ O
Schwing -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
proposed -X- _ O
memory -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
that -X- _ O
represent -X- _ O
knowledge -X- _ O
facts -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
memory -X- _ O
and -X- _ O
calculate -X- _ O
soft -X- _ O
attention -X- _ O
scores -X- _ O
of -X- _ O
the -X- _ O
memory -X- _ O
with -X- _ O
a -X- _ O
question -X- _ O
. -X- _ O
( -X- _ O
Narasimhan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
represented -X- _ O
the -X- _ O
retrieved -X- _ O
facts -X- _ O
as -X- _ O
a -X- _ O
graph -X- _ O
and -X- _ O
performed -X- _ O
graph -X- _ O
reasoning -X- _ O
through -X- _ O
message -X- _ O
passing -X- _ O
scheme -X- _ O
utilizing -X- _ O
graph -X- _ O
convolution -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
methods -X- _ O
are -X- _ O
complicated -X- _ O
to -X- _ O
encode -X- _ O
inherent -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
semantics -X- _ O
and -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
relationships -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
knowledge -X- _ O
graph -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
concept -X- _ O
of -X- _ O
hypergraph -X- _ O
and -X- _ O
propose -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
attention -X- _ O
mechanism -X- _ O
over -X- _ O
hypergraphs -X- _ O
. -X- _ O

To -X- _ O
address -X- _ O
the -X- _ O
above -X- _ O
limitation -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
method -X- _ O
, -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
, -X- _ O
which -X- _ O
exploits -X- _ O
hypergraph -X- _ O
structure -X- _ O
to -X- _ O
encode -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
relationships -X- _ O
and -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
attention -X- _ O
mechanism -X- _ O
to -X- _ O
learn -X- _ O
to -X- _ O
pay -X- _ O
attention -X- _ O
to -X- _ O
important -X- _ O
knowledge -X- _ O
evidences -X- _ O
for -X- _ O
a -X- _ O
question -X- _ O
. -X- _ O
We -X- _ O
construct -X- _ O
a -X- _ O
question -X- _ O
hypergraph -X- _ O
and -X- _ O
a -X- _ O
knowledge -X- _ O
hypergraph -X- _ O
to -X- _ O
explicitly -X- _ O
encode -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
semantics -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
each -X- _ O
knowledge -X- _ O
fact -X- _ O
, -X- _ O
and -X- _ O
capture -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
relational -X- _ O
knowledge -X- _ O
facts -X- _ O
effectively -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
hyperedge -X- _ B-HyperparameterValue
matching -X- _ I-HyperparameterValue
between -X- _ O
the -X- _ O
two -X- _ O
hypergraphs -X- _ O
by -X- _ O
leveraging -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
attention -X- _ O
mechanism -X- _ O
. -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
introducing -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
hypergraph -X- _ O
is -X- _ O
powerful -X- _ O
for -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
reasoning -X- _ O
problem -X- _ O
in -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
encode -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
semantics -X- _ O
without -X- _ O
the -X- _ O
constraint -X- _ O
of -X- _ O
length -X- _ O
and -X- _ O
learn -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
associations -X- _ O
. -X- _ O

Under -X- _ O
weak -X- _ O
supervision -X- _ O
, -X- _ O
previous -X- _ O
studies -X- _ O
proposed -X- _ O
memory -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
( -X- _ O
Narasimhan -X- _ O
and -X- _ O
Schwing -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
and -X- _ O
graph -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
( -X- _ O
Narasimhan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
to -X- _ O
learn -X- _ O
to -X- _ O
selectively -X- _ O
focus -X- _ O
on -X- _ O
necessary -X- _ O
pieces -X- _ O
of -X- _ O
knowledge -X- _ O
. -X- _ O
The -X- _ O
memory -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
represent -X- _ O
knowledge -X- _ O
facts -X- _ O
in -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
memory -X- _ O
and -X- _ O
calculate -X- _ O
soft -X- _ O
attention -X- _ O
scores -X- _ O
of -X- _ O
each -X- _ O
memory -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
a -X- _ O
question -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
it -X- _ O
infers -X- _ O
an -X- _ O
answer -X- _ O
by -X- _ O
attending -X- _ O
to -X- _ O
knowledge -X- _ O
evidence -X- _ O
with -X- _ O
high -X- _ O
attention -X- _ O
scores -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
to -X- _ O
explicitly -X- _ O
consider -X- _ O
relational -X- _ O
structure -X- _ O
between -X- _ O
knowledge -X- _ O
facts -X- _ O
, -X- _ O
graph -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
construct -X- _ O
a -X- _ O
query -X- _ O
- -X- _ O
aware -X- _ O
knowledge -X- _ O
graph -X- _ O
by -X- _ O
retrieving -X- _ O
facts -X- _ O
from -X- _ O
KB -X- _ O
and -X- _ O
perform -X- _ O
graph -X- _ O
reasoning -X- _ O
for -X- _ O
a -X- _ O
question -X- _ O
. -X- _ O
These -X- _ O
methods -X- _ O
mainly -X- _ O
adopt -X- _ O
an -X- _ O
iterative -X- _ O
message -X- _ O
passing -X- _ O
process -X- _ O
to -X- _ O
propagate -X- _ O
information -X- _ O
between -X- _ O
adjacent -X- _ O
nodes -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
capture -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
relationships -X- _ O
containing -X- _ O
long -X- _ O
- -X- _ O
distance -X- _ O
nodes -X- _ O
from -X- _ O
the -X- _ O
graph -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
over -X- _ O
- -X- _ O
smoothing -X- _ O
problem -X- _ O
, -X- _ O
where -X- _ O
repetitive -X- _ O
message -X- _ O
passing -X- _ O
process -X- _ O
to -X- _ O
propagate -X- _ O
information -X- _ O
across -X- _ O
long -X- _ O
distance -X- _ O
makes -X- _ O
features -X- _ O
of -X- _ O
connected -X- _ O
nodes -X- _ O
too -X- _ O
similar -X- _ O
and -X- _ O
undiscriminating -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
. -X- _ O

That -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
should -X- _ O
learn -X- _ O
which -X- _ O
knowledge -X- _ O
facts -X- _ O
to -X- _ O
be -X- _ O
attended -X- _ O
to -X- _ O
and -X- _ O
how -X- _ O
to -X- _ O
combine -X- _ O
them -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
on -X- _ O
its -X- _ O
own -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
call -X- _ O
this -X- _ O
setting -X- _ O
under -X- _ O
weak -X- _ O
supervision -X- _ O
. -X- _ O

where -X- _ O
a -X- _ O
massive -X- _ O
number -X- _ O
of -X- _ O
knowledge -X- _ O
facts -X- _ O
from -X- _ O
a -X- _ O
general -X- _ O
knowledge -X- _ O
base -X- _ O
( -X- _ O
KB -X- _ O
) -X- _ O
is -X- _ O
given -X- _ O
with -X- _ O
an -X- _ O
image -X- _ O
- -X- _ O
question -X- _ O
pair -X- _ O
. -X- _ O
To -X- _ O
answer -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
a -X- _ O
model -X- _ O
should -X- _ O
understand -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
, -X- _ O
link -X- _ O
visual -X- _ O
entities -X- _ O
appearing -X- _ O
in -X- _ O
the -X- _ O
given -X- _ O
image -X- _ O
to -X- _ O
the -X- _ O
KB -X- _ O
, -X- _ O
extract -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
evidences -X- _ O
from -X- _ O
the -X- _ O
KB -X- _ O
and -X- _ O
predict -X- _ O
an -X- _ O
answer -X- _ O
by -X- _ O
aggregating -X- _ O
semantics -X- _ O
of -X- _ O
both -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
the -X- _ O
extracted -X- _ O
evidences -X- _ O
. -X- _ O
Following -X- _ O
these -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
two -X- _ O
fundamental -X- _ O
challenges -X- _ O
in -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O
i -X- _ O
) -X- _ O
To -X- _ O
answer -X- _ O
a -X- _ O
complex -X- _ O
question -X- _ O
, -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
reasoning -X- _ O
over -X- _ O
multiple -X- _ O
knowledge -X- _ O
evidences -X- _ O
is -X- _ O
necessary -X- _ O
. -X- _ O
ii -X- _ O
) -X- _ O
Learning -X- _ O
a -X- _ O
complex -X- _ O
reasoning -X- _ O
process -X- _ O
is -X- _ O
difficult -X- _ O
especially -X- _ O
in -X- _ O
a -X- _ O
condition -X- _ O
where -X- _ O
only -X- _ O
QA -X- _ B-TaskName
is -X- _ O
provided -X- _ O
without -X- _ O
extra -X- _ O
supervision -X- _ O
on -X- _ O
how -X- _ O
to -X- _ O
capture -X- _ O
any -X- _ O
evidence -X- _ O
from -X- _ O
the -X- _ O
KB -X- _ O
and -X- _ O
infer -X- _ O
based -X- _ O
on -X- _ O
them -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
which -X- _ O
is -X- _ O
called -X- _ O
knowledge -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
visual -X- _ I-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
, -X- _ O
To -X- _ O
answer -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
, -X- _ O
the -X- _ O
multiple -X- _ O
reasoning -X- _ O
evidences -X- _ O
( -X- _ O
marked -X- _ O
as -X- _ O
orange -X- _ O
) -X- _ O
are -X- _ O
required -X- _ O
. -X- _ O

Visual -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
( -X- _ O
VQA -X- _ B-TaskName
) -X- _ O
is -X- _ O
a -X- _ O
semantic -X- _ B-TaskName
reasoning -X- _ I-TaskName
task -X- _ O
that -X- _ O
aims -X- _ O
to -X- _ O
answer -X- _ O
questions -X- _ O
about -X- _ O
visual -X- _ O
content -X- _ O
depicted -X- _ O
in -X- _ O
images -X- _ O
( -X- _ O
Antol -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Hudson -X- _ O
and -X- _ O
Manning -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
has -X- _ O
become -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
active -X- _ O
areas -X- _ O
of -X- _ O
research -X- _ O
with -X- _ O
advances -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
and -X- _ O
computer -X- _ O
vision -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
researches -X- _ O
for -X- _ O
VQA -X- _ B-TaskName
have -X- _ O
advanced -X- _ O
, -X- _ O
from -X- _ O
inferring -X- _ O
visual -X- _ O
properties -X- _ O
on -X- _ O
entities -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
image -X- _ O
, -X- _ O
to -X- _ O
inferring -X- _ O
commonsense -X- _ O
or -X- _ O
world -X- _ O
knowledge -X- _ O
about -X- _ O
those -X- _ O
entities -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017(Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2018Marino -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Zellers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

GLM -X- _ B-MethodName
: -X- _ O
He -X- _ O
was -X- _ O
a -X- _ O
voice -X- _ O
actor -X- _ O
for -X- _ O
the -X- _ O
" -X- _ O
X -X- _ O
- -X- _ O
Men -X- _ O
" -X- _ O
cartoon -X- _ O
series -X- _ O
. -X- _ O
He -X- _ O
was -X- _ O
also -X- _ O
a -X- _ O
voice -X- _ O
actor -X- _ O
for -X- _ O
" -X- _ O
the -X- _ O
Simpsons -X- _ O
" -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
" -X- _ O
the -X- _ O
marvelous -X- _ O
misadventures -X- _ O
of -X- _ O
superman -X- _ O
. -X- _ O
He -X- _ O
also -X- _ O
has -X- _ O
voiced -X- _ O
characters -X- _ O
in -X- _ O
" -X- _ O
the -X- _ O
legend -X- _ O
of -X- _ O
korra -X- _ O
" -X- _ O
He -X- _ O
has -X- _ O
appeared -X- _ O
on -X- _ O
several -X- _ O
television -X- _ O
series -X- _ O
, -X- _ O
including -X- _ O
" -X- _ O
the -X- _ O
simpsons -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
the -X- _ O
x -X- _ O
- -X- _ O
files -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
heroes -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
the -X- _ O
simpsons -X- _ O
movie -X- _ O
" -X- _ O
as -X- _ O
the -X- _ O
character -X- _ O
captain -X- _ O
billy -X- _ O
higgledy -X- _ O
- -X- _ O
pig -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
web -X- _ O
series -X- _ O
" -X- _ O
krusty -X- _ O
mysteries -X- _ O
" -X- _ O
as -X- _ O
the -X- _ O
character -X- _ O
Colonel -X- _ O
Trungus -X- _ O
. -X- _ O
He -X- _ O
wrote -X- _ O
for -X- _ O
" -X- _ O
the -X- _ O
Guardian -X- _ O
" -X- _ O
newspaper -X- _ O
. -X- _ O
Jonathan -X- _ O
Terry -X- _ O
was -X- _ O
born -X- _ O
in -X- _ O
London -X- _ O
. -X- _ O
Terry -X- _ O
grew -X- _ O
up -X- _ O
in -X- _ O
Surrey -X- _ O
, -X- _ O
England -X- _ O
and -X- _ O
attended -X- _ O
the -X- _ O
University -X- _ O
of -X- _ O
Sussex -X- _ O
in -X- _ O
the -X- _ O
United -X- _ O
Kingdom -X- _ O
, -X- _ O
graduating -X- _ O
with -X- _ O
a -X- _ O
degree -X- _ O
in -X- _ O
english -X- _ O
literature -X- _ O
. -X- _ O
He -X- _ O
was -X- _ O
a -X- _ O
guest -X- _ O
lecturer -X- _ O
at -X- _ O
King -X- _ O
's -X- _ O
College -X- _ O
London -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
took -X- _ O
two -X- _ O
years -X- _ O
of -X- _ O
acting -X- _ O
courses -X- _ O
at -X- _ O
the -X- _ O
brit -X- _ O
school -X- _ O
of -X- _ O
acting -X- _ O
to -X- _ O
prepare -X- _ O
for -X- _ O
his -X- _ O
future -X- _ O
career -X- _ O
in -X- _ O
the -X- _ O
entertainment -X- _ O
industry -X- _ O
. -X- _ O
Terry -X- _ O
first -X- _ O
appeared -X- _ O
in -X- _ O
the -X- _ O
TV -X- _ O
series -X- _ O
" -X- _ O
theKnowledge -X- _ O
- -X- _ O
based -X- _ O
visual -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
( -X- _ O
QA -X- _ B-TaskName
) -X- _ O
aims -X- _ O
to -X- _ O
answer -X- _ O
a -X- _ O
question -X- _ O
which -X- _ O
requires -X- _ O
visually -X- _ O
- -X- _ O
grounded -X- _ O
external -X- _ O
knowledge -X- _ O
beyond -X- _ O
image -X- _ O
content -X- _ O
itself -X- _ O
. -X- _ O
Answering -X- _ O
complex -X- _ O
questions -X- _ O
that -X- _ O
require -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
reasoning -X- _ O
under -X- _ O
weak -X- _ O
supervision -X- _ O
is -X- _ O
considered -X- _ O
as -X- _ O
a -X- _ O
challenging -X- _ O
problem -X- _ O
since -X- _ O
i -X- _ O
) -X- _ O
no -X- _ O
supervision -X- _ O
is -X- _ O
given -X- _ O
to -X- _ O
the -X- _ O
reasoning -X- _ O
process -X- _ O
and -X- _ O
ii -X- _ O
) -X- _ O
highorder -X- _ O
semantics -X- _ O
of -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
knowledge -X- _ O
facts -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
captured -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
concept -X- _ O
of -X- _ O
hypergraph -X- _ O
to -X- _ O
encode -X- _ O
highlevel -X- _ O
semantics -X- _ O
of -X- _ O
a -X- _ O
question -X- _ O
and -X- _ O
a -X- _ O
knowledge -X- _ O
base -X- _ O
, -X- _ O
and -X- _ O
to -X- _ O
learn -X- _ O
high -X- _ O
- -X- _ O
order -X- _ O
associations -X- _ O
between -X- _ O
them -X- _ O
. -X- _ O
The -X- _ O
proposed -X- _ O
model -X- _ O
, -X- _ O
Hypergraph -X- _ B-MethodName
Transformer -X- _ I-MethodName
, -X- _ O
constructs -X- _ O
a -X- _ O
question -X- _ O
hypergraph -X- _ O
and -X- _ O
a -X- _ O
query -X- _ O
- -X- _ O
aware -X- _ O
knowledge -X- _ O
hypergraph -X- _ O
, -X- _ O
and -X- _ O
infers -X- _ O
an -X- _ O
answer -X- _ O
by -X- _ O
encoding -X- _ O
inter -X- _ O
- -X- _ O
associations -X- _ O
between -X- _ O
two -X- _ O
hypergraphs -X- _ O
and -X- _ O
intra -X- _ O
- -X- _ O
associations -X- _ O
in -X- _ O
both -X- _ O
hypergraph -X- _ O
itself -X- _ O
. -X- _ O
Extensive -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
knowledgebased -X- _ B-TaskName
visual -X- _ I-TaskName
QA -X- _ I-TaskName
and -X- _ O
two -X- _ O
knowledge -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
textual -X- _ I-TaskName
QA -X- _ I-TaskName
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
, -X- _ O
especially -X- _ O
for -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
reasoning -X- _ O
problem -X- _ O
. -X- _ O
Our -X- _ O
source -X- _ O
code -X- _ O
is -X- _ O
available -X- _ O
at -X- _ O
https://github.com/yujungheo/ -X- _ O
kbvqa -X- _ O
- -X- _ O
public -X- _ O
. -X- _ O

Example -X- _ O
D.2 -X- _ O
. -X- _ O
Jonathan -X- _ O
Terry -X- _ O
is -X- _ O
a -X- _ O
television -X- _ O
and -X- _ O
film -X- _ O
actor -X- _ O
. -X- _ O

Perplexity -X- _ B-MetricName
is -X- _ O
an -X- _ O
evaluation -X- _ O
criterion -X- _ O
that -X- _ O
has -X- _ O
been -X- _ O
changes -X- _ O
to -X- _ O
the -X- _ O
senate -X- _ O
. -X- _ O
The -X- _ O
most -X- _ O
recent -X- _ O
is -X- _ O
the -X- _ O
creation -X- _ O
of -X- _ O
a -X- _ O
six -X- _ O
- -X- _ O
seat -X- _ O
district -X- _ O
that -X- _ O
includes -X- _ O
all -X- _ O
or -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
following -X- _ O
: -X- _ O
In -X- _ O
the -X- _ O
2009 -X- _ O
elections -X- _ O
, -X- _ O
the -X- _ O
state -X- _ O
senate -X- _ O
members -X- _ O
were -X- _ O
elected -X- _ O
to -X- _ O
six -X- _ O
- -X- _ O
year -X- _ O
terms -X- _ O
. -X- _ O
The -X- _ O
current -X- _ O
state -X- _ O
house -X- _ O
members -X- _ O
are -X- _ O
: -X- _ O
The -X- _ O
Wyoming -X- _ O
Constitution -X- _ O
assigns -X- _ O
certain -X- _ O
powers -X- _ O
to -X- _ O
the -X- _ O
governor -X- _ O
. -X- _ O
Most -X- _ O
notably -X- _ O
, -X- _ O
the -X- _ O
governor -X- _ O
is -X- _ O
president -X- _ O
of -X- _ O
the -X- _ O
senate -X- _ O
and -X- _ O
governor -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
governor -X- _ O
desires -X- _ O
to -X- _ O
appoint -X- _ O
a -X- _ O
member -X- _ O
to -X- _ O
the -X- _ O
Wyoming -X- _ O
state -X- _ O
senate -X- _ O
, -X- _ O
a -X- _ O
law -X- _ O
authorizes -X- _ O
the -X- _ O
governor -X- _ O
to -X- _ O
do -X- _ O
so -X- _ O
. -X- _ O
The -X- _ O
governor -X- _ O
of -X- _ O
Wyoming -X- _ O
holds -X- _ O
no -X- _ O
legislative -X- _ O
power -X- _ O
but -X- _ O
has -X- _ O
the -X- _ O
power -X- _ O
to -X- _ O
veto -X- _ O
lawmakers -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
limited -X- _ O
to -X- _ O
the -X- _ O
veto -X- _ O
of -X- _ O
laws -X- _ O
. -X- _ O
Under -X- _ O
the -X- _ O
wyoming -X- _ O
state -X- _ O
constitution -X- _ O
, -X- _ O
the -X- _ O
governor -X- _ O
can -X- _ O
veto -X- _ O
the -X- _ O
actions -X- _ O
of -X- _ O
the -X- _ O
other -X- _ O
members -X- _ O
of -X- _ O
the -X- _ O
wyoming -X- _ O
house -X- _ O
of -X- _ O
representatives -X- _ O
. -X- _ O
The -X- _ O
governor -X- _ O
can -X- _ O
also -X- _ O
appoint -X- _ O
members -X- _ O
of -X- _ O
the -X- _ O
wyoming -X- _ O
senate -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
the -X- _ O
governor -X- _ O
can -X- _ O
appoint -X- _ O
members -X- _ O
of -X- _ O
the -X- _ O
Wyoming -X- _ O
house -X- _ O
of -X- _ O
representatives -X- _ O
. -X- _ O
Wyoming -X- _ O
's -X- _ O
constitution -X- _ O
provides -X- _ O
that -X- _ O
the -X- _ O
governor -X- _ O
can -X- _ O
appoint -X- _ O
a -X- _ O
member -X- _ O
of -X- _ O
the -X- _ O
wyoming -X- _ O
state -X- _ O
senate -X- _ O
to -X- _ O
the -X- _ O
wyoming -X- _ O
supreme -X- _ O
court -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
chairman -X- _ O
of -X- _ O
the -X- _ O
wyoming -X- _ O
senate -X- _ O
. -X- _ O

For -X- _ O
comparison -X- _ O
with -X- _ O
previous -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
test -X- _ O
set -X- _ O
constructed -X- _ O
by -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
evaluation -X- _ O
metric -X- _ O
is -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
of -X- _ O
the -X- _ O
infilled -X- _ O
text -X- _ O
against -X- _ O
the -X- _ O
original -X- _ O
document -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
with -X- _ O
two -X- _ O
baselines -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
which -X- _ O
learns -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
masked -X- _ O
tokens -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
blank -X- _ O
representation -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
BLM -X- _ B-MethodName
proposed -X- _ O
by -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
fill -X- _ O
in -X- _ O
the -X- _ O
blank -X- _ O
with -X- _ O
arbitrary -X- _ O
trajectories -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
ability -X- _ O
of -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
with -X- _ O
perplexity -X- _ B-MetricName
on -X- _ O
BookWiki -X- _ B-DatasetName
and -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
the -X- _ O
LAMBDA -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Paperno -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
train -X- _ O
GLM -X- _ B-MethodName
RoBERTa -X- _ I-MethodName
, -X- _ O
we -X- _ O
follow -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
hyperparameters -X- _ O
of -X- _ O
RoBERTa -X- _ B-MethodName
. -X- _ O
The -X- _ O
main -X- _ O
difference -X- _ O
baselines -X- _ O
on -X- _ O
seq2seq -X- _ B-TaskName
tasks -X- _ O
are -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
corresponding -X- _ O
papers -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
evaluate -X- _ O
text -X- _ B-TaskName
infilling -X- _ I-TaskName
performance -X- _ O
on -X- _ O
the -X- _ O
Yahoo -X- _ B-DatasetName
Answers -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
100K/10K/10 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
documents -X- _ I-HyperparameterValue
for -X- _ O
train -X- _ B-HyperparameterName
/ -X- _ I-HyperparameterName
valid -X- _ I-HyperparameterName
/ -X- _ I-HyperparameterName
test -X- _ I-HyperparameterName
respectively -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
document -X- _ O
length -X- _ O
is -X- _ O
78 -X- _ O
words -X- _ O
. -X- _ O
To -X- _ O
construct -X- _ O
the -X- _ O
text -X- _ B-TaskName
infilling -X- _ I-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
mask -X- _ O
a -X- _ O
given -X- _ O
ratio -X- _ B-HyperparameterName
r -X- _ O
∈ -X- _ O
{ -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
• -X- _ O
• -X- _ O
• -X- _ O
50 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
} -X- _ O
of -X- _ O
each -X- _ O
document -X- _ O
's -X- _ O
tokens -X- _ O
and -X- _ O
the -X- _ O
contiguous -X- _ O
masked -X- _ O
tokens -X- _ O
are -X- _ O
collapsed -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
blank -X- _ O
. -X- _ O
We -X- _ O
finetune -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
for -X- _ O
5 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
dynamic -X- _ O
masking -X- _ O
, -X- _ O
i.e. -X- _ O
the -X- _ O
blanks -X- _ O
are -X- _ O
randomly -X- _ O
generated -X- _ O
at -X- _ O
training -X- _ O
time -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
the -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
an -X- _ O
AdamW -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
peak -X- _ B-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
1e-5 -X- _ B-HyperparameterValue
and -X- _ O
6 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
warm -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
up -X- _ I-HyperparameterName
linear -X- _ I-HyperparameterName
scheduler -X- _ I-HyperparameterName
. -X- _ O

To -X- _ O
train -X- _ O
GLM -X- _ B-MethodName
RoBERTa -X- _ I-MethodName
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
pretraining -X- _ O
datasets -X- _ O
of -X- _ O
RoBERTa -X- _ B-MethodName
, -X- _ O
which -X- _ O
consist -X- _ O
of -X- _ O
BookCorups -X- _ B-DatasetName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015),Wikipedia -X- _ B-DatasetName
( -X- _ O
16 -X- _ O
GB -X- _ O
) -X- _ O
, -X- _ O
CC -X- _ B-DatasetName
- -X- _ I-DatasetName
News -X- _ I-DatasetName
( -X- _ O
the -X- _ O
English -X- _ B-DatasetName
portion -X- _ I-DatasetName
of -X- _ I-DatasetName
the -X- _ I-DatasetName
Com -X- _ I-DatasetName
- -X- _ I-DatasetName
monCrawl -X- _ I-DatasetName
News -X- _ I-DatasetName
dataset -X- _ O
3 -X- _ O
76 -X- _ O
GB -X- _ O
) -X- _ O
, -X- _ O
OpenWebText -X- _ B-DatasetName
( -X- _ O
web -X- _ O
content -X- _ O
extracted -X- _ O
from -X- _ O
URLs -X- _ O
shared -X- _ O
on -X- _ O
Reddit -X- _ O
with -X- _ O
at -X- _ O
least -X- _ O
three -X- _ O
upvotes -X- _ O
( -X- _ O
Gokaslan -X- _ O
and -X- _ O
Cohen -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
38 -X- _ O
GB -X- _ O
) -X- _ O
and -X- _ O
Stories -X- _ B-DatasetName
( -X- _ O
subset -X- _ O
of -X- _ O
Common -X- _ B-DatasetName
- -X- _ I-DatasetName
Crawl -X- _ I-DatasetName
data -X- _ O
filtered -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
story -X- _ O
- -X- _ O
like -X- _ O
style -X- _ O
of -X- _ O
Winograd -X- _ B-DatasetName
schemas -X- _ I-DatasetName
( -X- _ O
Trinh -X- _ O
and -X- _ O
Le -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
31 -X- _ O
GB -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
Stories -X- _ B-DatasetName
dataset -X- _ O
is -X- _ O
no -X- _ O
longer -X- _ O
publicly -X- _ O
available -X- _ O
4 -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
Stories -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
replace -X- _ O
OpenWebText -X- _ B-DatasetName
with -X- _ O
OpenWebText2 -X- _ B-DatasetName
5 -X- _ I-DatasetName
( -X- _ O
66 -X- _ O
GB -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
CC -X- _ B-DatasetName
- -X- _ I-DatasetName
News -X- _ I-DatasetName
dataset -X- _ O
is -X- _ O
not -X- _ O
publicly -X- _ O
available -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
CC -X- _ B-DatasetName
- -X- _ I-DatasetName
News -X- _ I-DatasetName
- -X- _ I-DatasetName
en -X- _ I-DatasetName
published -X- _ O
by -X- _ O
( -X- _ O
Mackenzie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
the -X- _ O
datasets -X- _ O
used -X- _ O
total -X- _ O
158 -X- _ O
GB -X- _ O
of -X- _ O
uncompressed -X- _ O
texts -X- _ O
, -X- _ O
close -X- _ O
in -X- _ O
size -X- _ O
to -X- _ O
RoBERTa -X- _ B-MethodName
's -X- _ O
160 -X- _ O
GB -X- _ O
datasets -X- _ O
. -X- _ O
The -X- _ O
hyperparameters -X- _ O
for -X- _ O
GLM -X- _ B-MethodName
Base -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
are -X- _ O
similar -X- _ O
to -X- _ O
those -X- _ O
used -X- _ O
by -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
For -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
of -X- _ O
training -X- _ O
speed -X- _ O
and -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
256 -X- _ B-HyperparameterValue
and -X- _ O
1,000,000 -X- _ B-HyperparameterValue
training -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
1024 -X- _ B-HyperparameterValue
and -X- _ O
200,000 -X- _ B-HyperparameterValue
training -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
for -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
Since -X- _ O
GLM -X- _ B-MethodName
Base -X- _ I-MethodName
is -X- _ O
smaller -X- _ O
, -X- _ O
we -X- _ O
reduce -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
training -X- _ I-HyperparameterName
steps -X- _ I-HyperparameterName
to -X- _ O
120,000 -X- _ B-HyperparameterValue
to -X- _ O
speed -X- _ O
up -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
The -X- _ O
hyperparameters -X- _ O
for -X- _ O
GLM -X- _ B-MethodName
Doc -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
Sent -X- _ I-MethodName
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
those -X- _ O
of -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
The -X- _ O
hyperparameters -X- _ O
except -X- _ O
Transformer -X- _ O
architecture -X- _ O
for -X- _ O
GLM -X- _ B-MethodName
410 -X- _ I-MethodName
M -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
515 -X- _ I-MethodName
M -X- _ I-MethodName
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
those -X- _ O
of -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
The -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
64 -X- _ B-HyperparameterValue
V100 -X- _ I-HyperparameterValue
GPUs -X- _ B-HyperparameterName
for -X- _ O
200 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
1024 -X- _ B-HyperparameterValue
and -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
, -X- _ O
which -X- _ O
takes -X- _ O
about -X- _ O
2.5 -X- _ O
days -X- _ O
for -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O

GLM -X- _ B-MethodName
: -X- _ O
In -X- _ O
his -X- _ O
four -X- _ O
- -X- _ O
year -X- _ O
NFL -X- _ O
career -X- _ O
, -X- _ O
he -X- _ O
played -X- _ O
in -X- _ O
33 -X- _ O
games -X- _ O
and -X- _ O
started -X- _ O
14 -X- _ O
, -X- _ O
registering -X- _ O
62 -X- _ O
career -X- _ O
interceptions -X- _ O
. -X- _ O
He -X- _ O
completed -X- _ O
his -X- _ O
NFL -X- _ O
career -X- _ O
with -X- _ O
five -X- _ O
interceptions -X- _ O
. -X- _ O
Smith -X- _ O
was -X- _ O
born -X- _ O
in -X- _ O
La -X- _ O
Canada -X- _ O
Flintridge -X- _ O
, -X- _ O
Michigan -X- _ O
, -X- _ O
in -X- _ O
1938 -X- _ O
. -X- _ O
He -X- _ O
attended -X- _ O
Bishop -X- _ O
O -X- _ O
' -X- _ O
Dowd -X- _ O
high -X- _ O
school -X- _ O
in -X- _ O
Flintridge -X- _ O
. -X- _ O
Smith -X- _ O
' -X- _ O
s -X- _ O
father -X- _ O
was -X- _ O
a -X- _ O
pharmacist -X- _ O
. -X- _ O
He -X- _ O
graduated -X- _ O
from -X- _ O
Michigan -X- _ O
State -X- _ O
University -X- _ O
in -X- _ O
1958 -X- _ O
with -X- _ O
a -X- _ O
degree -X- _ O
in -X- _ O
business -X- _ O
administration -X- _ O
. -X- _ O
Smith -X- _ O
played -X- _ O
for -X- _ O
the -X- _ O
Michigan -X- _ O
Wolverines -X- _ O
football -X- _ O
team -X- _ O
from -X- _ O
1959 -X- _ O
to -X- _ O
1963 -X- _ O
. -X- _ O
In -X- _ O
his -X- _ O
two -X- _ O
years -X- _ O
as -X- _ O
a -X- _ O
reserve -X- _ O
cornerback -X- _ O
, -X- _ O
he -X- _ O
led -X- _ O
the -X- _ O
conference -X- _ O
in -X- _ O
interceptions -X- _ O
with -X- _ O
five -X- _ O
. -X- _ O
In -X- _ O
1962 -X- _ O
, -X- _ O
he -X- _ O
set -X- _ O
the -X- _ O
Wolverines -X- _ O
' -X- _ O
all -X- _ O
- -X- _ O
time -X- _ O
interception -X- _ O
record -X- _ O
with -X- _ O
13 -X- _ O
, -X- _ O
and -X- _ O
was -X- _ O
second -X- _ O
overall -X- _ O
in -X- _ O
the -X- _ O
1962 -X- _ O
season -X- _ O
's -X- _ O
Heisman -X- _ O
Trophy -X- _ O
voting -X- _ O
. -X- _ O
Smith -X- _ O
also -X- _ O
won -X- _ O
the -X- _ O
Dick -X- _ O
Butkus -X- _ O
award -X- _ O
as -X- _ O
the -X- _ O
nation -X- _ O
's -X- _ O
outstanding -X- _ O
linebacker -X- _ O
. -X- _ O
In -X- _ O
1961 -X- _ O
, -X- _ O
the -X- _ O
" -X- _ O
Los -X- _ O
Angeles -X- _ O
Times -X- _ O
" -X- _ O
wrote -X- _ O
that -X- _ O
Smith -X- _ O
" -X- _ O
is -X- _ O
an -X- _ O
outstanding -X- _ O
pass -X- _ O
rusher -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
average -X- _ O
of -X- _ O
almost -X- _ O
100 -X- _ O
yards -X- _ O
per -X- _ O
punt -X- _ O
return -X- _ O
. -X- _ O
" -X- _ O
Smith -X- _ O
was -X- _ O
inducted -X- _ O
into -X- _ O
the -X- _ O
university -X- _ O
of -X- _ O
Michigan -X- _ O
athletic -X- _ O
hall -X- _ O
of -X- _ O
honor -X- _ O
in -X- _ O
1989 -X- _ O
and -X- _ O
the -X- _ O
national -X- _ O
football -X- _ O
foundation -X- _ O
hall -X- _ O
of -X- _ O
fame -X- _ O
in -X- _ O
1991 -X- _ O
. -X- _ O
He -X- _ O
was -X- _ O
elected -X- _ O
to -X- _ O
the -X- _ O
Michigan -X- _ O
sports -X- _ O
hall -X- _ O
of -X- _ O
fame -X- _ O
in -X- _ O
1995 -X- _ O
. -X- _ O
Smith -X- _ O
earned -X- _ O
the -X- _ O
honor -X- _ O
because -X- _ O
of -X- _ O
his -X- _ O
accomplishments -X- _ O
prior -X- _ O
to -X- _ O
his -X- _ O
NFL -X- _ O
career -X- _ O
. -X- _ O
He -X- _ O
was -X- _ O
one -X- _ O
of -X- _ O
four -X- _ O
Michigan -X- _ O
players -X- _ O
honored -X- _ O
as -X- _ O
first -X- _ O
- -X- _ O
overall -X- _ O
selections -X- _ O
in -X- _ O
the -X- _ O
1964 -X- _ O
NFL -X- _ O
draft -X- _ O
. -X- _ O
The -X- _ O
others -X- _ O
were -X- _ O
Joe -X- _ O
Namath -X- _ O
, -X- _ O
Bill -X- _ O
Nelsen -X- _ O
, -X- _ O
and -X- _ O
Jerry -X- _ O
Kramer -X- _ O
. -X- _ O
In -X- _ O
1966 -X- _ O
, -X- _ O
the -X- _ O
NFL -X- _ O
gave -X- _ O
players -X- _ O
$ -X- _ O
300,000 -X- _ O
a -X- _ O
season -X- _ O
to -X- _ O
play -X- _ O
football -X- _ O
. -X- _ O
After -X- _ O
his -X- _ O
rookie -X- _ O
season -X- _ O
, -X- _ O
he -X- _ O
was -X- _ O
not -X- _ O
selected -X- _ O
to -X- _ O
play -X- _ O
in -X- _ O
the -X- _ O
1966 -X- _ O
pro -X- _ O
bowl -X- _ O
. -X- _ O
On -X- _ O
January -X- _ O
13 -X- _ O
, -X- _ O
1966 -X- _ O
, -X- _ O
the -X- _ O
Rams -X- _ O
traded -X- _ O
smith -X- _ O
to -X- _ O
the -X- _ O
Detroit -X- _ O
Lions -X- _ O
for -X- _ O
Paul -X- _ O
Hornung -X- _ O
, -X- _ O
and -X- _ O
later -X- _ O
that -X- _ O
year -X- _ O
he -X- _ O
was -X- _ O
traded -X- _ O
to -X- _ O
the -X- _ O
Lions -X- _ O
for -X- _ O
Ray -X- _ O
" -X- _ O
the -X- _ O
Lion -X- _ O
" -X- _ O
Jones -X- _ O
in -X- _ O
exchange -X- _ O
for -X- _ O
Linebacker -X- _ O
Jim -X- _ O
" -X- _ O
the -X- _ O
Hawk -X- _ O
" -X- _ O
Johnson -X- _ O
. -X- _ O
On -X- _ O
September -X- _ O
10 -X- _ O
, -X- _ O
1968 -X- _ O
, -X- _ O
he -X- _ O
was -X- _ O
traded -X- _ O
back -X- _ O
to -X- _ O
Los -X- _ O
Angeles -X- _ O
for -X- _ O
a -X- _ O
second -X- _ O
round -X- _ O
pick -X- _ O
in -X- _ O
the -X- _ O
1970 -X- _ O
draft -X- _ O
. -X- _ O
He -X- _ O
was -X- _ O
also -X- _ O
traded -X- _ O
to -X- _ O
the -X- _ O
St. -X- _ O
Louis -X- _ O
Cardinals -X- _ O
for -X- _ O
a -X- _ O
second -X- _ O
round -X- _ O
pick -X- _ O
in -X- _ O
the -X- _ O
1970 -X- _ O
draft -X- _ O
. -X- _ O
On -X- _ O
June -X- _ O
2 -X- _ O
, -X- _ O
1970 -X- _ O
he -X- _ O
was -X- _ O
cut -X- _ O
by -X- _ O
the -X- _ O
Cardinals -X- _ O
. -X- _ O
On -X- _ O
November -X- _ O
15 -X- _ O
, -X- _ O
1970 -X- _ O
, -X- _ O
the -X- _ O
Los -X- _ O
Angeles -X- _ O
Rams -X- _ O
acquired -X- _ O
Smith -X- _ O
from -X- _ O
the -X- _ O
Lions -X- _ O
in -X- _ O
exchange -X- _ O
for -X- _ O
Linebacker -X- _ O
Tony -X- _ O
Harris -X- _ O
. -X- _ O
The -X- _ O
Rams -X- _ O
waived -X- _ O
Smith -X- _ O
during -X- _ O
the -X- _ O
September -X- _ O
1 -X- _ O
, -X- _ O
1972 -X- _ O
offseason -X- _ O
. -X- _ O
Smith -X- _ O
's -X- _ O
number -X- _ O
at -X- _ O
Michigan -X- _ O
State -X- _ O
was -X- _ O
# -X- _ O
7 -X- _ O
in -X- _ O
1969.The -X- _ O
work -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
NSFC -X- _ O
for -X- _ O
Distinguished -X- _ O
Young -X- _ O
Scholar(61825602 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Beijing -X- _ O
Academy -X- _ O
of -X- _ O
Artificial -X- _ O
Intelligence -X- _ O
( -X- _ O
BAAI).To -X- _ O
train -X- _ O
GLM -X- _ B-MethodName
Base -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
Book -X- _ B-DatasetName
- -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
Wikipedia -X- _ B-DatasetName
used -X- _ O
by -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Example -X- _ O
D.4 -X- _ O
. -X- _ O
Robert -X- _ O
Lee -X- _ O
Smith -X- _ O
( -X- _ O
born -X- _ O
July -X- _ O
5 -X- _ O
, -X- _ O
1938 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
former -X- _ O
American -X- _ O
football -X- _ O
cornerback -X- _ O
in -X- _ O
the -X- _ O
national -X- _ O
football -X- _ O
league -X- _ O
. -X- _ O
He -X- _ O
played -X- _ O
for -X- _ O
the -X- _ O
Los -X- _ O
Angeles -X- _ O
Rams -X- _ O
( -X- _ O
1962)(1963)(1964)(1965 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
Detroit -X- _ O
Lions -X- _ O
( -X- _ O
1965)(1966 -X- _ O
) -X- _ O
. -X- _ O
He -X- _ O
was -X- _ O
also -X- _ O
a -X- _ O
kick -X- _ O
and -X- _ O
punt -X- _ O
returner -X- _ O
. -X- _ O

Example -X- _ O
D.3 -X- _ O
. -X- _ O
Corona -X- _ O
was -X- _ O
a -X- _ O
station -X- _ O
along -X- _ O
the -X- _ O
port -X- _ O
Washington -X- _ O
branch -X- _ O
of -X- _ O
the -X- _ O
long -X- _ O
island -X- _ O
rail -X- _ O
road -X- _ O
in -X- _ O
the -X- _ O
Corona -X- _ O
section -X- _ O
of -X- _ O
queens -X- _ O
, -X- _ O
New -X- _ O
York -X- _ O
City -X- _ O
. -X- _ O
It -X- _ O
was -X- _ O
one -X- _ O
of -X- _ O
two -X- _ O
stations -X- _ O
built -X- _ O
by -X- _ O
the -X- _ O
flushing -X- _ O
railroad -X- _ O
in -X- _ O
Corona -X- _ O
, -X- _ O
this -X- _ O
one -X- _ O
having -X- _ O
been -X- _ O
at -X- _ O
Grand -X- _ O
Avenue -X- _ O
( -X- _ O
later -X- _ O
called -X- _ O
National -X- _ O
Avenue -X- _ O
, -X- _ O
now -X- _ O
National -X- _ O
Street -X- _ O
) -X- _ O
and -X- _ O
45th -X- _ O
Avenue -X- _ O
. -X- _ O
GLM -X- _ O
: -X- _ O
It -X- _ O
had -X- _ O
a -X- _ O
brick -X- _ O
entrance -X- _ O
building -X- _ O
next -X- _ O
to -X- _ O
the -X- _ O
tracks -X- _ O
, -X- _ O
and -X- _ O
one -X- _ O
platform -X- _ O
with -X- _ O
2 -X- _ O
side -X- _ O
platforms -X- _ O
. -X- _ O
The -X- _ O
station -X- _ O
burned -X- _ O
down -X- _ O
and -X- _ O
was -X- _ O
rebuilt -X- _ O
in -X- _ O
1908 -X- _ O
. -X- _ O
The -X- _ O
station -X- _ O
closed -X- _ O
on -X- _ O
september -X- _ O
15 -X- _ O
, -X- _ O
1927 -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
train -X- _ O
service -X- _ O
transferred -X- _ O
from -X- _ O
Grand -X- _ O
Avenue -X- _ O
to -X- _ O
45th -X- _ O
Avenue -X- _ O
. -X- _ O
There -X- _ O
were -X- _ O
plans -X- _ O
to -X- _ O
build -X- _ O
a -X- _ O
subway -X- _ O
extension -X- _ O
to -X- _ O
Corona -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
was -X- _ O
never -X- _ O
built -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
1980s -X- _ O
, -X- _ O
two -X- _ O
stations -X- _ O
were -X- _ O
constructed -X- _ O
on -X- _ O
the -X- _ O
line -X- _ O
, -X- _ O
Corona -X- _ O
Road -X- _ O
and -X- _ O
Corona -X- _ O
Park -X- _ O
. -X- _ O
The -X- _ O
new -X- _ O
Corona -X- _ O
station -X- _ O
opened -X- _ O
in -X- _ O
1988 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
original -X- _ O
Corona -X- _ O
station -X- _ O
was -X- _ O
demolished -X- _ O
. -X- _ O

He -X- _ O
appeared -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
few -X- _ O
episodes -X- _ O
of -X- _ O
" -X- _ O
" -X- _ O
as -X- _ O
the -X- _ O
character -X- _ O
major -X- _ O
Jack -X- _ O
Ryan -X- _ O
. -X- _ O
He -X- _ O
has -X- _ O
also -X- _ O
appeared -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
supporting -X- _ O
cast -X- _ O
of -X- _ O
several -X- _ O
episodes -X- _ O
of -X- _ O
" -X- _ O
the -X- _ O
secret -X- _ O
life -X- _ O
of -X- _ O
pets -X- _ O
" -X- _ O
. -X- _ O
He -X- _ O
has -X- _ O
also -X- _ O
worked -X- _ O
on -X- _ O
" -X- _ O
the -X- _ O
simpsons -X- _ O
" -X- _ O
TV -X- _ O
show -X- _ O
since -X- _ O
" -X- _ O
the -X- _ O
simpsons -X- _ O
movie -X- _ O
" -X- _ O
, -X- _ O
most -X- _ O
notably -X- _ O
playing -X- _ O
the -X- _ O
roles -X- _ O
of -X- _ O
Captain -X- _ O
Skeletor -X- _ O
and -X- _ O
the -X- _ O
ghost -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
name -X- _ O
. -X- _ O
He -X- _ O
plays -X- _ O
characters -X- _ O
in -X- _ O
several -X- _ O
films -X- _ O
, -X- _ O
including -X- _ O
" -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
" -X- _ O
. -X- _ O
He -X- _ O
has -X- _ O
appeared -X- _ O
in -X- _ O
music -X- _ O
videos -X- _ O
for -X- _ O
the -X- _ O
killers -X- _ O
in -X- _ O
1993 -X- _ O
, -X- _ O
the -X- _ O
pretenders -X- _ O
in -X- _ O
1995 -X- _ O
, -X- _ O
and -X- _ O
in -X- _ O
the -X- _ O
TV -X- _ O
shows -X- _ O
" -X- _ O
the -X- _ O
royal -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
the -X- _ O
bill -X- _ O
" -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
and -X- _ O
SQuAD -X- _ B-DatasetName
are -X- _ O
shown -X- _ O
in -X- _ O
Tables -X- _ O
9 -X- _ O
and -X- _ O
10 -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
two -X- _ O
benchmarks -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
can -X- _ O
still -X- _ O
outperform -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
parameters -X- _ O
, -X- _ O
but -X- _ O
with -X- _ O
a -X- _ O
smaller -X- _ O
margin -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
texts -X- _ O
generated -X- _ O
by -X- _ O
GLM -X- _ B-MethodName
Doc -X- _ I-MethodName
given -X- _ O
unseen -X- _ O
contexts -X- _ O
randomly -X- _ O
sampled -X- _ O
from -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
top -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
k -X- _ I-HyperparameterName
random -X- _ I-HyperparameterName
sampling -X- _ I-HyperparameterName
with -X- _ O
k -X- _ B-HyperparameterName
= -X- _ O
40 -X- _ B-HyperparameterValue
for -X- _ O
generation -X- _ O
and -X- _ O
set -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
to -X- _ I-HyperparameterName
512 -X- _ I-HyperparameterName
. -X- _ O
Some -X- _ O
of -X- _ O
the -X- _ O
texts -X- _ O
are -X- _ O
cut -X- _ O
short -X- _ O
. -X- _ O
Simpsons -X- _ O
" -X- _ O
as -X- _ O
the -X- _ O
character -X- _ O
captain -X- _ O
Billy -X- _ O
Higgledypig -X- _ O
, -X- _ O
but -X- _ O
his -X- _ O
character -X- _ O
was -X- _ O
only -X- _ O
a -X- _ O
one -X- _ O
- -X- _ O
time -X- _ O
recurring -X- _ O
character -X- _ O
in -X- _ O
the -X- _ O
series -X- _ O
' -X- _ O
first -X- _ O
six -X- _ O
seasons -X- _ O
. -X- _ O
He -X- _ O
later -X- _ O
appeared -X- _ O
as -X- _ O
a -X- _ O
regular -X- _ O
for -X- _ O
the -X- _ O
show -X- _ O
's -X- _ O
final -X- _ O
six -X- _ O
seasons -X- _ O
, -X- _ O
and -X- _ O
has -X- _ O
been -X- _ O
a -X- _ O
frequent -X- _ O
guest -X- _ O
in -X- _ O
the -X- _ O
show -X- _ O
since -X- _ O
. -X- _ O

Results -X- _ O
of -X- _ O
T5 -X- _ B-MethodName
Large -X- _ I-MethodName
on -X- _ O
XSum -X- _ B-DatasetName
are -X- _ O
obtained -X- _ O
by -X- _ O
running -X- _ O
the -X- _ O
summarization -X- _ O
script -X- _ O
provided -X- _ O
by -X- _ O
Huggingface -X- _ B-HyperparameterValue
transformers -X- _ I-HyperparameterValue
6 -X- _ I-HyperparameterValue
. -X- _ O
All -X- _ O
the -X- _ O
other -X- _ O
results -X- _ O
of -X- _ O
well -X- _ O
studied -X- _ O
for -X- _ O
language -X- _ O
modeling -X- _ O
. -X- _ O
Perplexity -X- _ B-MetricName
is -X- _ O
the -X- _ O
exponentiation -X- _ O
of -X- _ O
the -X- _ O
average -X- _ O
cross -X- _ O
entropy -X- _ O
of -X- _ O
a -X- _ O
corpus -X- _ O
. -X- _ O
LAMBDA -X- _ B-DatasetName
is -X- _ O
a -X- _ O
cloze -X- _ O
- -X- _ O
style -X- _ O
dataset -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
long -X- _ O
- -X- _ O
range -X- _ O
dependency -X- _ O
modeling -X- _ O
. -X- _ O
Each -X- _ O
example -X- _ O
is -X- _ O
a -X- _ O
passage -X- _ O
consisting -X- _ O
of -X- _ O
4 -X- _ O
- -X- _ O
5 -X- _ O
sentences -X- _ O
with -X- _ O
the -X- _ O
last -X- _ O
word -X- _ O
missing -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
required -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
last -X- _ O
word -X- _ O
of -X- _ O
the -X- _ O
passage -X- _ O
. -X- _ O
Since -X- _ O
we -X- _ O
use -X- _ O
WordPiece -X- _ B-HyperparameterValue
tokenization -X- _ B-HyperparameterName
, -X- _ O
a -X- _ O
word -X- _ O
can -X- _ O
be -X- _ O
split -X- _ O
into -X- _ O
several -X- _ O
subword -X- _ O
units -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
teacher -X- _ B-HyperparameterValue
forcing -X- _ I-HyperparameterValue
and -X- _ O
consider -X- _ O
the -X- _ O
prediction -X- _ O
correct -X- _ O
only -X- _ O
when -X- _ O
all -X- _ O
the -X- _ O
predicted -X- _ O
tokens -X- _ O
are -X- _ O
correct -X- _ O
. -X- _ O
GLUE -X- _ B-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
another -X- _ O
widely -X- _ O
- -X- _ O
used -X- _ O
NLU -X- _ B-TaskName
benchmark -X- _ O
, -X- _ O
including -X- _ O
single -X- _ O
sentence -X- _ O
tasks -X- _ O
( -X- _ O
e.g. -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
) -X- _ O
and -X- _ O
sentence -X- _ O
pair -X- _ O
tasks -X- _ O
( -X- _ O
e.g. -X- _ O
text -X- _ B-TaskName
similarity -X- _ I-TaskName
( -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Dagan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
benchmark -X- _ O
is -X- _ O
usually -X- _ O
considered -X- _ O
as -X- _ O
less -X- _ O
challenging -X- _ O
than -X- _ O
Super -X- _ B-DatasetName
- -X- _ I-DatasetName
GLUE -X- _ I-DatasetName
. -X- _ O
SQuAD -X- _ B-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016(Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
an -X- _ O
extractive -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
benchmark -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
compare -X- _ O
GLM -X- _ B-MethodName
with -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
two -X- _ O
benchmarks -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
question -X- _ B-TaskName
generation -X- _ I-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
1.1 -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
follow -X- _ O
the -X- _ O
dataset -X- _ B-HyperparameterName
split -X- _ I-HyperparameterName
of -X- _ O
( -X- _ O
Du -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
optimizer -X- _ B-HyperparameterName
hyperparameters -X- _ I-HyperparameterName
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
those -X- _ O
of -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
. -X- _ O
The -X- _ O
maximum -X- _ B-HyperparameterName
passage -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
464 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
question -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
48 -X- _ B-HyperparameterValue
. -X- _ O
During -X- _ O
decoding -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
beam -X- _ B-HyperparameterValue
search -X- _ I-HyperparameterValue
with -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
5 -X- _ B-HyperparameterValue
and -X- _ O
tweak -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
length -X- _ O
penalty -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
evaluation -X- _ O
metrics -X- _ O
are -X- _ O
the -X- _ O
scores -X- _ O
of -X- _ O
BLEU-1 -X- _ B-MetricName
, -X- _ O
BLEU-2 -X- _ B-MetricName
, -X- _ O
BLEU-3 -X- _ B-MetricName
, -X- _ O
BLEU-4 -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
METEOR -X- _ B-MetricName
( -X- _ O
Denkowski -X- _ O
and -X- _ O
Lavie -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
Rouge -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
has -X- _ O
a -X- _ O
peak -X- _ O
value -X- _ O
of -X- _ O
3e-5 -X- _ B-HyperparameterValue
, -X- _ O
warmup -X- _ B-HyperparameterName
over -X- _ O
the -X- _ O
6 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
training -X- _ I-HyperparameterValue
steps -X- _ I-HyperparameterValue
and -X- _ O
a -X- _ O
linear -X- _ B-HyperparameterValue
decay -X- _ I-HyperparameterValue
. -X- _ O
We -X- _ O
also -X- _ O
use -X- _ O
label -X- _ B-HyperparameterName
smoothing -X- _ I-HyperparameterName
with -X- _ O
rate -X- _ O
0.1 -X- _ B-HyperparameterValue
( -X- _ O
Pereyra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
maximum -X- _ B-HyperparameterName
document -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
192 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
summary -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
32 -X- _ B-HyperparameterValue
. -X- _ O
During -X- _ O
decoding -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
beam -X- _ B-HyperparameterValue
search -X- _ I-HyperparameterValue
with -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
5 -X- _ B-HyperparameterValue
and -X- _ O
remove -X- _ O
repeated -X- _ O
trigrams -X- _ O
. -X- _ O
We -X- _ O
tweak -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
length -X- _ O
penalty -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
evaluation -X- _ O
metrics -X- _ O
are -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
of -X- _ O
Rouge-1 -X- _ B-MetricName
, -X- _ O
Rouge-2 -X- _ B-MetricName
, -X- _ O
and -X- _ O
Rouge -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
baseline -X- _ O
classifiers -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
standard -X- _ O
practice -X- _ O
to -X- _ O
concatenate -X- _ O
the -X- _ O
input -X- _ O
parts -X- _ O
of -X- _ O
each -X- _ O
task -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
premise -X- _ O
and -X- _ O
hypothesis -X- _ O
for -X- _ O
textual -X- _ B-TaskName
entailment -X- _ I-TaskName
, -X- _ O
or -X- _ O
the -X- _ O
passage -X- _ O
, -X- _ O
question -X- _ B-TaskName
and -X- _ I-TaskName
answer -X- _ I-TaskName
for -X- _ O
ReCORD -X- _ O
and -X- _ O
MultiRC -X- _ O
) -X- _ O
and -X- _ O
add -X- _ O
a -X- _ O
classification -X- _ B-HyperparameterName
layer -X- _ I-HyperparameterName
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
representation -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
implemented -X- _ O
cloze -X- _ O
- -X- _ O
style -X- _ O
finetuning -X- _ O
for -X- _ O
the -X- _ O
other -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
performance -X- _ O
was -X- _ O
usually -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
standard -X- _ O
classifier -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
ablation -X- _ O
study -X- _ O
. -X- _ O
Models -X- _ O
with -X- _ O
blank -X- _ O
- -X- _ O
infilling -X- _ O
objectives -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
T5 -X- _ B-MethodName
and -X- _ O
our -X- _ O
GLM -X- _ B-MethodName
, -X- _ O
benefits -X- _ O
more -X- _ O
from -X- _ O
converting -X- _ O
the -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
into -X- _ O
cloze -X- _ B-TaskName
questions -X- _ I-TaskName
. -X- _ O
Thus -X- _ O
for -X- _ O
T5 -X- _ B-MethodName
and -X- _ O
GLM -X- _ B-MethodName
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
performance -X- _ O
after -X- _ O
such -X- _ O
conversion -X- _ O
in -X- _ O
our -X- _ O
main -X- _ O
results -X- _ O
. -X- _ O
Fot -X- _ O
the -X- _ O
text -X- _ O
summarization -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
dataset -X- _ O
Gigaword -X- _ B-DatasetName
( -X- _ O
Rush -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
for -X- _ O
model -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
and -X- _ O
evaluation -X- _ O
. -X- _ O
We -X- _ O
finetune -X- _ O
GLM -X- _ B-MethodName
LARGE -X- _ I-MethodName
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
for -X- _ O
4 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
AdamW -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
. -X- _ O

When -X- _ O
finetuning -X- _ O
GLM -X- _ B-MethodName
on -X- _ O
the -X- _ O
SuperGLUE -X- _ B-DatasetName
tasks -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
the -X- _ O
input -X- _ O
using -X- _ O
the -X- _ O
cloze -X- _ O
questions -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
and -X- _ O
replace -X- _ O
the -X- _ O
blank -X- _ O
with -X- _ O
a -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
generating -X- _ O
each -X- _ O
answer -X- _ O
candidate -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
5 -X- _ O
single -X- _ O
- -X- _ O
token -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
score -X- _ O
is -X- _ O
defined -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
logit -X- _ O
of -X- _ O
the -X- _ O
verbalizer -X- _ O
token -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
3 -X- _ O
multi -X- _ O
- -X- _ O
token -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
log -X- _ O
- -X- _ O
probabilities -X- _ O
of -X- _ O
the -X- _ O
verbalizer -X- _ O
tokens -X- _ O
. -X- _ O
Thanks -X- _ O
to -X- _ O
the -X- _ O
autoregressive -X- _ O
blank -X- _ O
infilling -X- _ O
mechanism -X- _ O
we -X- _ O
proposed -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
all -X- _ O
the -X- _ O
log -X- _ O
- -X- _ O
probabilities -X- _ O
in -X- _ O
one -X- _ O
pass -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
cross -X- _ B-HyperparameterValue
entropy -X- _ I-HyperparameterValue
loss -X- _ B-HyperparameterName
using -X- _ O
the -X- _ O
groundtruth -X- _ O
label -X- _ O
and -X- _ O
update -X- _ O
the -X- _ O
model -X- _ O
parameters -X- _ O
. -X- _ O

Blank -X- _ B-MethodName
Language -X- _ I-MethodName
Modeling -X- _ I-MethodName
. -X- _ O
Donahue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
also -X- _ O
study -X- _ O
blanking -X- _ O
infilling -X- _ O
models -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
their -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
language -X- _ O
models -X- _ O
with -X- _ O
blank -X- _ O
infilling -X- _ O
objectives -X- _ O
and -X- _ O
evaluate -X- _ O
their -X- _ O
performance -X- _ O
in -X- _ O
downstream -X- _ O
NLU -X- _ B-TaskName
and -X- _ O
generation -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
GLM -X- _ B-MethodName
is -X- _ O
a -X- _ O
general -X- _ O
pretraining -X- _ O
framework -X- _ O
for -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
and -X- _ I-TaskName
generation -X- _ I-TaskName
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
can -X- _ O
be -X- _ O
formulated -X- _ O
as -X- _ O
conditional -X- _ B-TaskName
generation -X- _ I-TaskName
tasks -X- _ I-TaskName
, -X- _ O
and -X- _ O
therefore -X- _ O
solvable -X- _ O
by -X- _ O
autoregressive -X- _ O
models -X- _ O
. -X- _ O
GLM -X- _ B-MethodName
unifies -X- _ O
the -X- _ O
pretraining -X- _ O
objectives -X- _ O
for -X- _ O
different -X- _ O
tasks -X- _ O
as -X- _ O
autoregressive -X- _ O
blank -X- _ O
infilling -X- _ O
, -X- _ O
with -X- _ O
mixed -X- _ O
attention -X- _ O
masks -X- _ O
and -X- _ O
the -X- _ O
novel -X- _ O
2D -X- _ B-HyperparameterValue
position -X- _ I-HyperparameterValue
encodings -X- _ I-HyperparameterValue
. -X- _ O
Empirically -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
GLM -X- _ B-MethodName
outperforms -X- _ O
previous -X- _ O
methods -X- _ O
for -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
and -X- _ O
can -X- _ O
effectively -X- _ O
share -X- _ O
parameters -X- _ O
for -X- _ O
different -X- _ O
tasks -X- _ O
. -X- _ O
The -X- _ O
hyperparameters -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
settings -X- _ O
are -X- _ O
summarized -X- _ O
in -X- _ O
Table -X- _ O
7.Our -X- _ O
pretraining -X- _ O
implementation -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
Megatron -X- _ B-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
( -X- _ O
Shoeybi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
Deep -X- _ B-MethodName
- -X- _ I-MethodName
Speed -X- _ I-MethodName
( -X- _ O
Rasley -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
include -X- _ O
our -X- _ O
code -X- _ O
in -X- _ O
the -X- _ O
supplementary -X- _ O
material -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
size -X- _ O
limit -X- _ O
of -X- _ O
supplementary -X- _ O
material -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
not -X- _ O
include -X- _ O
the -X- _ O
pretrained -X- _ O
models -X- _ O
, -X- _ O
but -X- _ O
will -X- _ O
make -X- _ O
them -X- _ O
public -X- _ O
available -X- _ O
in -X- _ O
the -X- _ O
future -X- _ O
. -X- _ O
The -X- _ O
SuperGLUE -X- _ B-DatasetName
benchmark -X- _ O
consists -X- _ O
of -X- _ O
8 -X- _ O
NLU -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
formulate -X- _ O
them -X- _ O
as -X- _ O
blank -X- _ B-TaskName
infilling -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
following -X- _ O
( -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
Table -X- _ O
8 -X- _ O
shows -X- _ O
the -X- _ O
cloze -X- _ O
questions -X- _ O
and -X- _ O
verbalizers -X- _ O
we -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
For -X- _ O
3 -X- _ O
tasks -X- _ O
( -X- _ O
ReCoRD -X- _ B-DatasetName
, -X- _ O
COPA -X- _ B-DatasetName
, -X- _ O
and -X- _ O
WSC -X- _ B-DatasetName
) -X- _ O
, -X- _ O
the -X- _ O
answer -X- _ O
may -X- _ O
consist -X- _ O
of -X- _ O
multiple -X- _ O
tokens -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
other -X- _ O
5 -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
answer -X- _ O
is -X- _ O
always -X- _ O
a -X- _ O
single -X- _ O
token -X- _ O
. -X- _ O

NLU -X- _ B-TaskName
as -X- _ O
Generation -X- _ O
. -X- _ O
Previously -X- _ O
, -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
complete -X- _ O
classification -X- _ B-TaskName
tasks -X- _ O
for -X- _ O
NLU -X- _ B-TaskName
with -X- _ O
linear -X- _ O
classifiers -X- _ O
on -X- _ O
the -X- _ O
learned -X- _ O
representations -X- _ O
. -X- _ O
GPT-2 -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
and -X- _ O
GPT-3 -X- _ B-MethodName
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
generative -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
complete -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
such -X- _ O
as -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
by -X- _ O
directly -X- _ O
predicting -X- _ O
the -X- _ O
correct -X- _ O
answers -X- _ O
without -X- _ O
finetuning -X- _ O
, -X- _ O
given -X- _ O
task -X- _ O
instructions -X- _ O
or -X- _ O
a -X- _ O
few -X- _ O
labeled -X- _ O
examples -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
generative -X- _ O
models -X- _ O
require -X- _ O
much -X- _ O
more -X- _ O
parameters -X- _ O
to -X- _ O
work -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
limit -X- _ O
of -X- _ O
unidirectional -X- _ O
attention -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
PET -X- _ O
( -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2020a -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
proposes -X- _ O
to -X- _ O
reformulate -X- _ O
input -X- _ O
examples -X- _ O
as -X- _ O
cloze -X- _ B-TaskName
questions -X- _ I-TaskName
with -X- _ O
patterns -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
pretraining -X- _ O
corpus -X- _ O
in -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
. -X- _ O
It -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
that -X- _ O
combined -X- _ O
with -X- _ O
gradient -X- _ O
- -X- _ O
based -X- _ O
finetuning -X- _ O
, -X- _ O
PET -X- _ O
can -X- _ O
achieve -X- _ O
better -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
than -X- _ O
GPT-3 -X- _ B-MethodName
while -X- _ O
requiring -X- _ O
only -X- _ O
0.1 -X- _ O
% -X- _ O
of -X- _ O
its -X- _ O
parameters -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
Athiwaratkun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Paolini -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
convert -X- _ O
structured -X- _ B-TaskName
prediction -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
sequence -X- _ B-TaskName
tagging -X- _ I-TaskName
and -X- _ O
relation -X- _ B-TaskName
extraction -X- _ I-TaskName
, -X- _ O
to -X- _ O
sequence -X- _ B-TaskName
generation -X- _ I-TaskName
tasks -X- _ O
. -X- _ O

Among -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
models -X- _ O
, -X- _ O
BART -X- _ B-MethodName
conducts -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
by -X- _ O
feeding -X- _ O
the -X- _ O
same -X- _ O
input -X- _ O
into -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
, -X- _ O
and -X- _ O
taking -X- _ O
the -X- _ O
final -X- _ O
hidden -X- _ O
states -X- _ O
of -X- _ O
the -X- _ O
decoder -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
T5 -X- _ B-MethodName
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
formulates -X- _ O
most -X- _ O
language -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
framework -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
both -X- _ O
models -X- _ O
require -X- _ O
more -X- _ O
parameters -X- _ O
to -X- _ O
outperform -X- _ O
autoencoding -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
RoBERTa -X- _ B-MethodName
. -X- _ O
UniLM -X- _ B-MethodName
( -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Bao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
unifies -X- _ O
three -X- _ O
pretraining -X- _ O
models -X- _ O
under -X- _ O
the -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
with -X- _ O
different -X- _ O
attention -X- _ O
masks -X- _ O
. -X- _ O

( -X- _ O
1 -X- _ O
) -X- _ O
GLM -X- _ B-MethodName
consists -X- _ O
of -X- _ O
a -X- _ O
single -X- _ B-HyperparameterValue
encoder -X- _ B-HyperparameterName
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
GLM -X- _ B-MethodName
shuffles -X- _ O
the -X- _ O
masked -X- _ O
spans -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
GLM -X- _ B-MethodName
uses -X- _ O
a -X- _ O
single -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
instead -X- _ O
of -X- _ O
multiple -X- _ O
sentinel -X- _ O
tokens -X- _ O
. -X- _ O
While -X- _ O
we -X- _ O
can -X- _ O
not -X- _ O
directly -X- _ O
compare -X- _ O
GLM -X- _ B-MethodName
with -X- _ O
T5 -X- _ B-MethodName
due -X- _ O
to -X- _ O
the -X- _ O
differences -X- _ O
in -X- _ O
training -X- _ O
data -X- _ O
and -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
parameters -X- _ I-HyperparameterName
, -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Tables -X- _ O
1 -X- _ O
and -X- _ O
6 -X- _ O
have -X- _ O
demonstrated -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
GLM.Pretrained -X- _ B-MethodName
Language -X- _ O
Models -X- _ O
. -X- _ O
Pretraining -X- _ O
largescale -X- _ O
language -X- _ O
models -X- _ O
significantly -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
three -X- _ O
types -X- _ O
of -X- _ O
pretrained -X- _ O
models -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
autoencoding -X- _ O
models -X- _ O
learn -X- _ O
a -X- _ O
bidirectional -X- _ O
contextualized -X- _ O
encoder -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
via -X- _ O
denoising -X- _ O
objectives -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Joshi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
autoregressive -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
, -X- _ O
b;Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Third -X- _ O
, -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
models -X- _ O
are -X- _ O
pretrained -X- _ O
for -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
tasks -X- _ O
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Bi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
note -X- _ O
that -X- _ O
T5 -X- _ B-MethodName
is -X- _ O
pretrained -X- _ O
with -X- _ O
a -X- _ O
similar -X- _ O
blank -X- _ O
infilling -X- _ O
objective -X- _ O
. -X- _ O
GLM -X- _ B-MethodName
differs -X- _ O
in -X- _ O
three -X- _ O
aspects -X- _ O
: -X- _ O

The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O
All -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
evaluated -X- _ O
in -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
. -X- _ O
Since -X- _ O
GLM -X- _ B-MethodName
learns -X- _ O
the -X- _ O
bidirectional -X- _ O
attention -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
evaluate -X- _ O
GLM -X- _ B-MethodName
under -X- _ O
the -X- _ O
setting -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
contexts -X- _ O
are -X- _ O
encoded -X- _ O
with -X- _ O
bidirectional -X- _ O
attention -X- _ O
. -X- _ O
Without -X- _ O
generative -X- _ O
objective -X- _ O
during -X- _ O
pretraining -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
can -X- _ O
not -X- _ O
complete -X- _ O
the -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
with -X- _ O
perplexity -X- _ B-MetricName
larger -X- _ O
than -X- _ O
100 -X- _ B-MetricValue
. -X- _ O
With -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
parameters -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
Doc -X- _ I-MethodName
performs -X- _ O
worse -X- _ O
than -X- _ O
GPT -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
This -X- _ O
is -X- _ O
expected -X- _ O
since -X- _ O
GLM -X- _ B-MethodName
Doc -X- _ I-MethodName
also -X- _ O
optimizes -X- _ O
the -X- _ O
blank -X- _ O
infilling -X- _ O
objective -X- _ O
. -X- _ O
Increasing -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
parameters -X- _ B-HyperparameterName
to -X- _ O
410 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
( -X- _ O
1.25× -X- _ O
of -X- _ O
GPT -X- _ O
Large -X- _ O
) -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
performance -X- _ O
close -X- _ O
to -X- _ O
GPT -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
GLM -X- _ B-MethodName
515 -X- _ I-MethodName
M -X- _ I-MethodName
( -X- _ O
1.5× -X- _ O
of -X- _ O
GPT -X- _ O
Large -X- _ O
) -X- _ O
can -X- _ O
further -X- _ O
outperform -X- _ O
GPT -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
With -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
parameters -X- _ O
, -X- _ O
encoding -X- _ O
the -X- _ O
context -X- _ O
with -X- _ O
bidirectional -X- _ O
attention -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
language -X- _ O
modeling -X- _ O
. -X- _ O
Under -X- _ O
this -X- _ O
setting -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
410 -X- _ I-MethodName
M -X- _ I-MethodName
outperforms -X- _ O
GPT -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
This -X- _ O
is -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
GLM -X- _ B-MethodName
over -X- _ O
unidirectional -X- _ B-MethodName
GPT -X- _ I-MethodName
. -X- _ O
We -X- _ O
also -X- _ O
study -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
2D -X- _ B-HyperparameterValue
positional -X- _ I-HyperparameterValue
encoding -X- _ I-HyperparameterValue
to -X- _ O
long -X- _ B-TaskName
text -X- _ I-TaskName
generation -X- _ I-TaskName
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
removing -X- _ O
the -X- _ O
2D -X- _ B-HyperparameterValue
positional -X- _ I-HyperparameterValue
encoding -X- _ I-HyperparameterValue
leads -X- _ O
to -X- _ O
lower -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
higher -X- _ O
perplexity -X- _ B-MetricName
in -X- _ O
language -X- _ O
modeling -X- _ O
. -X- _ O
Summary -X- _ O
. -X- _ O
Above -X- _ O
all -X- _ O
, -X- _ O
we -X- _ O
conclude -X- _ O
that -X- _ O
GLM -X- _ B-MethodName
effectively -X- _ O
shares -X- _ O
model -X- _ O
parameters -X- _ O
across -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
and -X- _ O
generation -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
achieving -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
a -X- _ O
standalone -X- _ B-MethodName
BERT -X- _ I-MethodName
, -X- _ O
encoder -X- _ B-MethodName
- -X- _ I-MethodName
decoder -X- _ I-MethodName
, -X- _ O
or -X- _ O
GPT -X- _ B-MethodName
model -X- _ I-MethodName
. -X- _ O
Table -X- _ O
6 -X- _ O
shows -X- _ O
our -X- _ O
ablation -X- _ O
analysis -X- _ O
for -X- _ O
GLM -X- _ B-MethodName
. -X- _ O
First -X- _ O
, -X- _ O
to -X- _ O
provide -X- _ O
an -X- _ O
apple -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
apple -X- _ O
comparison -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
Large -X- _ I-MethodName
model -X- _ O
with -X- _ O
our -X- _ O
implementation -X- _ O
, -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
hyperparameters -X- _ O
( -X- _ O
row -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
is -X- _ O
slightly -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
official -X- _ O
BERT -X- _ B-MethodName
Large -X- _ I-MethodName
and -X- _ O
significantly -X- _ O
worse -X- _ O
than -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
It -X- _ O
confirms -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
GLM -X- _ B-MethodName
over -X- _ O
Masked -X- _ O
LM -X- _ O
pretraining -X- _ O
on -X- _ O
NLU -X- _ O
tasks -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
SuperGLUE -X- _ B-DatasetName
performance -X- _ O
of -X- _ O
GLM -X- _ B-MethodName
finetuned -X- _ O
as -X- _ O
sequence -X- _ O
classifiers -X- _ O
( -X- _ O
row -X- _ O
5 -X- _ O
) -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
clozestyle -X- _ O
finetuning -X- _ O
( -X- _ O
row -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
cloze -X- _ O
- -X- _ O
style -X- _ O
finetuning -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
benefits -X- _ O
from -X- _ O
the -X- _ O
autoregressive -X- _ O
pretraining -X- _ O
. -X- _ O
Especially -X- _ O
on -X- _ O
ReCoRD -X- _ B-DatasetName
and -X- _ O
WSC -X- _ B-DatasetName
, -X- _ O
where -X- _ O
the -X- _ O
verbalizer -X- _ O
consists -X- _ O
of -X- _ O
multiple -X- _ O
tokens -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
This -X- _ O
demonstrates -X- _ O
GLM -X- _ B-MethodName
's -X- _ O
advantage -X- _ O
in -X- _ O
handling -X- _ O
variable -X- _ O
- -X- _ O
length -X- _ O
blank -X- _ O
. -X- _ O
Another -X- _ O
observation -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
cloze -X- _ O
formulation -X- _ O
is -X- _ O
critical -X- _ O
for -X- _ O
GLM -X- _ B-MethodName
's -X- _ O
performance -X- _ O
on -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
large -X- _ O
model -X- _ O
, -X- _ O
clozestyle -X- _ O
finetuning -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
by -X- _ O
7 -X- _ B-MetricValue
points -X- _ I-MetricValue
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
GLM -X- _ B-MethodName
variants -X- _ O
with -X- _ O
different -X- _ O
pretraining -X- _ B-HyperparameterName
designs -X- _ I-HyperparameterName
to -X- _ O
understand -X- _ O
their -X- _ O
importance -X- _ O
. -X- _ O
Row -X- _ O
6 -X- _ O
shows -X- _ O
that -X- _ O
removing -X- _ O
the -X- _ O
span -X- _ O
shuffling -X- _ O
( -X- _ O
always -X- _ O
predicting -X- _ O
the -X- _ O
masked -X- _ O
spans -X- _ O
from -X- _ O
left -X- _ O
to -X- _ O
right -X- _ O
) -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
severe -X- _ O
performance -X- _ O
drop -X- _ O
on -X- _ O
SuperGLUE -X- _ B-DatasetName
. -X- _ O
Row -X- _ O
7 -X- _ O
uses -X- _ O
different -X- _ O
sentinel -X- _ O
tokens -X- _ O
instead -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
to -X- _ O
represent -X- _ O
different -X- _ O
masked -X- _ O
spans -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
standard -X- _ B-MethodName
GLM -X- _ I-MethodName
. -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
it -X- _ O
wastes -X- _ O
some -X- _ O
modeling -X- _ O
capacity -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
different -X- _ O
sentinel -X- _ O
tokens -X- _ O
which -X- _ O
are -X- _ O
not -X- _ O
used -X- _ O
in -X- _ O
downstream -X- _ O
tasks -X- _ O
with -X- _ O
only -X- _ O
one -X- _ O
blank -X- _ O
. -X- _ O
In -X- _ O
Figure -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
removing -X- _ O
the -X- _ O
second -X- _ O
dimension -X- _ O
of -X- _ O
2D -X- _ O
positional -X- _ O
encoding -X- _ O
hurts -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
long -X- _ B-TaskName
text -X- _ I-TaskName
generation -X- _ I-TaskName
. -X- _ O

Text -X- _ B-TaskName
Infilling -X- _ I-TaskName
. -X- _ O
Text -X- _ B-TaskName
infilling -X- _ I-TaskName
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
predicting -X- _ O
missing -X- _ O
spans -X- _ O
of -X- _ O
text -X- _ O
which -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
surrounding -X- _ O
context -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Donahue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
GLM -X- _ B-MethodName
is -X- _ O
trained -X- _ O
with -X- _ O
an -X- _ O
autoregressive -X- _ O
blank -X- _ O
infilling -X- _ O
objective -X- _ O
, -X- _ O
thus -X- _ O
can -X- _ O
straightforwardly -X- _ O
solve -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
GLM -X- _ B-MethodName
on -X- _ O
the -X- _ O
Yahoo -X- _ B-DatasetName
Answers -X- _ I-DatasetName
dataset -X- _ I-DatasetName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
compare -X- _ O
it -X- _ O
with -X- _ O
Blank -X- _ B-MethodName
Language -X- _ I-MethodName
Model -X- _ I-MethodName
( -X- _ O
BLM -X- _ B-MethodName
) -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
specifically -X- _ O
designed -X- _ O
model -X- _ O
for -X- _ O
text -X- _ B-TaskName
infilling -X- _ I-TaskName
. -X- _ O
From -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
outperforms -X- _ O
previous -X- _ O
methods -X- _ O
by -X- _ O
large -X- _ O
margins -X- _ O
( -X- _ O
1.3 -X- _ B-MetricValue
to -X- _ O
3.9 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
) -X- _ O
and -X- _ O
achieves -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
result -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
. -X- _ O
We -X- _ O
notice -X- _ O
that -X- _ O
GLM -X- _ B-MethodName
Doc -X- _ I-MethodName
slightly -X- _ O
underperforms -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
our -X- _ O
observations -X- _ O
in -X- _ O
the -X- _ O
seq2seq -X- _ O
experiments -X- _ O
. -X- _ O
Language -X- _ B-TaskName
Modeling -X- _ I-TaskName
. -X- _ O
Most -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
datasets -X- _ O
such -X- _ O
as -X- _ O
WikiText103 -X- _ B-DatasetName
are -X- _ O
constructed -X- _ O
from -X- _ O
Wikipedia -X- _ O
documents -X- _ O
, -X- _ O
which -X- _ O
our -X- _ O
pretraining -X- _ O
dataset -X- _ O
already -X- _ O
contains -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
perplexity -X- _ B-MetricName
on -X- _ O
a -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
our -X- _ O
pretraining -X- _ O
dataset -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
about -X- _ O
20 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
tokens -X- _ I-HyperparameterValue
, -X- _ O
denoted -X- _ O
as -X- _ O
BookWiki -X- _ B-DatasetName
. -X- _ O
We -X- _ O
also -X- _ O
evaluate -X- _ O
GLM -X- _ B-MethodName
on -X- _ O
the -X- _ O
LAMBADA -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Paperno -X- _ O
The -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
final -X- _ O
word -X- _ O
of -X- _ O
a -X- _ O
passage -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
baseline -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
GPT -X- _ B-MethodName
Large -X- _ I-MethodName
model -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b;Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
and -X- _ O
tokenization -X- _ O
as -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O

The -X- _ O
results -X- _ O
for -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
BookCorpus -X- _ B-DatasetName
and -X- _ O
Wikipedia -X- _ B-DatasetName
are -X- _ O
shown -X- _ O
in -X- _ O
Tables -X- _ O
3 -X- _ O
and -X- _ O
4 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
can -X- _ O
achieve -X- _ O
performance -X- _ O
matching -X- _ O
the -X- _ O
other -X- _ O
pretraining -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
generation -X- _ O
tasks -X- _ O
. -X- _ O
GLM -X- _ B-MethodName
Sent -X- _ I-MethodName
can -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
while -X- _ O
GLM -X- _ B-MethodName
Doc -X- _ I-MethodName
performs -X- _ O
slightly -X- _ O
worse -X- _ O
than -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
documentlevel -X- _ O
objective -X- _ O
, -X- _ O
which -X- _ O
teaches -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
extend -X- _ O
the -X- _ O
given -X- _ O
contexts -X- _ O
, -X- _ O
is -X- _ O
less -X- _ O
helpful -X- _ O
to -X- _ O
conditional -X- _ B-TaskName
generation -X- _ I-TaskName
, -X- _ O
which -X- _ O
aims -X- _ O
to -X- _ O
extract -X- _ O
useful -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
context -X- _ O
. -X- _ O
Increasing -X- _ B-MethodName
GLM -X- _ I-MethodName
Doc -X- _ I-MethodName
's -X- _ O
parameters -X- _ O
to -X- _ O
410 -X- _ O
M -X- _ O
leads -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
both -X- _ O
tasks -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
for -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
larger -X- _ O
corpora -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
GLM -X- _ B-MethodName
RoBERTa -X- _ I-MethodName
can -X- _ O
achieve -X- _ O
performance -X- _ O
matching -X- _ O
the -X- _ O
seq2seq -X- _ B-MethodName
BART -X- _ I-MethodName
model -X- _ O
, -X- _ O
and -X- _ O
outperform -X- _ O
T5 -X- _ B-MethodName
and -X- _ O
UniLMv2 -X- _ B-MethodName
. -X- _ O

Considering -X- _ O
the -X- _ O
available -X- _ O
baseline -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Gigaword -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Rush -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
for -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
and -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
1.1 -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
for -X- _ O
question -X- _ B-TaskName
generation -X- _ I-TaskName
( -X- _ O
Du -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
benchmarks -X- _ O
for -X- _ O
models -X- _ O
pretrained -X- _ O
on -X- _ O
BookCorpus -X- _ B-DatasetName
and -X- _ O
Wikipedia -X- _ B-DatasetName
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DailyMail -X- _ I-DatasetName
( -X- _ O
See -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
XSum -X- _ B-DatasetName
( -X- _ O
Narayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
datasets -X- _ O
for -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
as -X- _ O
the -X- _ O
benchmarks -X- _ O
for -X- _ O
models -X- _ O
pretrained -X- _ O
on -X- _ O
larger -X- _ O
corpora -X- _ O
. -X- _ O

Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
most -X- _ O
tasks -X- _ O
with -X- _ O
either -X- _ O
base -X- _ O
or -X- _ O
large -X- _ O
architecture -X- _ O
. -X- _ O
The -X- _ O
only -X- _ O
exception -X- _ O
is -X- _ O
WiC -X- _ B-TaskName
( -X- _ O
word -X- _ B-TaskName
sense -X- _ I-TaskName
disambiguation -X- _ I-TaskName
) -X- _ O
. -X- _ O
On -X- _ O
average -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
Base -X- _ I-MethodName
scores -X- _ O
4.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
Base -X- _ I-MethodName
, -X- _ O
and -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
scores -X- _ O
5.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O
It -X- _ O
clearly -X- _ O
demonstrates -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
in -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
setting -X- _ O
of -X- _ O
RoBERTa -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
GLM -X- _ B-MethodName
RoBERTa -X- _ I-MethodName
can -X- _ O
still -X- _ O
achieve -X- _ O
improvements -X- _ O
over -X- _ O
the -X- _ O
baselines -X- _ O
, -X- _ O
but -X- _ O
with -X- _ O
a -X- _ O
smaller -X- _ O
margin -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
RoBERTa -X- _ I-MethodName
outperforms -X- _ O
T5 -X- _ B-MethodName
Large -X- _ I-MethodName
but -X- _ O
is -X- _ O
only -X- _ O
half -X- _ O
its -X- _ O
size -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
BART -X- _ B-MethodName
does -X- _ O
not -X- _ O
perform -X- _ O
well -X- _ O
on -X- _ O
the -X- _ O
challenging -X- _ O
SuperGLUE -X- _ B-DatasetName
benchmark -X- _ O
. -X- _ O
We -X- _ O
conjecture -X- _ O
this -X- _ O
can -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
the -X- _ O
low -X- _ O
parameter -X- _ O
efficiency -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
architecture -X- _ O
and -X- _ O
the -X- _ O
denoising -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
objective -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
GLM -X- _ B-MethodName
's -X- _ O
performance -X- _ O
in -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
setting -X- _ O
( -X- _ O
Section -X- _ O
2.1 -X- _ O
) -X- _ O
. -X- _ O
Within -X- _ O
one -X- _ O
training -X- _ O
batch -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
short -X- _ O
spans -X- _ O
and -X- _ O
longer -X- _ O
spans -X- _ O
( -X- _ O
document -X- _ O
- -X- _ O
level -X- _ O
or -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
) -X- _ O
with -X- _ O
equal -X- _ O
chances -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
model -X- _ O
for -X- _ O
NLU -X- _ B-TaskName
, -X- _ O
seq2seq -X- _ B-TaskName
, -X- _ O
blank -X- _ B-TaskName
infilling -X- _ I-TaskName
, -X- _ O
and -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
language -X- _ O
modeling -X- _ O
. -X- _ O
SuperGLUE -X- _ B-DatasetName
. -X- _ O
For -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
SuperGLUE -X- _ B-DatasetName
benchmark -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
Sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Sequence -X- _ O
. -X- _ O

For -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
GLM -X- _ B-MethodName
Base -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
we -X- _ O
choose -X- _ O
BERT -X- _ B-MethodName
Base -X- _ I-MethodName
and -X- _ O
BERT -X- _ B-MethodName
Large -X- _ I-MethodName
as -X- _ O
our -X- _ O
baselines -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
pretrained -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
corpus -X- _ O
and -X- _ O
for -X- _ O
a -X- _ O
similar -X- _ O
amount -X- _ O
of -X- _ O
time -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
standard -X- _ O
finetuning -X- _ O
( -X- _ O
i.e. -X- _ O
classification -X- _ O
on -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
representation -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
cloze -X- _ B-TaskName
questions -X- _ I-TaskName
is -X- _ O
reported -X- _ O
in -X- _ O
Section -X- _ O
3.4 -X- _ O
. -X- _ O
To -X- _ O
compare -X- _ O
with -X- _ O
GLM -X- _ B-MethodName
RoBERTa -X- _ B-MethodName
, -X- _ O
we -X- _ O
choose -X- _ O
T5 -X- _ B-MethodName
, -X- _ O
BART -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
and -X- _ O
RoBERTa -X- _ B-MethodName
Large -X- _ I-MethodName
as -X- _ O
our -X- _ O
baselines -X- _ O
. -X- _ O
T5 -X- _ B-MethodName
has -X- _ O
no -X- _ O
direct -X- _ O
match -X- _ O
in -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
so -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
both -X- _ O
T5 -X- _ B-MethodName
Base -X- _ I-MethodName
( -X- _ O
220 -X- _ O
M -X- _ O
parameters -X- _ O
) -X- _ O
and -X- _ O
T5 -X- _ B-MethodName
Large -X- _ I-MethodName
( -X- _ O
770 -X- _ O
M -X- _ O
parameters -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
the -X- _ O
other -X- _ O
baselines -X- _ O
are -X- _ O
of -X- _ O
similar -X- _ O
size -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
Large -X- _ I-MethodName
. -X- _ O

To -X- _ O
compare -X- _ O
with -X- _ O
SOTA -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
train -X- _ O
a -X- _ O
Large -X- _ O
- -X- _ O
sized -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
, -X- _ O
tokenization -X- _ O
, -X- _ O
and -X- _ O
hyperparameters -X- _ O
as -X- _ O
RoBERTa -X- _ B-MethodName
, -X- _ O
denoted -X- _ O
as -X- _ O
GLM -X- _ B-MethodName
RoBERTa -X- _ I-MethodName
. -X- _ O
Due -X- _ O
to -X- _ O
resource -X- _ O
limitations -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
pretrain -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
250,000 -X- _ B-HyperparameterValue
steps -X- _ I-HyperparameterValue
, -X- _ O
which -X- _ O
are -X- _ O
half -X- _ O
of -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
BART -X- _ B-MethodName
's -X- _ O
training -X- _ O
steps -X- _ O
and -X- _ O
close -X- _ O
to -X- _ O
T5 -X- _ B-MethodName
in -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
trained -X- _ I-HyperparameterName
tokens -X- _ I-HyperparameterName
. -X- _ O
More -X- _ O
experiment -X- _ O
details -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.To -X- _ O
evaluate -X- _ O
our -X- _ O
pretrained -X- _ O
GLM -X- _ B-MethodName
models -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
SuperGLUE -X- _ B-DatasetName
bench -X- _ O
- -X- _ O
mark -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
standard -X- _ B-MetricName
metrics -X- _ I-MetricName
. -X- _ O
SuperGLUE -X- _ B-DatasetName
consists -X- _ O
of -X- _ O
8 -X- _ O
challenging -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
We -X- _ O
reformulate -X- _ O
the -X- _ O
classification -X- _ B-TaskName
tasks -X- _ O
as -X- _ O
blank -X- _ B-TaskName
infilling -X- _ I-TaskName
with -X- _ O
human -X- _ O
- -X- _ O
crafted -X- _ O
cloze -X- _ B-TaskName
questions -X- _ I-TaskName
, -X- _ O
following -X- _ O
PET -X- _ O
( -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
finetune -X- _ O
the -X- _ O
pretrained -X- _ O
GLM -X- _ B-MethodName
models -X- _ O
on -X- _ O
each -X- _ O
task -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
2.3 -X- _ O
. -X- _ O
The -X- _ O
cloze -X- _ B-TaskName
questions -X- _ I-TaskName
and -X- _ O
other -X- _ O
details -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
B.1 -X- _ O
. -X- _ O

For -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
pretraining -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
two -X- _ O
Largesized -X- _ O
models -X- _ O
with -X- _ O
a -X- _ O
mixture -X- _ O
of -X- _ O
the -X- _ O
blank -X- _ O
infilling -X- _ O
objective -X- _ O
and -X- _ O
the -X- _ O
document -X- _ O
- -X- _ O
level -X- _ O
or -X- _ O
sentencelevel -X- _ O
objective -X- _ O
, -X- _ O
denoted -X- _ O
as -X- _ O
GLM -X- _ B-MethodName
Doc -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
Sent -X- _ I-MethodName
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
two -X- _ O
larger -X- _ O
GLM -X- _ B-MethodName
models -X- _ O
of -X- _ O
410 -X- _ O
M -X- _ O
( -X- _ O
30 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
, -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
1024 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
16 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
) -X- _ O
and -X- _ O
515 -X- _ O
M -X- _ O
( -X- _ O
30 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
, -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
1152 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
18 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
) -X- _ O
parameters -X- _ O
with -X- _ O
documentlevel -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
pretraining -X- _ O
, -X- _ O
denoted -X- _ O
as -X- _ O
GLM -X- _ B-MethodName
410 -X- _ I-MethodName
M -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
515 -X- _ I-MethodName
M -X- _ I-MethodName
. -X- _ O

Comparison -X- _ O
with -X- _ O
UniLM -X- _ B-MethodName
( -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
UniLM -X- _ B-MethodName
combines -X- _ O
different -X- _ O
pretraining -X- _ O
objectives -X- _ O
under -X- _ O
the -X- _ O
autoencoding -X- _ O
framework -X- _ O
by -X- _ O
changing -X- _ O
the -X- _ O
attention -X- _ O
mask -X- _ O
among -X- _ O
bidirectional -X- _ O
, -X- _ O
unidirectional -X- _ O
, -X- _ O
and -X- _ O
cross -X- _ O
attention -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
UniLM -X- _ B-MethodName
always -X- _ O
replaces -X- _ O
masked -X- _ O
spans -X- _ O
with -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
tokens -X- _ O
, -X- _ O
which -X- _ O
limits -X- _ O
its -X- _ O
ability -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
dependencies -X- _ O
between -X- _ O
the -X- _ O
masked -X- _ O
spans -X- _ O
and -X- _ O
their -X- _ O
context -X- _ O
. -X- _ O
GLM -X- _ B-MethodName
feeds -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
token -X- _ O
and -X- _ O
autoregressively -X- _ O
generates -X- _ O
the -X- _ O
next -X- _ O
token -X- _ O
. -X- _ O
Finetuning -X- _ O
UniLM -X- _ B-MethodName
on -X- _ O
downstream -X- _ O
generation -X- _ O
tasks -X- _ O
also -X- _ O
relies -X- _ O
on -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
less -X- _ O
efficient -X- _ O
. -X- _ O
UniLMv2 -X- _ B-MethodName
( -X- _ O
Bao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
adopts -X- _ O
partially -X- _ O
autoregressive -X- _ O
modeling -X- _ O
for -X- _ O
generation -X- _ O
tasks -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
autoencoding -X- _ O
objective -X- _ O
for -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
unifies -X- _ O
NLU -X- _ B-TaskName
and -X- _ O
generation -X- _ O
tasks -X- _ O
with -X- _ O
autoregressive -X- _ O
pretraining -X- _ O
. -X- _ O
We -X- _ O
now -X- _ O
describe -X- _ O
our -X- _ O
pretraining -X- _ O
setup -X- _ O
and -X- _ O
the -X- _ O
evaluation -X- _ O
of -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
BooksCorpus -X- _ B-DatasetName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
English -X- _ B-DatasetName
Wikipedia -X- _ I-DatasetName
as -X- _ O
our -X- _ O
pretraining -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
uncased -X- _ O
wordpiece -X- _ O
tokenizer -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
30k -X- _ O
vocabulary -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
GLM -X- _ B-MethodName
Base -X- _ I-MethodName
and -X- _ O
GLM -X- _ B-MethodName
Large -X- _ I-MethodName
with -X- _ O
the -X- _ O
same -X- _ O
architectures -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
Base -X- _ I-MethodName
and -X- _ O
BERT -X- _ B-MethodName
Large -X- _ I-MethodName
, -X- _ O
containing -X- _ O
110 -X- _ O
M -X- _ O
and -X- _ O
340 -X- _ O
M -X- _ O
parameters -X- _ O
respectively -X- _ O
. -X- _ O

Comparison -X- _ O
with -X- _ O
T5 -X- _ B-MethodName
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
T5 -X- _ B-MethodName
proposes -X- _ O
a -X- _ O
similar -X- _ O
blank -X- _ O
infilling -X- _ O
objective -X- _ O
to -X- _ O
pretrain -X- _ O
an -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
Transformer -X- _ O
. -X- _ O
T5 -X- _ B-MethodName
uses -X- _ O
independent -X- _ O
positional -X- _ O
encodings -X- _ O
for -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
, -X- _ O
and -X- _ O
relies -X- _ O
on -X- _ O
multiple -X- _ O
sentinel -X- _ O
tokens -X- _ O
to -X- _ O
differentiate -X- _ O
the -X- _ O
masked -X- _ O
spans -X- _ O
. -X- _ O
In -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
only -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
sentinel -X- _ O
tokens -X- _ O
is -X- _ O
used -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
a -X- _ O
waste -X- _ O
of -X- _ O
model -X- _ O
capacity -X- _ O
and -X- _ O
inconsistency -X- _ O
between -X- _ O
pretraining -X- _ O
and -X- _ O
finetuning -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
T5 -X- _ B-MethodName
always -X- _ O
predicts -X- _ O
spans -X- _ O
in -X- _ O
a -X- _ O
fixed -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
order -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
can -X- _ O
significantly -X- _ O
outperform -X- _ O
T5 -X- _ B-MethodName
on -X- _ O
NLU -X- _ B-TaskName
and -X- _ O
seq2seq -X- _ B-TaskName
tasks -X- _ I-TaskName
with -X- _ O
fewer -X- _ O
parameters -X- _ O
and -X- _ O
data -X- _ O
, -X- _ O
as -X- _ O
stated -X- _ O
in -X- _ O
Sections -X- _ O
3.2 -X- _ O
and -X- _ O
3.3 -X- _ O
. -X- _ O

Comparison -X- _ O
with -X- _ O
XLNet -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Both -X- _ O
GLM -X- _ B-MethodName
and -X- _ O
XLNet -X- _ B-MethodName
are -X- _ O
pretrained -X- _ O
with -X- _ O
autoregressive -X- _ O
objectives -X- _ O
, -X- _ O
but -X- _ O
there -X- _ O
are -X- _ O
two -X- _ O
differences -X- _ O
between -X- _ O
them -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
XLNet -X- _ B-MethodName
uses -X- _ O
the -X- _ O
original -X- _ O
position -X- _ O
encodings -X- _ O
before -X- _ O
corruption -X- _ O
. -X- _ O
During -X- _ O
inference -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
either -X- _ O
know -X- _ O
or -X- _ O
enumerate -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
answer -X- _ O
, -X- _ O
the -X- _ O
same -X- _ O
problem -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
Second -X- _ O
, -X- _ O
XLNet -X- _ B-MethodName
uses -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stream -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
mechanism -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
right -X- _ O
- -X- _ O
shift -X- _ O
, -X- _ O
to -X- _ O
avoid -X- _ O
the -X- _ O
information -X- _ O
leak -X- _ O
within -X- _ O
Transformer -X- _ O
. -X- _ O
It -X- _ O
doubles -X- _ O
the -X- _ O
time -X- _ O
cost -X- _ O
of -X- _ O
pretraining -X- _ O
. -X- _ O

Comparison -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
pointed -X- _ O
out -X- _ O
by -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
fails -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
interdependencies -X- _ O
of -X- _ O
masked -X- _ O
tokens -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
independence -X- _ O
assumption -X- _ O
of -X- _ O
MLM -X- _ O
. -X- _ O
Another -X- _ O
disadvantage -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
not -X- _ O
fill -X- _ O
in -X- _ O
the -X- _ O
blanks -X- _ O
of -X- _ O
multiple -X- _ O
tokens -X- _ O
properly -X- _ O
. -X- _ O
To -X- _ O
infer -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
an -X- _ O
answer -X- _ O
of -X- _ O
length -X- _ O
l -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
needs -X- _ O
to -X- _ O
perform -X- _ O
l -X- _ O
consecutive -X- _ O
predictions -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
length -X- _ O
l -X- _ O
is -X- _ O
unknown -X- _ O
, -X- _ O
we -X- _ O
may -X- _ O
need -X- _ O
to -X- _ O
enumerate -X- _ O
all -X- _ O
possible -X- _ O
lengths -X- _ O
, -X- _ O
since -X- _ O
BERT -X- _ B-MethodName
needs -X- _ O
to -X- _ O
change -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
tokens -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
length -X- _ O
. -X- _ O

For -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
the -X- _ O
given -X- _ O
context -X- _ O
constitutes -X- _ O
the -X- _ O
Part -X- _ O
A -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
mask -X- _ O
token -X- _ O
appended -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
generates -X- _ O
the -X- _ O
text -X- _ O
of -X- _ O
Part -X- _ O
B -X- _ O
autoregressively -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
directly -X- _ O
apply -X- _ O
the -X- _ O
pretrained -X- _ O
GLM -X- _ B-MethodName
for -X- _ O
unconditional -X- _ B-TaskName
generation -X- _ I-TaskName
, -X- _ O
or -X- _ O
finetune -X- _ O
it -X- _ O
on -X- _ O
downstream -X- _ O
conditional -X- _ B-TaskName
generation -X- _ I-TaskName
tasks -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
discuss -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
GLM -X- _ B-MethodName
and -X- _ O
other -X- _ O
pretraining -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
are -X- _ O
mainly -X- _ O
concerned -X- _ O
with -X- _ O
how -X- _ O
they -X- _ O
can -X- _ O
be -X- _ O
adapted -X- _ O
to -X- _ O
downstream -X- _ O
blank -X- _ O
infilling -X- _ O
tasks -X- _ O
. -X- _ O

Then -X- _ O
we -X- _ O
finetune -X- _ O
GLM -X- _ B-MethodName
with -X- _ O
a -X- _ O
cross -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
entropy -X- _ I-HyperparameterValue
loss -X- _ B-HyperparameterName
( -X- _ O
see -X- _ O
Figure -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O

where -X- _ O
Y -X- _ O
is -X- _ O
the -X- _ O
label -X- _ O
set -X- _ O
. -X- _ O
Therefore -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
being -X- _ O
positive -X- _ O
or -X- _ O
negative -X- _ O
is -X- _ O
proportional -X- _ O
to -X- _ O
predicting -X- _ O
" -X- _ O
good -X- _ O
" -X- _ O
or -X- _ O
" -X- _ O
bad -X- _ O
" -X- _ O
in -X- _ O
the -X- _ O
blank -X- _ O
. -X- _ O

) -X- _ O

p(y|x -X- _ O
) -X- _ O
= -X- _ O
p(v(y)|c(x -X- _ O
) -X- _ O
) -X- _ O
y -X- _ O
∈Y -X- _ O
p(v(y -X- _ O
) -X- _ O
|c(x -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O

Instead -X- _ O
, -X- _ O
we -X- _ O
reformulate -X- _ O
NLU -X- _ B-TaskName
classification -X- _ O
tasks -X- _ O
as -X- _ O
generation -X- _ O
tasks -X- _ O
of -X- _ O
blank -X- _ O
infilling -X- _ O
, -X- _ O
following -X- _ O
PET -X- _ O
( -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
labeled -X- _ O
example -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
convert -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
x -X- _ O
to -X- _ O
a -X- _ O
cloze -X- _ O
question -X- _ O
c(x -X- _ O
) -X- _ O
via -X- _ O
a -X- _ O
pattern -X- _ O
containing -X- _ O
a -X- _ O
single -X- _ O
mask -X- _ O
token -X- _ O
. -X- _ O
The -X- _ O
pattern -X- _ O
is -X- _ O
written -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
a -X- _ O
sentiment -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ O
can -X- _ O
be -X- _ O
formulated -X- _ O
as -X- _ O
" -X- _ O
{ -X- _ O
SENTENCE -X- _ O
} -X- _ O
. -X- _ O
It -X- _ O
's -X- _ O
really -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
candidate -X- _ O
labels -X- _ O
y -X- _ O
∈ -X- _ O
Y -X- _ O
are -X- _ O
also -X- _ O
mapped -X- _ O
to -X- _ O
answers -X- _ O
to -X- _ O
the -X- _ O
cloze -X- _ O
, -X- _ O
called -X- _ O
verbalizer -X- _ O
v(y -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
sentiment -X- _ B-TaskName
classification -X- _ I-TaskName
, -X- _ O
the -X- _ O
labels -X- _ O
" -X- _ O
positive -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
negative -X- _ O
" -X- _ O
are -X- _ O
mapped -X- _ O
to -X- _ O
the -X- _ O
words -X- _ O
" -X- _ O
good -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
bad -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
conditional -X- _ O
probability -X- _ O
of -X- _ O
predicting -X- _ O
y -X- _ O
given -X- _ O
x -X- _ O
is -X- _ O

+ -X- _ O
A -X- _ O
Q -X- _ O
J -X- _ O
o -X- _ O
0 -X- _ O
q -X- _ O
7 -X- _ O
7 -X- _ O
r -X- _ O
c -X- _ O
1 -X- _ O
N -X- _ O
7 -X- _ O
+ -X- _ O
w -X- _ O
u -X- _ O
L -X- _ O
R -X- _ O
c -X- _ O
W -X- _ O
L -X- _ O
F -X- _ O
X -X- _ O
1 -X- _ O
9 -X- _ O
Y -X- _ O
3 -X- _ O
N -X- _ O
o -X- _ O
t -X- _ O
b -X- _ O
2 -X- _ O
3 -X- _ O
U -X- _ O
l -X- _ O
U -X- _ O
o -X- _ O
l -X- _ O
J -X- _ O
D -X- _ O
Q -X- _ O
s -X- _ O
m -X- _ O
Z -X- _ O
D -X- _ O
N -X- _ O
A -X- _ O
i -X- _ O
j -X- _ O
D -X- _ O
K -X- _ O
S -X- _ O
U -X- _ O
1 -X- _ O
T -X- _ O
z -X- _ O
U -X- _ O
g -X- _ O
z -X- _ O
k -X- _ O
Q -X- _ O
T -X- _ O
F -X- _ O
A -X- _ O
S -X- _ O
O -X- _ O
N -X- _ O
o -X- _ O
H -X- _ O
+ -X- _ O
R -X- _ O
+ -X- _ O
4 -X- _ O
1 -X- _ O
b -X- _ O
I -X- _ O
h -X- _ O
U -X- _ O
V -X- _ O
/ -X- _ O
F -X- _ O
o -X- _ O
P -X- _ O
E -X- _ O
u -X- _ O
L -X- _ O
H -X- _ O
q -X- _ O
M -X- _ O
t -X- _ O
p -X- _ O
R -X- _ O
D -X- _ O
H -X- _ O
S -X- _ O
R -X- _ O
r -X- _ O
p -X- _ O
p -X- _ O
B -X- _ O
4 -X- _ O
K -X- _ O
F -X- _ O
a -X- _ O
h -X- _ O
C -X- _ O
b -X- _ O
K -X- _ O
7 -X- _ O
s -X- _ O
f -X- _ O
d -X- _ O
o -X- _ O
o -X- _ O
l -X- _ O
t -X- _ O
+ -X- _ O
y -X- _ O
O -X- _ O
4 -X- _ O
M -X- _ O
w -X- _ O
S -X- _ O
b -X- _ O
0 -X- _ O
J -X- _ O
K -X- _ O
Z -X- _ O
x -X- _ O
/ -X- _ O
2 -X- _ O
a -X- _ O
f -X- _ O
L -X- _ O
y -X- _ O
Z -X- _ O
V -X- _ O
c -X- _ O
7 -X- _ O
x -X- _ O
c -X- _ O
9 -X- _ O
2 -X- _ O
K -X- _ O
H -X- _ O
A -X- _ O
a -X- _ O
E -X- _ O
6 -X- _ O
4 -X- _ O
x -X- _ O
Q -X- _ O
0 -X- _ O
q -X- _ O
1 -X- _ O
P -X- _ O
D -X- _ O
f -X- _ O
R -X- _ O
f -X- _ O
o -X- _ O
a -X- _ O
k -X- _ O
p -X- _ O
p -X- _ O
i -X- _ O
R -X- _ O
o -X- _ O
d -X- _ O
1 -X- _ O
O -X- _ O
F -X- _ O
U -X- _ O
k -X- _ O
Q -X- _ O
7 -X- _ O
q -X- _ O
M -X- _ O
u -X- _ O
a -X- _ O
R -X- _ O
n -X- _ O
K -X- _ O
U -X- _ O
U -X- _ O
y -X- _ O
U -X- _ O
n -X- _ O
4 -X- _ O
1 -X- _ O
S -X- _ O
D -X- _ O
5 -X- _ O
1 -X- _ O
9 -X- _ O
o -X- _ O
4 -X- _ O
R -X- _ O
O -X- _ O
J -X- _ O
K -X- _ O
Q -X- _ O
5 -X- _ O
X -X- _ O
D -X- _ O
s -X- _ O
j -X- _ O
9 -X- _ O
f -X- _ O
d -X- _ O
G -X- _ O
h -X- _ O
m -X- _ O
K -X- _ O
V -X- _ O
R -X- _ O
z -X- _ O
O -X- _ O
T -X- _ O
M -X- _ O
d -X- _ O
I -X- _ O
9 -X- _ O
N -X- _ O
e -X- _ O
3 -X- _ O
l -X- _ O
4 -X- _ O
n -X- _ O
9 -X- _ O
e -X- _ O
K -X- _ O
9 -X- _ O
X -X- _ O
R -X- _ O
i -X- _ O
Z -X- _ O
9 -X- _ O
R -X- _ O
n -X- _ O
q -X- _ O
S -X- _ O
a -X- _ O
c -X- _ O
D -X- _ O
x -X- _ O
+ -X- _ O
K -X- _ O
E -X- _ O
q -X- _ O
Z -X- _ O
o -X- _ O
4 -X- _ O
W -X- _ O
T -X- _ O
V -X- _ O
+ -X- _ O
C -X- _ O
E -X- _ O
V -X- _ O
B -X- _ O
K -X- _ O
s -X- _ O
2 -X- _ O
c -X- _ O
A -X- _ O
Q -X- _ O
h -X- _ O
C -X- _ O
U -X- _ O
1 -X- _ O
W -X- _ O
R -X- _ O
3 -X- _ O
c -X- _ O
Q -X- _ O
x -X- _ O
J -X- _ O
h -X- _ O
b -X- _ O
Y -X- _ O
q -X- _ O
y -X- _ O
T -X- _ O
Q -X- _ O
n -X- _ O
e -X- _ O
9 -X- _ O
J -X- _ O
d -X- _ O
n -X- _ O
S -X- _ O
f -X- _ O
2 -X- _ O
w -X- _ O
7 -X- _ O
B -X- _ O
2 -X- _ O
V -X- _ O
3 -X- _ O
S -X- _ O
u -X- _ O
3 -X- _ O
V -X- _ O
D -X- _ O
m -X- _ O
H -X- _ O
M -X- _ O
Q -X- _ O
q -X- _ O
w -X- _ O
C -X- _ O
3 -X- _ O
t -X- _ O
w -X- _ O
A -X- _ O
B -X- _ O
4 -X- _ O
c -X- _ O
Q -X- _ O
w -X- _ O
U -X- _ O
u -X- _ O
o -X- _ O
Q -X- _ O
o -X- _ O
1 -X- _ O
w -X- _ O
C -X- _ O
D -X- _ O
h -X- _ O
A -X- _ O
Z -X- _ O
7 -X- _ O
g -X- _ O
2 -X- _ O
b -X- _ O
q -X- _ O
z -X- _ O
HTypically -X- _ O
, -X- _ O
for -X- _ O
downstream -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
a -X- _ O
linear -X- _ O
classifier -X- _ O
takes -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
sequences -X- _ O
or -X- _ O
tokens -X- _ O
produced -X- _ O
by -X- _ O
pretrained -X- _ O
models -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
predicts -X- _ O
the -X- _ O
correct -X- _ O
labels -X- _ O
. -X- _ O
The -X- _ O
practices -X- _ O
are -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
generative -X- _ O
pretraining -X- _ O
task -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
inconsistency -X- _ O
between -X- _ O
pretraining -X- _ O
and -X- _ O
finetuning -X- _ O
. -X- _ O

3 -X- _ O
r -X- _ O
+ -X- _ O
R -X- _ O
G -X- _ O
E -X- _ O
y -X- _ O
3 -X- _ O
g -X- _ O
K -X- _ O
C -X- _ O
U -X- _ O
a -X- _ O
U -X- _ O
f -X- _ O
2 -X- _ O
i -X- _ O
3 -X- _ O
S -X- _ O
j -X- _ O
J -X- _ O
Q -X- _ O
= -X- _ O
" -X- _ O
> -X- _ O
A -X- _ O
A -X- _ O
A -X- _ O
B -X- _ O
6 -X- _ O
H -X- _ O
i -X- _ O
c -X- _ O
b -X- _ O
V -X- _ O
D -X- _ O
J -X- _ O
S -X- _ O
g -X- _ O
N -X- _ O
B -X- _ O
E -X- _ O
K -X- _ O
2 -X- _ O
J -X- _ O
W -X- _ O
4 -X- _ O
x -X- _ O
b -X- _ O
1 -X- _ O
K -X- _ O
M -X- _ O
i -X- _ O
j -X- _ O
U -X- _ O
H -X- _ O
w -X- _ O
F -X- _ O
G -X- _ O
Y -X- _ O
q -X- _ O
M -X- _ O
e -X- _ O
g -X- _ O
F -X- _ O
4 -X- _ O
8 -X- _ O
J -X- _ O
m -X- _ O
A -X- _ O
W -X- _ O
S -X- _ O
I -X- _ O
f -X- _ O
R -X- _ O
0 -X- _ O
a -X- _ O
p -X- _ O
I -X- _ O
2 -X- _ O
P -X- _ O
Q -X- _ O
v -X- _ O
d -X- _ O
P -X- _ O
c -X- _ O
I -X- _ O
w -X- _ O
5 -X- _ O
O -X- _ O
j -X- _ O
J -X- _ O
i -X- _ O
w -X- _ O
d -X- _ O
F -X- _ O
v -X- _ O
P -X- _ O
o -X- _ O
V -X- _ O
+ -X- _ O
Q -X- _ O
5 -X- _ O
v -X- _ O
f -X- _ O
o -X- _ O
M -X- _ O
/ -X- _ O
Y -X- _ O
W -X- _ O
c -X- _ O
5 -X- _ O
a -X- _ O
P -X- _ O
R -X- _ O
B -X- _ O
w -X- _ O
e -X- _ O
O -X- _ O
9 -X- _ O
K -X- _ O
q -X- _ O
r -X- _ O
q -X- _ O
e -X- _ O
b -X- _ O
H -X- _ O
g -X- _ O
S -X- _ O
t -X- _ O
v -X- _ O
2 -X- _ O
p -X- _ O
5 -X- _ O
V -X- _ O
b -X- _ O
W -X- _ O
l -X- _ O
5 -X- _ O
Z -X- _ O
X -X- _ O
c -X- _ O
u -X- _ O
v -X- _ O
F -X- _ O
z -X- _ O
Y -X- _ O
2 -X- _ O
t -X- _ O
7 -X- _ O
Z -X- _ O
3 -X- _ O
i -X- _ O
r -X- _ O
t -X- _ O
7 -X- _ O
D -X- _ O
R -X- _ O
U -X- _ O
l -X- _ O
k -X- _ O
m -X- _ O
G -X- _ O
d -X- _ O
R -X- _ O
S -X- _ O
K -X- _ O
S -X- _ O
L -X- _ O
Y -X- _ O
8 -X- _ O
q -X- _ O
F -X- _ O
D -X- _ O
z -X- _ O
E -X- _ O
u -X- _ O
u -X- _ O
Z -X- _ O
a -X- _ O
Y -X- _ O
C -X- _ O
u -X- _ O
W -X- _ O
S -X- _ O
A -X- _ O
N -X- _ O
P -X- _ O
Y -X- _ O
N -X- _ O
M -X- _ O
b -X- _ O
X -X- _ O
k -X- _ O
/ -X- _ O
8 -X- _ O
5 -X- _ O
j -X- _ O
1 -X- _ O
K -X- _ O
x -X- _ O
a -X- _ O
P -X- _ O
w -X- _ O
V -X- _ O
q -X- _ O
c -X- _ O
x -X- _ O
u -X- _ O
g -X- _ O
H -X- _ O
t -X- _ O
h -X- _ O
9 -X- _ O
z -X- _ O
n -X- _ O
j -X- _ O
G -X- _ O
o -X- _ O
j -X- _ O
1 -X- _ O
d -X- _ O
J -X- _ O
u -X- _ O
s -X- _ O
W -X- _ O
S -X- _ O
X -X- _ O
7 -X- _ O
S -X- _ O
n -X- _ O
I -X- _ O
X -X- _ O
+ -X- _ O
L -X- _ O
M -X- _ O
S -X- _ O
a -X- _ O
l -X- _ O
y -X- _ O
O -X- _ O
K -X- _ O
5 -X- _ O
9 -X- _ O
P -X- _ O
R -X- _ O
y -X- _ O
N -X- _ O
q -X- _ O
9 -X- _ O
3 -X- _ O
i -X- _ O
R -X- _ O
6 -X- _ O
c -X- _ O
X -X- _ O
s -X- _ O
S -X- _ O
T -X- _ O
A -X- _ O
U -X- _ O
D -X- _ O
N -X- _ O
B -X- _ O
l -X- _ O
W -X- _ O
o -X- _ O
7 -X- _ O
d -X- _ O
q -X- _ O
z -X- _ O
d -X- _ O
j -X- _ O
E -X- _ O
r -X- _ O
N -X- _ O
m -X- _ O
c -X- _ O
B -X- _ O
R -X- _ O
o -X- _ O
Z -X- _ O
M -X- _ O
o -X- _ O
j -X- _ O
C -X- _ O
k -X- _ O
b -X- _ O
0 -X- _ O
j -X- _ O
6 -X- _ O
2 -X- _ O
D -X- _ O
Q -X- _ O
1 -X- _ O
p -X- _ O
g -X- _ O
M -X- _ O
r -X- _ O
N -X- _ O
p -X- _ O
o -X- _ O
e -X- _ O
O -X- _ O
y -X- _ O
I -X- _ O
l -X- _ O
R -X- _ O
e -X- _ O
s -X- _ O
S -X- _ O
P -X- _ O
p -X- _ O
K -X- _ O
l -X- _ O
Q -X- _ O
k -X- _ O
6 -X- _ O
n -X- _ O
6 -X- _ O
c -X- _ O
y -X- _ O
K -X- _ O
j -X- _ O
g -X- _ O
V -X- _ O
J -X- _ O
p -X- _ O
4 -X- _ O
J -X- _ O
n -X- _ O
O -X- _ O
g -X- _ O
O -X- _ O
q -X- _ O
B -X- _ O
W -X- _ O
v -X- _ O
Q -X- _ O
m -X- _ O
4 -X- _ O
n -X- _ O
9 -X- _ O
e -X- _ O
O -X- _ O
9 -X- _ O
H -X- _ O
+ -X- _ O
p -X- _ O
Z -X- _ O
v -X- _ O
x -X- _ O
M -X- _ O
E -X- _ O
4 -X- _ O
0 -X- _ O
h -X- _ O
m -X- _ O
y -X- _ O
2 -X- _ O
y -X- _ O
E -X- _ O
8 -X- _ O
E -X- _ O
0 -X- _ O
R -X- _ O
G -X- _ O
Z -X- _ O
f -X- _ O
E -X- _ O
1 -X- _ O
6 -X- _ O
X -X- _ O
C -X- _ O
L -X- _ O
T -X- _ O
I -X- _ O
j -X- _ O
W -X- _ O
E -X- _ O
M -X- _ O
s -X- _ O
n -X- _ O
N -X- _ O
r -X- _ O
Y -X- _ O
Q -X- _ O
N -X- _ O
q -X- _ O
K -X- _ O
R -X- _ O
M -X- _ O
m -X- _ O
2 -X- _ O
w -X- _ O
K -X- _ O
J -X- _ O
g -X- _ O
R -X- _ O
n -X- _ O
8 -X- _ O
e -X- _ O
W -X- _ O
/ -X- _ O
p -X- _ O
H -X- _ O
F -X- _ O
W -X- _ O
d -X- _ O
s -X- _ O
7 -X- _ O
L -X- _ O
d -X- _ O
s -X- _ O
2 -X- _ O
k -X- _ O
c -X- _ O
Q -X- _ O
U -X- _ O
z -X- _ O
5 -X- _ O
O -X- _ O
E -X- _ O
A -X- _ O
j -X- _ O
u -X- _ O
E -X- _ O
U -X- _ O
H -X- _ O
L -X- _ O
i -X- _ O
A -X- _ O
C -X- _ O
t -X- _ O
x -X- _ O
A -X- _ O
F -X- _ O
e -X- _ O
r -X- _ O
A -X- _ O
A -X- _ O
O -X- _ O
E -X- _ O
R -X- _ O
n -X- _ O
u -X- _ O
H -X- _ O
F -X- _ O
u -X- _ O
r -X- _ O
O -X- _ O
e -X- _ O
r -X- _ O
F -X- _ O
f -X- _ O
r -X- _ O
b -X- _ O
d -X- _ O
a -X- _ O
a -X- _ O
s -X- _ O
+ -X- _ O
Y -X- _ O
z -X- _ O
+ -X- _ O
/ -X- _ O
A -X- _ O
L -X- _ O
1 -X- _ O
v -X- _ O
s -X- _ O
3 -X- _ O
1 -X- _ O
m -X- _ O
K -X- _ O
Q -X- _ O
q -X- _ O
Q -X- _ O
= -X- _ O
= -X- _ O
< -X- _ O
/ -X- _ O
l -X- _ O
a -X- _ O
t -X- _ O
e -X- _ O
x -X- _ O
i -X- _ O
t -X- _ O
> -X- _ O
y -X- _ O
good -X- _ O
< -X- _ O
lA -X- _ O
A -X- _ O
A -X- _ O
B -X- _ O
6 -X- _ O
3 -X- _ O
i -X- _ O
c -X- _ O
b -X- _ O
V -X- _ O
B -X- _ O
N -X- _ O
S -X- _ O
w -X- _ O
M -X- _ O
x -X- _ O
E -X- _ O
J -X- _ O
2 -X- _ O
t -X- _ O
X -X- _ O
7 -X- _ O
V -X- _ O
+ -X- _ O
V -X- _ O
T -X- _ O
1 -X- _ O
6 -X- _ O
C -X- _ O
S -X- _ O
1 -X- _ O
C -X- _ O
R -X- _ O
S -X- _ O
i -X- _ O
7 -X- _ O
H -X- _ O
t -X- _ O
R -X- _ O
j -X- _ O
0 -X- _ O
Y -X- _ O
v -X- _ O
H -X- _ O
C -X- _ O
v -X- _ O
Y -X- _ O
D -X- _ O
2 -X- _ O
q -X- _ O
V -X- _ O
k -X- _ O
0 -X- _ O
7 -X- _ O
Q -X- _ O
N -X- _ O
T -X- _ O
b -X- _ O
J -X- _ O
L -X- _ O
k -X- _ O
i -X- _ O
0 -X- _ O
s -X- _ O
S -X- _ O
/ -X- _ O
+ -X- _ O
C -X- _ O
F -X- _ O
w -X- _ O
V -X- _ O
F -X- _ O
v -X- _ O
P -X- _ O
q -X- _ O
H -X- _ O
v -X- _ O
P -X- _ O
X -X- _ O
f -X- _ O
m -X- _ O
G -X- _ O
1 -X- _ O
7 -X- _ O
0 -X- _ O
N -X- _ O
Y -X- _ O
H -X- _ O
A -X- _ O
4 -X- _ O
/ -X- _ O
3 -X- _ O
Z -X- _ O
p -X- _ O
i -X- _ O
Z -X- _ O
F -X- _ O
0 -X- _ O
S -X- _ O
c -X- _ O
a -X- _ O
e -X- _ O
O -X- _ O
6 -X- _ O
M -X- _ O
y -X- _ O
e -X- _ O
3 -X- _ O
s -X- _ O
b -X- _ O
m -X- _ O
1 -X- _ O
v -X- _ O
Z -X- _ O
P -X- _ O
f -X- _ O
L -X- _ O
e -X- _ O
z -X- _ O
t -X- _ O
H -X- _ O
x -X- _ O
w -X- _ O
e -X- _ O
F -X- _ O
Y -X- _ O
9 -X- _ O
P -X- _ O
m -X- _ O
j -X- _ O
q -X- _ O
M -X- _ O
F -X- _ O
a -X- _ O
E -X- _ O
N -X- _ O
E -X- _ O
v -X- _ O
J -X- _ O
Q -X- _ O
t -X- _ O
Q -X- _ O
O -X- _ O
s -X- _ O
K -X- _ O
W -X- _ O
e -X- _ O
S -X- _ O
N -X- _ O
g -X- _ O
w -X- _ O
z -X- _ O
n -X- _ O
L -X- _ O
Y -X- _ O
j -X- _ O
R -X- _ O
b -X- _ O
E -X- _ O
I -X- _ O
O -X- _ O
G -X- _ O
0 -X- _ O
F -X- _ O
4 -X- _ O
/ -X- _ O
v -X- _ O
M -X- _ O
b -X- _ O
0 -X- _ O
2 -X- _ O
o -X- _ O
0 -X- _ O
i -X- _ O
y -X- _ O
U -X- _ O
T -X- _ O
y -X- _ O
a -X- _ O
J -X- _ O
q -X- _ O
C -X- _ O
/ -X- _ O
w -X- _ O
U -X- _ O
L -X- _ O
I -X- _ O
B -X- _ O
I -X- _ O
9 -X- _ O
h -X- _ O
k -X- _ O
0 -X- _ O
q -X- _ O
S -X- _ O
S -X- _ O
X -X- _ O
P -X- _ O
S -X- _ O
K -X- _ O
Z -X- _ O
b -X- _ O
f -X- _ O
q -X- _ O
z -X- _ O
o -X- _ O
H -X- _ O
W -X- _ O
i -X- _ O
b -X- _ O
c -X- _ O
k -X- _ O
5 -X- _ O
V -X- _ O
q -X- _ O
p -X- _ O
e -X- _ O
/ -X- _ O
k -X- _ O
6 -X- _ O
q -X- _ O
y -X- _ O
X -X- _ O
1 -X- _ O
X -X- _ O
v -X- _ O
G -X- _ O
7 -X- _ O
2 -X- _ O
w -X- _ O
9 -X- _ O
J -X- _ O
L -X- _ O
K -X- _ O
g -X- _ O
0 -X- _ O
h -X- _ O
G -X- _ O
O -X- _ O
t -X- _ O
O -X- _ O
5 -X- _ O
4 -X- _ O
b -X- _ O
G -X- _ O
T -X- _ O
/ -X- _ O
F -X- _ O
y -X- _ O
j -X- _ O
D -X- _ O
C -X- _ O
6 -X- _ O
b -X- _ O
T -X- _ O
Q -X- _ O
j -X- _ O
T -X- _ O
W -X- _ O
N -X- _ O
M -X- _ O
B -X- _ O
n -X- _ O
j -X- _ O
I -X- _ O
e -X- _ O
1 -X- _ O
Y -X- _ O
K -X- _ O
r -X- _ O
G -X- _ O
g -X- _ O
2 -X- _ O
k -X- _ O
/ -X- _ O
n -X- _ O
t -X- _ O
0 -X- _ O
7 -X- _ O
R -X- _ O
u -X- _ O
V -X- _ O
X -X- _ O
6 -X- _ O
a -X- _ O
B -X- _ O
A -X- _ O
q -X- _ O
W -X- _ O
9 -X- _ O
K -X- _ O
g -X- _ O
u -X- _ O
f -X- _ O
p -X- _ O
7 -X- _ O
I -X- _ O
s -X- _ O
V -X- _ O
C -X- _ O
6 -X- _ O
0 -X- _ O
Q -X- _ O
E -X- _ O
t -X- _ O
l -X- _ O
N -X- _ O
g -X- _ O
M -X- _ O
9 -X- _ O
K -X- _ O
r -X- _ O
X -X- _ O
i -X- _ O
b -X- _ O
+ -X- _ O
5 -X- _ O
3 -X- _ O
V -X- _ O
i -X- _ O
M -X- _ O
7 -X- _ O
j -X- _ O
1 -X- _ O
U -X- _ O
y -X- _ O
a -X- _ O
j -X- _ O
2 -X- _ O
F -X- _ O
B -X- _ O
J -X- _ O
F -X- _ O
o -X- _ O
s -X- _ O
G -X- _ O
M -X- _ O
U -X- _ O
c -X- _ O
m -X- _ O
R -X- _ O
N -X- _ O
n -X- _ O
j -X- _ O
q -X- _ O
M -X- _ O
8 -X- _ O
U -X- _ O
J -X- _ O
Y -X- _ O
Y -X- _ O
n -X- _ O
l -X- _ O
m -X- _ O
C -X- _ O
i -X- _ O
m -X- _ O
L -X- _ O
0 -X- _ O
V -X- _ O
k -X- _ O
R -X- _ O
F -X- _ O
W -X- _ O
m -X- _ O
B -X- _ O
g -X- _ O
b -X- _ O
T -X- _ O
8 -X- _ O
G -X- _ O
G -X- _ O
4 -X- _ O
K -X- _ O
2 -X- _ O
+ -X- _ O
v -X- _ O
E -X- _ O
6 -X- _ O
a -X- _ O
V -X- _ O
1 -X- _ O
X -X- _ O
v -X- _ O
u -X- _ O
u -X- _ O
o -X- _ O
+ -X- _ O
2 -X- _ O
j -X- _ O
T -X- _ O
u -X- _ O
Y -X- _ O
I -X- _ O
E -X- _ O
8 -X- _ O
n -X- _ O
E -X- _ O
E -X- _ O
J -X- _ O
K -X- _ O
u -X- _ O
D -X- _ O
B -X- _ O
D -X- _ O
d -X- _ O
T -X- _ O
g -X- _ O
A -X- _ O
e -X- _ O
r -X- _ O
Q -X- _ O
A -X- _ O
A -X- _ O
I -X- _ O
j -X- _ O
e -X- _ O
I -X- _ O
Y -X- _ O
3 -X- _ O
e -X- _ O
H -X- _ O
e -X- _ O
E -X- _ O
8 -X- _ O
+ -X- _ O
J -X- _ O
8 -X- _ O
O -X- _ O
J -X- _ O
+ -X- _ O
L -X- _ O
1 -X- _ O
p -X- _ O
y -X- _ O
z -X- _ O
n -X- _ O
D -X- _ O
m -X- _ O
F -X- _ O
P -X- _ O
3 -X- _ O
C -X- _ O
+ -X- _ O
f -X- _ O
g -X- _ O
C -X- _ O
i -X- _ O
o -X- _ O
5 -X- _ O
D -X- _ O
y -X- _ O
< -X- _ O
/ -X- _ O
l -X- _ O
a -X- _ O
t -X- _ O
e -X- _ O
x -X- _ O
i -X- _ O
t -X- _ O
> -X- _ O
v(y -X- _ O
) -X- _ O
GLM -X- _ B-MethodName
< -X- _ O
l -X- _ O
a -X- _ O
t -X- _ O
e -X- _ O
x -X- _ O
i -X- _ O
t -X- _ O
s -X- _ O
h -X- _ O
a -X- _ O
1 -X- _ O
_ -X- _ O
b -X- _ O
a -X- _ O
s -X- _ O
e -X- _ O
6 -X- _ O
4 -X- _ O
= -X- _ O
" -X- _ O
c -X- _ O
I -X- _ O
l -X- _ O
X -X- _ O
H -X- _ O
K -X- _ O
T -X- _ O
M -X- _ O
H -X- _ O
L -X- _ O
8 -X- _ O
y -X- _ O
9 -X- _ O
4 -X- _ O
G -X- _ O
I -X- _ O
+ -X- _ O
K -X- _ O
Z -X- _ O
X -X- _ O
n -X- _ O
l -X- _ O
T -X- _ O
1 -X- _ O
K -X- _ O
7 -X- _ O
g -X- _ O
= -X- _ O
" -X- _ O
> -X- _ O
A -X- _ O
A -X- _ O
A -X- _ O
B -X- _ O
7 -X- _ O
X -X- _ O
i -X- _ O
c -X- _ O
b -X- _ O
V -X- _ O
D -X- _ O
L -X- _ O
S -X- _ O
g -X- _ O
N -X- _ O
B -X- _ O
E -X- _ O
O -X- _ O
y -X- _ O
N -X- _ O
r -X- _ O
x -X- _ O
h -X- _ O
f -X- _ O
U -X- _ O
Y -X- _ O
9 -X- _ O
e -X- _ O
h -X- _ O
g -X- _ O
Q -X- _ O
h -X- _ O
I -X- _ O
o -X- _ O
R -X- _ O
d -X- _ O
D -X- _ O
+ -X- _ O
o -X- _ O
x -X- _ O
6 -X- _ O
M -X- _ O
V -X- _ O
j -X- _ O
B -X- _ O
P -X- _ O
O -X- _ O
A -X- _ O
Z -X- _ O
A -X- _ O
m -X- _ O
z -X- _ O
k -X- _ O
9 -X- _ O
l -X- _ O
k -X- _ O
z -X- _ O
O -X- _ O
z -X- _ O
M -X- _ O
M -X- _ O
j -X- _ O
M -X- _ O
r -X- _ O
L -X- _ O
j -X- _ O
H -X- _ O
/ -X- _ O
4 -X- _ O
E -X- _ O
E -X- _ O
P -X- _ O
i -X- _ O
n -X- _ O
j -X- _ O
1 -X- _ O
f -X- _ O
7 -X- _ O
z -X- _ O
l -X- _ O
b -X- _ O
5 -X- _ O
w -X- _ O
8 -X- _ O
D -X- _ O
p -X- _ O
p -X- _ O
Y -X- _ O
0 -X- _ O
F -X- _ O
B -X- _ O
U -X- _ O
d -X- _ O
d -X- _ O
P -X- _ O
d -X- _ O
F -X- _ O
c -X- _ O
S -X- _ O
c -X- _ O
a -X- _ O
e -X- _ O
O -X- _ O
6 -X- _ O
Y -X- _ O
y -X- _ O
e -X- _ O
z -X- _ O
s -X- _ O
r -X- _ O
q -X- _ O
2 -X- _ O
v -X- _ O
p -X- _ O
H -X- _ O
d -X- _ O
z -X- _ O
G -X- _ O
1 -X- _ O
t -X- _ O
7 -X- _ O
+ -X- _ O
z -X- _ O
u -X- _ O
5 -X- _ O
f -X- _ O
c -X- _ O
P -X- _ O
6 -X- _ O
l -X- _ O
o -X- _ O
m -X- _ O
i -X- _ O
t -X- _ O
A -X- _ O
a -X- _ O
k -X- _ O
V -X- _ O
y -X- _ O
q -X- _ O
Z -X- _ O
o -X- _ O
A -X- _ O
1 -X- _ O
5 -X- _ O
U -X- _ O
z -X- _ O
Q -X- _ O
m -X- _ O
m -X- _ O
G -X- _ O
G -X- _ O
0 -X- _ O
2 -X- _ O
a -X- _ O
s -X- _ O
K -X- _ O
I -X- _ O
4 -X- _ O
C -X- _ O
T -X- _ O
h -X- _ O
v -X- _ O
B -X- _ O
4 -X- _ O
H -X- _ O
r -X- _ O
i -X- _ O
N -X- _ O
x -X- _ O
6 -X- _ O
o -X- _ O
0 -X- _ O
k -X- _ O
y -X- _ O
K -X- _ O
O -X- _ O
5 -X- _ O
P -X- _ O
G -X- _ O
1 -X- _ O
I -X- _ O
9 -X- _ O
w -X- _ O
T -X- _ O
7 -X- _ O
C -X- _ O
Q -X- _ O
E -X- _ O
W -X- _ O
y -X- _ O
s -X- _ O
V -X- _ O
I -X- _ O
9 -X- _ O
L -X- _ O
6 -X- _ O
d -X- _ O
P -X- _ O
j -X- _ O
S -X- _ O
S -X- _ O
d -X- _ O
f -X- _ O
d -X- _ O
M -X- _ O
v -X- _ O
u -X- _ O
F -X- _ O
G -X- _ O
i -X- _ O
Z -X- _ O
e -X- _ O
H -X- _ O
N -X- _ O
S -X- _ O
r -X- _ O
B -X- _ O
T -X- _ O
a -X- _ O
p -X- _ O
y -X- _ O
/ -X- _ O
j -X- _ O
S -X- _ O
l -X- _ O
r -X- _ O
t -X- _ O
5 -X- _ O
L -X- _ O
/ -X- _ O
b -X- _ O
X -X- _ O
U -X- _ O
m -X- _ O
S -X- _ O
i -X- _ O
A -X- _ O
p -X- _ O
D -X- _ O
O -X- _ O
N -X- _ O
a -X- _ O
6 -X- _ O
5 -X- _ O
b -X- _ O
m -X- _ O
x -X- _ O
8 -X- _ O
Y -X- _ O
d -X- _ O
Y -X- _ O
G -X- _ O
U -X- _ O
Y -X- _ O
4 -X- _ O
H -X- _ O
e -X- _ O
X -X- _ O
a -X- _ O
i -X- _ O
a -X- _ O
Y -X- _ O
x -X- _ O
J -X- _ O
g -X- _ O
P -X- _ O
c -X- _ O
o -X- _ O
y -X- _ O
1 -X- _ O
L -X- _ O
B -X- _ O
Y -X- _ O
6 -X- _ O
o -X- _ O
9 -X- _ O
o -X- _ O
f -X- _ O
T -X- _ O
a -X- _ O
0 -X- _ O
f -X- _ O
o -X- _ O
2 -X- _ O
C -X- _ O
p -X- _ O
d -X- _ O
F -X- _ O
E -X- _ O
p -X- _ O
l -X- _ O
S -X- _ O
x -X- _ O
g -X- _ O
0 -X- _ O
V -X- _ O
X -X- _ O
9 -X- _ O
P -X- _ O
D -X- _ O
H -X- _ O
G -X- _ O
k -X- _ O
d -X- _ O
R -X- _ O
o -X- _ O
F -X- _ O
t -X- _ O
j -X- _ O
P -X- _ O
C -X- _ O
p -X- _ O
q -X- _ O
8 -X- _ O
X -X- _ O
v -X- _ O
Y -X- _ O
n -X- _ O
4 -X- _ O
n -X- _ O
9 -X- _ O
d -X- _ O
K -X- _ O
T -X- _ O
H -X- _ O
j -X- _ O
p -X- _ O
D -X- _ O
5 -X- _ O
m -X- _ O
I -X- _ O
E -X- _ O
0 -X- _ O
M -X- _ O
F -X- _ O
m -X- _ O
S -X- _ O
0 -X- _ O
K -X- _ O
E -X- _ O
4 -X- _ O
6 -X- _ O
M -X- _ O
R -X- _ O
J -X- _ O
P -X- _ O
X -X- _ O
U -X- _ O
Z -X- _ O
c -X- _ O
p -X- _ O
S -X- _ O
g -X- _ O
x -X- _ O
P -X- _ O
L -X- _ O
c -X- _ O
F -X- _ O
E -X- _ O
M -X- _ O
X -X- _ O
s -X- _ O
r -X- _ O
I -X- _ O
n -X- _ O
2 -X- _ O
s -X- _ O
M -X- _ O
D -X- _ O
E -X- _ O
2 -X- _ O
o -X- _ O
J -X- _ O
w -X- _ O
N -X- _ O
w -X- _ O
V -X- _ O
t -X- _ O
8 -X- _ O
e -X- _ O
Z -X- _ O
n -X- _ O
U -X- _ O
z -X- _ O
8 -X- _ O
r -X- _ O
e -X- _ O
e -X- _ O
d -X- _ O
m -X- _ O
9 -X- _ O
t -X- _ O
W -X- _ O
l -X- _ O
c -X- _ O
w -X- _ O
Q -X- _ O
x -X- _ O
Z -X- _ O
O -X- _ O
I -X- _ O
I -X- _ O
C -X- _ O
l -X- _ O
M -X- _ O
C -X- _ O
D -X- _ O
C -X- _ O
6 -X- _ O
j -X- _ O
A -X- _ O
D -X- _ O
V -X- _ O
S -X- _ O
h -X- _ O
B -X- _ O
g -X- _ O
T -X- _ O
u -X- _ O
4 -X- _ O
R -X- _ O
n -X- _ O
e -X- _ O
4 -X- _ O
N -X- _ O
2 -X- _ O
R -X- _ O
z -X- _ O
q -X- _ O
v -X- _ O
z -X- _ O
4 -X- _ O
X -X- _ O
z -X- _ O
O -X- _ O
W -X- _ O
j -X- _ O
P -X- _ O
O -X- _ O
f -X- _ O
O -X- _ O
Y -X- _ O
Q -X- _ O
/ -X- _ O
s -X- _ O
D -X- _ O
5 -X- _ O
+ -X- _ O
g -X- _ O
F -X- _ O
Y -X- _ O
z -X- _ O
5 -X- _ O
H -X- _ O
0 -X- _ O
< -X- _ O
/ -X- _ O
l -X- _ O
a -X- _ O
t -X- _ O
e -X- _ O
x -X- _ O
i -X- _ O
t -X- _ O
> -X- _ O
p(y|x -X- _ O
) -X- _ O
< -X- _ O
l -X- _ O
a -X- _ O
t -X- _ O
e -X- _ O
x -X- _ O
i -X- _ O
t -X- _ O
s -X- _ O
h -X- _ O
a -X- _ O
1 -X- _ O
_ -X- _ O
b -X- _ O
a -X- _ O
s -X- _ O
e -X- _ O
6 -X- _ O
4 -X- _ O
= -X- _ O
" -X- _ O
X -X- _ O
k -X- _ O
n -X- _ O
P -X- _ O
s -X- _ O
X -X- _ O
X -X- _ O
F -X- _ O
T -X- _ O
3 -X- _ O
s -X- _ O
4 -X- _ O
6 -X- _ O
5 -X- _ O
1 -X- _ O
7 -X- _ O
5 -X- _ O
q -X- _ O
1 -X- _ O
X -X- _ O
6 -X- _ O
2 -X- _ O
0 -X- _ O
8 -X- _ O
reconstructing -X- _ O
them -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
an -X- _ O
important -X- _ O
difference -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
other -X- _ O
models -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
XL -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
encodes -X- _ O
the -X- _ O
original -X- _ O
position -X- _ O
so -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
perceive -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
missing -X- _ O
tokens -X- _ O
, -X- _ O
and -X- _ O
SpanBERT -X- _ B-MethodName
( -X- _ O
Joshi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
replaces -X- _ O
the -X- _ O
span -X- _ O
with -X- _ O
multiple -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
tokens -X- _ O
and -X- _ O
keeps -X- _ O
the -X- _ O
length -X- _ O
unchanged -X- _ O
. -X- _ O
Our -X- _ O
design -X- _ O
fits -X- _ O
downstream -X- _ O
tasks -X- _ O
as -X- _ O
usually -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
text -X- _ O
is -X- _ O
unknown -X- _ O
beforehand -X- _ O
. -X- _ O

Our -X- _ O
encoding -X- _ O
method -X- _ O
ensures -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
not -X- _ O
aware -X- _ O
of -X- _ O
the -X- _ O
length -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
masked -X- _ I-HyperparameterName
span -X- _ I-HyperparameterName
when -X- _ O
Coronet -X- _ O
has -X- _ O
the -X- _ O
best -X- _ O
lines -X- _ O
of -X- _ O
all -X- _ O
day -X- _ O
cruisers -X- _ O
. -X- _ O
Positive -X- _ O
< -X- _ O
l -X- _ O
a -X- _ O
t -X- _ O
e -X- _ O
x -X- _ O
i -X- _ O
t -X- _ O
s -X- _ O
h -X- _ O
a -X- _ O
1 -X- _ O
_ -X- _ O
b -X- _ O
a -X- _ O
s -X- _ O
e -X- _ O
6 -X- _ O
4 -X- _ O
= -X- _ O
" -X- _ O
c -X- _ O
b -X- _ O
5 -X- _ O
S -X- _ O
9 -X- _ O

( -X- _ O
3 -X- _ O
) -X- _ O
we -X- _ O
replace -X- _ O
ReLU -X- _ B-HyperparameterValue
activation -X- _ B-HyperparameterName
functions -X- _ I-HyperparameterName
with -X- _ O
GeLUs -X- _ B-HyperparameterValue
( -X- _ O
Hendrycks -X- _ O
and -X- _ O
Gimpel -X- _ O
, -X- _ O
2016).One -X- _ O
of -X- _ O
the -X- _ O
challenges -X- _ O
of -X- _ O
the -X- _ O
autoregressive -X- _ O
blank -X- _ O
infilling -X- _ O
task -X- _ O
is -X- _ O
how -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
positional -X- _ O
information -X- _ O
. -X- _ O
Transformers -X- _ O
rely -X- _ O
on -X- _ O
positional -X- _ B-HyperparameterName
encodings -X- _ I-HyperparameterName
to -X- _ O
inject -X- _ O
the -X- _ O
absolute -X- _ O
and -X- _ O
relative -X- _ O
positions -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
2D -X- _ B-HyperparameterValue
positional -X- _ I-HyperparameterValue
encodings -X- _ I-HyperparameterValue
to -X- _ O
address -X- _ O
the -X- _ O
challenge -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
each -X- _ O
token -X- _ O
is -X- _ O
encoded -X- _ O
with -X- _ O
two -X- _ O
positional -X- _ O
ids -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
positional -X- _ O
i -X- _ O
d -X- _ O
represents -X- _ O
the -X- _ O
position -X- _ O
in -X- _ O
the -X- _ O
corrupted -X- _ O
text -X- _ O
x -X- _ O
corrupt -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
masked -X- _ O
spans -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
the -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
positional -X- _ O
i -X- _ O
d -X- _ O
represents -X- _ O
the -X- _ O
intra -X- _ O
- -X- _ O
span -X- _ O
position -X- _ O
. -X- _ O
For -X- _ O
tokens -X- _ O
in -X- _ O
Part -X- _ O
A -X- _ O
, -X- _ O
their -X- _ O
second -X- _ O
positional -X- _ O
ids -X- _ O
are -X- _ O
0 -X- _ O
. -X- _ O
For -X- _ O
tokens -X- _ O
in -X- _ O
Part -X- _ O
B -X- _ O
, -X- _ O
they -X- _ O
range -X- _ O
from -X- _ O
1 -X- _ O
to -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
span -X- _ O
. -X- _ O
The -X- _ O
two -X- _ O
positional -X- _ O
ids -X- _ O
are -X- _ O
projected -X- _ O
into -X- _ O
two -X- _ O
vectors -X- _ O
via -X- _ O
learnable -X- _ O
embedding -X- _ O
tables -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
both -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O

Both -X- _ O
new -X- _ O
objectives -X- _ O
are -X- _ O
defined -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
as -X- _ O
the -X- _ O
original -X- _ O
objective -X- _ O
, -X- _ O
i.e. -X- _ O
Eq -X- _ O
. -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
only -X- _ O
difference -X- _ O
is -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
spans -X- _ I-HyperparameterName
and -X- _ O
the -X- _ O
span -X- _ B-HyperparameterName
lengths -X- _ I-HyperparameterName
. -X- _ O
GLM -X- _ B-MethodName
uses -X- _ O
a -X- _ O
single -X- _ O
Transformer -X- _ B-HyperparameterName
with -X- _ O
several -X- _ O
modifications -X- _ O
to -X- _ O
the -X- _ O
architecture -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
we -X- _ O
rearrange -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
layer -X- _ O
normalization -X- _ O
and -X- _ O
the -X- _ O
residual -X- _ O
connection -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
critical -X- _ O
for -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
avoid -X- _ O
numerical -X- _ O
errors -X- _ O
( -X- _ O
Shoeybi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
single -X- _ O
linear -X- _ B-HyperparameterName
layer -X- _ I-HyperparameterName
for -X- _ O
the -X- _ O
output -X- _ O
token -X- _ O
prediction -X- _ O
; -X- _ O

• -X- _ O
Sentence -X- _ O
- -X- _ O
level -X- _ O
. -X- _ O
We -X- _ O
restrict -X- _ O
that -X- _ O
the -X- _ O
masked -X- _ O
spans -X- _ O
must -X- _ O
be -X- _ O
full -X- _ O
sentences -X- _ O
. -X- _ O
Multiple -X- _ B-HyperparameterName
spans -X- _ I-HyperparameterName
( -X- _ O
sentences -X- _ O
) -X- _ O
are -X- _ O
sampled -X- _ O
to -X- _ O
cover -X- _ O
15 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ I-HyperparameterValue
the -X- _ I-HyperparameterValue
original -X- _ I-HyperparameterValue
tokens -X- _ I-HyperparameterValue
. -X- _ O
This -X- _ O
objective -X- _ O
aims -X- _ O
for -X- _ O
seq2seq -X- _ O
tasks -X- _ O
whose -X- _ O
predictions -X- _ O
are -X- _ O
often -X- _ O
complete -X- _ O
sentences -X- _ O
or -X- _ O
paragraphs -X- _ O
. -X- _ O

• -X- _ O
Document -X- _ O
- -X- _ O
level -X- _ O
. -X- _ O
We -X- _ O
sample -X- _ O
a -X- _ O
single -X- _ O
span -X- _ O
whose -X- _ O
length -X- _ O
is -X- _ O
sampled -X- _ O
from -X- _ O
a -X- _ O
uniform -X- _ O
distribution -X- _ O
over -X- _ O
50%-100 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ I-HyperparameterValue
the -X- _ I-HyperparameterValue
original -X- _ I-HyperparameterValue
length -X- _ I-HyperparameterValue
. -X- _ O
The -X- _ O
objective -X- _ O
aims -X- _ O
for -X- _ O
long -X- _ O
text -X- _ O
generation -X- _ O
. -X- _ O

Position -X- _ O
1 -X- _ O
1 -X- _ O
2 -X- _ O
3 -X- _ O
4 -X- _ O
5 -X- _ O
5 -X- _ O
5 -X- _ O
5 -X- _ O
3 -X- _ O
3 -X- _ O
Position -X- _ O
2 -X- _ O
0 -X- _ O
0 -X- _ O
0 -X- _ O
0 -X- _ O
0 -X- _ O
1 -X- _ O
2 -X- _ O
3 -X- _ O
1 -X- _ O
2 -X- _ O
output -X- _ O
respectively -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
automatically -X- _ O
learns -X- _ O
a -X- _ O
bidirectional -X- _ O
encoder -X- _ O
( -X- _ O
for -X- _ O
Part -X- _ O
A -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
unidirectional -X- _ O
decoder -X- _ O
( -X- _ O
for -X- _ O
Part -X- _ O
B -X- _ O
) -X- _ O
in -X- _ O
a -X- _ O
unified -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
implementation -X- _ O
of -X- _ O
GLM -X- _ B-MethodName
is -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
randomly -X- _ O
sample -X- _ O
spans -X- _ O
of -X- _ O
length -X- _ O
drawn -X- _ O
from -X- _ O
a -X- _ O
Poisson -X- _ O
distribution -X- _ O
with -X- _ O
λ -X- _ B-HyperparameterName
= -X- _ O
3 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
repeatedly -X- _ O
sample -X- _ O
new -X- _ O
spans -X- _ O
until -X- _ O
at -X- _ O
least -X- _ O
15 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
original -X- _ B-HyperparameterName
tokens -X- _ I-HyperparameterName
are -X- _ I-HyperparameterName
masked -X- _ I-HyperparameterName
. -X- _ O
Empirically -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
15 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
ratio -X- _ O
is -X- _ O
critical -X- _ O
for -X- _ O
good -X- _ O
performance -X- _ O
on -X- _ O
downstream -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
previous -X- _ O
section -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
masks -X- _ O
short -X- _ O
spans -X- _ O
and -X- _ O
is -X- _ O
suited -X- _ O
for -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
interested -X- _ O
in -X- _ O
pretraining -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
that -X- _ O
can -X- _ O
handle -X- _ O
both -X- _ O
NLU -X- _ B-TaskName
and -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O
We -X- _ O
then -X- _ O
study -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
pretraining -X- _ O
setup -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
a -X- _ O
second -X- _ O
objective -X- _ O
of -X- _ O
generating -X- _ O
longer -X- _ O
text -X- _ O
is -X- _ O
jointly -X- _ O
optimized -X- _ O
with -X- _ O
the -X- _ O
blank -X- _ O
infilling -X- _ O
objective -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
the -X- _ O
following -X- _ O
two -X- _ O
objectives -X- _ O
: -X- _ O

We -X- _ O
implement -X- _ O
the -X- _ O
autoregressive -X- _ O
blank -X- _ O
infilling -X- _ O
objective -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
techniques -X- _ O
. -X- _ O
The -X- _ O
input -X- _ O
x -X- _ O
is -X- _ O
divided -X- _ O
into -X- _ O
two -X- _ O
parts -X- _ O
: -X- _ O
Part -X- _ O
A -X- _ O
is -X- _ O
the -X- _ O
corrupted -X- _ O
text -X- _ O
x -X- _ O
corrupt -X- _ O
, -X- _ O
and -X- _ O
Part -X- _ O
B -X- _ O
consists -X- _ O
of -X- _ O
the -X- _ O
masked -X- _ O
spans -X- _ O
. -X- _ O
Part -X- _ O
A -X- _ O
tokens -X- _ O
can -X- _ O
attend -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
, -X- _ O
but -X- _ O
can -X- _ O
not -X- _ O
attend -X- _ O
to -X- _ O
any -X- _ O
tokens -X- _ O
in -X- _ O
B. -X- _ O
Part -X- _ O
B -X- _ O
tokens -X- _ O
can -X- _ O
attend -X- _ O
to -X- _ O
Part -X- _ O
A -X- _ O
and -X- _ O
antecedents -X- _ O
in -X- _ O
B -X- _ O
, -X- _ O
but -X- _ O
can -X- _ O
not -X- _ O
attend -X- _ O
to -X- _ O
any -X- _ O
subsequent -X- _ O
tokens -X- _ O
in -X- _ O
B. -X- _ O
To -X- _ O
enable -X- _ O
autoregressive -X- _ O
generation -X- _ O
, -X- _ O
each -X- _ O
span -X- _ O
is -X- _ O
padded -X- _ O
with -X- _ O
special -X- _ O
tokens -X- _ O
[ -X- _ O
START -X- _ O
] -X- _ O
and -X- _ O
[ -X- _ O
END -X- _ O
] -X- _ O
, -X- _ O
for -X- _ O
input -X- _ O
and -X- _ O
Token -X- _ O

p -X- _ O
θ -X- _ O
( -X- _ O
s -X- _ O
i -X- _ O
|x -X- _ O
corrupt -X- _ O
, -X- _ O
s -X- _ O
z -X- _ O
< -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
l -X- _ O
i -X- _ O
j=1 -X- _ O
p(s -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
|x -X- _ O
corrupt -X- _ O
, -X- _ O
s -X- _ O
z -X- _ O
< -X- _ O
i -X- _ O
, -X- _ O
s -X- _ O
i,<j -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O

We -X- _ O
always -X- _ O
generate -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
each -X- _ O
blank -X- _ O
following -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
order -X- _ O
, -X- _ O
i.e. -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
generating -X- _ O
the -X- _ O
span -X- _ O
s -X- _ O
i -X- _ O
is -X- _ O
factorized -X- _ O
as -X- _ O
: -X- _ O

max -X- _ O
θ -X- _ O
E -X- _ O
z∼Zm -X- _ O
m -X- _ O
i=1 -X- _ O
log -X- _ O
p -X- _ O
θ -X- _ O
( -X- _ O
s -X- _ O
z -X- _ O
i -X- _ O
|x -X- _ O
corrupt -X- _ O
, -X- _ O
s -X- _ O
z -X- _ O
< -X- _ O
i -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O

Each -X- _ O
span -X- _ O
is -X- _ O
replaced -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
, -X- _ O
forming -X- _ O
a -X- _ O
corrupted -X- _ O
text -X- _ O
x -X- _ O
corrupt -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
predicts -X- _ O
the -X- _ O
missing -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
spans -X- _ O
from -X- _ O
the -X- _ O
corrupted -X- _ O
text -X- _ O
in -X- _ O
an -X- _ O
autoregressive -X- _ O
manner -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
when -X- _ O
predicting -X- _ O
the -X- _ O
missing -X- _ O
tokens -X- _ O
in -X- _ O
a -X- _ O
span -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
corrupted -X- _ O
text -X- _ O
and -X- _ O
the -X- _ O
previously -X- _ O
predicted -X- _ O
spans -X- _ O
. -X- _ O
To -X- _ O
fully -X- _ O
capture -X- _ O
the -X- _ O
interdependencies -X- _ O
between -X- _ O
different -X- _ O
spans -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
permute -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
the -X- _ O
spans -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
permutation -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
let -X- _ O
Z -X- _ O
m -X- _ O
be -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
all -X- _ O
possible -X- _ O
permutations -X- _ O
of -X- _ O
the -X- _ O
length -X- _ O
- -X- _ O
m -X- _ O
index -X- _ O
sequence -X- _ O
[ -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
m -X- _ O
] -X- _ O
, -X- _ O
and -X- _ O
s -X- _ O
z -X- _ O
< -X- _ O
i -X- _ O
be -X- _ O
[ -X- _ O
s -X- _ O
z -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
s -X- _ O
z -X- _ O
i−1 -X- _ O
] -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
the -X- _ O
pretraining -X- _ O
objective -X- _ O
as -X- _ O

x -X- _ O
= -X- _ O
[ -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
x -X- _ O
n -X- _ O
] -X- _ O
, -X- _ O
multiple -X- _ O
text -X- _ O
spans -X- _ O
{ -X- _ O
s -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
s -X- _ O
m -X- _ O
} -X- _ O
are -X- _ O
sampled -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
span -X- _ O
s -X- _ O
i -X- _ O
corresponds -X- _ O
to -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
consecutive -X- _ O
tokens -X- _ O
[ -X- _ O
s -X- _ O
i,1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
s -X- _ O
i -X- _ O
, -X- _ O
l -X- _ O
i -X- _ O
] -X- _ O
in -X- _ O
x. -X- _ O

Furthermore -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
by -X- _ O
varying -X- _ O
the -X- _ B-HyperparameterName
number -X- _ I-HyperparameterName
and -X- _ I-HyperparameterName
lengths -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
missing -X- _ I-HyperparameterName
spans -X- _ I-HyperparameterName
, -X- _ O
the -X- _ O
autoregressive -X- _ O
blank -X- _ O
filling -X- _ O
objective -X- _ O
can -X- _ O
pretrain -X- _ O
language -X- _ O
models -X- _ O
for -X- _ O
conditional -X- _ B-TaskName
and -X- _ I-TaskName
unconditional -X- _ I-TaskName
generation -X- _ I-TaskName
. -X- _ O
Through -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
of -X- _ O
different -X- _ O
pretraining -X- _ O
objectives -X- _ O
, -X- _ O
a -X- _ O
single -X- _ O
GLM -X- _ B-MethodName
can -X- _ O
excel -X- _ O
in -X- _ O
both -X- _ O
NLU -X- _ B-TaskName
and -X- _ O
( -X- _ O
conditional -X- _ O
and -X- _ O
unconditional -X- _ O
) -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O
Empirically -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
standalone -X- _ O
baselines -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
with -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
pretraining -X- _ O
achieves -X- _ O
improvements -X- _ O
in -X- _ O
NLU -X- _ B-TaskName
, -X- _ O
conditional -X- _ B-TaskName
text -X- _ I-TaskName
generation -X- _ I-TaskName
, -X- _ O
and -X- _ O
language -X- _ B-TaskName
modeling -X- _ I-TaskName
tasks -X- _ O
altogether -X- _ O
by -X- _ O
sharing -X- _ O
the -X- _ O
parameters -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
general -X- _ O
pretraining -X- _ O
framework -X- _ O
GLM -X- _ B-MethodName
based -X- _ O
on -X- _ O
a -X- _ O
novel -X- _ O
autoregressive -X- _ O
blank -X- _ O
infilling -X- _ O
objective -X- _ O
. -X- _ O
GLM -X- _ B-MethodName
formulates -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
as -X- _ O
cloze -X- _ B-TaskName
questions -X- _ I-TaskName
that -X- _ I-TaskName
contain -X- _ I-TaskName
task -X- _ I-TaskName
descriptions -X- _ I-TaskName
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
answered -X- _ O
by -X- _ O
autoregressive -X- _ O
generation -X- _ O
. -X- _ O
GLM -X- _ B-MethodName
is -X- _ O
trained -X- _ O
by -X- _ O
optimizing -X- _ O
an -X- _ O
autoregressive -X- _ O
blank -X- _ O
infilling -X- _ O
objective -X- _ O
. -X- _ O
Given -X- _ O
an -X- _ O
input -X- _ O
text -X- _ O

Inspired -X- _ O
by -X- _ O
Pattern -X- _ O
- -X- _ O
Exploiting -X- _ O
Training -X- _ O
( -X- _ O
PET -X- _ O
) -X- _ O
( -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
reformulate -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
as -X- _ O
manually -X- _ B-TaskName
- -X- _ I-TaskName
crafted -X- _ I-TaskName
cloze -X- _ I-TaskName
questions -X- _ I-TaskName
that -X- _ O
mimic -X- _ O
human -X- _ O
language -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
the -X- _ O
BERTbased -X- _ O
models -X- _ O
used -X- _ O
by -X- _ O
PET -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
can -X- _ O
naturally -X- _ O
handle -X- _ O
multi -X- _ O
- -X- _ O
token -X- _ O
answers -X- _ O
to -X- _ O
the -X- _ O
cloze -X- _ O
question -X- _ O
via -X- _ O
autoregressive -X- _ O
blank -X- _ O
filling -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
pretraining -X- _ O
framework -X- _ O
named -X- _ O
GLM -X- _ B-MethodName
( -X- _ O
General -X- _ B-MethodName
Language -X- _ I-MethodName
Model -X- _ I-MethodName
) -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
autoregressive -X- _ O
blank -X- _ O
infilling -X- _ O
. -X- _ O
We -X- _ O
randomly -X- _ O
blank -X- _ O
out -X- _ O
continuous -X- _ O
spans -X- _ O
of -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
, -X- _ O
following -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
autoencoding -X- _ O
, -X- _ O
and -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
sequentially -X- _ O
reconstruct -X- _ O
the -X- _ O
spans -X- _ O
, -X- _ O
following -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
autoregressive -X- _ O
pretraining -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
blanking -X- _ O
filling -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
in -X- _ O
T5 -X- _ B-MethodName
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
pretraining -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
two -X- _ O
improvements -X- _ O
, -X- _ O
namely -X- _ O
span -X- _ O
shuffling -X- _ O
and -X- _ O
2D -X- _ O
positional -X- _ O
encoding -X- _ O
. -X- _ O
Empirically -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
parameters -X- _ O
and -X- _ O
computational -X- _ O
cost -X- _ O
, -X- _ O
GLM -X- _ B-MethodName
significantly -X- _ O
outperforms -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
SuperGLUE -X- _ B-DatasetName
benchmark -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
of -X- _ O
4.6 -X- _ O
% -X- _ O
-5.0 -X- _ O
% -X- _ O
and -X- _ O
outperforms -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
BART -X- _ B-MethodName
when -X- _ O
pretrained -X- _ O
on -X- _ O
a -X- _ O
corpus -X- _ O
of -X- _ O
similar -X- _ O
size -X- _ O
( -X- _ O
158 -X- _ O
GB -X- _ O
) -X- _ O
. -X- _ O
GLM -X- _ B-MethodName
also -X- _ O
significantly -X- _ O
outperforms -X- _ O
T5 -X- _ B-MethodName
on -X- _ O
NLU -X- _ B-TaskName
and -X- _ O
generation -X- _ B-TaskName
tasks -X- _ O
with -X- _ O
fewer -X- _ O
parameters -X- _ O
and -X- _ O
data -X- _ O
. -X- _ O

None -X- _ O
of -X- _ O
these -X- _ O
pretraining -X- _ O
frameworks -X- _ O
is -X- _ O
flexible -X- _ O
enough -X- _ O
to -X- _ O
perform -X- _ O
competitively -X- _ O
across -X- _ O
all -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
Previous -X- _ O
works -X- _ O
have -X- _ O
tried -X- _ O
to -X- _ O
unify -X- _ O
different -X- _ O
frameworks -X- _ O
by -X- _ O
combining -X- _ O
their -X- _ O
objectives -X- _ O
via -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
( -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Bao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
autoencoding -X- _ O
and -X- _ O
autoregressive -X- _ O
objectives -X- _ O
differ -X- _ O
by -X- _ O
nature -X- _ O
, -X- _ O
a -X- _ O
simple -X- _ O
unification -X- _ O
can -X- _ O
not -X- _ O
fully -X- _ O
inherit -X- _ O
the -X- _ O
advantages -X- _ O
of -X- _ O
both -X- _ O
frameworks -X- _ O
. -X- _ O

† -X- _ O
Corresponding -X- _ O
authors -X- _ O
. -X- _ O
1 -X- _ O
The -X- _ O
code -X- _ O
and -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
//github.com -X- _ O
/ -X- _ O
THUDM -X- _ O
/ -X- _ O
GLM -X- _ O
In -X- _ O
general -X- _ O
, -X- _ O
existing -X- _ O
pretraining -X- _ O
frameworks -X- _ O
can -X- _ O
be -X- _ O
categorized -X- _ O
into -X- _ O
three -X- _ O
families -X- _ O
: -X- _ O
autoregressive -X- _ O
, -X- _ O
autoencoding -X- _ O
, -X- _ O
and -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
models -X- _ O
. -X- _ O
Autoregressive -X- _ O
models -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
GPT -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
, -X- _ O
learn -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
While -X- _ O
they -X- _ O
succeed -X- _ O
in -X- _ O
long -X- _ B-TaskName
- -X- _ I-TaskName
text -X- _ I-TaskName
generation -X- _ I-TaskName
and -X- _ O
show -X- _ O
fewshot -X- _ O
learning -X- _ O
ability -X- _ O
when -X- _ O
scaled -X- _ O
to -X- _ O
billions -X- _ O
of -X- _ O
parameters -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b;Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
inherent -X- _ O
disadvantage -X- _ O
is -X- _ O
the -X- _ O
unidirectional -X- _ O
attention -X- _ O
mechanism -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
not -X- _ O
fully -X- _ O
capture -X- _ O
the -X- _ O
dependencies -X- _ O
between -X- _ O
the -X- _ O
context -X- _ O
words -X- _ O
in -X- _ O
NLU -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
Autoencoding -X- _ O
models -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
learn -X- _ O
bidirectional -X- _ O
context -X- _ O
encoders -X- _ O
via -X- _ O
denoising -X- _ O
objectives -X- _ O
, -X- _ O
e.g. -X- _ O
Masked -X- _ O
Language -X- _ O
Model -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
encoders -X- _ O
produce -X- _ O
contextualized -X- _ O
representations -X- _ O
that -X- _ O
suit -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
tasks -X- _ O
, -X- _ O
but -X- _ O
could -X- _ O
not -X- _ O
be -X- _ O
directly -X- _ O
applied -X- _ O
for -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O
Encoder -X- _ O
- -X- _ O
decoder -X- _ O
models -X- _ O
adopt -X- _ O
bidirectional -X- _ O
attention -X- _ O
for -X- _ O
the -X- _ O
encoder -X- _ O
, -X- _ O
unidirectional -X- _ O
attention -X- _ O
for -X- _ O
the -X- _ O
decoder -X- _ O
, -X- _ O
and -X- _ O
cross -X- _ O
attention -X- _ O
between -X- _ O
them -X- _ O
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Bi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
. -X- _ O
They -X- _ O
are -X- _ O
typically -X- _ O
deployed -X- _ O
in -X- _ O
conditional -X- _ O
generation -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
text -X- _ B-TaskName
summarization -X- _ I-TaskName
and -X- _ O
response -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O
2 -X- _ O
. -X- _ O
T5 -X- _ B-MethodName
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
unifies -X- _ O
NLU -X- _ B-TaskName
and -X- _ O
conditional -X- _ B-TaskName
generation -X- _ I-TaskName
via -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
models -X- _ O
but -X- _ O
requires -X- _ O
more -X- _ O
parameters -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
BRET -X- _ B-MethodName
- -X- _ O
based -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
DeBERTa -X- _ B-MethodName
( -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Language -X- _ O
models -X- _ O
pretrained -X- _ O
on -X- _ O
unlabeled -X- _ O
texts -X- _ O
have -X- _ O
substantially -X- _ O
advanced -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
in -X- _ O
various -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
ranging -X- _ O
from -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
( -X- _ B-TaskName
NLU -X- _ I-TaskName
) -X- _ O
to -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a;Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b;Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Downstream -X- _ O
task -X- _ O
performance -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
scale -X- _ O
of -X- _ O
the -X- _ O
parameters -X- _ O
have -X- _ O
also -X- _ O
constantly -X- _ O
increased -X- _ O
in -X- _ O
the -X- _ O
past -X- _ O
few -X- _ O
years -X- _ O
. -X- _ O
* -X- _ O
The -X- _ O
first -X- _ O
two -X- _ O
authors -X- _ O
contributed -X- _ O
equally -X- _ O
. -X- _ O

